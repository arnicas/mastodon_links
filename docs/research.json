[
  {
    "link": "https://doi.org/10.1162/qss_e_00061",
    "title": "https://doi.org/10.1162/qss_e_00061",
    "latest": "2023-03-14T21:28:45+00:00",
    "last_post": {
      "url": "https://scicomm.xyz/@QSS_ISSI/110023460867433219",
      "content": "<p>Sad news - Our former editorial board member Loet Leydesdorff passed away.</p><p>Loet was a passionate scholar, great colleague, and strong supporter of our journal.</p><p>He played a crucial role in connecting different science studies communities. To remember him, read our special issue 'Bridging the divide between qualitative and quantitative science studies', of which Loet was guest editor <a href=\"https://doi.org/10.1162/qss_e_00061\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1162/qss_e_00061</span><span class=\"invisible\"></span></a>.</p><p>Thank you Loet for everything you have done for our community.</p><p><span class=\"h-card\"><a href=\"https://social.cwts.nl/@LudoWaltman\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>LudoWaltman</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.social/@lariviev\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>lariviev</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@MikeMugabushaka",
        "display_name": "MikeMugabushaka"
      }
    ]
  },
  {
    "link": "https://link.springer.com/journal/10991/volumes-and-issues/44-1?utm_source=toc&amp;utm_medium=email&amp;utm_campaign=toc_10991_44_1&amp;utm_content=etoc_springer_20230313\u2026",
    "title": "Liverpool Law Review | Volume 44, issue 1",
    "latest": "2023-03-14T21:18:31+00:00",
    "last_post": {
      "url": "https://mas.to/@jamesahand/110023553594672961",
      "content": "<p>Vol 44 iss 1 (April) of the Liverpool Law Review was published yesterday<br><a href=\"https://link.springer.com/journal/10991/volumes-and-issues/44-1?utm_source=toc&amp;utm_medium=email&amp;utm_campaign=toc_10991_44_1&amp;utm_content=etoc_springer_20230313\u2026\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/journal/1099</span><span class=\"invisible\">1/volumes-and-issues/44-1?utm_source=toc&amp;utm_medium=email&amp;utm_campaign=toc_10991_44_1&amp;utm_content=etoc_springer_20230313\u2026</span></a> and includes UoPLaw\u2019s Joanne Atkinson\u2019s A Behavioural Analysis of the Future of Collective Redress for Financial Consumers Following the [UKSC] in Merricks v Mastercard. <a href=\"https://doi.org/10.1007/s10991-022-09320-8\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1007/s10991-022-093</span><span class=\"invisible\">20-8</span></a></p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1007/s10991-022-09320-8",
    "title": "doi.org/10.1007/s10991-022-093...",
    "latest": "2023-03-14T21:18:31+00:00",
    "last_post": {
      "url": "https://mas.to/@jamesahand/110023553594672961",
      "content": "<p>Vol 44 iss 1 (April) of the Liverpool Law Review was published yesterday<br><a href=\"https://link.springer.com/journal/10991/volumes-and-issues/44-1?utm_source=toc&amp;utm_medium=email&amp;utm_campaign=toc_10991_44_1&amp;utm_content=etoc_springer_20230313\u2026\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/journal/1099</span><span class=\"invisible\">1/volumes-and-issues/44-1?utm_source=toc&amp;utm_medium=email&amp;utm_campaign=toc_10991_44_1&amp;utm_content=etoc_springer_20230313\u2026</span></a> and includes UoPLaw\u2019s Joanne Atkinson\u2019s A Behavioural Analysis of the Future of Collective Redress for Financial Consumers Following the [UKSC] in Merricks v Mastercard. <a href=\"https://doi.org/10.1007/s10991-022-09320-8\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1007/s10991-022-093</span><span class=\"invisible\">20-8</span></a></p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.06537",
    "title": "https://arxiv.org/abs/2303.06537",
    "latest": "2023-03-14T21:08:24+00:00",
    "last_post": {
      "url": "https://vis.social/@elm/110023678655578151",
      "content": "<p>While Pat is powerful, it is still only a design tool and not intended for academic or scientific testing. In other words, this is not a true virtual human visual system, even if we have our eye on such work in the future. For now, we look forward to hearing your thoughts about the work at <a href=\"https://vis.social/tags/chi2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>chi2023</span></a> or here! /end</p><p>PDF: <a href=\"https://users.umiacs.umd.edu/~elm/projects/perceptual-pat/perceptual-pat.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">users.umiacs.umd.edu/~elm/proj</span><span class=\"invisible\">ects/perceptual-pat/perceptual-pat.pdf</span></a> <br>arXiv: <a href=\"https://arxiv.org/abs/2303.06537\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.06537</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://vis.social/@elm",
        "display_name": "Niklas Elmqvist"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/pdf/10.1145/3545945.3569855",
    "title": "dl.acm.org/doi/pdf/10.1145/354...",
    "latest": "2023-03-14T20:20:30+00:00",
    "last_post": {
      "url": "https://dair-community.social/@RuthStarkman/110022590706586373",
      "content": "<p>\ud83d\udd25\ud83d\udd25<a href=\"https://dair-community.social/tags/sigcse2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>sigcse2023</span></a> paper from <br><span class=\"h-card\"><a href=\"https://hci.social/@cfiesler\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cfiesler</span></a></span>  et al.  <a href=\"https://dl.acm.org/doi/pdf/10.1145/3545945.3569855\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/pdf/10.1145/354</span><span class=\"invisible\">5945.3569855</span></a>  CS ethics educators benefit from \"providing additional resources for educators to re-use material or make their own material from scratch; collaboration with others; and community or institutional support.\"\ud83e\udd29\ud83e\udd29</p>"
    },
    "people": [
      {
        "url": "https://hci.social/@cfiesler",
        "display_name": "Dr. Casey Fiesler"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/09685332231154562",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-03-14T20:19:40+00:00",
    "last_post": {
      "url": "https://someone.elses.computer/@israblack/110021847683241182",
      "content": "<p>RT @ECRomanis<br>My case commentary on the US SC decision Dobbs v Jackson is out in @MedLawInt \ud83e\udd13 \"Dobbs further solidifies that the United States is firmly \u2018out of step\u2019 with global norms and trends in abortion\" <a href=\"https://journals.sagepub.com/doi/10.1177/09685332231154562\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/09685332231154562</span></a><br>@PetrieFlom @HarvardEthics @DurhamLawSchool @DurhamCELLS</p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05040",
    "title": "https://doi.org/10.21105/joss.05040",
    "latest": "2023-03-14T19:50:53+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110023373834630338",
      "content": "<p>Just published in JOSS: 'Atramhasis: An online SKOS vocabulary editor' <a href=\"https://doi.org/10.21105/joss.05040\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05040</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05891v1",
    "title": "https://arxiv.org/abs/2303.05891v1",
    "latest": "2023-03-14T19:44:17+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110023347894100771",
      "content": "<p>\ud83d\udcdd Creation and Evaluation of Timelines for Longitudinal User Posts \ud83d\udcda</p><p>\"Proposes a set of novel methods to segment longitudinal user posts into timelines which are likely to contain interesting moments of change in their posting behaviour and show the applicability of the proposed methods on two different Twitter datasets.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Maria-Liakata-NLP-Group/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/Maria-Liakata-NLP-G</span><span class=\"invisible\">roup/</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05891v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05891v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21428/a1847950.acdc99d6",
    "title": "doi.org/10.21428/a1847950.acdc...",
    "latest": "2023-03-14T18:04:22+00:00",
    "last_post": {
      "url": "https://social.cwts.nl/@LudoWaltman/110009780421914267",
      "content": "<p>VOSviewer: putting research into context <a href=\"https://doi.org/10.21428/a1847950.acdc99d6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.21428/a1847950.acdc</span><span class=\"invisible\">99d6</span></a></p><p>\"VOSviewer is an application to provide overviews of scientific landscapes by clustering related publications. It can help you find more accurate keywords for searching, collaboration partners, seminal papers and knowledge gaps.\"</p><p>Many thanks to the colleagues at <span class=\"h-card\"><a href=\"https://akademienl.social/@ubleiden\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ubleiden</span></a></span> for preparing this VOSviewer introduction.</p><p><a href=\"https://www.vosviewer.com\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"\">vosviewer.com</span><span class=\"invisible\"></span></a></p><p><span class=\"h-card\"><a href=\"https://social.cwts.nl/@neesjanvaneck\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>neesjanvaneck</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://social.cwts.nl/@vtraag",
        "display_name": "Vincent Traag"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1007/s11192-023-04673-x",
    "title": "doi.org/10.1007/s11192-023-046...",
    "latest": "2023-03-14T18:04:18+00:00",
    "last_post": {
      "url": "https://social.cwts.nl/@LudoWaltman/110022898471892827",
      "content": "<p>\"Trendy journals generate reputational advantages. If they are influencing right now, they are likely to continue to do so in the future because they are gaining, recovering, or maintaining their notoriety ... it is possible to predict entry of some trendy journals, which are not on core journal list or not even on JCR list, into these lists; this may be true of journals such as <span class=\"h-card\"><a href=\"https://scicomm.xyz/@QSS_ISSI\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>QSS_ISSI</span></a></span>, especially if it maintains its capacity for influence in the coming years.\"</p><p><a href=\"https://doi.org/10.1007/s11192-023-04673-x\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1007/s11192-023-046</span><span class=\"invisible\">73-x</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.cwts.nl/@vtraag",
        "display_name": "Vincent Traag"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.01768",
    "title": "The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation",
    "latest": "2023-03-14T18:01:06+00:00",
    "last_post": {
      "url": "https://mastodon.uy/@ted_barkov/110022902609822867",
      "content": "<p><span class=\"h-card\"><a href=\"https://mastodon.uy/@santiago\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>santiago</span></a></span> \u00bfQuiz\u00e1s al menos introducir\u00e1 una renta b\u00e1sica universal? </p><p><a href=\"https://arxiv.org/abs/2301.01768\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.01768</span><span class=\"invisible\"></span></a></p><p>La inteligencia artificial conversacional (IA) altera la forma en que los humanos interact\u00faan con la tecnolog\u00eda. Recientemente, OpenAI present\u00f3 ChatGPT, un modelo de di\u00e1logo de \u00faltima generaci\u00f3n que puede conversar con sus hom\u00f3logos humanos con capacidades sin precedentes. ChatGPT ha sido testigo de una gran atenci\u00f3n de los medios, la academia, la industria y el p\u00fablico en general, atrayendo a m\u00e1s de un mill\u00f3n de usuarios a los pocos d\u00edas de su lanzamiento. Sin embargo, su adopci\u00f3n explosiva para la b\u00fasqueda de informaci\u00f3n y como ayuda para la toma de decisiones automatizada subraya la importancia de comprender sus limitaciones y sesgos. Este art\u00edculo se centra en uno de los procesos de toma de decisiones m\u00e1s importantes de la sociedad democr\u00e1tica: las elecciones pol\u00edticas. Impulsando ChatGPT con 630 declaraciones pol\u00edticas de dos aplicaciones l\u00edderes de asesoramiento electoral y la prueba de br\u00fajula pol\u00edtica agn\u00f3stica de la naci\u00f3n en tres experimentos registrados previamente, descubrimos la ideolog\u00eda libertaria de izquierda proambiental de ChatGPT. Por ejemplo, ChatGPT impondr\u00eda impuestos a los vuelos, restringir\u00eda los aumentos de alquiler y legalizar\u00eda el aborto. En las elecciones de 2021, lo m\u00e1s probable es que hubiera votado por los Verdes tanto en Alemania (B\u00fcndnis 90/Die Gr\u00fcnen) como en los Pa\u00edses Bajos (GroenLinks). Nuestros hallazgos son s\u00f3lidos al negar las indicaciones, invertir el orden de las declaraciones, variar la formalidad de las indicaciones y en todos los idiomas (ingl\u00e9s, alem\u00e1n, holand\u00e9s y espa\u00f1ol). Concluimos discutiendo las implicaciones de la IA conversacional pol\u00edticamente sesgada en la sociedad.</p><p><a href=\"https://mastodon.uy/tags/chatgpt\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>chatgpt</span></a> <a href=\"https://mastodon.uy/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a>  <a href=\"https://mastodon.uy/tags/politics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>politics</span></a> <a href=\"https://mastodon.uy/tags/politica\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>politica</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07295",
    "title": "Meet in the Middle: A New Pre-training Paradigm",
    "latest": "2023-03-14T08:24:40+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110020675540590414",
      "content": "<p>RT @WeizhuChen@twitter.com</p><p>Meet In the Middle (MIM) : A New Pretraining Paradigm. <br>MIM(2.7B) outperforms CodeGen 16B, Incoder 6.7B, PaLM 540B, LLaMA 65B, FIM 2.7B in Code generation tasks. Read <a href=\"https://arxiv.org/abs/2303.07295\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07295</span><span class=\"invisible\"></span></a> to know why MIM could be a new pre-training paradigm for left-to-right and infilling LMs.</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/WeizhuChen/status/1635498612938670080\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/WeizhuChen/status/</span><span class=\"invisible\">1635498612938670080</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.06689",
    "title": "Self-planning Code Generation with Large Language Model",
    "latest": "2023-03-14T08:24:38+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110020675391560599",
      "content": "<p>Self-planning Code Generation with Large Language Model</p><p>Proposes a self-planning code generation method with LLM, which leads to substantial improvements on code generation tasks like HumanEval.</p><p><a href=\"https://arxiv.org/abs/2303.06689\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.06689</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.06349",
    "title": "Resurrecting Recurrent Neural Networks for Long Sequences",
    "latest": "2023-03-14T08:24:35+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110020675225856893",
      "content": "<p>Resurrecting Recurrent Neural Networks for Long Sequences</p><p>Shows that careful design of deep RNNs performs on par with SSMs on long-range reasoning tasks with comparable speed.</p><p><a href=\"https://arxiv.org/abs/2303.06349\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.06349</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.06614",
    "title": "Synthetic Experience Replay",
    "latest": "2023-03-14T08:24:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110020675035533853",
      "content": "<p>Synthetic Experience Replay</p><p>Presents SYNTHER, a diffusion-based approach to arbitrarily upsample an agent\u2019s collected experience.</p><p><a href=\"https://arxiv.org/abs/2303.06614\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.06614</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.06555",
    "title": "https://arxiv.org/abs/2303.06555",
    "latest": "2023-03-14T08:24:30+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110020674865800794",
      "content": "<p>One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale</p><p>repo: <a href=\"https://github.com/thu-ml/unidiffuser\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/thu-ml/unidiffuser</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.06555\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.06555</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07203",
    "title": "On the Robustness of Text Vectorizers",
    "latest": "2023-03-14T08:07:15+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@vaiter/110020606707751098",
      "content": "<p>\ud83d\udce3 Preprint out</p><p>\"On the robustness of text vectorizers\"</p><p>We prove that popular embedding schemes (concatenation, TF-IDF, doc2vec) exhibit robustness \ud83d\udcaa in the H\u00f6lder/Lipschitz sense w.r.t the Hamming dist. </p><p>With R. Catellier &amp; D. Garreau</p><p><a href=\"https://arxiv.org/abs/2303.07203\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07203</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07345",
    "title": "https://arxiv.org/abs/2303.07345",
    "latest": "2023-03-14T07:50:41+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110018900218140915",
      "content": "<p>Erasing Concepts from Diffusion Models</p><p>Can remove concepts from a diffusion model permanently unlike previous methods.</p><p>proj: <a href=\"https://erasing.baulab.info/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">erasing.baulab.info/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.07345\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07345</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@vh",
        "display_name": "Vincent HETRU"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05759v1",
    "title": "An Overview on Language Models: Recent Developments and Outlook",
    "latest": "2023-03-14T07:44:03+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110020515813342009",
      "content": "<p>\ud83d\udcdd An Overview on Language Models: Recent Developments and Outlook \ud83d\udcda</p><p>\"CLMs predict the probability of linguistic sequences in a causal manner, while PLMs cover a broader concepts and can be used in both casual modeling and fine-tuning tasks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05759v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05759v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05670v1",
    "title": "Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence Reasoning",
    "latest": "2023-03-14T04:24:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110019729585749665",
      "content": "<p>\ud83d\udcdd Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence Reasoning \ud83d\udcda\ud83d\udc7e</p><p>\"Explicit logic learning with textual entailment can significantly reduce bias and improve the recognition of social communities, without an explicit de-biasing process, compared to sentence representation models.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CY\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CY</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05670v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05670v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.06865",
    "title": "High-throughput Generative Inference of Large Language Models with a Single GPU",
    "latest": "2023-03-14T01:07:07+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110018955021927809",
      "content": "<p>High-throughput Generative Inference of Large Language Models with a Single GPU</p><p>Presents FlexGen, a high-throughput generation engine for running LLMs with limited GPU memory</p><p>repo: <a href=\"https://github.com/FMInference/FlexGen\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/FMInference/FlexGen</span><span class=\"invisible\"></span></a> <br>abs: <a href=\"https://arxiv.org/abs/2303.06865\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.06865</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07226",
    "title": "Scaling Vision-Language Models with Sparse Mixture of Experts",
    "latest": "2023-03-14T01:02:09+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110018935503375593",
      "content": "<p>Scaling Vision-Language Models with Sparse Mixture of Experts</p><p>Explores the effectiveness of MoE in scaling VLMs, demonstrating its potential to achieve SotA performance on a range of benchmarks over dense models of equivalent computational cost.</p><p><a href=\"https://arxiv.org/abs/2303.07226\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07226</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41467-023-36657-z",
    "title": "Fundamental limits to learning closed-form mathematical models from data - Nature Communications",
    "latest": "2023-03-14T00:59:15+00:00",
    "last_post": {
      "url": "https://masto.ai/@cheng/110018924087833180",
      "content": "<p>I see two ways to interpret the results of this paper \"Fundamental limits to learning closed-form mathematical models from data\"</p><p>1. Be <a href=\"https://masto.ai/tags/Bayesian\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Bayesian</span></a><br>2. There is a sharp phase transition between low noise and high noise data, when trying to apply <a href=\"https://masto.ai/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a> to it.</p><p><a href=\"https://www.nature.com/articles/s41467-023-36657-z\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41467-023</span><span class=\"invisible\">-36657-z</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      },
      {
        "url": "https://masto.ai/@cheng",
        "display_name": "Cheng Soon Ong"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07109",
    "title": "Transformer-based World Models Are Happy With 100k Interactions",
    "latest": "2023-03-14T00:56:07+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110018911779358412",
      "content": "<p>Transformer-based World Models Are Happy With 100k Interactions</p><p>Outperforms previous model-free and model-based RL algorithms on the Atari 100k benchmark.</p><p><a href=\"https://arxiv.org/abs/2303.07109\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07109</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04289",
    "title": "Do Prosody Transfer Models Transfer Prosody?",
    "latest": "2023-03-13T22:02:09+00:00",
    "last_post": {
      "url": "https://icosahedron.website/@halcy/110018192027697626",
      "content": "<p><a href=\"https://arxiv.org/abs/2303.04289\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04289</span><span class=\"invisible\"></span></a> i don't know that this is a good paper but I randomly saw it on arxiv and the title made me chuckle</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.13136v2",
    "title": "Fewer is More: Efficient Object Detection in Large Aerial Images",
    "latest": "2023-03-13T21:20:05+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@hue/110018062310647137",
      "content": "<p>Fewer is More: Efficient Object Detection in Large Aerial Images</p><p><a href=\"https://arxiv.org/abs/2212.13136v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.13136v2</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@hue",
        "display_name": "Hue :notverified:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05313v1",
    "title": "Replacement as a Self-supervision for Fine-grained Vision-language Pre-training",
    "latest": "2023-03-13T19:50:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110017708744615655",
      "content": "<p>\ud83d\udcdd Replacement as a Self-Supervision for Fine-Grained Vision-Language Pre-Training \ud83d\udd2d\ud83d\udcda</p><p>\"A HSR algorithm is proposed to provide token-level supervision, which replaces a verb/noun/adjective/quantifier word of the caption with its homonyms from WordNet.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05313v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05313v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00633-w",
    "title": "Fed up and burnt out: \u2018quiet quitting\u2019 hits academia",
    "latest": "2023-03-13T18:27:59+00:00",
    "last_post": {
      "url": "https://glasgow.social/@jayvanbavel/110006732227055964",
      "content": "<p>75% of scientists are burned out and pulling back on conferences, peer review, committee membership, etc <a href=\"https://www.nature.com/articles/d41586-023-00633-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00633-w</span></a></p><p>When scientists set boundaries, it not only improves their own personal well-being, but also creates norms that limits are acceptable and healthy</p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@mszll",
        "display_name": "Michael Szell"
      },
      {
        "url": "https://mastodon.social/@ojala",
        "display_name": "Luis Apiolaza"
      },
      {
        "url": "https://tech.lgbt/@_dmh",
        "display_name": "Dave Howcroft \ud83e\udd94"
      },
      {
        "url": "https://social.luca.run/@luca",
        "display_name": "Luca \ud83d\udd28"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41591-021-01260-6",
    "title": "Dismantling the anti-vaxx industry - Nature Medicine",
    "latest": "2023-03-13T18:17:18+00:00",
    "last_post": {
      "url": "https://mastodon.social/@lordmatt/110016828083878445",
      "content": "<p>Investigations show that those spreading misinformation that undermines the rollout of vaccines against COVID-19 are well financed, determined and disciplined. To counter their activities, we need to understand them as an industry actively working to sow doubts about the deadliness of COVID-19, vaccines and medical professionals\u2019 integrity.</p><p>--Imran Ahmed, Nature Magazine</p><p><a href=\"https://www.nature.com/articles/s41591-021-01260-6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41591-021</span><span class=\"invisible\">-01260-6</span></a></p><p><a href=\"https://mastodon.social/tags/Covid\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Covid</span></a> <a href=\"https://mastodon.social/tags/VaccinesSaveLives\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>VaccinesSaveLives</span></a></p>"
    },
    "people": [
      {
        "url": "https://bbq.snoot.com/@ProgGrrl",
        "display_name": "ProgGrrl"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05398",
    "title": "MathPrompter: Mathematical Reasoning using Large Language Models",
    "latest": "2023-03-13T18:12:13+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110017323544706409",
      "content": "<p>[R] MathPrompter: Mathematical Reasoning using Large Language Models. New State of the Art on MultiArith ( 78.7% to 92.5%) with Text-Davinci 002</p><p><a href=\"https://arxiv.org/abs/2303.05398\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05398</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2303.05398\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2303.05398</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05309v1",
    "title": "https://arxiv.org/abs/2303.05309v1",
    "latest": "2023-03-13T17:30:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110017158338660023",
      "content": "<p>\ud83d\udcdd MixSpeech: Cross-Modality Self-Learning with Audio-Visual Stream Mixup for Visual Speech Translation and Recognition \ud83d\udd2d\ud83d\udcda</p><p>\"MixSpeech regularizes the training of visual speech by utilizing audio speech as a teacher to learn the knowledge of visual speech and using mixed speech with a curriculum learning strategy to adjust the mixing ratio as needed.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Exgc/AVMuST-TED\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/Exgc/AVMuST-TED</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05309v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05309v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05431v1",
    "title": "https://arxiv.org/abs/2303.05431v1",
    "latest": "2023-03-13T09:30:08+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110015270672256838",
      "content": "<p>\ud83d\udcdd Disco: A Toolkit for Distributional Control of Generative Models \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"By combining a generative language model with an adversarial classifier, the technique allows controlling the prevalence of any features of interest in the model's outputs, such as gender and religion for generated text.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/naver/disco\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/naver/disco</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05431v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05431v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05401v1",
    "title": "Early Warning Signals of Social Instabilities in Twitter Data",
    "latest": "2023-03-13T06:10:11+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110014484411133842",
      "content": "<p>\ud83d\udcdd Early Warning Signals of Social Instabilities in Twitter Data \ud83d\udcda\ud83e\udde0</p><p>\"Uses two different approaches (persistent-gradient and BERT) to build the binary classifier: the persistent-gradient is trained on a topological signature extracted from the dataset, while the BERT model is trained on the raw text.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/SI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05401v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05401v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41598-023-30367-8#ref-CR3",
    "title": "nature.com/articles/s41598-023...",
    "latest": "2023-03-13T03:31:25+00:00",
    "last_post": {
      "url": "https://fediscience.org/@ct_bergstrom/110013860086896294",
      "content": "<p>The article in full is linked here \u2013 <a href=\"https://timesmachine.nytimes.com/timesmachine/1899/05/07/issue.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">timesmachine.nytimes.com/times</span><span class=\"invisible\">machine/1899/05/07/issue.html</span></a> \u2014  and reproduced in the attached images below. </p><p>I found the article via a reference in a new Scientific Reports paper by Schawe et al: <a href=\"https://www.nature.com/articles/s41598-023-30367-8#ref-CR3\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41598-023</span><span class=\"invisible\">-30367-8#ref-CR3</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@ct_bergstrom",
        "display_name": "Carl T. Bergstrom"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05398v1",
    "title": "MathPrompter: Mathematical Reasoning using Large Language Models",
    "latest": "2023-03-13T03:30:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110013855012279357",
      "content": "<p>\ud83d\udcdd MathPrompter: Mathematical Reasoning Using Large Language Models \ud83d\udcda\ud83d\udc7e</p><p>\"A: Uses the Zero-shot chain-of-thought prompting technique to generate multiple Algebraic expressions or Python functions to solve the same math problem in different ways and thereby raise the confidence level in the output results.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05398v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05398v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05391v1",
    "title": "https://arxiv.org/abs/2303.05391v1",
    "latest": "2023-03-13T01:10:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110013304725053661",
      "content": "<p>\ud83d\udcdd Disambiguation of Company Names via Deep Recurrent Networks \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Works by creating a low dimensional embedding vector of company names, and then using this embedding to identify which company names actually represent the same company (i the same Entity).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/DB\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DB</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/rcrupi/SiameseDisambiguation\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/rcrupi/SiameseDisam</span><span class=\"invisible\">biguation</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05391v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05391v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05383v1",
    "title": "Making a Computational Attorney",
    "latest": "2023-03-12T20:30:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110012203521822577",
      "content": "<p>\ud83d\udcdd Making a Computational Attorney \ud83d\udcda\ud83e\udde0</p><p>\"A ChatGPT-like Large Legal Language Model (L$^3$M) is a large language model pre-trained from scratch on the large legal corpus and then fine-tuned on the target legal tasks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CY\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CY</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05383v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05383v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/nrn.2018.20",
    "title": "https://www.nature.com/articles/nrn.2018.20",
    "latest": "2023-03-12T20:21:05+00:00",
    "last_post": {
      "url": "https://neuromatch.social/@laurentperrinet/110011729094365732",
      "content": "<p>\ud83d\udce3The <a href=\"https://neuromatch.social/tags/NeuroSchool\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NeuroSchool</span></a> Ph.D. Program of Aix-Marseille University is hiring with new Neuroscience PhD contracts \ud83c\udf93</p><p>The <a href=\"https://neuromatch.social/tags/NeuroSchool\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NeuroSchool</span></a> Ph.D. Program of Aix-Marseille University (France) has launched it call for PhD contracts. Deadline for application: April 2, 2023, three weeks left \ud83d\udcc6.</p><p>\ud83d\udc49\ud83c\udffc<a href=\"https://neuro-marseille.org/en/Calls/2023-phd-scholarships-for-international-students/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">neuro-marseille.org/en/Calls/2</span><span class=\"invisible\">023-phd-scholarships-for-international-students/</span></a> \u2026</p><p><a href=\"https://neuromatch.social/tags/hiring\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>hiring</span></a>  <a href=\"https://neuromatch.social/tags/PhDposition\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PhDposition</span></a> </p><p>You can read <a href=\"https://neuro-marseille.org/wp-content/uploads/2023/03/inter2023-neuroschool-phd-research-projects-list.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">all projects in one PDF</a></p><p>In particular, check-out our projet no 11 :</p><p>An efficient modelling approach for the detection of spiking motifs in neurobiological data</p><p>State of the art. Neuroscience has recently undergone a scientific and technological revolution. The scales at which neuronal activity can be experimentally recorded has considerably expanded. One striking example is the use of photonic imaging approaches to simultaneously sample the activity of thousands of neurons in vivo. Such novel experimental evidence shows that information processing in the brain is not a purely feed-forward process but relies also on internally generated activity in recurrent networks forming complex dynamical systems. Interestingly, it has been recently shown that neural information can be carried by way of series of spikes distributed on neurons of large networks and forming <a href=\"https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">precise spiking spatio-temporal motifs</a>.</p><p>Objectives. The goal of this project is to bring an interdisciplinary perspective to the detection of precise spike motifs in neurobiological data. In particular, inspired by neurobiological observations, we will mathematically formalize a representation in an assembly of neurons based on a set of motifs with different relative spike times. The main innovative aspect is to consider a representation based on repetitions of these spiking motifs at precise times of occurrence, thus extending the capabilities of analog representations based on vectors of instantaneous firing rate.</p><p>Methods. In preliminary work, we showed that this dedicated artificial neural network outperforms classical covariance-based methods in recognizing spiking motif timing and identity. This machine learning algorithm is particularly powerful when there is a large number of overlapping motifs as the temporal depth of the motifs increases. We used the pyTorch deep learning library, which is well suited for high-performance computing architectures such as GPUs, making it a viable option for high-throughput analysis of neurobiological data.</p><p>Expected results. An added value of this algorithm is that it can be used to learn precise spiking motifs in an unsupervised manner. It is a powerful tool for the detection of sequential activation of motifs in neurobiological data. In particular, the motifs may take the form of elementary waves and we will challenge the hypothesis that <a href=\"https://www.nature.com/articles/nrn.2018.20\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">neural activity drives computations thanks to traveling waves</a>, an aspect in which the collaboration with the team of Fr\u00e9d\u00e9ric Chavane, an expert on their functional role in the visual cortex, will be crucial.</p><p>Feasibility. Thanks to our preliminary work, we have validated this algorithm on synthetic data for which the ground truth is known. The method will be applied on existing data by our group, notably from cats, macaques or marmosets. The availability of this material makes the project highly feasible.</p><p>Expected candidate profile, specifying at least 4 skills. The candidate should have a strong inter-disciplinary profile in 1/ computational neuroscience, 2/ biological neuroscience, 3/ machine learning, and 4/ open science (FAIR principles).</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@vh",
        "display_name": "Vincent HETRU"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05208v1",
    "title": "Geometry of Language",
    "latest": "2023-03-12T18:10:15+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110011653516643367",
      "content": "<p>\ud83d\udcdd Geometry of Language \ud83d\udcda</p><p>\"By forming chains of tokens representing words, followed by matching these chains with pre-existing chains representing grammatical word orders, as in the diagram on the right, which can be visualized by two- or three-dimensional complexes.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05208v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05208v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.13971v1",
    "title": "LLaMA: Open and Efficient Foundation Language Models",
    "latest": "2023-03-12T17:58:44+00:00",
    "last_post": {
      "url": "https://mast.eu.org/@martin1975/110011607979445917",
      "content": "<p>\ud83e\udd16\ud83e\udd13 LLaMA: Open and Efficient Foundation Language Models <a href=\"https://arxiv.org/abs/2302.13971v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.13971v1</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://onlinelibrary.wiley.com/doi/10.1111/geb.13648?af=R",
    "title": "onlinelibrary.wiley.com/doi/10...",
    "latest": "2023-03-12T16:58:04+00:00",
    "last_post": {
      "url": "https://ecoevo.social/@sMarten_Winter/110010103259549185",
      "content": "<p>RT @GEB_macro<br>The global EPTO database: Worldwide occurrences of aquatic insects  <a href=\"https://onlinelibrary.wiley.com/doi/10.1111/geb.13648?af=R\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">onlinelibrary.wiley.com/doi/10</span><span class=\"invisible\">.1111/geb.13648?af=R</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@jebyrnes",
        "display_name": "jebyrnes"
      }
    ]
  },
  {
    "link": "https://link.springer.com/shop/springer/yellow-sale/de-eu/?sap-outbound-id=EFD7CCF2BC4D6B5733A9D53DF9D2444A8C1938B7&amp;utm_source=standard&amp;utm_medium=email&amp;utm_campaign=103_WADI01_0000028414_CONR_BOOKS_ECOM_GL_PHSS_002AA_spr-yel&amp;utm_content=EN_52642_20230312&amp;mkt-key=42010A0D569E1EECB3C8900FB514BDC0",
    "title": "Yellow Sale | Springer Nature ",
    "latest": "2023-03-12T16:32:13+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@filipw/110010666461214684",
      "content": "<p>dear Mathstodon friends, Springer has a \"yellow sale\" - 50% off for Mathematics books</p><p>\ud83d\udd17 <a href=\"https://link.springer.com/shop/springer/yellow-sale/de-eu/?sap-outbound-id=EFD7CCF2BC4D6B5733A9D53DF9D2444A8C1938B7&amp;utm_source=standard&amp;utm_medium=email&amp;utm_campaign=103_WADI01_0000028414_CONR_BOOKS_ECOM_GL_PHSS_002AA_spr-yel&amp;utm_content=EN_52642_20230312&amp;mkt-key=42010A0D569E1EECB3C8900FB514BDC0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/shop/springe</span><span class=\"invisible\">r/yellow-sale/de-eu/?sap-outbound-id=EFD7CCF2BC4D6B5733A9D53DF9D2444A8C1938B7&amp;utm_source=standard&amp;utm_medium=email&amp;utm_campaign=103_WADI01_0000028414_CONR_BOOKS_ECOM_GL_PHSS_002AA_spr-yel&amp;utm_content=EN_52642_20230312&amp;mkt-key=42010A0D569E1EECB3C8900FB514BDC0</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.coop/@ansate",
        "display_name": "Melissa Santos"
      }
    ]
  },
  {
    "link": "https://onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2575.2008.00304.x",
    "title": "onlinelibrary.wiley.com/doi/fu...",
    "latest": "2023-03-12T16:15:50+00:00",
    "last_post": {
      "url": "https://hci.social/@clifflampe/110011203598377836",
      "content": "<p><span class=\"h-card\"><a href=\"https://mstdn.social/@kissane\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>kissane</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.social/@jamiemccarthy\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>jamiemccarthy</span></a></span> Sorry, haven't checked this channel for a minute. I like this one for the things that work in an online community: <a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2575.2008.00304.x\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">onlinelibrary.wiley.com/doi/fu</span><span class=\"invisible\">ll/10.1111/j.1365-2575.2008.00304.x</span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@clifflampe",
        "display_name": "Cliff Lampe"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5281/zenodo.7715492",
    "title": "https://doi.org/10.5281/zenodo.7715492",
    "latest": "2023-03-12T09:53:19+00:00",
    "last_post": {
      "url": "https://openbiblio.social/@msiemund/110009676659430431",
      "content": "<p>Ihr sucht noch einen Workshop f\u00fcr Dienstag auf der <a href=\"https://openbiblio.social/tags/DHd2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DHd2023</span></a>? Ein paar wenige Pl\u00e4tze h\u00e4tten wir noch frei in der perfekten <a href=\"https://openbiblio.social/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://openbiblio.social/tags/Publikation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Publikation</span></a>. </p><p>Abstract: <a href=\"https://doi.org/10.5281/zenodo.7715492\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7715492</span><span class=\"invisible\"></span></a> </p><p>Ich bin gespannt auf den Workshop! <span class=\"h-card\"><a href=\"https://fedihum.org/@DHdKonferenz\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>DHdKonferenz</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch (moderator)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2009.01325",
    "title": "Learning to summarize from human feedback",
    "latest": "2023-03-12T09:50:00+00:00",
    "last_post": {
      "url": "https://c.im/@hyperplane/110009686063061145",
      "content": "<p>Learning to summarize from human feedback <a href=\"https://arxiv.org/abs/2009.01325\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2009.01325</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05082v1",
    "title": "https://arxiv.org/abs/2303.05082v1",
    "latest": "2023-03-12T07:50:14+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110009215533850605",
      "content": "<p>\ud83d\udcdd Dynamic Multi-View Fusion Mechanism for Chinese Relation Extraction \ud83d\udcda</p><p>\"Proposes a Mixture-of-View-Experts framework for Chinese relation extraction (MoVE), which dynamically learns the multi-view features of Chinese characters.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/kfcd/chaizi\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/kfcd/chaizi</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05082v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05082v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05077v1",
    "title": "https://arxiv.org/abs/2303.05077v1",
    "latest": "2023-03-12T05:50:11+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110008743461484036",
      "content": "<p>\ud83d\udcdd Learning the Legibility of Visual Text Perturbations \ud83d\udcda\ud83d\udd2d</p><p>\"Learns models that predict the legibility of text and rank perturbations based on the legibility score produced by the model, without using any visual information about the perturbation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/dvsth/learning-legibility-2023\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/dvsth/learning-legi</span><span class=\"invisible\">bility-2023</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05077v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05077v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05063v1",
    "title": "ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction",
    "latest": "2023-03-12T03:10:15+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110008114556294292",
      "content": "<p>\ud83d\udcdd ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction \ud83d\udcda</p><p>\"ICL-D3IE extracts the most difficult and distinct segments from hard training documents as hard demonstrations for benefiting all test instances, introduces demonstrations describing relationships that enable LLMs to understand positional relationships, and adds formatting demonstrations for easy answer extraction.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05063v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05063v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05046v1",
    "title": "Unsupervised Language agnostic WER Standardization",
    "latest": "2023-03-12T01:30:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110007720838032468",
      "content": "<p>\ud83d\udcdd Unsupervised Language Agnostic WER Standardization \ud83d\udcda</p><p>\"Normalizes spelling variations and segmentation variations in both transcription and hypothesis before computing WER between them and uses this normalized WER (NWER) as an evaluation metric.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05046v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05046v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.05034v1",
    "title": "Multi-Stage Coarse-to-Fine Contrastive Learning for Conversation Intent Induction",
    "latest": "2023-03-11T23:10:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110007170192373310",
      "content": "<p>\ud83d\udcdd Multi-Stage Coarse-to-Fine Contrastive Learning for Conversation Intent Induction \ud83d\udcda</p><p>\"Our solution is based on a multi-stage coarse-to-fine contrastive learning model training scheme including unsupervised contrastive learning pre-training, supervised contrastive learning pre-training, and fine-tuning with joint contrastive learning and clustering.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.05034v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.05034v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/full/10.1177/1461444815608807",
    "title": "journals.sagepub.com/doi/full/...",
    "latest": "2023-03-11T22:02:49+00:00",
    "last_post": {
      "url": "https://social.coop/@natematias/110006905685099092",
      "content": "<p>People complain to algorithm makers about obvious social problems \u2014&nbsp;and get frustrated when system makers say they can't possibly anticipate them.</p><p>Aside from corporate self-interest, I think this may result from differences in the level of analysis \u2014&nbsp;algorithm makers imagine individual situations, while critics are imagining population trends.</p><p>For example, sexism &amp; harassment has been a rampant pattern on reddit, but might still be hard to predict in individual cases</p><p><a href=\"https://journals.sagepub.com/doi/full/10.1177/1461444815608807\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/full/</span><span class=\"invisible\">10.1177/1461444815608807</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.coop/@natematias",
        "display_name": "J. Nathan Matias \ud83e\udda3"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41562-022-01495-4",
    "title": "US universities are not succeeding in diversifying faculty - Nature Human Behaviour",
    "latest": "2023-03-11T21:55:25+00:00",
    "last_post": {
      "url": "https://social.coop/@natematias/110006876601805286",
      "content": "<p>While marketers &amp; algorithm designers care about making individual-level predictions, people concerned about the social impact of algorithms are often more interested in population-level predictions. </p><p>And collective behavior can be frustratingly stable. Consider, for example, the problem of inequality. Universities are highly complex systems, but my colleagues and I were able to model 99% of the variation in US faculty diversity, on average, with a very simple model </p><p><a href=\"https://www.nature.com/articles/s41562-022-01495-4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41562-022</span><span class=\"invisible\">-01495-4</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.coop/@natematias",
        "display_name": "J. Nathan Matias \ud83e\udda3"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.00848",
    "title": "Understanding the Diffusion Objective as a Weighted Integral of ELBOs",
    "latest": "2023-03-11T18:12:13+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110005998963513650",
      "content": "<p>[R] Understanding the Diffusion Objective as a Weighted Integral of ELBOs</p><p><a href=\"https://arxiv.org/abs/2303.00848\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.00848</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2303.00848\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2303.00848</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "http://osf.io/cy3wj/",
    "title": "http://osf.io/cy3wj/",
    "latest": "2023-03-11T09:56:49+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110004050968376680",
      "content": "<p>Meta-dominance analysis - A tool for the assessment of the quality of digital behavioural data <a href=\"http://osf.io/cy3wj/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/cy3wj/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://doi.org/10.36850/p761-ey93",
    "title": "https://doi.org/10.36850/p761-ey93",
    "latest": "2023-03-11T09:42:48+00:00",
    "last_post": {
      "url": "https://social.cwts.nl/@LudoWaltman/110003761916586397",
      "content": "<p>How 'Recognition and Rewards' in Dutch academia turned metrics into incentives <a href=\"https://doi.org/10.36850/p761-ey93\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.36850/p761-ey93</span><span class=\"invisible\"></span></a></p><p>\"In the end, we should realize that \u2018recognition and rewards\u2019 is not about quantitative or qualitative indicators: it are the social and political goals of science that are at stake\"</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@RonaldSnijder",
        "display_name": "Ronald Snijder"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04381v1",
    "title": "Automatically Auditing Large Language Models via Discrete Optimization",
    "latest": "2023-03-11T09:01:53+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110003834952460810",
      "content": "<p>\ud83d\udcdd Automatically Auditing Large Language Models via Discrete Optimization \ud83e\udde0\ud83d\udcda</p><p>\"Uses a novel gradient-based discrete optimization algorithm, Alternating Random Coordinate Ascent (ARCA), that jointly and efficiently optimizes over inputs and outputs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04381v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04381v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04526v1",
    "title": "Student's t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce",
    "latest": "2023-03-11T06:31:47+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110003244708623202",
      "content": "<p>\ud83d\udcdd Student's T-Distribution: On Measuring the Inter-Rater Reliability When the Observations Are Scarce \ud83d\udcda</p><p>\"The ``Student's \\textit{t}-Distribution'' method is used to calculate the confidence interval of the inter-rater reliability (IRR) score using only two observations.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/IT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>IT</span></a> <a href=\"https://creative.ai/tags/NA\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NA</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04526v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04526v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04715v1",
    "title": "Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results",
    "latest": "2023-03-11T04:01:52+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110002655199694136",
      "content": "<p>\ud83d\udcdd Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results \ud83d\udcda\ud83d\udc7e</p><p>\"The BLOOM-zh model is a transformer-based masked language model that has been trained on 22 billion tokens covering a variety of domains such as news articles, books, encyclopedias, educational materials, and spoken language.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04715v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04715v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.09255",
    "title": "Multi hash embeddings in spaCy",
    "latest": "2023-03-11T02:36:18+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@sofie/110000028559192331",
      "content": "<p>Happy to announce the release of spaCy 3.5.1!</p><p>It introduces  'spancat_singlelabel', support for mypy v1.0, new operators for the dependency matchers, a 'PlainTextCorpusReader', various bug fixes and more!</p><p>We recently also added two new resources:</p><p>* <a href=\"https://github.com/explosion/projects/tree/v3/benchmarks/span-labeling-datasets\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/explosion/projects/</span><span class=\"invisible\">tree/v3/benchmarks/span-labeling-datasets</span></a> bundles various NER &amp; spancat datasets + .spacy convertors</p><p>* <a href=\"https://github.com/explosion/projects/tree/v3/benchmarks/ner_embeddings\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/explosion/projects/</span><span class=\"invisible\">tree/v3/benchmarks/ner_embeddings</span></a> contains all resources to reproduce the results of our \"Multi hash embeddings\" technical report: <a href=\"https://arxiv.org/abs/2212.09255\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.09255</span><span class=\"invisible\"></span></a></p><p>Happy weekend!</p>"
    },
    "people": [
      {
        "url": "https://universeodon.com/@pchiusano",
        "display_name": "Paul Chiusano"
      },
      {
        "url": "https://dekok.dk/@daniel",
        "display_name": "Dani\u00ebl de Kok :verified:"
      },
      {
        "url": "https://sigmoid.social/@ryanwesslen",
        "display_name": "Ryan Wesslen"
      },
      {
        "url": "https://fosstodon.org/@ljvmiranda",
        "display_name": "Lj V. Miranda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/1706.03762.pdf",
    "title": "https://arxiv.org/pdf/1706.03762.pdf",
    "latest": "2023-03-11T01:21:57+00:00",
    "last_post": {
      "url": "https://collapsitarian.io/objects/062f21ce-e654-4951-b72f-d89e7c234329",
      "content": "there's a paper that I think everyone needs to read, called \"Attention Is All You Need.\" Everything we're seeing in language models these days has its origin in this paper, and all the meta-usage of AI you see was essentially proven out here long before any of this was public.<br><br><a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://arxiv.org/pdf/1706.03762.pdf</a>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04487v1",
    "title": "Query-Utterance Attention with Joint modeling for Query-Focused Meeting Summarization",
    "latest": "2023-03-11T01:01:48+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110001947195784455",
      "content": "<p>\ud83d\udcdd Query-Utterance Attention with Joint Modeling for Query-Focused Meeting Summarization \ud83d\udcda\ud83d\udc7e</p><p>\"Proposes a query-aware framework with joint modeling token and utterance based on Query-Utterance Attention for query-focused meeting summarization (QFMS).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04487v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04487v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/a25xq/",
    "title": "http://osf.io/a25xq/",
    "latest": "2023-03-11T00:46:27+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110001886823083239",
      "content": "<p>When Emotions Work: A Single-Case Analysis of De-escalation <a href=\"http://osf.io/a25xq/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/a25xq/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/fyrb6/",
    "title": "http://osf.io/fyrb6/",
    "latest": "2023-03-11T00:26:44+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110001809319458212",
      "content": "<p>Diffusion and Collective Violence in India <a href=\"http://osf.io/fyrb6/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/fyrb6/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/7fgj2/",
    "title": "http://osf.io/7fgj2/",
    "latest": "2023-03-10T21:31:41+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110001120982586347",
      "content": "<p>Coronavirus and Journalism: A Meta-analysis of Early Research on Journalism in the COVID-19 pandemic <a href=\"http://osf.io/7fgj2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/7fgj2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/2er9a/",
    "title": "http://osf.io/2er9a/",
    "latest": "2023-03-10T21:01:31+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110001002346168292",
      "content": "<p>Violent conflict and hostility towards ethno-religious outgroups in Nigeria <a href=\"http://osf.io/2er9a/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/2er9a/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/2c83b/",
    "title": "http://osf.io/2c83b/",
    "latest": "2023-03-10T20:26:34+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110000864900112951",
      "content": "<p>EVALUATING POLICY INSTRUMENT COMPLEXITY WITH CAUSAL LOOP DIAGRAMS <a href=\"http://osf.io/2c83b/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/2c83b/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41562-022-01516-2",
    "title": "Evidence of a predictive coding hierarchy in the human brain listening to speech - Nature Human Behaviour",
    "latest": "2023-03-10T19:20:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110000603284797974",
      "content": "<p>Evidence of a predictive coding hierarchy in the human brain listening to speech - <a href=\"https://www.nature.com/articles/s41562-022-01516-2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41562-022</span><span class=\"invisible\">-01516-2</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5281/zenodo.7716098",
    "title": "https://doi.org/10.5281/zenodo.7716098",
    "latest": "2023-03-10T18:55:45+00:00",
    "last_post": {
      "url": "https://mastodon.social/@jrglmn/110000507831491082",
      "content": "<p>If you would like to work with <a href=\"https://mastodon.social/tags/BigData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BigData</span></a>, here are some:</p><p>Metadata of 200.000+ digitized works in the digitized collections of the Berlin State Library:<br><a href=\"https://doi.org/10.5281/zenodo.7716098\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7716098</span><span class=\"invisible\"></span></a></p><p>Fulltexts of about 30.000 digitized and OCR'd works in the digitized collections of the Berlin State Library:<br><a href=\"https://doi.org/10.5281/zenodo.7716032\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7716032</span><span class=\"invisible\"></span></a></p><p>Both datasets are accompanied by datasheets according to <span class=\"h-card\"><a href=\"https://dair-community.social/@timnitGebru\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>timnitGebru</span></a></span> et al's famous proposal <a href=\"https://doi.org/10.48550/arXiv.1803.09010\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.48550/arXiv.1803.09</span><span class=\"invisible\">010</span></a></p><p>Enjoy!</p><p><a href=\"https://mastodon.social/tags/culturalheritage\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>culturalheritage</span></a> <a href=\"https://mastodon.social/tags/GLAMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GLAMs</span></a> <a href=\"https://mastodon.social/tags/ResearchData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ResearchData</span></a> <a href=\"https://mastodon.social/tags/distantreading\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>distantreading</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jrglmn",
        "display_name": "J\u00f6rg Lehmann"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5281/zenodo.7716032",
    "title": "https://doi.org/10.5281/zenodo.7716032",
    "latest": "2023-03-10T18:55:45+00:00",
    "last_post": {
      "url": "https://mastodon.social/@jrglmn/110000507831491082",
      "content": "<p>If you would like to work with <a href=\"https://mastodon.social/tags/BigData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BigData</span></a>, here are some:</p><p>Metadata of 200.000+ digitized works in the digitized collections of the Berlin State Library:<br><a href=\"https://doi.org/10.5281/zenodo.7716098\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7716098</span><span class=\"invisible\"></span></a></p><p>Fulltexts of about 30.000 digitized and OCR'd works in the digitized collections of the Berlin State Library:<br><a href=\"https://doi.org/10.5281/zenodo.7716032\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7716032</span><span class=\"invisible\"></span></a></p><p>Both datasets are accompanied by datasheets according to <span class=\"h-card\"><a href=\"https://dair-community.social/@timnitGebru\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>timnitGebru</span></a></span> et al's famous proposal <a href=\"https://doi.org/10.48550/arXiv.1803.09010\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.48550/arXiv.1803.09</span><span class=\"invisible\">010</span></a></p><p>Enjoy!</p><p><a href=\"https://mastodon.social/tags/culturalheritage\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>culturalheritage</span></a> <a href=\"https://mastodon.social/tags/GLAMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GLAMs</span></a> <a href=\"https://mastodon.social/tags/ResearchData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ResearchData</span></a> <a href=\"https://mastodon.social/tags/distantreading\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>distantreading</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jrglmn",
        "display_name": "J\u00f6rg Lehmann"
      }
    ]
  },
  {
    "link": "https://doi.org/10.48550/arXiv.1803.09010",
    "title": "doi.org/10.48550/arXiv.1803.09...",
    "latest": "2023-03-10T18:55:45+00:00",
    "last_post": {
      "url": "https://mastodon.social/@jrglmn/110000507831491082",
      "content": "<p>If you would like to work with <a href=\"https://mastodon.social/tags/BigData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BigData</span></a>, here are some:</p><p>Metadata of 200.000+ digitized works in the digitized collections of the Berlin State Library:<br><a href=\"https://doi.org/10.5281/zenodo.7716098\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7716098</span><span class=\"invisible\"></span></a></p><p>Fulltexts of about 30.000 digitized and OCR'd works in the digitized collections of the Berlin State Library:<br><a href=\"https://doi.org/10.5281/zenodo.7716032\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7716032</span><span class=\"invisible\"></span></a></p><p>Both datasets are accompanied by datasheets according to <span class=\"h-card\"><a href=\"https://dair-community.social/@timnitGebru\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>timnitGebru</span></a></span> et al's famous proposal <a href=\"https://doi.org/10.48550/arXiv.1803.09010\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.48550/arXiv.1803.09</span><span class=\"invisible\">010</span></a></p><p>Enjoy!</p><p><a href=\"https://mastodon.social/tags/culturalheritage\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>culturalheritage</span></a> <a href=\"https://mastodon.social/tags/GLAMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GLAMs</span></a> <a href=\"https://mastodon.social/tags/ResearchData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ResearchData</span></a> <a href=\"https://mastodon.social/tags/distantreading\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>distantreading</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jrglmn",
        "display_name": "J\u00f6rg Lehmann"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04673v1",
    "title": "https://arxiv.org/abs/2303.04673v1",
    "latest": "2023-03-10T18:01:53+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110000295980682507",
      "content": "<p>\ud83d\udcdd Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"A framework named EcooptiGen is designed to automatically select hyperparameters that maximize the value of generation under a limited inference budget and is implemented in the FLAML library.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/microsoft/FLAML\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/microsoft/FLAML</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04673v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04673v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/abs/10.1145/3173574.3173869",
    "title": "dl.acm.org/doi/abs/10.1145/317...",
    "latest": "2023-03-10T17:37:45+00:00",
    "last_post": {
      "url": "https://hci.social/@jbigham/110000201115652872",
      "content": "<p><span class=\"h-card\"><a href=\"https://hci.social/@justin\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>justin</span></a></span> we've had years of on-again/off-again work in human-powered dialog systems, <span class=\"h-card\"><a href=\"https://hci.social/@windx0303\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>windx0303</span></a></span>'s dissertation was about this, e.g., \"Evorus: A Crowd-Powered System Built to Automate Itself Over Time,\" <a href=\"https://dl.acm.org/doi/abs/10.1145/3173574.3173869\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/abs/10.1145/317</span><span class=\"invisible\">3574.3173869</span></a>. we also recently concluded a DARPA program in which we were consistently among or the winner, essentially using human feedback to make systems high quality. but, i'm not actually working on RLHF \u2026&nbsp;</p>"
    },
    "people": [
      {
        "url": "https://hci.social/@jbigham",
        "display_name": "Jeff Bigham"
      }
    ]
  },
  {
    "link": "https://doi.org/10.17175/wp_2021_001_v2",
    "title": "doi.org/10.17175/wp_2021_001_v...",
    "latest": "2023-03-10T17:32:43+00:00",
    "last_post": {
      "url": "https://openbiblio.social/@steyerti/109998258156650130",
      "content": "<p>P\u00fcnktlich zur Jahreskonferenz des DHd-Verbandes ist die zweite Version des Workingpapers \"Digitales Publizieren in den Geisteswissenschaften: Begriffe, Standards, Empfehlungen\" der DH AG Digitales Publizieren erschienen. Publiziert ist das Workinpaper in der Zeitschrift f\u00fcr digitale Geisteswissenschaften unter: <a href=\"https://doi.org/10.17175/wp_2021_001_v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.17175/wp_2021_001_v</span><span class=\"invisible\">2</span></a> <a href=\"https://openbiblio.social/tags/digitalespublizieren\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>digitalespublizieren</span></a> <a href=\"https://openbiblio.social/tags/openaccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>openaccess</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@dbellingradt",
        "display_name": "Daniel Bellingradt :mastodon:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04918",
    "title": "Coloring in R's Blind Spot",
    "latest": "2023-03-10T09:20:17.116000+00:00",
    "last_post": {
      "url": "https://fediscience.org/@davdittrich/109998132391791096",
      "content": "<p>Recently <a href=\"https://fediscience.org/tags/Rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Rstats</span></a> gained a new &amp; much improved default palette and a selection of more than 100 well-established palettes are now available via the functions palette.colors() &amp; hcl.colors().<br>\u2026provides an overview of these new <a href=\"https://fediscience.org/tags/color\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>color</span></a> functions &amp; the palettes they provide along with advice about which palettes are appropriate for specific tasks, especially with regard to making them accessible to viewers with color vision deficiencies.</p><p><a href=\"https://arxiv.org/abs/2303.04918\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04918</span><span class=\"invisible\"></span></a><br><a href=\"https://fediscience.org/tags/accessibility\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>accessibility</span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@ERDonnachie",
        "display_name": "Ewan Donnachie"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2212.09611.pdf",
    "title": "https://arxiv.org/pdf/2212.09611.pdf",
    "latest": "2023-03-10T07:54:47+00:00",
    "last_post": {
      "url": "https://infosec.exchange/@tsomersu/109868522507102175",
      "content": "<p>Microsoft Open Source LMOps: An AI Prompt Optimization Toolkit For Generative AI Models </p><p><a href=\"https://www.marktechpost.com/2023/02/14/microsoft-open-source-lmops-an-ai-prompt-optimization-toolkit-for-generative-ai-models/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">marktechpost.com/2023/02/14/mi</span><span class=\"invisible\">crosoft-open-source-lmops-an-ai-prompt-optimization-toolkit-for-generative-ai-models/</span></a></p><p><a href=\"https://github.com/microsoft/LMOps\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/microsoft/LMOps</span><span class=\"invisible\"></span></a></p><p>Optimizing Prompts for Text-to-Image Generation<br><a href=\"https://arxiv.org/pdf/2212.09611.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2212.09611.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://infosec.exchange/tags/GPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GPT</span></a> <a href=\"https://infosec.exchange/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a> <a href=\"https://infosec.exchange/tags/Microsoft\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Microsoft</span></a> <a href=\"https://infosec.exchange/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04245v1",
    "title": "How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding",
    "latest": "2023-03-10T07:31:50+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109997818520989434",
      "content": "<p>\ud83d\udcdd How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding \ud83e\udde0\ud83d\udcda</p><p>\"The embedding and attention layers learn latent representations of the text which capture the semantic structure, as measured by the inner product of the embeddings for same-topic words and pairwise attention for same-topic words.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04245v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04245v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41559-023-02008-w",
    "title": "Better incentives are needed to reward academic software development - Nature Ecology & Evolution",
    "latest": "2023-03-10T06:50:27+00:00",
    "last_post": {
      "url": "https://mas.to/@warrickball/109948362508660635",
      "content": "<p>This article in Nature Ecology &amp; Evolution seems to be making the rounds:</p><p>\"Better incentives are needed to reward academic software development\"<br><a href=\"https://www.nature.com/articles/s41559-023-02008-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41559-023</span><span class=\"invisible\">-02008-w</span></a></p><p>I don't disagree with the premise but one of my hotter takes (I think) is that the solution is not more journal articles but rather recognition of software (and, importantly, its maintenance) as a research output.</p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@underdarkGIS",
        "display_name": "Anita Graser \ud83c\uddea\ud83c\uddfa\ud83c\uddfa\ud83c\udde6"
      },
      {
        "url": "https://fediscience.org/@tschfflr",
        "display_name": "Tatjana Scheffler"
      },
      {
        "url": "https://mstdn.social/@felwert",
        "display_name": "Frederik Elwert"
      },
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      },
      {
        "url": "https://fosstodon.org/@mdsumner",
        "display_name": "mdsumner"
      },
      {
        "url": "https://vis.social/@jhilden",
        "display_name": "Jonatan Hild\u00e9n"
      }
    ]
  },
  {
    "link": "http://osf.io/3u52w/",
    "title": "http://osf.io/3u52w/",
    "latest": "2023-03-10T06:20:57+00:00",
    "last_post": {
      "url": "https://botsin.space/@MetaArXivBot/109978336559682377",
      "content": "<p>Selecting Studies for Replication in Social Neuroscience: Exploring a Formal Approach <a href=\"http://osf.io/3u52w/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/3u52w/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03628v1",
    "title": "https://arxiv.org/abs/2303.03628v1",
    "latest": "2023-03-10T06:08:48+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109990704212722117",
      "content": "<p>\ud83d\udcdd CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification \ud83d\udcda\ud83e\udde0</p><p>\"A tool for annotating the factual correctness of generated explanations and collecting revision data of wrong explanations for enhancing the faithfulness of generated explanations from large language models (LLMs).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/SeungoneKim/CoTEVer\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/SeungoneKim/CoTEVer</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.03628v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03628v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://fosstodon.org/@ljvmiranda",
        "display_name": "Lj V. Miranda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04761",
    "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
    "latest": "2023-03-10T04:54:45+00:00",
    "last_post": {
      "url": "https://masto.ai/@machine_revolution/109864251739541490",
      "content": "<p><a href=\"https://arxiv.org/abs/2302.04761\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04761</span><span class=\"invisible\"></span></a> transformers can learn how to use APIs ... wow</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2211.13203",
    "title": "http://arxiv.org/abs/2211.13203",
    "latest": "2023-03-10T03:50:12.321000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/47ea9bc2-32e5-4fe8-91da-dd002d94691e",
      "content": "\"Inversion-Based Style Transfer with Diffusion Models. (arXiv:2211.13203v2 [cs.CV] UPDATED)\" \u2014 Accurately transfer the style attributes such as semantics, material, object shape, brushstrokes and colors of an input image to the target image.<br><br>Paper: <a href=\"http://arxiv.org/abs/2211.13203\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2211.13203</a><br>Code: <a href=\"https://github.com/zyxelsa/InST\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/zyxelsa/InST</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/fd921051b97c78e7d384097a7634d2cab4c4358cfeabed5fb007c9bf9b34a03d.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Style transfer results by using\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.05511",
    "title": "http://arxiv.org/abs/2303.05511",
    "latest": "2023-03-10T03:39:21.438000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/ad444100-2a96-4bca-819e-4cfee018d1b0",
      "content": "\"Scaling up GANs for Text-to-Image Synthesis. (arXiv:2303.05511v1 [cs.CV])\" \u2014 Adapting the GAN architecture for generating images via text prompts to work with large datasets, offering faster generation times and higher resolutions.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.05511\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.05511</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/aeafddf1a2327fbe0237b44dee73ec1aedc27b7a1037192d19335567cbd302bf.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Some sample images generated by\u2026</a>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      },
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.05498",
    "title": "http://arxiv.org/abs/2303.05498",
    "latest": "2023-03-10T03:33:51.150000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/84b333b7-0171-4fe7-a01d-6efaa4de8b10",
      "content": "\"Mark My Words: Dangers of Watermarked Images in ImageNet. (arXiv:2303.05498v1 [cs.LG])\" \u2014 A look at the potential risks of watermarked images present in<br>ImageNet and their impact on popular Deep Neural Networks (DNN) trained on this dataset.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.05498\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.05498</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/2817a87a8dbd66d32260168ca53f9e8e8325d5d34601d67746935c7b5f66fbcc.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Multiple images with watermarks\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.05371",
    "title": "http://arxiv.org/abs/2303.05371",
    "latest": "2023-03-10T03:30:10.424000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/7868fb11-c19a-40e8-bc04-ddd53ce734ae",
      "content": "\"3DGen: Triplane Latent Diffusion for Textured Mesh Generation. (arXiv:2303.05371v1 [cs.CV])\" \u2014 Generating 3D meshes using diffusion models.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.05371\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.05371</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/32bb6b5a1b09127e524cda2a1aa0a1b3fa7ca2ca625e1c3ac90c782e82756cd9.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Single category unconditional m\u2026</a>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      },
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.05325",
    "title": "http://arxiv.org/abs/2303.05325",
    "latest": "2023-03-10T03:26:46.385000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/4815090a-e38b-4e4f-be36-a07bf0449145",
      "content": "\"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset. (arXiv:2303.05325v1 [cs.CV])\" \u2014 A dataset to help with Bengali document layout analysis, containing 33,695 human annotated document samples from six domains.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.05325\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.05325</a><br>Code: <a href=\"https://github.com/anon-user-for-web/badlad\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/anon-user-for-web/badlad</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/497b688a120ce6e469f6d3a0c631ef4178af1338cfa8f0b65e3300fc9773693c.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">A sample of the different layou\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.05275",
    "title": "http://arxiv.org/abs/2303.05275",
    "latest": "2023-03-10T03:22:47.897000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/c22451b0-22c3-46ab-bc43-2c875923ef69",
      "content": "\"Detecting Images Generated by Diffusers. (arXiv:2303.05275v1 [cs.CV])\" \u2014 Detecting if given images were generated by diffusion models or not. Appears to be limited to detecting images only if images generated by a particular diffusion model were in the training set.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.05275\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.05275</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/ed829a289352cad3acd5d60fe84ab52379380ede8bab49967a1997e433c3205b.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">The two different network setup\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.04884",
    "title": "http://arxiv.org/abs/2303.04884",
    "latest": "2023-03-10T03:16:39.616000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/53436b1a-0cdf-430d-b578-e7bb11d275a9",
      "content": "\"O2RNet: Occluder-Occludee Relational Network for Robust Apple Detection in Clustered Orchard Environments. (arXiv:2303.04884v1 [cs.CV])\" \u2014 Using deep learning to detect apples in orchards for harvesting.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.04884\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.04884</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/bae88ba440b124086392146a624a1c52b9d18b7c291c8e596427af6d68d646ea.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Six sample images from the coll\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/abs/10.1080/19439962.2023.2178566?journalCode=utss20",
    "title": "tandfonline.com/doi/abs/10.108...",
    "latest": "2023-03-10T01:56:05+00:00",
    "last_post": {
      "url": "https://sfba.social/@niedermeyer/109956211943246983",
      "content": "<p>For years, Tesla and its supporters have waved away detailed investigations tying Autopilot's design to multiple deaths, claiming that the safety benefits outweighed them.</p><p>Now, finally, we have published academic work proving that Autopilot has no safety benefits, when you adjust the numbers for road type and driver age. In fact crashes appear to be 11% higher with Autopilot!</p><p>Huge thanks to Noah Goodall of the Virginia Transportation Research Council for this work!</p><p><a href=\"https://www.tandfonline.com/doi/abs/10.1080/19439962.2023.2178566?journalCode=utss20\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/abs/10.108</span><span class=\"invisible\">0/19439962.2023.2178566?journalCode=utss20</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.scot/@mike_moran",
        "display_name": "Mike Moran"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02083",
    "title": "Theory of Mind May Have Spontaneously Emerged in Large Language Models",
    "latest": "2023-03-10T01:54:43+00:00",
    "last_post": {
      "url": "https://universeodon.com/@rayh/109860913355526067",
      "content": "<p>Also \"Theory of Mind May Have Spontaneously Emerged in Large Language Models\" by Kosinski</p><p><a href=\"https://arxiv.org/abs/2302.02083\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02083</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://fediscience.org/@ct_bergstrom",
        "display_name": "Carl T. Bergstrom"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://sigmoid.social/@pbrane",
        "display_name": "Jake Mannix"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04248",
    "title": "TRACT: Denoising Diffusion Models with Transitive Closure Time-Distillation",
    "latest": "2023-03-10T01:14:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/109996333616482879",
      "content": "<p>RT @D_Berthelot_ML@twitter.com</p><p>New paper TRACT - Faster diffusion model sampling<br>- Single-step diffusion SotA for CIFAR10 and ImageNet64 with L2 loss without architecture changes<br>- Up to 2.4x FID improvement<br><a href=\"https://arxiv.org/abs/2303.04248\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04248</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/D_Berthelot_ML/status/1633922777228148736\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/D_Berthelot_ML/sta</span><span class=\"invisible\">tus/1633922777228148736</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      },
      {
        "url": "https://sigmoid.social/@mat_kelcey",
        "display_name": "Mat Kelcey"
      },
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00642-9",
    "title": "Indoor air is full of flu and COVID viruses. Will countries clean it up?",
    "latest": "2023-03-09T21:57:16+00:00",
    "last_post": {
      "url": "https://mas.to/@lneumannca/109983383694575116",
      "content": "<p>\"In the 316 classrooms that had mechanical ventilation with rates of 1.4\u201314 litres per second per person, the students\u2019 risk of infection was reduced by at least 74% over a 4-month period at the end of 2021, compared with that for students in classrooms that relied on windows for ventilation. ... When ventilation rates were at least 10 l/s per student, the infection risk was 80% lower.\"<br><a href=\"https://mas.to/tags/Covid\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Covid</span></a> <a href=\"https://mas.to/tags/Covid19\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Covid19</span></a> <a href=\"https://mas.to/tags/CleanAir\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CleanAir</span></a>  </p><p><a href=\"https://www.nature.com/articles/d41586-023-00642-9\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00642-9</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.cloud/@mogul",
        "display_name": "Bret Mogilefsky"
      },
      {
        "url": "https://mastodon.online/@vladiliescu",
        "display_name": "Vlad Iliescu \ud83d\udc2c"
      },
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      },
      {
        "url": "https://social.coop/@MichaelTBacon",
        "display_name": "Michael T. Bacon, Ph.D."
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04896",
    "title": "https://doi.org/10.21105/joss.04896",
    "latest": "2023-03-09T21:41:28+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109995497132942694",
      "content": "<p>Just published in JOSS: 'OpenMSIStream: A Python package for facilitating integration of streaming data in diverse laboratory environments' <a href=\"https://doi.org/10.21105/joss.04896\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04896</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04134v1",
    "title": "https://arxiv.org/abs/2303.04134v1",
    "latest": "2023-03-09T21:22:46+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109995423616270788",
      "content": "<p>\ud83d\udcdd A Hybrid Architecture for Out of Domain Intent Detection and Intent Discovery \ud83d\udcda\ud83d\udc7e</p><p>\"A Variational Autoencoder is used to distinguish between known and unknown intents independent of input data distribution and an unsupervised clustering method is used to discover different unknown intents underlying OOD/OOS inputs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Makbari1997/Persian-Atis\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/Makbari1997/Persian</span><span class=\"invisible\">-Atis</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04134v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04134v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05021",
    "title": "https://doi.org/10.21105/joss.05021",
    "latest": "2023-03-09T21:00:15+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109995335050238927",
      "content": "<p>Just published in JOSS: 'flowMC: Normalizing flow enhanced sampling package for probabilistic inference in JAX' <a href=\"https://doi.org/10.21105/joss.05021\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05021</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.06466.pdf",
    "title": "https://arxiv.org/pdf/2302.06466.pdf",
    "latest": "2023-03-09T19:54:39+00:00",
    "last_post": {
      "url": "https://discuss.systems/@emansour/109864049442648804",
      "content": "<p>We are happy to share our survey paper, the first to review the differences between conversational <a href=\"https://discuss.systems/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> models, such as <a href=\"https://discuss.systems/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a>, and traditional question-answering systems for <a href=\"https://discuss.systems/tags/KG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>KG</span></a>. Thanks to my students (Reham Omarand Omij Mangukiya) and Panos Kalnis. <br>Our survey conducted a comprehensive evaluation, including four real <a href=\"https://discuss.systems/tags/KGs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>KGs</span></a> of different application domains and 450 English questions of various linguistic complexity. Our paper proposes open research opportunities in developing <a href=\"https://discuss.systems/tags/chatbots\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>chatbots</span></a> for <a href=\"https://discuss.systems/tags/KGs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>KGs</span></a>.<br>The paper is available at <a href=\"https://arxiv.org/pdf/2302.06466.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.06466.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04132v1",
    "title": "https://arxiv.org/abs/2303.04132v1",
    "latest": "2023-03-09T19:52:29+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109995068613024340",
      "content": "<p>\ud83d\udcdd Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"SynthIE uses the asymmetry in task difficulty between generation and extraction to synthetically generate a dataset of 1,8M data points for closed information extraction with a large-language model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/epfl-dlab/SynthIE\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/epfl-dlab/SynthIE</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04132v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04132v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/7xgh3/",
    "title": "http://osf.io/7xgh3/",
    "latest": "2023-03-09T19:26:34+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109994966676909480",
      "content": "<p>Heterogeneous Effects of Deferred Action for Childhood Arrivals (DACA) on Undocumented College Students' Educational Outcomes <a href=\"http://osf.io/7xgh3/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/7xgh3/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/fce7q/",
    "title": "http://osf.io/fce7q/",
    "latest": "2023-03-09T19:26:34+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109994966703541452",
      "content": "<p>Does a Troubled Family Background Predict Adult Masturbation and Pornography Use? <a href=\"http://osf.io/fce7q/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/fce7q/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04093v1",
    "title": "https://arxiv.org/abs/2303.04093v1",
    "latest": "2023-03-09T18:22:29+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109994714705269408",
      "content": "<p>\ud83d\udcdd Marpa and Nullable Symbols \ud83d\udcda</p><p>\"In a nutshell: it's a matter of adding a bit of bookkeeping information to the parser, along the lines of what's done in a top-down parser.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/jeffreykegler/Marpa--R2/blob/master/cpan/pperl/Marpa/R2/Perl.pm\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/jeffreykegler/Marpa</span><span class=\"invisible\">--R2/blob/master/cpan/pperl/Marpa/R2/Perl.pm</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04093v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04093v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/qrgmp/",
    "title": "http://osf.io/qrgmp/",
    "latest": "2023-03-09T18:16:11+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109994689897795068",
      "content": "<p>How polarized is Europe? Public opinion disagreement, issue alignment, and sorting across European countries <a href=\"http://osf.io/qrgmp/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/qrgmp/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41599-023-01582-5",
    "title": "A bibliometric analysis of cultural heritage research in the humanities: The Web of Science as a tool of knowledge management - Humanities and Social Sciences Communications",
    "latest": "2023-03-09T18:03:50+00:00",
    "last_post": {
      "url": "https://fediscience.org/@petersuber/109994641382609779",
      "content": "<p>Update. A new study of the <a href=\"https://fediscience.org/tags/CulturalHeritage\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CulturalHeritage</span></a> research indexed in <a href=\"https://fediscience.org/tags/WOS\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>WOS</span></a> finds it skewed toward English-language publications and the global <a href=\"https://fediscience.org/tags/north\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>north</span></a>. The authors conclude that this is partly due to biases in the research itself and partly due to biases in what <a href=\"https://fediscience.org/tags/WOS\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>WOS</span></a> chooses to index.<br><a href=\"https://www.nature.com/articles/s41599-023-01582-5\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41599-023</span><span class=\"invisible\">-01582-5</span></a></p><p>\"WOS itself can be seen as a Western platform continuing the Eurocentric history of science.\" </p><p><a href=\"https://fediscience.org/tags/multilingualism\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>multilingualism</span></a> <a href=\"https://fediscience.org/tags/south\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>south</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@petersuber",
        "display_name": "petersuber"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04092v1",
    "title": "https://arxiv.org/abs/2303.04092v1",
    "latest": "2023-03-09T17:07:45+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109994420853345935",
      "content": "<p>\ud83d\udcdd CroCoSum: A Benchmark Dataset for Cross-Lingual Code-Switched Summarization \ud83d\udcda</p><p>\"CroCoSum is a collection of human generated summaries with code-switched sentences from technology news articles in English and Chinese language, with more than 92% of the summaries containing cod-switched phrases.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/RosenZhang/CroCoSum\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/RosenZhang/CroCoSum</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.04092v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04092v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/z93jm/",
    "title": "http://osf.io/z93jm/",
    "latest": "2023-03-09T10:01:55+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109992746366270888",
      "content": "<p>Why the United States Suffers from Exceptionally High Rates of Intentional Homicide: Cross-National and Intra-National Comparisons Demonstrate that the Primary Cause is the Extraordinarily High Rates of Firearms Possession That is Necessary to Sustain the Financial Health of the Gun Industry <a href=\"http://osf.io/z93jm/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/z93jm/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/5284s/",
    "title": "http://osf.io/5284s/",
    "latest": "2023-03-09T10:01:55+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109992746397959087",
      "content": "<p>The perils of male migration. The impact of male dominated migration on sex ratios in Germany and Austria <a href=\"http://osf.io/5284s/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/5284s/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04758",
    "title": "RANG: Reconstructing reproducible R computational environments",
    "latest": "2023-03-09T09:53:44+00:00",
    "last_post": {
      "url": "https://emacs.ch/@chainsawriot/109992670678569986",
      "content": "<p>New preprint with David Schoch: rang: Reconstructing reproducible <a href=\"https://emacs.ch/tags/rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rstats</span></a>  computational environments</p><p><a href=\"https://arxiv.org/abs/2303.04758\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04758</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@brodriguesco",
        "display_name": "Bruno Rodrigues :rstats: :tux:"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1140/epjs/s11734-022-00687-3",
    "title": "Recurrence flow measure of nonlinear dependence - The European Physical Journal Special Topics",
    "latest": "2023-03-09T09:26:59+00:00",
    "last_post": {
      "url": "https://mastodon.social/@pucicu/109988525982147746",
      "content": "<p>Our novel idea of a Recurrence flow measure of nonlinear dependence now published open access in @EPJST <a href=\"https://link.springer.com/article/10.1140/epjs/s11734-022-00687-3\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">140/epjs/s11734-022-00687-3</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@bendfulcher",
        "display_name": "bendfulcher"
      }
    ]
  },
  {
    "link": "https://doi.org/10.3389/fams.2023.1129105",
    "title": "doi.org/10.3389/fams.2023.1129...",
    "latest": "2023-03-09T09:26:40+00:00",
    "last_post": {
      "url": "https://mastodon.social/@pucicu/109992540347082824",
      "content": "<p>Now published: Challenges and perspectives in <a href=\"https://mastodon.social/tags/recurrence_analyses\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>recurrence_analyses</span></a> of <a href=\"https://mastodon.social/tags/event_time_series\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>event_time_series</span></a> in Frontiers in Applied Mathematics and Statistics<br> <a href=\"https://doi.org/10.3389/fams.2023.1129105\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.3389/fams.2023.1129</span><span class=\"invisible\">105</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@bendfulcher",
        "display_name": "bendfulcher"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2207.14382",
    "title": "Large Language Models and the Reverse Turing Test",
    "latest": "2023-03-09T07:54:26+00:00",
    "last_post": {
      "url": "https://federate.social/@Roundtrip/109860579092503903",
      "content": "<p>\u2018Large Language Models and the Reverse Turing Test\u2019 <br>Terrence Sejnowski (Nov 2022 v9)</p><p>A brilliant and enjoyable essay on Large Language Models, human cognition, and intelligence</p><p>\u201cA road map for achieving artificial general autonomy is outlined with seven major improvements inspired by brain systems.\u201d</p><p>Sejnowski is the Francis Crick Professor at the Salk Institute for Biological Studies where he directs the Computational Neurobiology Laboratory </p><p>\ud83e\uddf5 <a href=\"https://federate.social/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> <a href=\"https://federate.social/tags/AGI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AGI</span></a> <a href=\"https://federate.social/tags/cognition\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>cognition</span></a> </p><p><a href=\"https://arxiv.org/abs/2207.14382\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2207.14382</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03912v1",
    "title": "https://arxiv.org/abs/2303.03912v1",
    "latest": "2023-03-09T07:37:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109992178580832834",
      "content": "<p>\ud83d\udcdd Document-Level Relation Extraction with Cross-Sentence Reasoning Graph \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"A simplified document-level graph is constructed to model the semantic information of all mentions and sentences in a document, and an entity-level graph is designed to explore relations of long-distance cross-sentence entity pairs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/SI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/UESTC-LHF/GRACR\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/UESTC-LHF/GRACR</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.03912v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03912v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03846v1",
    "title": "Larger language models do in-context learning differently",
    "latest": "2023-03-09T05:07:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109991589139414945",
      "content": "<p>\ud83d\udcdd Larger Language Models Do in-Context Learning Differently \ud83d\udcda</p><p>\"A combination of two skills: semantic prior and input-label mapping learning abilities of language models that scale with model size and are further strengthened by instruction tuning.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.03846v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03846v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02083v1",
    "title": "Theory of Mind May Have Spontaneously Emerged in Large Language Models",
    "latest": "2023-03-09T04:54:24+00:00",
    "last_post": {
      "url": "https://sfba.social/@dangrsmind/109852624076959958",
      "content": "<p>A theory of mind may have spontaneously emerged in LLMs</p><p>(or not)</p><p><a href=\"https://arxiv.org/abs/2302.02083v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02083v1</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2212.09555",
    "title": "http://arxiv.org/abs/2212.09555",
    "latest": "2023-03-09T04:13:18.090000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/1b360103-fc83-497c-9643-c48846e3d43b",
      "content": "\"Interactive Cartoonization with Controllable Perceptual Factors. (arXiv:2212.09555v2 [cs.CV] UPDATED)\" \u2014 A model capable of converting input images to cartoons where you have the ability to control the texture and color of the final image.<br><br>Paper: <a href=\"http://arxiv.org/abs/2212.09555\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2212.09555</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/b2f36209e031d6046e3c87c6823bdc613da63004de89617f63a89f19c721a03d.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Example of the background makin\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03840v1",
    "title": "A Challenging Benchmark for Low-Resource Learning",
    "latest": "2023-03-09T03:52:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109991294346005664",
      "content": "<p>\ud83d\udcdd A Challenging Benchmark for Low-Resource Learning \ud83d\udcda\ud83d\udc7e</p><p>\"Proposes a challenging benchmark to better evaluate the learning ability under low-resource settings, which covers 2 CV datasets and 8 NLP datasets, and contains many hard examples.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.03840v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03840v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.04671",
    "title": "http://arxiv.org/abs/2303.04671",
    "latest": "2023-03-09T03:42:02.563000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/62387500-a8c1-4957-8931-49a31351d0e0",
      "content": "\"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models. (arXiv:2303.04671v1 [cs.CV])\" \u2014 An amalgamation of ChatGPT and image generation models such as Stable Diffusion to allow providing ChatGPT with not just text input but also images and to be able to provide visual questions or image editing instructions to ChatGPT.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.04671\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.04671</a><br>No repo exists on GitHub matching the one linked in the paper.<br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/0bd817a4df4d9a89063889060308673191ea0cacd1163cd121901b9efb28be6f.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Overview of Visual ChatGPT. The\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.04587",
    "title": "http://arxiv.org/abs/2303.04587",
    "latest": "2023-03-09T03:26:55.287000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/f727c2ec-dde1-4c45-b72a-c6699677cca3",
      "content": "\"A Prompt Log Analysis of Text-to-Image Generation Systems. (arXiv:2303.04587v1 [cs.HC])\" \u2014 Analyzing prompts used with diffusion models to get an idea of the informational needs of the users and to get an idea as to how to improve text-to-image generation systems.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.04587\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.04587</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/b5381b4745f4ce6a53ea4b98e004e13a9a6c01a46bc19db408a4d63ba3fe4dc7.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Two tables showing most frequen\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.04291",
    "title": "http://arxiv.org/abs/2303.04291",
    "latest": "2023-03-09T03:22:26.671000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/58bc2796-8cbe-4a43-92da-b2643422987e",
      "content": "\"Diffusion in the Dark: A Diffusion Model for Low-Light Text Recognition. (arXiv:2303.04291v1 [eess.IV])\" \u2014 Recognizing text in images taken under low-light conditions while preserving high-frequency details in the image.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.04291\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.04291</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/1ba6799cae2c71fbb6ec675000c084977579521368cd7a5c274f735351d98c64.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Low-light image reconstruction \u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.04208",
    "title": "http://arxiv.org/abs/2303.04208",
    "latest": "2023-03-09T03:02:21.650000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/f5576adc-47c4-4381-a9d3-518de1052d07",
      "content": "\"EscherNet 101. (arXiv:2303.04208v1 [cs.CV])\" \u2014 Teaching an artificial neural network symmetry groups and their relations as found in M. C. Escher drawings and other similar artwork.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.04208\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.04208</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/e58bf9a94898ff2857bd8894f701a426a15fcfe75963488bccff450a5ce983b8.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">(A) Three drawings by M.C. Esch\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2206.07682?mibextid=Zxz2cZ",
    "title": "Emergent Abilities of Large Language Models",
    "latest": "2023-03-09T01:54:19+00:00",
    "last_post": {
      "url": "https://universeodon.com/@rayh/109860909314740680",
      "content": "<p>e.g. \"Emergent abilities of Large Language Models\" by Wei et al</p><p><a href=\"https://arxiv.org/abs/2206.07682?mibextid=Zxz2cZ\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">arxiv.org/abs/2206.07682?mibex</span><span class=\"invisible\">tid=Zxz2cZ</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3488666",
    "title": "The steep cost of capture | Interactions",
    "latest": "2023-03-08T20:31:15+00:00",
    "last_post": {
      "url": "https://mastodon.world/@Mer__edith/109989558704521111",
      "content": "<p>TLRD, great AI capture is getting attention! But to address it, we need to tackle the political econ of tech, grapple w the term \"AI\" (&amp; who gets to define/apply it), &amp; recognize that extending access to BigTech infra/data entrenches the power dynamics at the root of the problem. </p><p>For those interested, here is the paper that lays this argument out in more detail: <a href=\"https://dl.acm.org/doi/10.1145/3488666\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">dl.acm.org/doi/10.1145/3488666</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.world/@Mer__edith",
        "display_name": "Meredith Whittaker"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/2515245918815849",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-03-08T20:19:05+00:00",
    "last_post": {
      "url": "https://mefi.social/@melissaekline/109989502190782749",
      "content": "<p><span class=\"h-card\"><a href=\"https://mastodon.social/@eckles\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>eckles</span></a></span>  I co-wrote a semi related paper that describes some potential infrastructure along these lines. You could probably create non-automated versions of many of the desiderata we describe. </p><p><a href=\"https://journals.sagepub.com/doi/10.1177/2515245918815849\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/2515245918815849</span></a></p><p>There are also now a few templates for preregistration of secondary data analyses out there,  usually with a corresponding paper that might describe some approaches that could be helpful!</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@eckles",
        "display_name": "Dean Eckles"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.11225",
    "title": "The Amplification Paradox in Recommender Systems",
    "latest": "2023-03-08T20:18:17+00:00",
    "last_post": {
      "url": "https://mastodon.social/@mmasnick/109989507737836766",
      "content": "<p>Hany Farid is completely making shit up now. He says that users like being taken to \"illegal\" content when it's recommended to them. Literally the studies say that's not true: <a href=\"https://arxiv.org/abs/2302.11225\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.11225</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://recsys.social/@karlhigley",
        "display_name": "Karl Higley"
      },
      {
        "url": "https://mastodon.social/@jonathanstray",
        "display_name": "Jonathan Stray"
      },
      {
        "url": "https://mastodon.social/@mmasnick",
        "display_name": "Mike Masnick \u2705"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03610",
    "title": "Revisiting the Transit Timing and Atmosphere Characterization of the Neptune-mass Planet HAT-P-26 b",
    "latest": "2023-03-08T20:03:06+00:00",
    "last_post": {
      "url": "https://astrodon.social/@eamonn_kerins/109989448007067019",
      "content": "<p>The other paper pushed out this week is here: <a href=\"https://arxiv.org/abs/2303.03610\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03610</span><span class=\"invisible\"></span></a>. it's led by my SPEARNET colleague, Napaporn A-thano. She has modeled the transmission spectrum of another exoplanet, Hat-P-26b. She's also used the data to look for possible evidence of any other planets in the system that may be gravitationally tugging on Hat-P-26b. (14/n)</p>"
    },
    "people": [
      {
        "url": "https://astrodon.social/@eamonn_kerins",
        "display_name": "Eamonn Kerins"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2103.12139",
    "title": "TransitFit: combined multi-instrument exoplanet transit fitting for JWST, HST and ground-based transmission spectroscopy studies",
    "latest": "2023-03-08T18:22:22+00:00",
    "last_post": {
      "url": "https://astrodon.social/@eamonn_kerins/109989051946141389",
      "content": "<p>So, what about the two papers I mentioned? The first is available here: <a href=\"https://arxiv.org/abs/2103.12139\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2103.12139</span><span class=\"invisible\"></span></a></p><p>It is led by two of my PhD students: Josh Hayes and Akshay Priyadarshi, and it presents a new code that the SPEARNET team has developed specifically to combine information from multiple telescope data to measure the chemistry of an <a href=\"https://astrodon.social/tags/exoplanet\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>exoplanet</span></a> <a href=\"https://astrodon.social/tags/atmosphere\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>atmosphere</span></a>. </p><p>But how exactly does this work?   (4/n)</p>"
    },
    "people": [
      {
        "url": "https://astrodon.social/@eamonn_kerins",
        "display_name": "Eamonn Kerins"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5210/fm.v27i11.12712",
    "title": "doi.org/10.5210/fm.v27i11.1271...",
    "latest": "2023-03-08T18:03:07+00:00",
    "last_post": {
      "url": "https://vis.social/@nrchtct/109988976202169312",
      "content": "<p>I\u2019ll start with a project that I was lucky to be involved in at <a href=\"https://vis.social/tags/FHPotsdam\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>FHPotsdam</span></a> and <span class=\"h-card\"><a href=\"https://vis.social/@uclab_potsdam\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>uclab_potsdam</span></a></span> - an attempt to visually explain a central concept of contemporary feminism:</p><p>\u00bbInter...what? Intersectionality A visual introduction\u00ab<br>by Hannah Schwan, Jonas Arndt and Sandra Cartes<br><a href=\"https://uclab.fh-potsdam.de/intervis/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">uclab.fh-potsdam.de/intervis/</span><span class=\"invisible\"></span></a></p><p>We also wrote a paper about the disclosure aspects of the data story:<br><a href=\"https://doi.org/10.5210/fm.v27i11.12712\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.5210/fm.v27i11.1271</span><span class=\"invisible\">2</span></a></p><p><a href=\"https://vis.social/tags/InternationalWomensDay\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>InternationalWomensDay</span></a> <a href=\"https://vis.social/tags/datafeminism\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>datafeminism</span></a> <a href=\"https://vis.social/tags/feministDataVis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>feministDataVis</span></a></p>"
    },
    "people": [
      {
        "url": "https://vis.social/@nrchtct",
        "display_name": "Marian D\u00f6rk"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03846",
    "title": "Larger language models do in-context learning differently",
    "latest": "2023-03-08T17:41:39+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109988891805728683",
      "content": "<p>Larger language models do in-context learning differently</p><p>Studies how in-context learning (ICL) in LMs is affected by semantic priors versus input\u2013label mappings.</p><p><a href=\"https://arxiv.org/abs/2303.03846\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03846</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03915",
    "title": "https://arxiv.org/abs/2303.03915",
    "latest": "2023-03-08T17:41:35+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109988891563638800",
      "content": "<p>The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset</p><p>Documents the data creation and curation efforts of ROOTS corpus, a 1.6TB dataset used to train BLOOM</p><p>Releases a large initial subset of the corpus</p><p>data: <a href=\"https://huggingface.co/bigscience-data\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">huggingface.co/bigscience-data</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.03915\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03915</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04129",
    "title": "Foundation Models for Decision Making: Problems, Methods, and Opportunities",
    "latest": "2023-03-08T17:41:31+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109988891323689726",
      "content": "<p>Foundation Models for Decision Making: Problems, Methods, and Opportunities</p><p>Reviews recent approaches that ground foundation models in practical decision making applications.</p><p><a href=\"https://arxiv.org/abs/2303.04129\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04129</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@andrey",
        "display_name": "Andrey Kurenkov"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04449",
    "title": "Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals",
    "latest": "2023-03-08T17:41:28+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109988891095794471",
      "content": "<p>RT @johnjnay@twitter.com</p><p>Speeding up RL w/ LLMs Reading Manuals</p><p>-Finds &amp; summarizes info from Atari manuals<br>-LLM evaluates agent actions based on manual</p><p>-Improves on games w/ sparse rewards<br>-Requires 1000x less training frames than previous SoTA on hardest Atari game</p><p>Paper: <a href=\"https://arxiv.org/abs/2302.04449\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04449</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/johnjnay/status/1633272031461400579\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/johnjnay/status/16</span><span class=\"invisible\">33272031461400579</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05022",
    "title": "https://doi.org/10.21105/joss.05022",
    "latest": "2023-03-08T10:00:44+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109987079425083919",
      "content": "<p>Just published in JOSS: 'Persistable: persistent and stable clustering' <a href=\"https://doi.org/10.21105/joss.05022\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05022</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.02468v1",
    "title": "https://arxiv.org/abs/2303.02468v1",
    "latest": "2023-03-08T09:22:17+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109986928241924540",
      "content": "<p>\ud83d\udcdd Lon-E\u00e5 at SemEval-2023 Task 11: A Comparison Of\\\\Activation Functions for Soft and Hard Label Prediction \ud83d\udcda\ud83e\udde0</p><p>\"Uses BERT, RoBERTa and XLNet models for the soft label prediction task and vary the activation function used in the output layer, while keeping other parameters constant.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Speymanhs/SemEval_2023_Task_\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/Speymanhs/SemEval_2</span><span class=\"invisible\">023_Task_</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.02468v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.02468v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/09637214211057841",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-03-08T08:40:16+00:00",
    "last_post": {
      "url": "https://mastodon.online/@tomstafford/109986759600413973",
      "content": "<p>For those who missed it, here is a recording of my talk @ Centre for Educational Neuroscience, UCL</p><p>\"Maximizing the potential of digital games for understanding skill acquisition\"<br><a href=\"https://www.youtube.com/watch?v=En1lBcGTpo0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">youtube.com/watch?v=En1lBcGTpo</span><span class=\"invisible\">0</span></a></p><p>Key paper: <a href=\"https://journals.sagepub.com/doi/10.1177/09637214211057841\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/09637214211057841</span></a></p>"
    },
    "people": [
      {
        "url": "https://ciberlandia.pt/@villares",
        "display_name": "Alexandre B A Villares \ud83d\udc0d"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2109.07958",
    "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
    "latest": "2023-03-08T04:53:58+00:00",
    "last_post": {
      "url": "https://mastodon.social/@thefirstred/109855640613669874",
      "content": "<p>\u201cWe tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58% of questions, while human perf. was 94%. The LARGEST models were generally the LEAST truthful. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution.\" <br><a href=\"https://arxiv.org/abs/2109.07958\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2109.07958</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.02357v1",
    "title": "DiTTO: A Feature Representation Imitation Approach for Improving Cross-Lingual Transfer",
    "latest": "2023-03-08T04:37:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109985808283550106",
      "content": "<p>\ud83d\udcdd DiTTO: A Feature Representation Imitation Approach for Improving Cross-Lingual Transfer \ud83d\udcda\ud83d\udc7e</p><p>\"We jointly reduce the feature incongruity between the source and the target language and increase the generalization capabilities of pre-trained multilingual transformers for cross-lingual transfer by adapting the transformer model on multiple target language data.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.02357v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.02357v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3555538",
    "title": "https://dl.acm.org/doi/10.1145/3555538",
    "latest": "2023-03-08T04:20:31+00:00",
    "last_post": {
      "url": "https://hci.social/@sabid/109982801135359665",
      "content": "<p>A precise summary of our work on \"Bitrotting Photos for Enhanced Privacy\" by <span class=\"h-card\"><a href=\"https://hci.social/@apukapadia\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>apukapadia</span></a></span> in the Shifting Privacy Left Podcast: <a href=\"https://shiftingprivacyleft.com/audio/8323/402170\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">shiftingprivacyleft.com/audio/</span><span class=\"invisible\">8323/402170</span></a><br>Detail: <a href=\"https://dl.acm.org/doi/10.1145/3555538\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">dl.acm.org/doi/10.1145/3555538</span><span class=\"invisible\"></span></a></p><p>He also talks about the work on \"Tangible Privacy in Smart Home\" by <span class=\"h-card\"><a href=\"https://hci.social/@imtahmad\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>imtahmad</span></a></span> and <span class=\"h-card\"><a href=\"https://hci.social/@taslima\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>taslima</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@andresmh",
        "display_name": "Andr\u00e9s Monroy-Hern\u00e1ndez"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.03405",
    "title": "http://arxiv.org/abs/2303.03405",
    "latest": "2023-03-08T03:55:58.322000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/4215b443-370b-41b3-91d9-24f78a45a294",
      "content": "\"Neural Style Transfer for Vector Graphics. (arXiv:2303.03405v1 [cs.CV])\" \u2014 Transferring style from an input style image to an source vector image to create a target vector image that adheres to the style of the input style image.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.03405\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.03405</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/e30da26a4afb12c5972276065e088f7d6c25aa800920c2120c3b9205f1d0de7a.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">We propose a novel neural style\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.03755",
    "title": "http://arxiv.org/abs/2303.03755",
    "latest": "2023-03-08T03:35:17.376000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/74e9d1ca-4701-486c-87cc-c1c4e83affa5",
      "content": "\"DLT: Conditioned layout generation with Joint Discrete-Continuous Diffusion Layout Transformer. (arXiv:2303.03755v1 [cs.CV])\" \u2014 Using diffusion models to create visual layouts as part of graphics design.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.03755\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.03755</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/0617194fd7b0b4e9b36d5d9f910ec41a9297bc68ce456851a028ca6f9ea8396f.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Overview of our Joint Discrete-\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2301.13302.pdf",
    "title": "https://arxiv.org/pdf/2301.13302.pdf",
    "latest": "2023-03-08T02:26:14+00:00",
    "last_post": {
      "url": "https://vis.social/@mcnutt/109985292259031351",
      "content": "<p>In \u201cA Study of Editor Features in a Creative Coding Classroom\u201d (<a href=\"https://arxiv.org/pdf/2301.13302.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2301.13302.pdf</span><span class=\"invisible\"></span></a>) we explore editor design in a creative coding course. We reflect on 5 iterations of a course for non-majors (<a href=\"http://cs111.org/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">cs111.org/</span><span class=\"invisible\"></span></a>)  (which also has some *fancy* modifications)</p><p>We find that usage of advanced features (eg bidirectionality) may initially be perceived as detrimental to learning; in practice it ends up being like a calculator in a math class. Old problems get out of the way for new ones!</p>"
    },
    "people": [
      {
        "url": "https://vis.social/@mcnutt",
        "display_name": "Andrew McNutt"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2301.11178.pdf",
    "title": "https://arxiv.org/pdf/2301.11178.pdf",
    "latest": "2023-03-08T02:22:29+00:00",
    "last_post": {
      "url": "https://vis.social/@mcnutt/109985277506599100",
      "content": "<p>In \u201cOn the Design of AI-powered Code Assistants for Notebooks\u201d (<a href=\"https://arxiv.org/pdf/2301.11178.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2301.11178.pdf</span><span class=\"invisible\"></span></a>) we study the role the copilot style assistants might have in notebooks. We conduct a design space analysis, which we then use as the basis for interviews with practicing data scientists.</p><p>We find that data scientists value assistants that help them do tasks that are not perceived as being central to their intellectual contribution. Suggesting that such assistants should then be akin to ghost writers.</p>"
    },
    "people": [
      {
        "url": "https://vis.social/@mcnutt",
        "display_name": "Andrew McNutt"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.02242v1",
    "title": "https://arxiv.org/abs/2303.02242v1",
    "latest": "2023-03-08T02:22:26+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109985277285311701",
      "content": "<p>\ud83d\udcdd TrojText: Test-Time Invisible Textual Trojan Insertion \ud83d\udcda</p><p>\"The proposed approach, called the Representation-Logit Trojan Insertion (RLI) algorithm, uses smaller sampled test data instead of large training data to achieve the desired attack.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/UCF-ML-Research/TrojText\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/UCF-ML-Research/Tro</span><span class=\"invisible\">jText</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.02242v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.02242v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s42803-022-00054-7",
    "title": "Civil service examination records and political independence in the autonomous northeastern region during the second half of the Tang dynasty (755\u2013907 C.E.)",
    "latest": "2023-03-08T02:14:02+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@WenyiShang/109983673208648595",
      "content": "<p>My article with <br><span class=\"h-card\"><a href=\"https://sigmoid.social/@TedUnderwood\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>TedUnderwood</span></a></span><br> for the special issue of <a href=\"https://sigmoid.social/tags/IJDH\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>IJDH</span></a> on digital humanities and East Asia studies is available at: <a href=\"https://rdcu.be/cXhLQ\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">rdcu.be/cXhLQ</span><span class=\"invisible\"></span></a>. The article in the journal website can be found at: <a href=\"https://link.springer.com/article/10.1007/s42803-022-00054-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s42803-022-00054-7</span></a>.<br>We discussed the relationship between civil service examination records and political independence in Tang China (755\u2013907 C.E.) 1/7</p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@quinnanya",
        "display_name": "Quinn Dombrowski"
      },
      {
        "url": "https://sigmoid.social/@TedUnderwood",
        "display_name": "Ted Underwood"
      },
      {
        "url": "https://mastodon.social/@jose_eduardo",
        "display_name": "Jos\u00e9 Eduardo Gonz\u00e1lez"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04761v1",
    "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
    "latest": "2023-03-08T01:53:56+00:00",
    "last_post": {
      "url": "https://techhub.social/@nic221/109855433152918127",
      "content": "<p>Toolformer: Language Models Can Teach Themselves to Use Tools <a href=\"https://arxiv.org/abs/2302.04761v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04761v1</span><span class=\"invisible\"></span></a> <a href=\"https://techhub.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.nature.com/collections/hjhbgijcei",
    "title": "Applied physics and mathematics",
    "latest": "2023-03-07T20:36:01+00:00",
    "last_post": {
      "url": "https://social.skewed.de/@tiago/109983915149411768",
      "content": "<p>Crosspost from @sees_lab@twitter.com:</p><p>Our article on fundamental limits  to learning closed-form mathematical models from data has now been featured in the @NatureComms@twitter.com Editors\u2019 Highlights collection on Applied physics and mathematics!</p><p>Excited to see our work among such great pieces! <a href=\"https://www.nature.com/collections/hjhbgijcei\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/collections/hjhbgij</span><span class=\"invisible\">cei</span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/sees_lab/status/1633156397943627776\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/sees_lab/status/16</span><span class=\"invisible\">33156397943627776</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3290605.3300469",
    "title": "AI-Mediated Communication | Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
    "latest": "2023-03-07T20:29:46+00:00",
    "last_post": {
      "url": "https://hci.social/@Mor/109983890594190437",
      "content": "<p>Why is this important? It's now clear that more of our online content and communication will be generated by AI. In our previous work, we demonstrated the \"Replicant Effect\": as soon as the use of AI is suspected, evaluations of trustworthiness drop.</p><p><a href=\"https://dl.acm.org/doi/10.1145/3290605.3300469\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/10.1145/3290605</span><span class=\"invisible\">.3300469</span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@Mor",
        "display_name": "Mor Naaman"
      }
    ]
  },
  {
    "link": "https://doi.org/10.48550/arXiv.2206.04603",
    "title": "doi.org/10.48550/arXiv.2206.04...",
    "latest": "2023-03-07T20:20:30+00:00",
    "last_post": {
      "url": "https://neuromatch.social/@NicoleCRust/109983712786015333",
      "content": "<p>I've slowly been enjoying this (157 page monster):</p><p><p>In search for an alternative to the computer metaphor of the mind and brain.  </p></p><p>It's set up in a clever way, with different authors making the case for different metaphors. I'm not sure if any of the authors are here? Either way, I'd love to hear thoughts, including what strikes you as the most (or least) convincing \"new\" metaphors. </p><p><a href=\"https://doi.org/10.48550/arXiv.2206.04603\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.48550/arXiv.2206.04</span><span class=\"invisible\">603</span></a></p>"
    },
    "people": [
      {
        "url": "https://scicomm.xyz/@sharoz",
        "display_name": "Steve Haroz (@sharoz on \ud83d\udc24)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.03281",
    "title": "Visual Place Recognition: A Tutorial",
    "latest": "2023-03-07T20:11:41+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@at/109982882859844190",
      "content": "<p>Visual Place Recognition: A Tutorial<br>Stefan Schubert, Peer Neubert, Sourav Garg, Michael Milford, Tobias Fischer </p><p>[15 pages] presents VPR for newcomers &amp; deals with evaluation. Maybe the code would serve as a good baseline method?</p><p>abs:<a href=\"https://arxiv.org/abs/2303.03281\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.03281</span><span class=\"invisible\"></span></a> <br>code: <a href=\"https://github.com/stschubert/VPR_Tutorial\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/stschubert/VPR_Tuto</span><span class=\"invisible\">rial</span></a> <br><a href=\"https://sigmoid.social/tags/VPR\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>VPR</span></a> <a href=\"https://sigmoid.social/tags/ComputerVision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ComputerVision</span></a> <a href=\"https://sigmoid.social/tags/arXiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arXiv</span></a> <a href=\"https://sigmoid.social/tags/AmyPostsPapers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AmyPostsPapers</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@hue",
        "display_name": "Hue :notverified:"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41467-022-34113-y",
    "title": "The emergence and development of behavioral individuality in clonal fish - Nature Communications",
    "latest": "2023-03-07T19:58:56+00:00",
    "last_post": {
      "url": "https://vis.social/@jhilden/109983769310367803",
      "content": "<p>Extremely interesting paper!<br>Even small naturally clonal fish are still individuals. Bad news for genetic determinism. The setup is also neat. <a href=\"https://vis.social/tags/biology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>biology</span></a> <a href=\"https://vis.social/tags/genetics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>genetics</span></a> </p><p>\u201dWe show that genetically identical individuals already exhibit substantial behavioral individuality on their first day of life, highlighting pre-birth influences as being of critical importance to initializing durable behavioral differences among individuals.\u201d</p><p><a href=\"https://www.nature.com/articles/s41467-022-34113-y\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41467-022</span><span class=\"invisible\">-34113-y</span></a></p>"
    },
    "people": [
      {
        "url": "https://vis.social/@jhilden",
        "display_name": "Jonatan Hild\u00e9n"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.10559",
    "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
    "latest": "2023-03-07T19:53:51+00:00",
    "last_post": {
      "url": "https://tilde.zone/@left_adjoint/109854592661078770",
      "content": "<p>This paper is kinda interesting. I'm digesting the technical content but at least the gist of it kinda makes sense: pre-pending text to prompts, when you're using attention layers, does something equivalent to a fine-tuning process</p><p><a href=\"https://arxiv.org/abs/2212.10559\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.10559</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01903v1",
    "title": "Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering",
    "latest": "2023-03-07T19:52:53+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109983745561419804",
      "content": "<p>\ud83d\udcdd Prompting Large Language Models with Answer Heuristics for Knowledge-Based Visual Question Answering \ud83d\udd2d\ud83d\udcda\ud83e\udde0</p><p>\"Trains a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge, then extract answer heuristics from that model, including the top-K answer candidates and the question-image-answer examples.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01903v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01903v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3545945.3569855",
    "title": "Incorporating Ethics in Computing Courses | Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1",
    "latest": "2023-03-07T19:15:30+00:00",
    "last_post": {
      "url": "https://hci.social/@cfiesler/109983598536130508",
      "content": "<p>In general the panel here on \u201cbuy in\u201d is bringing up a lot of the barriers to ethics integration in computing classes that we identified in this upcoming <a href=\"https://hci.social/tags/sigcse2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>sigcse2023</span></a> paper: not enough control over the curriculum, not enough relevant knowledge, poor incentive structures, not enough support, etc. <a href=\"https://dl.acm.org/doi/10.1145/3545945.3569855\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/10.1145/3545945</span><span class=\"invisible\">.3569855</span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@cfiesler",
        "display_name": "Dr. Casey Fiesler"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1038/s41558-023-01605-8",
    "title": "doi.org/10.1038/s41558-023-016...",
    "latest": "2023-03-07T19:13:48+00:00",
    "last_post": {
      "url": "https://mastodon.social/@ojala/109983591828833901",
      "content": "<p>\"Future warming from global food consumption\" methane appears to have a much larger role than the one usually discussed in Aotearoa New Zealand.</p><p><a href=\"https://doi.org/10.1038/s41558-023-01605-8\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1038/s41558-023-016</span><span class=\"invisible\">05-8</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@ojala",
        "display_name": "Luis Apiolaza"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04416",
    "title": "https://doi.org/10.21105/joss.04416",
    "latest": "2023-03-07T17:52:01+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109983270254507742",
      "content": "<p>Just published in JOSS: 'pydynpd: A Python package for dynamic panel model' <a href=\"https://doi.org/10.21105/joss.04416\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04416</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/1701.03077",
    "title": "A General and Adaptive Robust Loss Function",
    "latest": "2023-03-07T09:58:13+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/109981407194929999",
      "content": "<p>There are examples of self-tuning loss functions that improve results:<br><a href=\"https://arxiv.org/abs/1701.03077\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1701.03077</span><span class=\"invisible\"></span></a></p><p>.. but do you know examples of self-hardening OHEM-style loss functions?<br><a href=\"https://arxiv.org/abs/1604.03540\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1604.03540</span><span class=\"invisible\"></span></a></p><p>The idea is to make the problem as hard as the model can handle it, via loss function.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/1604.03540",
    "title": "https://arxiv.org/abs/1604.03540",
    "latest": "2023-03-07T09:58:13+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/109981407194929999",
      "content": "<p>There are examples of self-tuning loss functions that improve results:<br><a href=\"https://arxiv.org/abs/1701.03077\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1701.03077</span><span class=\"invisible\"></span></a></p><p>.. but do you know examples of self-hardening OHEM-style loss functions?<br><a href=\"https://arxiv.org/abs/1604.03540\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1604.03540</span><span class=\"invisible\"></span></a></p><p>The idea is to make the problem as hard as the model can handle it, via loss function.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21100/msor.v21i1",
    "title": "https://doi.org/10.21100/msor.v21i1",
    "latest": "2023-03-07T09:52:45+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@peterrowlett/109981385713481890",
      "content": "<p>The new issue of MSOR Connections is available. It collects some of the papers from last year's CETL-MSOR Conference, covering teaching, learning, assessment and support in maths, stats and OR university teaching. Enjoy! </p><p><a href=\"https://doi.org/10.21100/msor.v21i1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21100/msor.v21i1</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@peterrowlett",
        "display_name": "Peter Rowlett"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3442188.3445922",
    "title": "On the Dangers of Stochastic Parrots | Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
    "latest": "2023-03-07T09:52:25+00:00",
    "last_post": {
      "url": "https://tech.lgbt/@jesper/109981384411349005",
      "content": "<p><span class=\"h-card\"><a href=\"https://sigmoid.social/@Adverb\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Adverb</span></a></span> <a href=\"https://dl.acm.org/doi/10.1145/3442188.3445922\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/10.1145/3442188</span><span class=\"invisible\">.3445922</span></a></p><p>You misspelled psychology there</p>"
    },
    "people": [
      {
        "url": "https://mamot.fr/@pluralistic",
        "display_name": "Cory Doctorow's linkblog"
      },
      {
        "url": "https://mstdn.social/@emmatonkin",
        "display_name": ""
      },
      {
        "url": "https://tech.lgbt/@jesper",
        "display_name": "Jesper Dr.amsch :v_enby:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01912v1",
    "title": "https://arxiv.org/abs/2303.01912v1",
    "latest": "2023-03-07T08:52:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109981149380294452",
      "content": "<p>\ud83d\udcdd Ancient Chinese Word Segmentation and Part-of-Speech Tagging Using Distant Supervision \ud83d\udcda</p><p>\"Uses distant supervision over parallel corpus to augment ancient Chinese word segmentation and part-of-speech tagging data and then uses the small amount of annotated data to relabel the data generated from distant supervision.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/farlit/ACDS\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/farlit/ACDS</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01912v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01912v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2212.03860",
    "title": "http://arxiv.org/abs/2212.03860",
    "latest": "2023-03-07T07:38:50+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/109980859144462040",
      "content": "<p>RT @micahgoldblum@twitter.com</p><p>Diffusion models like <a href=\"https://creative.ai/tags/StableDiffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>StableDiffusion</span></a> and <a href=\"https://creative.ai/tags/dalle2\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dalle2</span></a> generate beautiful pictures, but are these images new or are they copies of the images they were trained on? \ud83e\uddf5 <a href=\"https://creative.ai/tags/CVPR2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CVPR2023</span></a><br><a href=\"http://arxiv.org/abs/2212.03860\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2212.03860</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/micahgoldblum/status/1632759852803014660\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/micahgoldblum/stat</span><span class=\"invisible\">us/1632759852803014660</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01542v1",
    "title": "Self-attention in Vision Transformers Performs Perceptual Grouping, Not Attention",
    "latest": "2023-03-07T07:23:00+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cv/109979498630632771",
      "content": "<p>\ud83d\udcdd Self-Attention in Vision Transformers Performs Perceptual Grouping, Not Attention \ud83d\udd2d</p><p>\"Self-attention mechanism of vision transformers implements a special type of relaxation labeling with similarity grouping effects which is different from the mechanisms involved in human visual attention and saliency detection.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01542v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01542v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@Adverb",
        "display_name": "Advadnoun"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01911v1",
    "title": "https://arxiv.org/abs/2303.01911v1",
    "latest": "2023-03-07T06:37:40+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109980618595791087",
      "content": "<p>\ud83d\udcdd Investigating the Translation Performance of a Large Multilingual Language Model: The Case of BLOOM \ud83d\udcda</p><p>\"BLOOM is a 200 billion parameter language model trained in a multi-task learning paradigm over 46 typologically diverse languages on 720GB of filtered CommonCrawl data.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/rbawden/mtbigscience\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/rbawden/mtbigscienc</span><span class=\"invisible\">e</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01911v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01911v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.02747",
    "title": "Flow Matching for Generative Modeling",
    "latest": "2023-03-07T06:23:38+00:00",
    "last_post": {
      "url": "https://mastodon.social/@matrig/109873278684362714",
      "content": "<p>This <a href=\"https://mastodon.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a> paper at <a href=\"https://mastodon.social/tags/ICLR2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ICLR2023</span></a> seems quite neat:</p><p>'Flow Matching for Generative Modeling' by Lipman et al. generalizes diffusion models and improves on them in training speed, sampling efficiency and generation quality.<br><a href=\"https://mastodon.social/tags/DeepLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeepLearning</span></a> <br><a href=\"https://arxiv.org/abs/2210.02747\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.02747</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21825/dlh.85750",
    "title": "https://doi.org/10.21825/dlh.85750",
    "latest": "2023-03-07T05:59:12+00:00",
    "last_post": {
      "url": "https://akademienl.social/@maxkemman/109976179891001681",
      "content": "<p>Very happy with this review of my book in the inaugural issue of the Journal for Digital Legal History by Femke Gordijn: \"Trading Zones of Digital History is a highly recommended read for all involved in digital history projects or those who aspire to be\" <a href=\"https://doi.org/10.21825/dlh.85750\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21825/dlh.85750</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://hcommons.social/@librarifran",
        "display_name": "franny gaede"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.02460",
    "title": "http://arxiv.org/abs/2303.02460",
    "latest": "2023-03-07T05:08:51.785000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/3ef61e34-c321-4b19-8c06-e4e977a72914",
      "content": "\"Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis. (arXiv:2303.02460v1 [cs.CV])\" \u2014 What it says in the title, an improved dataset for agricultural pattern analysis.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.02460\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.02460</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/32c29666323dffcb1688710322db62d9ea222cfc0652217882c433f32c0bf9f7.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Left: Full-field imagery (RGB-o\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.02490",
    "title": "http://arxiv.org/abs/2303.02490",
    "latest": "2023-03-07T05:05:14.317000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/9c8a8af4-1e9b-4dfb-a956-3740e30e29de",
      "content": "\"Diffusion Models Generate Images Like Painters: an Analytical Theory of Outline First, Details Later. (arXiv:2303.02490v1 [cs.CV])\" \u2014 An exploration of the the theory that diffusion models generate images like painters creating a painting: that it involves first committing to an outline, and then adding in finer details.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.02490\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.02490</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/ad0d4d2ff83fe02dba993e018a3624ea8f552b5e9315aace7cc3f03b19d42e11.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Characteristics of image genera\u2026</a>"
    },
    "people": [
      {
        "url": "https://corteximplant.com/@lardratboy",
        "display_name": "Brad P. Taylor"
      },
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2209.12152",
    "title": "http://arxiv.org/abs/2209.12152",
    "latest": "2023-03-07T04:53:15.839000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/fa5c5c0e-419f-4914-9292-65343f88347b",
      "content": "\"All are Worth Words: A ViT Backbone for Diffusion Models. (arXiv:2209.12152v3 [cs.CV] UPDATED)\" \u2014 A simple and general ViT-based architecture for image generation with diffusion models which is capable of unconditional and class-conditional image generation, as well as text-to-image generation tasks.<br><br>Paper: <a href=\"http://arxiv.org/abs/2209.12152\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2209.12152</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/1b42bb7e82ef3fd2d816cda2df8b48f8138153211579447d5b740a3b8df313c1.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Text-to-image generation on MS-\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.03371.pdf",
    "title": "https://arxiv.org/pdf/2303.03371.pdf",
    "latest": "2023-03-07T03:41:26+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/109979925670391750",
      "content": "<p>\"Complex Systems of Secrecy: The Offshore Networks of Oligarchs\"</p><p>Following the invasion of Ukraine, the US, UK, and EU governments--among others--sanctioned oligarchs close to Putin. This approach has come under scrutiny ..  To address this problem, we analyze the role of an overlooked but highly influential group: the secretive professional intermediaries who create and administer the oligarchs' offshore financial empires. ...</p><p><a href=\"https://arxiv.org/pdf/2303.03371.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.03371.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/sanctions\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>sanctions</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s42803-022-00063-6",
    "title": "DH in Japanese studies, Japanese studies in DH: Recent trends, tools, and concepts - International Journal of Digital Humanities",
    "latest": "2023-03-07T03:22:21+00:00",
    "last_post": {
      "url": "https://fedihum.org/@christof/109975067388205997",
      "content": "<p>As a complement to the visit of colleagues from <a href=\"https://fedihum.org/tags/Tokyo\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Tokyo</span></a> to the <span class=\"h-card\"><a href=\"https://fedihum.org/@tcdh\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>tcdh</span></a></span> recently, here's a paper on \"<a href=\"https://fedihum.org/tags/DH\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DH</span></a> in <a href=\"https://fedihum.org/tags/Japanese\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Japanese</span></a> studies, Japanese studies in DH: Recent trends, tools, and concepts\" by <span class=\"h-card\"><a href=\"https://fedihum.org/@alizhorvathaliz\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>alizhorvathaliz</span></a></span> \u2013 It appeared <a href=\"https://fedihum.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> in the  <br>International Journal of Digital Humanities (<a href=\"https://fedihum.org/tags/IJDH\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>IJDH</span></a>): <a href=\"https://link.springer.com/article/10.1007/s42803-022-00063-6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s42803-022-00063-6</span></a> <a href=\"https://fedihum.org/tags/DigitalHumanities\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DigitalHumanities</span></a> <a href=\"https://fedihum.org/tags/Japan\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Japan</span></a> <a href=\"https://fedihum.org/tags/multilingualism\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>multilingualism</span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@felwert",
        "display_name": "Frederik Elwert"
      },
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch (moderator)"
      },
      {
        "url": "https://dair-community.social/@miriamkp",
        "display_name": "Miriam Posner"
      },
      {
        "url": "https://mstdn.social/@quinnanya",
        "display_name": "Quinn Dombrowski"
      },
      {
        "url": "https://hcommons.social/@librarifran",
        "display_name": "franny gaede"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01795v1",
    "title": "https://arxiv.org/abs/2303.01795v1",
    "latest": "2023-03-07T02:07:51+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109979557651864356",
      "content": "<p>\ud83d\udcdd PAGE: A Position-Aware Graph-Based Model for Emotion Cause Entailment in Conversation \ud83d\udcda</p><p>\"A position-aware graph is built to encode the entire conversation, fully modeling causal relations among utterances, which are then utilized to learn the representation of target utterances for emotion entailment recognition.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/XiaojieGu/PAGE\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/XiaojieGu/PAGE</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01795v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01795v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04023",
    "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",
    "latest": "2023-03-07T01:50:49+00:00",
    "last_post": {
      "url": "https://paquita.masto.host/@fbpsy/109851226460116202",
      "content": "<p>Si no sab\u00e9is a qu\u00e9 me refiero, aqu\u00ed un ejemplo. Todos estos papers siguen la misma l\u00f3gica. Como ChatGPT permite interactuar por escrito, se le muestran como prompt los materiales de un test verbal dise\u00f1ado para humanos, y se registra la respuesta que da.</p><p><a href=\"https://arxiv.org/abs/2302.04023\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04023</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.08110",
    "title": "https://arxiv.org/abs/2301.08110",
    "latest": "2023-03-06T21:17:58+00:00",
    "last_post": {
      "url": "https://infosec.exchange/@Lola_Attenberger/109868462160690949",
      "content": "<p>Generative Pre-trained Models <a href=\"https://infosec.exchange/tags/GPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GPT</span></a> also generates false information. Researchers therefore attempt to improve the output. <br>There is an interesting discussion on twitter surrounding a research paper which attempts to improve the comprehending of the model\u2018s text generation. </p><p>It shows as well the importance of the correct data set by which the <a href=\"https://infosec.exchange/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> needs to be fed with.</p><p><a href=\"https://twitter.com/jonasandrulis/status/1616722810608427008?s=12&amp;t=3fCkU-Uwd1GHzOGvQBspCg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/jonasandrulis/stat</span><span class=\"invisible\">us/1616722810608427008?s=12&amp;t=3fCkU-Uwd1GHzOGvQBspCg</span></a> <br><a href=\"https://arxiv.org/abs/2301.08110\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.08110</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01580v1",
    "title": "Mixture of Soft Prompts for Controllable Data Generation",
    "latest": "2023-03-06T20:22:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109978200236177461",
      "content": "<p>\ud83d\udcdd Mixture of Soft Prompts for Controllable Data Generation \ud83d\udcda</p><p>\"A Mixture of Soft Prompts (MSP) serves as a parameter-efficient procedure for generating data in a controlled manner, where the prompts are optimized using gradient descent.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01580v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01580v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41550-023-01903-3",
    "title": "The impact of satellite trails on Hubble Space Telescope observations - Nature Astronomy",
    "latest": "2023-03-06T20:13:51+00:00",
    "last_post": {
      "url": "https://m.universetoday.com/@fraser/109977191264827321",
      "content": "<p>Hubble's Orbit Has Dropped so far that Starlinks are Phobobombing its Images</p><p>With the rise in satellite constellations, astronomers are finding that more and more of their images have a satellite trail obscuring some of their data. Just use space telescopes? Unfortunately, it appears that space telescopes like Hubble are having the same problem. Hubble's orbit has been decaying for years, and it's now so low that it's beneath Starlink shells. A new study reveals some of the satellite trails passing through science images.</p><p><a href=\"https://www.nature.com/articles/s41550-023-01903-3\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41550-023</span><span class=\"invisible\">-01903-3</span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@bkeegan",
        "display_name": "Brian C. Keegan"
      },
      {
        "url": "https://zirk.us/@man",
        "display_name": "Man Bartlett"
      },
      {
        "url": "https://wandering.shop/@sargent",
        "display_name": "Stephen Granade"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1016/S0140-6736(23)00349-5",
    "title": "doi.org/10.1016/S0140-6736(23)...",
    "latest": "2023-03-06T18:37:11+00:00",
    "last_post": {
      "url": "https://mastodon.social/@eckles/109977785551206665",
      "content": "<p>This is an impressive RCT. One weird thing is that the main analysis seems to avoid using multiple observations per household, despite cluster-randomization. So no estimates of spillovers, but also just discarded data...<br><a href=\"https://doi.org/10.1016/S0140-6736(23)00349-5\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1016/S0140-6736(23)</span><span class=\"invisible\">00349-5</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@eckles",
        "display_name": "Dean Eckles"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.04449.pdf",
    "title": "https://arxiv.org/pdf/2302.04449.pdf",
    "latest": "2023-03-06T18:28:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@andrey/109977751176785365",
      "content": "<p>oooh look at this paper \"Read and Reap the Rewards:Learning to Play Atari with the Help of Instruction Manuals\"</p><p>I wrote about how it doesn't make sense for game RL agents to not 'read' instructions/rules all the way back in 2018, hope this becomes norm.</p><p><a href=\"https://arxiv.org/pdf/2302.04449.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.04449.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@andrey",
        "display_name": "Andrey Kurenkov"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.13382",
    "title": "Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task",
    "latest": "2023-03-06T18:17:54+00:00",
    "last_post": {
      "url": "https://mstdn.io/@ayourtch/109866344537744346",
      "content": "<p><a href=\"https://arxiv.org/abs/2210.13382\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.13382</span><span class=\"invisible\"></span></a> So the AI builds the model of the world internally. How far is it from there to having a self-representation in that model of the world ? (Which is often associated with conscience)\u2026</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.12353",
    "title": "Autonomous Restructuring of Asteroids into Rotating Space Stations",
    "latest": "2023-03-06T17:55:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/109977619856829661",
      "content": "<p>Autonomous Restructuring of Asteroids into Rotating Space Stations - <a href=\"https://arxiv.org/abs/2302.12353\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.12353</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2208.07132",
    "title": "Intuitive Joint Priors for Bayesian Linear Multilevel Models: The R2D2M2 prior",
    "latest": "2023-03-06T17:43:36+00:00",
    "last_post": {
      "url": "https://bayes.club/@twiecki/109977574882865531",
      "content": "<p>Getting our math on at the  <span class=\"h-card\"><a href=\"https://bayes.club/@pymc_labs\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>pymc_labs</span></a></span> team meeting with Max Kochurov talking about his extensions to the R2D2M2 model for a more intuitive way to specify priors for regression coefficients <a href=\"https://arxiv.org/abs/2208.07132\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2208.07132</span><span class=\"invisible\"></span></a>.</p>"
    },
    "people": [
      {
        "url": "https://bayes.club/@twiecki",
        "display_name": "Thomas Wiecki"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s11214-022-00882-7",
    "title": "link.springer.com/article/10.1...",
    "latest": "2023-03-06T17:38:48+00:00",
    "last_post": {
      "url": "https://wandering.shop/@elakdawalla/109977555993627382",
      "content": "<p>When you have <a href=\"https://wandering.shop/tags/ADHD\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ADHD</span></a>, getting back in to writing a book when you haven't really worked on it for more than a year is intimidating. Fortunately I'm now doing <a href=\"https://wandering.shop/tags/CognitiveBehavioralTherapy\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CognitiveBehavioralTherapy</span></a> and my therapist has helped me come up with small(ish) steps that will help me get the ball rolling. First step is to read this summary paper, which has been on my \"to read\" pile for a year: <a href=\"https://link.springer.com/article/10.1007/s11214-022-00882-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s11214-022-00882-7</span></a></p><p><a href=\"https://wandering.shop/tags/amwriting\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>amwriting</span></a> <a href=\"https://wandering.shop/tags/science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>science</span></a> <a href=\"https://wandering.shop/tags/scicomm\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>scicomm</span></a> <a href=\"https://wandering.shop/tags/CuriosityBook\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CuriosityBook</span></a></p>"
    },
    "people": [
      {
        "url": "https://wandering.shop/@elakdawalla",
        "display_name": "Emily Lakdawalla"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.13966",
    "title": "The Debate Over Understanding in AI's Large Language Models",
    "latest": "2023-03-06T09:17:34+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@cigitalgem/109858491649163999",
      "content": "<p>New BIML Bibliography entry <a href=\"https://sigmoid.social/tags/MLsec\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MLsec</span></a> </p><p><a href=\"https://arxiv.org/abs/2210.13966\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.13966</span><span class=\"invisible\"></span></a></p><p>The Debate Over Understanding in AI's Large Language Models</p><p>Mitchell, et al <span class=\"h-card\"><a href=\"https://sigmoid.social/@melaniemitchell\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>melaniemitchell</span></a></span> </p><p>This paper is an excellent problem statement that clearly points out the criticality of understanding \u201cunderstanding\u201d in current ML systems.  Makes an excellent primer.</p><p>See <a href=\"https://berryvilleiml.com/references/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">berryvilleiml.com/references/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01432v1",
    "title": "WiCE: Real-World Entailment for Claims in Wikipedia",
    "latest": "2023-03-06T07:54:22+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109975257894127359",
      "content": "<p>\ud83d\udcdd WiCE: Real-World Entailment for Claims in Wikipedia \ud83d\udcda</p><p>\"Collects sentences in Wikipedia that cite one or more webpages and annotate whether the content on those pages entails those sentences or not (with fine-grained negative annotation).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01432v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01432v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00923",
    "title": "Multimodal Chain-of-Thought Reasoning in Language Models",
    "latest": "2023-03-06T07:47:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@dsj/109842804533443660",
      "content": "<p>Z. Zhang et al (2023). Multimodal Chain-of-Thought Reasoning in Language Models</p><p><a href=\"https://arxiv.org/abs/2302.00923\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00923</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.nature.com/collections/icbjafaedj",
    "title": "Decision making in digital & video games",
    "latest": "2023-03-06T07:17:23+00:00",
    "last_post": {
      "url": "https://social.coop/@natematias/109975112483508511",
      "content": "<p>When I was a student at Cambridge confusing the English department by proposing large-scale analysis of videogame behavior to understand moral psychology, I would have loved to contribute to this upcoming collection in Scientific Reports on decision making in digital/video games</p><p>cc <span class=\"h-card\"><a href=\"https://birdsite.link/@emshort\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>emshort</span></a></span> </p><p><a href=\"https://www.nature.com/collections/icbjafaedj\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/collections/icbjafa</span><span class=\"invisible\">edj</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.coop/@natematias",
        "display_name": "J. Nathan Matias \ud83e\udda3"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/1503.06960.pdf",
    "title": "https://arxiv.org/pdf/1503.06960.pdf",
    "latest": "2023-03-06T06:17:30+00:00",
    "last_post": {
      "url": "https://social.coop/@eob/109860073353410465",
      "content": "<p><span class=\"h-card\"><a href=\"https://genart.social/@stc\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>stc</span></a></span> What Ted Chiang is saying about <a href=\"https://social.coop/tags/compression\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compression</span></a> and <a href=\"https://social.coop/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a> is actually not just a metaphor</p><p>There is a fundamental theoretical relationship between compression and m<br><a href=\"https://social.coop/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a>:</p><p><a href=\"https://arxiv.org/pdf/1503.06960.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/1503.06960.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01586",
    "title": "https://arxiv.org/abs/2303.01586",
    "latest": "2023-03-06T05:52:52+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109974780118492485",
      "content": "<p>Alexa Arena: A User-Centric Interactive Platform for Embodied AI</p><p>repo: <a href=\"https://github.com/amazon-science/alexa-arena\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/amazon-science/alex</span><span class=\"invisible\">a-arena</span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.01586\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01586</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01986",
    "title": "https://arxiv.org/abs/2303.01986",
    "latest": "2023-03-06T05:52:48+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109974779882028642",
      "content": "<p>Towards Democratizing Joint-Embedding Self-Supervised Learning</p><p>Trains SSL method, e.g. SimCLR, using only 1 GPU in a reasonable amount of time.</p><p>repo: <a href=\"https://github.com/facebookresearch/FFCV-SSL\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/FF</span><span class=\"invisible\">CV-SSL</span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.01986\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01986</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2112.00183",
    "title": "Descriptive vs. inferential community detection in networks: pitfalls, myths, and half-truths",
    "latest": "2023-03-06T05:48:05+00:00",
    "last_post": {
      "url": "https://social.skewed.de/@tiago/109974761350299371",
      "content": "<p>Every point @lpachter@twitter.com makes about the unredeemable failures of UMAP is also valid for community detection in networks using modularity maximization.</p><p>The main difference is that with community detection we actually have robust inferential alternatives: <a href=\"https://arxiv.org/abs/2112.00183\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2112.00183</span><span class=\"invisible\"></span></a></p><p>Crosspost from @lpachter@twitter.com:</p><p>Kind of sucks when you've been telling people publicly that they should abandon UMAPs because they can be misleading and don't provide a faithful representation of the data... and then you look at a UMAP and it's really useful. 1/3</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/lpachter/status/1632509077711618049\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/lpachter/status/16</span><span class=\"invisible\">32509077711618049</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01421v1",
    "title": "Semiparametric Language Models Are Scalable Continual Learners",
    "latest": "2023-03-06T05:39:24+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109974727198755782",
      "content": "<p>\ud83d\udcdd Semiparametric Language Models Are Scalable Continual Learners \ud83d\udcda\ud83e\udde0</p><p>\"Selective memorization only memorizes difficult samples that the model is likely to struggle with, which makes the non-parametric memory to grow slowly over time as the model becomes stronger through continual learning.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01421v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01421v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/kqmw8/",
    "title": "http://osf.io/kqmw8/",
    "latest": "2023-03-06T05:21:43+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109974657650355218",
      "content": "<p>The Impact of Guessing and Retrieval on the Learning of Phrasal Verbs <a href=\"http://osf.io/kqmw8/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/kqmw8/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/full/10.1177/0306312714535679",
    "title": "SAGE Journals: Your gateway to world-class research journals",
    "latest": "2023-03-06T04:50:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/109974533113396472",
      "content": "<p>Academic Urban Legends - <a href=\"https://journals.sagepub.com/doi/full/10.1177/0306312714535679\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/full/</span><span class=\"invisible\">10.1177/0306312714535679</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05116",
    "title": "https://doi.org/10.21105/joss.05116",
    "latest": "2023-03-06T04:27:55+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109970496896825167",
      "content": "<p>Just published in JOSS: 'MultilayerGraphs.jl: Multilayer Network Science in Julia' <a href=\"https://doi.org/10.21105/joss.05116\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05116</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@bkeegan",
        "display_name": "Brian C. Keegan"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/full/10.1177/14614448211044025",
    "title": "journals.sagepub.com/doi/full/...",
    "latest": "2023-03-06T04:20:06+00:00",
    "last_post": {
      "url": "https://hci.social/@axz/109974415386182955",
      "content": "<p><span class=\"h-card\"><a href=\"https://social.coop/@mako\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mako</span></a></span> <span class=\"h-card\"><a href=\"https://hci.social/@andresmh\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>andresmh</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.social/@cyberlyra\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cyberlyra</span></a></span> <span class=\"h-card\"><a href=\"https://mstdn.ca/@gatesvp\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>gatesvp</span></a></span> <span class=\"h-card\"><a href=\"https://mamot.fr/@pluralistic\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>pluralistic</span></a></span> <span class=\"h-card\"><a href=\"https://octodon.social/@ethanz\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ethanz</span></a></span> <span class=\"h-card\"><a href=\"https://social.coop/@natematias\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>natematias</span></a></span> ugh yes we are building tools for community self governance! I would looove to incorporate the tools we\u2019ve built to enable community voice on Mastodon!</p><p>I also like this paper on exit and voice that echoes <span class=\"h-card\"><a href=\"https://mastodon.social/@cyberlyra\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cyberlyra</span></a></span>\u2019s point: <a href=\"https://journals.sagepub.com/doi/full/10.1177/14614448211044025\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/full/</span><span class=\"invisible\">10.1177/14614448211044025</span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@axz",
        "display_name": "Amy Zhang"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01410v1",
    "title": "https://arxiv.org/abs/2303.01410v1",
    "latest": "2023-03-06T03:54:19+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109974313999300936",
      "content": "<p>\ud83d\udcdd NLP Workbench: Efficient and Extensible Integration of State-of-the-Art Text Mining Tools \ud83d\udcda</p><p>\"A microservice architecture that allows allocation of acceleration hardware and parallelization of computation, an extensible platform that facilitates replacing an existing model or integrating a new one, and a website that is under active development.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/U-Alberta/NLPWorkbench/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/U-Alberta/NLPWorkbe</span><span class=\"invisible\">nch/</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01410v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01410v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/1806.03198v1",
    "title": "A neural network catalyzer for multi-dimensional similarity search",
    "latest": "2023-03-06T03:52:57+00:00",
    "last_post": {
      "url": "https://recsys.social/@karlhigley/109974308645062293",
      "content": "<p><span class=\"h-card\"><a href=\"https://vis.social/@mcnutt\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mcnutt</span></a></span> <span class=\"h-card\"><a href=\"https://hci.social/@mdekstrand\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mdekstrand</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.social/@noleli\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>noleli</span></a></span> Found it, this is the paper I was thinking of: <a href=\"https://arxiv.org/abs/1806.03198v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1806.03198v1</span><span class=\"invisible\"></span></a></p><p>For more on hubs/orphans, see: <a href=\"http://machinelearning.org/archive/icml2009/papers/360.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"ellipsis\">machinelearning.org/archive/ic</span><span class=\"invisible\">ml2009/papers/360.pdf</span></a></p>"
    },
    "people": [
      {
        "url": "https://recsys.social/@karlhigley",
        "display_name": "Karl Higley"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01507",
    "title": "Defending against Adversarial Audio via Diffusion Model",
    "latest": "2023-03-06T03:30:14.972000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/8533f97a-c838-4c0a-ae82-820c6f261c27",
      "content": "\"Defending against Adversarial Audio via Diffusion Model\" \u2014 Using diffusion models to purify/remove adversarial audio which can cause abnormal behaviour in acoustic systems.<br><br>Paper: <a href=\"https://arxiv.org/abs/2303.01507\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://arxiv.org/abs/2303.01507</a><br>Code: <a href=\"https://github.com/cychomatica/AudioPure\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/cychomatica/AudioPure</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/sound\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#Sound</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/security\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#Security</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/audio\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#Audio</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cryptograpy\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#Cryptograpy</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/5fe69ad6161a8073ce1fb029b09272270a2e7f9f6b7b782d73010c0c379eafde.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">The architecture of the whole a\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.01818",
    "title": "http://arxiv.org/abs/2303.01818",
    "latest": "2023-03-06T03:22:25.841000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/dceb2e78-2ab0-46ec-b3d1-bdac6faccd8f",
      "content": "\"Word-As-Image for Semantic Typography. (arXiv:2303.01818v1 [cs.CV])\" \u2014 Automatically visualizing words by modifying the typography to depict the meaning/representation of the word.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.01818\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.01818</a><br>Note: No code or demo available (yet) at the linked locations.<br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/4cf848fe7fe07a0702880f6f7a6fedac5550abb68f6a6bb2605bc87d19c514a1.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">A few examples of our word-as-i\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2301.13867.pdf?fbclid=IwAR0ja5OIlhmUeP12YzbexspsTXkc4gkEZefCVPuYLuCMjMx1AgGauDST7K0",
    "title": "arxiv.org/pdf/2301.13867.pdf?f...",
    "latest": "2023-03-06T03:17:26+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@kogler/109857302221416757",
      "content": "<p>\"We conclude that  ChatGPT\u2019s mathematical abilities are significantly below of an average math grad student. It often understands the question but fails to provide correct solutions. Hence, if you'll use it to pass an exam, you would be better off copying from your average peer!\" <br><a href=\"https://arxiv.org/pdf/2301.13867.pdf?fbclid=IwAR0ja5OIlhmUeP12YzbexspsTXkc4gkEZefCVPuYLuCMjMx1AgGauDST7K0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">arxiv.org/pdf/2301.13867.pdf?f</span><span class=\"invisible\">bclid=IwAR0ja5OIlhmUeP12YzbexspsTXkc4gkEZefCVPuYLuCMjMx1AgGauDST7K0</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.02153",
    "title": "http://arxiv.org/abs/2303.02153",
    "latest": "2023-03-06T03:16:28.493000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/e3b9a252-322d-4cd9-ab35-ce5612255730",
      "content": "\"Unleashing Text-to-Image Diffusion Models for Visual Perception. (arXiv:2303.02153v1 [cs.CV])\" \u2014 Using the pre-trained autoencoder in a diffusion model for visual perception tasks such as segmentation or depth estimation.<br><br>Paper: <a href=\"http://arxiv.org/abs/2303.02153\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2303.02153</a><br>Code: <a href=\"https://github.com/wl-zhao/VPD\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/wl-zhao/VPD</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/98d5de94a33ce08d8edcdeb33e5898192bdba5f1df9e57ecf12aba458f2c3078.jpeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">The main idea of the proposed V\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1080/17470218.2011.571267",
    "title": "doi.org/10.1080/17470218.2011....",
    "latest": "2023-03-06T02:39:12+00:00",
    "last_post": {
      "url": "https://a2mi.social/@w8emv/109972128451971598",
      "content": "<p>The \"doorway effect\", stated briefly, is that \"walking through doorways causes forgetting\". It's as though our short-term memory gets flushed out when we are in a new space, so that we're ready for new stuff.</p><p>Scientific American, 2011 <a href=\"https://www.scientificamerican.com/article/why-walking-through-doorway-makes-you-forget/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">scientificamerican.com/article</span><span class=\"invisible\">/why-walking-through-doorway-makes-you-forget/</span></a></p><p>Radvansky 2010 \"Walking through doorways causes forgetting: Further explorations\" <a href=\"https://doi.org/10.1080/17470218.2011.571267\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/17470218.2011.</span><span class=\"invisible\">571267</span></a></p><p>cc <span class=\"h-card\"><a href=\"https://xoxo.zone/@pb\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>pb</span></a></span> who reminded me of this</p>"
    },
    "people": [
      {
        "url": "https://vis.social/@mgiraldo",
        "display_name": "@mgiraldo"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2202.12299.pdf",
    "title": "https://arxiv.org/pdf/2202.12299.pdf",
    "latest": "2023-03-06T01:47:24+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/109838368400249611",
      "content": "<p>\"Capturing Failures of Large Language Models via<br>Human Cognitive Biases\"</p><p><a href=\"https://arxiv.org/pdf/2202.12299.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2202.12299.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.01347v1",
    "title": "https://arxiv.org/abs/2303.01347v1",
    "latest": "2023-03-06T01:24:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109973723588393713",
      "content": "<p>\ud83d\udcdd Letz Translate: Low-Resource Machine Translation for Luxembourgish \ud83d\udcda</p><p>\"Makes use of high-resource languages that are related or share the same linguistic root as the target LRL, such knowledge distillation from a large multilingual model and pseudotranslation, to build resource-efficient MT models for LRLs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/SE\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SE</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Etamin/Ltz\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/Etamin/Ltz</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.01347v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.01347v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.16759",
    "title": "General policy mapping: online continual reinforcement learning inspired on the insect brain",
    "latest": "2023-03-06T00:17:22+00:00",
    "last_post": {
      "url": "https://mastodon.social/@ayanguasgil/109852208101321225",
      "content": "<p>This simple trick improves online reinforcement learning algorithms: <a href=\"https://arxiv.org/abs/2211.16759\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.16759</span><span class=\"invisible\"></span></a> (From a Neurips 2022 workshop)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  }
]