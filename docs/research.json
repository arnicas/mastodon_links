[
  {
    "link": "https://arxiv.org/abs/2305.03132v1",
    "title": "The Role of Global and Local Context in Named Entity Recognition",
    "latest": "2023-05-08T09:29:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332355898722537",
      "content": "<p>\ud83d\udcdd The Role of Global and Local Context in Named Entity Recognition \ud83d\udcda</p><p>\"Finds that correctly retrieving global document context has a greater impact on performance than only leveraging local context, prompting for further research on how to better retrieve that context.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03132v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03132v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03130v1",
    "title": "https://arxiv.org/abs/2305.03130v1",
    "latest": "2023-05-08T09:05:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332261551212177",
      "content": "<p>\ud83d\udcdd Chain-of-Skills: A Configurable Model for Open-Domain Question Answering \ud83d\udcda</p><p>\"Modular retriever is a multitask retriever trained in a modular way, where individual retriever modules correspond to key retrieval skills that can be reused across datasets.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/facebookresearch/DPR\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/DP</span><span class=\"invisible\">R</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03130v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03130v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05019",
    "title": "https://doi.org/10.21105/joss.05019",
    "latest": "2023-05-08T09:00:03+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110332241711382737",
      "content": "<p>Just published in JOSS: 'CORA and LOGIGRAM: A Duo of Python Packages for Combinational Regularity Analysis (CORA)' <a href=\"https://doi.org/10.21105/joss.05019\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05019</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03117v1",
    "title": "Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations",
    "latest": "2023-05-08T08:53:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332214389730256",
      "content": "<p>\ud83d\udcdd Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations \ud83d\udcda</p><p>\"Evaluates the quality of explanation by the impact of the explanation on the model performance on the desired NLP task, for both fine-tuning (train phase) and inference (test phase).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03117v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03117v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03111v1",
    "title": "Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs",
    "latest": "2023-05-08T08:17:03+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332072635036666",
      "content": "<p>\ud83d\udcdd Can LLM Already Serve as a Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs \ud83d\udcda</p><p>\"Presents Bird, a big database grounded in text-to-SQL tasks, containing 12751 pairs of data-to-SQL data and 95 databases with a total size of 33.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03111v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03111v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14732",
    "title": "Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",
    "latest": "2023-05-08T07:46:47+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110331953652956029",
      "content": "<p>[Research] Towards Accurate, Credible and Traceable Large Language Models\uff01\uff01\uff01</p><p><a href=\"https://arxiv.org/abs/2304.14732\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14732</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2304.14732\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2304.14732</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03410",
    "title": "Tidally Heated Exomoons around $\u03b5$ Eridani b: Observability and prospects for characterization",
    "latest": "2023-05-08T07:39:57+00:00",
    "last_post": {
      "url": "https://mastodon.social/@mattkenworthy/110331836604163402",
      "content": "<p>Can we image tidally heated exomoons using JWST? Probably! This is a new paper by graduate student Elina Kleisioti who is working with me and Dominic Dirkx from TU Delft - she simulated internal models for exomoons around Eps Eri b, a gas giant exoplanet around a very nearby star. <a href=\"https://arxiv.org/abs/2305.03410\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03410</span><span class=\"invisible\"></span></a> \"Tidally Heated Exomoons around \u03b5 Eridani b: Observability and prospects for characterization\" /1 \ud83e\uddf5</p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@gregeganSF",
        "display_name": "Greg Egan"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03088v1",
    "title": "Modeling What-to-ask and How-to-ask for Answer-unaware Conversational Question Generation",
    "latest": "2023-05-08T07:17:43+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110331839329919135",
      "content": "<p>\ud83d\udcdd Modeling What-to-Ask and How-to-Ask for Answer-Unaware Conversational Question Generation \ud83d\udcda\ud83d\udc7e</p><p>\"Answer with content missing: SG-CQG, a two-stage Conversational Question Generation framework, is proposed to address the two main challenges in the answer-unaware setting: what-to-ask and how-to-ask.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03088v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03088v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03092v1",
    "title": "Curating corpora with classifiers: A case study of clean energy sentiment online",
    "latest": "2023-05-08T06:57:48+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110331761038876505",
      "content": "<p>\ud83d\udcdd Curating Corpora with Classifiers: A Case Study of Clean Energy Sentiment Online \ud83d\udcda</p><p>\"Trains a BERT-base-uncased transformer model (Devlin et al 2019) to predict whether a given tweet is relevant to public opinion on a given issue.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CY\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CY</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03092v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03092v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2204.03954",
    "title": "Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification",
    "latest": "2023-05-08T06:46:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ansgarscherp/110331715980114761",
      "content": "<p>Are we really making progress in text classification? Two AAAI papers outperformed by Logistic Regression -&gt; TextGCN (2019) and BERT-base -&gt; TextSSL (2022). What's wrong? See <span class=\"h-card\"><a href=\"https://sigmoid.social/@lpag\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>lpag</span></a></span>  et al. in <a href=\"https://arxiv.org/abs/2204.03954\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2204.03954</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/nmeth.2659",
    "title": "Error bars - Nature Methods",
    "latest": "2023-05-08T06:31:49+00:00",
    "last_post": {
      "url": "https://fediscience.org/@ct_bergstrom/110331658837624116",
      "content": "<p>It sounds trivial and obvious, but are you reading error bars correctly? </p><p>Do you know whether you're looking at standard errors (measures of inferential uncertainty), standard deviations (measures of spread of individual observations), or 95% confidence intervals around the mean? </p><p>And are your intuitions correct about how to interpret each of these?</p><p>Here's a nice primer, refresher, or teaching article. </p><p><a href=\"https://www.nature.com/articles/nmeth.2659\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"\">nature.com/articles/nmeth.2659</span><span class=\"invisible\"></span></a></p><p>h/t <span class=\"h-card\"><a href=\"https://hci.social/@jakehofman\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>jakehofman</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@bearloga",
        "display_name": "Mikhail Popov"
      },
      {
        "url": "https://datasci.social/@mszll",
        "display_name": "Michael Szell"
      },
      {
        "url": "https://fediscience.org/@ct_bergstrom",
        "display_name": "Carl T. Bergstrom"
      }
    ]
  },
  {
    "link": "http://osf.io/ve6rb/",
    "title": "http://osf.io/ve6rb/",
    "latest": "2023-05-08T03:06:13+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110330850383293766",
      "content": "<p>Emerging Measurement Opportunities for Studying Sexual and Gender Diverse Partnerships in Recent Population-based Surveys <a href=\"http://osf.io/ve6rb/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ve6rb/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.00118",
    "title": "Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",
    "latest": "2023-05-08T03:02:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110300973715415340",
      "content": "<p>Anyone working on such analyses for open models? Curious how the model size affects this analysis too.</p><p>The AI Act indeed mandates transparency of training data, so I think everyone is on same page here!</p><p>Time for @OpenAI@twitter.com to prepare non-infringing models.<br><a href=\"https://arxiv.org/abs/2305.00118\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.00118</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@dbamman",
        "display_name": "David Bamman"
      },
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      },
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      },
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch (moderator)"
      },
      {
        "url": "https://mastodon.social/@jose_eduardo",
        "display_name": "Jos\u00e9 Eduardo Gonz\u00e1lez"
      },
      {
        "url": "https://sigmoid.social/@roban",
        "display_name": "Roban Hultman Kramer"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/hk7fb/",
    "title": "http://osf.io/hk7fb/",
    "latest": "2023-05-08T03:02:17+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110330834937560983",
      "content": "<p>A Review of Longevity Validations up to May 2023 <a href=\"http://osf.io/hk7fb/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/hk7fb/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/fky6t/",
    "title": "http://osf.io/fky6t/",
    "latest": "2023-05-08T03:02:17+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110330834975128998",
      "content": "<p>What at power-with looks like and why we should choose it <a href=\"http://osf.io/fky6t/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/fky6t/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02301",
    "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes",
    "latest": "2023-05-07T22:42:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110307797061098943",
      "content": "<p>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes</p><p>Their 770M T5 outperforms the 540B PaLM model using only 80% of available data on a benchmark task.</p><p><a href=\"https://arxiv.org/abs/2305.02301\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02301</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2206.07682.pdf",
    "title": "https://arxiv.org/pdf/2206.07682.pdf",
    "latest": "2023-05-07T20:56:10+00:00",
    "last_post": {
      "url": "https://mastodon.uno/@PietroTerna/110329394912664242",
      "content": "<p>Emergent Abilities of Large Language Models<br>Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models.<br><a href=\"https://arxiv.org/pdf/2206.07682.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2206.07682.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02317",
    "title": "Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings",
    "latest": "2023-05-07T18:42:08+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110307616154617481",
      "content": "<p>Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings</p><p>Presents VCoT, a novel method that leverages chain of thought prompting with vision-language grounding to recursively bridge the logical gaps within sequential data</p><p><a href=\"https://arxiv.org/abs/2305.02317\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02317</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17651",
    "title": "https://arxiv.org/abs/2303.17651",
    "latest": "2023-05-07T18:20:52+00:00",
    "last_post": {
      "url": "https://z2h.dev/@volkan/110328783911026053",
      "content": "<p>Iterative Refinement with Self-Feedback</p><p>SELF-REFINE, a framework improving LLM outputs using iterative feedback, emulates human text refinement. It doesn't need supervised training or reinforcement learning, functioning with one LLM. In 7 diverse tasks, SELF-REFINE surpasses direct generation, with outputs favored by humans and automated metrics, outperforming GPT-3.5 and GPT-4.</p><p><a href=\"https://arxiv.org/abs/2303.17651\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17651</span><span class=\"invisible\"></span></a></p><p><a href=\"https://z2h.dev/tags/research\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>research</span></a> <a href=\"https://z2h.dev/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://z2h.dev/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a> <a href=\"https://z2h.dev/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2009.12240",
    "title": "Weird AI Yankovic: Generating Parody Lyrics",
    "latest": "2023-05-07T16:29:16+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@Riedl/110328345839214159",
      "content": "<p><span class=\"h-card\"><a href=\"https://hci.social/@jbigham\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>jbigham</span></a></span> <span class=\"h-card\"><a href=\"https://idf.social/@Ian\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Ian</span></a></span> <span class=\"h-card\"><a href=\"https://hci.social/@amyjko\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>amyjko</span></a></span> <a href=\"https://arxiv.org/abs/2009.12240\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2009.12240</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@Riedl",
        "display_name": "Mark Riedl"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.00944",
    "title": "Poisoning Language Models During Instruction Tuning",
    "latest": "2023-05-07T15:47:48+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110328182736960926",
      "content": "<p>[R] Poisoning Language Models During Instruction Tuning</p><p><a href=\"https://arxiv.org/abs/2305.00944\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.00944</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2305.00944\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2305.00944</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01487-y",
    "title": "\u2018Remarkable\u2019 AI tool designs mRNA vaccines that are more potent and stable",
    "latest": "2023-05-07T04:55:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110325616045116699",
      "content": "<p>\u2018Remarkable\u2019 AI tool designs mRNA vaccines that are more potent and stable - <a href=\"https://www.nature.com/articles/d41586-023-01487-y\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01487-y</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2204.14146",
    "title": "Training Language Models with Language Feedback",
    "latest": "2023-05-07T04:48:40+00:00",
    "last_post": {
      "url": "https://aus.social/@poofdyke/110325590335524673",
      "content": "<p>reinforcement learning via natural language feedback is a thing (<a href=\"https://arxiv.org/abs/2204.14146\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2204.14146</span><span class=\"invisible\"></span></a>) but... still seems inefficient</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11156",
    "title": "Can AI-Generated Text be Reliably Detected?",
    "latest": "2023-05-07T01:10:14+00:00",
    "last_post": {
      "url": "https://fediverse.randomfoo.net/objects/4578b0e1-5ae2-4e5a-bc71-bae31707f9cf",
      "content": "<p>A couple \u201chuman interest\u201d stories related to ChatGPT:</p><p><a href=\"https://www.reddit.com/r/ChatGPT/comments/139o1q6/lost_all_my_content_writing_contracts_feeling/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Lost all my content writing contracts. Feeling hopeless as an author.</a> - follows another thread from a couple days ago <a href=\"https://www.reddit.com/r/ChatGPT/comments/138clv9/spent_5_years_building_up_my_craft_and_ai_will/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Spent 5 years building up my craft and AI will make me jobless</a> - entire classes of dislocation will be happening this year and it will only accelerate<br><a href=\"https://www.reddit.com/r/OpenAI/comments/138ayhf/professor_using_gptzero_to_accuse_students_of/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Professor using GPTZero to accuse students of cheating</a> - these detectors <a href=\"https://www.reddit.com/r/ChatGPT/comments/12q6ktf/ta_here_and_we_have_to_use_this_website_to_detect/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">are pretty bad</a> and <a href=\"https://www.reddit.com/r/OpenAI/comments/132ax3i/research_discredits_ai_detectors_gptzero_below_50/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">easy to get around</a> and a <a href=\"https://arxiv.org/abs/2303.11156\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">losing proposition</a>- but also pretty misguided for education IMO. Sal Kahn gave a recent talk about the <a href=\"https://www.youtube.com/watch?v=hJP5GqnTrNo\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">positive implication for AI tutors and teaching assistants</a>; also Po Shen Loh (CMU) <a href=\"https://www.youtube.com/watch?v=oO-akX66i24\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">gave an interesting talk</a> that touched on some of this last month at the Berkeley Simons Institute. Ethan Mollick (UPenn Wharton) has also <a href=\"https://www.oneusefulthing.org/p/all-my-classes-suddenly-became-ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">published on his approach</a>.<br><a href=\"https://www.reddit.com/r/OpenAI/comments/134p47z/the_first_chatgpt_powered_video_game_free_and/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">ChatGPT Powered Video Game</a> - on the heels of Square Enix\u2019s <a href=\"https://www.jp.square-enix.com/ai-tech-preview/portopia/en/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">new NLP-powered Portopia Serial Muder Case port</a> and the <a href=\"https://www.youtube.com/watch?v=UVNZ3_FwqJE\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">ChatGPT NPC experiments</a> (that Skyrim video has 8-second delays (waiting for ElevenLabs?), but <a href=\"https://github.com/AUGMXNT/llm-experiments/blob/main/05-command-ai-tts.py\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">my simple chat script</a> using TTS VITS for local voice generation has almost no delays)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02519v1",
    "title": "ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos",
    "latest": "2023-05-06T21:52:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323954760334321",
      "content": "<p>\ud83d\udcdd ANetQA: A Large-Scale Benchmark for Fine-Grained Compositional Reasoning Over Untrimmed Videos \ud83d\udd2d\ud83d\udcda</p><p>\"Answer with content missing: (A) - Introduces a new benchmark that consists of fine-grained compositional questions over ActivityNet videos and spatio-temporal scene graphs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02519v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02519v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02790v1",
    "title": "BranchNorm: Robustly Scaling Extremely Deep Transformers",
    "latest": "2023-05-06T20:52:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323719036150224",
      "content": "<p>\ud83d\udcdd BranchNorm: Robustly Scaling Extremely Deep Transformers \ud83e\udde0\ud83d\udcda</p><p>\"A dynamic normalization technique that rescales the norm of the non-residual branch in the Transformer model according to the training period, which theoretically stabilizes the training with smooth gradient norms at the early stage and encourages better convergence in the subsequent training.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02790v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02790v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03029v1",
    "title": "https://arxiv.org/abs/2305.03029v1",
    "latest": "2023-05-06T19:32:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323404191468378",
      "content": "<p>\ud83d\udcdd What Changes When You Randomly Choose BPE Merge Operations? Not Much \ud83d\udcda\ud83d\udc7e</p><p>\"Byte pair encoding (BPE) is a data compression method which iteratively merges the most frequent pair of adjacent symbols into a new symbol and recodes the corpus accordingly.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/bltlab/random-bpe\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/bltlab/random-bpe</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03029v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03029v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03025v1",
    "title": "https://arxiv.org/abs/2305.03025v1",
    "latest": "2023-05-06T18:52:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323246897144780",
      "content": "<p>\ud83d\udcdd Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models \ud83d\udcda\ud83d\udc7e</p><p>\"It's the first time to explore how to enhance open-source large language models through instruction-tuning and provide comprehensive evaluations of their performance on various aspects including language understanding, dialogue, and commonsense reasoning.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/dandelionsllm/pandallm\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/dandelionsllm/panda</span><span class=\"invisible\">llm</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03025v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03025v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03010v1",
    "title": "Sentence Embedding Leaks More Information than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence",
    "latest": "2023-05-06T17:52:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323011030965624",
      "content": "<p>\ud83d\udcdd Sentence Embedding Leaks More Information Than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence \ud83d\udcda</p><p>\"GEIA treats sentence-embedding as initial tokens representations and trains a powerful sequence decoder, which can be fine-tuned from pre-trained language models, such as BERT or GPT-2.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CR\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CR</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03010v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03010v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02869v1",
    "title": "2x Faster Language Model Pre-training via Masked Structural Growth",
    "latest": "2023-05-06T16:32:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110322696421149124",
      "content": "<p>\ud83d\udcdd 2x Faster Language Model Pre-Training via Masked Structural Growth \ud83d\udcda</p><p>\"The Masked Structural Growth (MSG) pre-training framework involves growth schedules involving all possible dimensions and a strictly function-preserving growth operator that is independent of the initialization of new weights.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02869v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02869v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01628",
    "title": "The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers",
    "latest": "2023-05-06T16:20:29+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110301980608185874",
      "content": "<p>The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers</p><p>Proposes a novel approach that utilizes the contrast between layers to improve text generation outputs.</p><p><a href=\"https://arxiv.org/abs/2305.01628\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01628</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03007v1",
    "title": "https://arxiv.org/abs/2305.03007v1",
    "latest": "2023-05-06T16:12:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110322617807529598",
      "content": "<p>\ud83d\udcdd NatCS: Eliciting Natural Customer Support Dialogues \ud83d\udcda</p><p>\"NatCS contains multi-domain conversations between customers and agents that are more representative of real human-to-human conversations compared to previous dialogue datasets along multiple quality metrics.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/amazon-science/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/amazon-science/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03007v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03007v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/r5a7z/",
    "title": "http://osf.io/r5a7z/",
    "latest": "2023-05-06T16:03:20+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110322581529782893",
      "content": "<p>Degrees of Freedom Analysis: A mixed method for theory building, decision making, and prediction <a href=\"http://osf.io/r5a7z/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/r5a7z/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.10423",
    "title": "Fully Autonomous Programming with Large Language Models",
    "latest": "2023-05-06T15:47:08+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110322517804224569",
      "content": "<p>[R] Fully Autonomous Programming with Large Language Models</p><p><a href=\"https://arxiv.org/abs/2304.10423\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.10423</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2304.10423\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2304.10423</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a> <a href=\"https://mastodon.social/tags/programming\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>programming</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02865v1",
    "title": "CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing",
    "latest": "2023-05-06T15:32:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110322460310005821",
      "content": "<p>\ud83d\udcdd CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing \ud83d\udcda\ud83d\udc7e</p><p>\"Projects literal and semantic information into independent feature subspaces, and constrains the involvement of literal information in subsequent predictions by a causal intervention based on the backdoor adjustment criterion.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02865v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02865v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02750v1",
    "title": "A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects",
    "latest": "2023-05-06T09:52:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110321123501081960",
      "content": "<p>\ud83d\udcdd A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects \ud83d\udcda\ud83d\udc7e</p><p>\"A proactive dialogue system is a conversational agent that proactively leads the conversation to achieve pre-defined goals, which requires strategic dialogues to progress from simple to more complicated tasks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02750v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02750v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41541-023-00661-7",
    "title": "Risk assessment of retinal vascular occlusion after COVID-19 vaccination - npj Vaccines",
    "latest": "2023-05-06T09:35:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110321054709275285",
      "content": "<p>Risk assessment of retinal vascular occlusion after Covid-19 vaccination - <a href=\"https://www.nature.com/articles/s41541-023-00661-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41541-023</span><span class=\"invisible\">-00661-7</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01523-x",
    "title": "Saudi universities entice top scientists to switch affiliations \u2014 sometimes with cash",
    "latest": "2023-05-06T09:13:16+00:00",
    "last_post": {
      "url": "https://akademienl.social/@mvugt/110320827133099883",
      "content": "<p>Wow... One of the problems of the obsession with citation indices... <a href=\"https://www.nature.com/articles/d41586-023-01523-x\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01523-x</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@gvwilson",
        "display_name": "Greg Wilson"
      },
      {
        "url": "https://dair-community.social/@DrVeronikaCH",
        "display_name": "Veronika Cheplygina"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02747v1",
    "title": "https://arxiv.org/abs/2305.02747v1",
    "latest": "2023-05-06T08:52:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320887571314963",
      "content": "<p>\ud83d\udcdd Unsupervised Dialogue Topic Segmentation with Topic-Aware Utterance Representation \ud83d\udcda\ud83d\udc7e</p><p>\"DAMO-ConvAI is a novel unsupervised DTS framework that learns topic-aware utterance representations from unlabeled dialogue data through neighboring utterance matching and pseudo-segmentation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/AlibabaResearch/DAMO-ConvAI\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/AlibabaResearch/DAM</span><span class=\"invisible\">O-ConvAI</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02747v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02747v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02637v1",
    "title": "Towards Weakly-Supervised Hate Speech Classification Across Datasets",
    "latest": "2023-05-06T07:32:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320572880565541",
      "content": "<p>\ud83d\udcdd Towards Weakly-Supervised Hate Speech Classification Across Datasets \ud83d\udcda\ud83d\udc7e</p><p>\"Applies a state-of-the-art weak-supervision technique that relies solely on class names to train HS classifiers and analyze the source of their low generalizability.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CY\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CY</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02637v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02637v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02633v1",
    "title": "Conformal Nucleus Sampling",
    "latest": "2023-05-06T06:52:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320415749570117",
      "content": "<p>\ud83d\udcdd Conformal Nucleus Sampling \ud83d\udcda\ud83e\udde0</p><p>\"A calibration procedure based on conformal prediction that uses the entropy of the next-word distribution as a calibration score to calibrate the parameter $p$ of nucleus sampling as a function of the confidence level.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02633v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02633v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02615v1",
    "title": "Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach",
    "latest": "2023-05-06T05:52:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320179970859222",
      "content": "<p>\ud83d\udcdd Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach \ud83d\udcda\ud83d\udc7e</p><p>\"CACD contains two steps: (i) building a common centering one graph node causal skeleton for all utterances in variable-length conversations; (ii) Causal Auto-Encoder correcting the skeleton to yield causal representation through generated implicit causes and known explicit causes.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02615v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02615v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02606v1",
    "title": "Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-training",
    "latest": "2023-05-06T04:52:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319944007793795",
      "content": "<p>\ud83d\udcdd Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-Training \ud83d\udcda</p><p>\"Re3Dial first trains an Unsupervised Dense Session Retriever (UDSR) to capture semantic and discourse relationships within multi-turn dialogues for retrieving relevant and coherent sessions.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02606v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02606v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02564v1",
    "title": "RetroMAE-2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models",
    "latest": "2023-05-06T04:12:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319786463031550",
      "content": "<p>\ud83d\udcdd RetroMAE-2: Duplex Masked Auto-Encoder for Pre-Training Retrieval-Oriented Language Models \ud83d\udcda</p><p>\"Duplex Masked Auto-Encoder, a method that jointly learns two complementary Masked Token Prediction (MTP) tasks, namely, sentence-level MTP and token-level MTP.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02564v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02564v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02556v1",
    "title": "Faithful Question Answering with Monte-Carlo Planning",
    "latest": "2023-05-06T02:52:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319472162212090",
      "content": "<p>\ud83d\udcdd Faithful Question Answering with Monte-Carlo Planning \ud83d\udcda</p><p>\"Proposes FAME (FAithful question answering with MONTE-CARLO planning) to answer questions based on faithful reasoning steps organized as an entailment tree.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02556v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02556v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2305.00118",
    "title": "http://arxiv.org/abs/2305.00118",
    "latest": "2023-05-06T01:51:55+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110319233637367668",
      "content": "<p>8/</p><p>[3] Kent K. Chang, Mackenzie Cramer, Sandeep Soni, and David Bamman. 2023. Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4. <a href=\"http://arxiv.org/abs/2305.00118\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2305.00118</span><span class=\"invisible\"></span></a> </p><p><a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a> <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2305.00050",
    "title": "http://arxiv.org/abs/2305.00050",
    "latest": "2023-05-06T01:51:39+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110319232557899341",
      "content": "<p>7/</p><p>[1] Emre K\u0131c\u0131man, Robert Ness, Amit Sharma, and Chenhao Tan. 2023. Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. <a href=\"http://arxiv.org/abs/2305.00050\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2305.00050</span><span class=\"invisible\"></span></a></p><p>[2] Joris M. Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard Sch\u00f6lkopf. 2016. Distinguishing Cause from Effect Using Observational Data: Methods and Benchmarks. Journal of machine learning research: JMLR, 17(32):1\u2013102. <a href=\"https://jmlr.org/papers/v17/14-518.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">jmlr.org/papers/v17/14-518.htm</span><span class=\"invisible\">l</span></a> </p><p><a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a> <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/00031224231169790",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-05-06T01:22:20+00:00",
    "last_post": {
      "url": "https://sciences.social/@andrew_jorgenson/110316584941624562",
      "content": "<p>Our paper, Guns versus Climate: How Militarization Amplifies the Effect of Economic Growth on Carbon Emissions, is now published in American Sociological Review. <a href=\"https://journals.sagepub.com/doi/10.1177/00031224231169790\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/00031224231169790</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@dustinstoltz",
        "display_name": "D\u1d1cs\u1d1b\u026a\u0274 S\u1d1b\u1d0f\u029f\u1d1b\u1d22 :tardis:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02549v1",
    "title": "FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction",
    "latest": "2023-05-06T01:12:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319078750838393",
      "content": "<p>\ud83d\udcdd FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction \ud83d\udcda\ud83d\udd2d\ud83e\udde0</p><p>\"FormNetV2 unifies multimodal pre-training by graph contrastive learning, and extracts image features within the bounding box to capture targeted information for graph edges that connect text tokens.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02549v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02549v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02499v1",
    "title": "AutoML-GPT: Automatic Machine Learning with GPT",
    "latest": "2023-05-06T00:12:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110318842892144154",
      "content": "<p>\ud83d\udcdd AutoML-GPT: Automatic Machine Learning with GPT \ud83d\udcda\ud83d\udc7e\ud83d\udd2d\ud83e\udde0</p><p>\"AutoML-GPT uses the GPT model as the bridge to diverse AI models and dynamically trains models with optimized hyperparameters by leveraging {\\ours}'s powerful language capabilities.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02499v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02499v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01530-y",
    "title": "Hard feelings over mission change for NASA\u2019s Pluto spacecraft",
    "latest": "2023-05-05T22:00:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110318321880196489",
      "content": "<p>Hard feelings over mission change for NASA\u2019s Pluto spacecraft - <a href=\"https://www.nature.com/articles/d41586-023-01530-y\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01530-y</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02538",
    "title": "Cuttlefish: Low-rank Model Training without All The Tuning",
    "latest": "2023-05-05T21:55:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@rahuldave/110318303155768157",
      "content": "<p>RT @DimitrisPapail<br>1/6 \ud83c\udf89 Happy to share Cuttlefish \ud83e\udd91 our project for low-rank neural network training, without tuning factorization hyperparams! </p><p>arXiv link: <a href=\"https://arxiv.org/abs/2305.02538\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02538</span><span class=\"invisible\"></span></a></p><p>This is great work from my PhD graduate @HongyiWang10 that he'll present at MLSys this year</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@rahuldave",
        "display_name": "Rahul Dave"
      }
    ]
  },
  {
    "link": "http://osf.io/5rwa9/",
    "title": "http://osf.io/5rwa9/",
    "latest": "2023-05-05T20:32:20+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317976947541706",
      "content": "<p>Decolonizing Historical Linguistics in the Classroom and Beyond <a href=\"http://osf.io/5rwa9/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/5rwa9/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/4r6ws/",
    "title": "http://osf.io/4r6ws/",
    "latest": "2023-05-05T20:27:05+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317956337106307",
      "content": "<p>Revitalization at a Distance: Engaging Digital Archives for Language Reclamation <a href=\"http://osf.io/4r6ws/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/4r6ws/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/xcg8j/",
    "title": "http://osf.io/xcg8j/",
    "latest": "2023-05-05T20:27:04+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317956286324035",
      "content": "<p>Step-gap in Upward Support Regarding Biological Relatedness and Childhood Co-residence Duration <a href=\"http://osf.io/xcg8j/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/xcg8j/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/5s4gr/",
    "title": "http://osf.io/5s4gr/",
    "latest": "2023-05-05T20:27:04+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317956252534870",
      "content": "<p>Puzzling out graphic codes <a href=\"http://osf.io/5s4gr/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/5s4gr/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/6rshg/",
    "title": "http://osf.io/6rshg/",
    "latest": "2023-05-05T19:47:04+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317798971787943",
      "content": "<p>ON FACIAL RECOGNITION, REGULATION, AND DATA NECROPOLITICS <a href=\"http://osf.io/6rshg/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/6rshg/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/fhgm5/",
    "title": "http://osf.io/fhgm5/",
    "latest": "2023-05-05T19:47:03+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317798943829650",
      "content": "<p>Jobs and skills for adaptation and resilience in Scotland <a href=\"http://osf.io/fhgm5/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/fhgm5/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05340",
    "title": "https://doi.org/10.21105/joss.05340",
    "latest": "2023-05-05T19:12:12+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110317661903956142",
      "content": "<p>Just published in JOSS: 'STARRED: a two-channel deconvolution method with Starlet regularization' <a href=\"https://doi.org/10.21105/joss.05340\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05340</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02459v1",
    "title": "Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge",
    "latest": "2023-05-05T18:15:43+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110317439795574955",
      "content": "<p>\ud83d\udcdd Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge \ud83d\udcda\ud83e\udde0</p><p>\"A probability-of-rare-class (PRC) method is used for acquisition function which estimates the probability of a sample belonging to the rare class, and selects examples from a pool based on this score.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02459v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02459v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01625",
    "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input",
    "latest": "2023-05-05T18:15:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110317437176879156",
      "content": "<p>Unlimiformer: Long-Range Transformers with Unlimited Length Input - <a href=\"https://arxiv.org/abs/2305.01625\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01625</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@pbrane",
        "display_name": "Jake Mannix"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.07193",
    "title": "DINOv2: Learning Robust Visual Features without Supervision",
    "latest": "2023-05-05T17:32:24+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@j15r/110220758476432011",
      "content": "<p>Meta Research \"Dino v2\" model: <a href=\"https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">ai.facebook.com/blog/dino-v2-c</span><span class=\"invisible\">omputer-vision-self-supervised-learning/</span></a></p><p>Lots of interesting stuff in here, but one of my favorite bits is that their model internalized enough information about the \u201csemantic parts\u201d of objects it recognizes, that it can correlate them across widely-varying images.</p><p>Definitely try the demos (linked from the blog post).</p><p>Paper: <a href=\"https://arxiv.org/abs/2304.07193\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.07193</span><span class=\"invisible\"></span></a></p><p><a href=\"https://hachyderm.io/tags/ml\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ml</span></a> <a href=\"https://hachyderm.io/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a> <a href=\"https://hachyderm.io/tags/research\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>research</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1080/10724117.2023.2168404",
    "title": "doi.org/10.1080/10724117.2023....",
    "latest": "2023-05-05T17:05:49+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@peterrowlett/110317164918912338",
      "content": "<p>Ooo, a copy of Math Horizons has arrived - the April issue with my article about the 1960s set theory game On-Sets.</p><p>Read my article for free here: <a href=\"https://doi.org/10.1080/10724117.2023.2168404\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/10724117.2023.</span><span class=\"invisible\">2168404</span></a></p><p>See what else is in the issue here: <a href=\"https://www.tandfonline.com/toc/umho20/30/4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/toc/umho20/30/</span><span class=\"invisible\">4</span></a></p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@peterrowlett",
        "display_name": "Peter Rowlett"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/toc/umho20/30/4",
    "title": "tandfonline.com/toc/umho20/30/...",
    "latest": "2023-05-05T17:05:49+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@peterrowlett/110317164918912338",
      "content": "<p>Ooo, a copy of Math Horizons has arrived - the April issue with my article about the 1960s set theory game On-Sets.</p><p>Read my article for free here: <a href=\"https://doi.org/10.1080/10724117.2023.2168404\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/10724117.2023.</span><span class=\"invisible\">2168404</span></a></p><p>See what else is in the issue here: <a href=\"https://www.tandfonline.com/toc/umho20/30/4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/toc/umho20/30/</span><span class=\"invisible\">4</span></a></p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@peterrowlett",
        "display_name": "Peter Rowlett"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02437v1",
    "title": "Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory",
    "latest": "2023-05-05T16:55:42+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110317125136858528",
      "content": "<p>\ud83d\udcdd Lift Yourself Up: Retrieval-Augmented Text Generation with Self Memory \ud83d\udcda\ud83d\udc7e</p><p>\"A framework called Selfmem that iteratively adopts a retrieval-augmented generator itself to generate an unbounded memory pool and uses a memory selector to pick one generated memory for the next generation round.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02437v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02437v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41467-023-37194-5",
    "title": "Clarifying the effect of biodiversity on productivity in natural ecosystems with longitudinal data and methods for causal inference - Nature Communications",
    "latest": "2023-05-05T16:49:06+00:00",
    "last_post": {
      "url": "https://ecoevo.social/@jebyrnes/110317099193187970",
      "content": "<p>RT @Jon_Chase03<br>From a quick read, I think\ud83d\udc47 paper from \u2066\u2066@LauraEllenDee\u2069 et al, is probably one of the most important I\u2019ve seen in the BEF literature for some time. Better analytical \ud83d\udee0 suggest that \u2b06\ufe0f biodiversity =\u2b07\ufe0fproductivity in \u2066@NutNetGlobal\u2069 plots <a href=\"https://www.nature.com/articles/s41467-023-37194-5\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41467-023</span><span class=\"invisible\">-37194-5</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@jebyrnes",
        "display_name": "jebyrnes"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02386v1",
    "title": "Approximating CKY with Transformers",
    "latest": "2023-05-05T09:35:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110315394794337892",
      "content": "<p>\ud83d\udcdd Approximating CKY with Transformers \ud83d\udcda\ud83e\udde0</p><p>\"Works by predicting the parse chart directly using a transformer architecture that mirrors the chart structure, and then using gradients with respect to the chart to make a prediction at each span.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02386v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02386v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05220",
    "title": "https://doi.org/10.21105/joss.05220",
    "latest": "2023-05-05T08:39:47+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110315175146639989",
      "content": "<p>Just published in JOSS: 'TSInterpret: A Python Package for the Interpretability of Time Series Classification' <a href=\"https://doi.org/10.21105/joss.05220\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05220</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://piaille.fr/@paulanomalie",
        "display_name": "Paul"
      },
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02364v1",
    "title": "https://arxiv.org/abs/2305.02364v1",
    "latest": "2023-05-05T08:35:42+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110315159060621658",
      "content": "<p>\ud83d\udcdd PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives \ud83d\udcda</p><p>\"A large-scale dataset and commonsense knowledge graph, containing over 100k facts describing diverse personas and their world knowledge (e g a singer is likely to sing and be good at singing, and may have attended conservatoire).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Silin159/PeaCoK\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/Silin159/PeaCoK</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02364v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02364v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02363v1",
    "title": "Entity Tracking in Language Models",
    "latest": "2023-05-05T07:35:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110314922918915030",
      "content": "<p>\ud83d\udcdd Entity Tracking in Language Models \ud83d\udcda</p><p>\"Pretraining on large amounts of text corpora and code helps models learn to track entities in text, but large-scale pretraining alone does not make this capacity surface.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02363v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02363v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02437",
    "title": "Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory",
    "latest": "2023-05-05T01:01:24+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313372685356350",
      "content": "<p>Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory</p><p><a href=\"https://arxiv.org/abs/2305.02437\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02437</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02412",
    "title": "Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents",
    "latest": "2023-05-05T01:00:21+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313368544832809",
      "content": "<p>Plan, Eliminate, and Track \u2014 Language Models are Good Teachers for Embodied Agents</p><p><a href=\"https://arxiv.org/abs/2305.02412\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02412</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "http://arxiv.org/pdf/2304.14082v1.pdf",
    "title": "http://arxiv.org/pdf/2304.14082v1.pdf",
    "latest": "2023-05-05T00:49:27+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313325662205098",
      "content": "<p>RT @utkuevci@twitter.com</p><p>Hyped to share JaxPruner: a concise library for sparsity research.</p><p>JaxPruner includes 10+ easy-to-modify baseline algorithms and provides integration with popular libraries like t5x, scenic, dopamine and fedjax. 1/7</p><p>Code: <a href=\"http://github.com/google-research/jaxpruner\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"ellipsis\">github.com/google-research/jax</span><span class=\"invisible\">pruner</span></a><br>Paper: <a href=\"http://arxiv.org/pdf/2304.14082v1.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/pdf/2304.14082v1.pdf</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/utkuevci/status/1654251794845843457\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/utkuevci/status/16</span><span class=\"invisible\">54251794845843457</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03053",
    "title": "ZipIt! Merging Models from Different Tasks without Training",
    "latest": "2023-05-05T00:48:22+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313321437176788",
      "content": "<p>ZipIt! Merging Models from Different Tasks without Training</p><p>Presents ZipIt!, a general method for merging two arbitrary models of the same architecture that incorporates two simple strategies.</p><p><a href=\"https://arxiv.org/abs/2305.03053\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03053</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03052",
    "title": "https://arxiv.org/abs/2305.03052",
    "latest": "2023-05-05T00:44:23+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313305736457797",
      "content": "<p>Tracking through Containers and Occluders in the Wild</p><p>Proposes a model, called TCOW, that can segment objects in videos with a notion of object permanence.</p><p>proj: <a href=\"https://tcow.cs.columbia.edu/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">tcow.cs.columbia.edu/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2305.03052\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03052</span><span class=\"invisible\"></span></a> <a href=\"https://twitter.com/i/web/status/1654285634075238400\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/i/web/status/16542</span><span class=\"invisible\">85634075238400</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02463",
    "title": "Shap-E: Generating Conditional 3D Implicit Functions",
    "latest": "2023-05-05T00:39:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313286310917481",
      "content": "<p>RT @unixpickle@twitter.com</p><p>Super excited to release Shap-E, our latest work on 3D generative modeling.</p><p>Paper: <a href=\"https://arxiv.org/abs/2305.02463\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02463</span><span class=\"invisible\"></span></a><br>Code/models: <a href=\"https://github.com/openai/shap-e\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/openai/shap-e</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/unixpickle/status/1654282269065105409\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/unixpickle/status/</span><span class=\"invisible\">1654282269065105409</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02968",
    "title": "https://arxiv.org/abs/2305.02968",
    "latest": "2023-05-05T00:39:23+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313286123002080",
      "content": "<p>Masked Trajectory Models for Prediction, Representation, and Control</p><p>Presents Masked Trajectory Models (MTM) as a generic abstraction for sequential decision making.</p><p>repo: <a href=\"https://github.com/facebookresearch/mtm\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/mt</span><span class=\"invisible\">m</span></a><br>proj: <a href=\"https://wuphilipp.github.io/mtm/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">wuphilipp.github.io/mtm/</span><span class=\"invisible\"></span></a> <br>abs: <a href=\"https://arxiv.org/abs/2305.02968\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02968</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02265v1",
    "title": "https://arxiv.org/abs/2305.02265v1",
    "latest": "2023-05-04T21:53:23+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312633338300156",
      "content": "<p>\ud83d\udcdd A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval From Linguistically Complex Text \ud83d\udcda</p><p>\"A pretrained VLMs-based visual-linguistic interactor achieves the interaction between decomposed proposition sentences and images, a neural-symbolic reasoner combines the above reasoning states to obtain the final solution via a neural logic reasoning approach.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/YunxinLi/NDCR\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/YunxinLi/NDCR</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02265v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02265v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02261v1",
    "title": "https://arxiv.org/abs/2305.02261v1",
    "latest": "2023-05-04T21:23:18+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312515101770256",
      "content": "<p>\ud83d\udcdd End-to-End Training and Decoding for Pivot-Based Cascaded Translation Model \ud83d\udcda\ud83d\udc7e</p><p>\"The training of the source-pivot and pivot-target models is end-to-end, and a weighted pivot embedding is used as input to the pivot-target model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/fxsjy/jieba\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/fxsjy/jieba</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02261v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02261v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01711",
    "title": "Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner",
    "latest": "2023-05-04T21:23:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110312515022885739",
      "content": "<p>Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner</p><p>Proposes Prompt-based Continued Pre-training, which consistently improves the performance of prompt-based fine-tuning (up to 20.1% absolute).</p><p>Paper: <a href=\"https://arxiv.org/abs/2305.01711\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01711</span><span class=\"invisible\"></span></a><br>Code: <a href=\"https://github.com/ZhengxiangShi/PowerfulPromptFT\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/ZhengxiangShi/Power</span><span class=\"invisible\">fulPromptFT</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02239v1",
    "title": "The Benefits of Label-Description Training for Zero-Shot Text Classification",
    "latest": "2023-05-04T20:43:18+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312357766235395",
      "content": "<p>\ud83d\udcdd The Benefits of Label-Description Training for Zero-Shot Text Classification \ud83d\udcda\ud83d\udc7e</p><p>\"We finetune the model on data describing the labels in language, such as by using related words for a given label, dictionary/encyclopedia entries, and short templates.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02239v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02239v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02235v1",
    "title": "AttenWalker: Unsupervised Long-Document Question Answering via Attention-based Graph Walking",
    "latest": "2023-05-04T20:13:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312240025243815",
      "content": "<p>\ud83d\udcdd AttenWalker: Unsupervised Long-Document Question Answering via Attention-Based Graph Walking \ud83d\udcda</p><p>\"AttenWalker is composed of three modules, i) Span Collector, ii) Span Linker and iii) Answer Aggregator, to generate answers with long-range dependency in an unsupervised fashion.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02235v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02235v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01469-0",
    "title": "The sleight-of-hand trick that can simplify scientific computing",
    "latest": "2023-05-04T20:13:00+00:00",
    "last_post": {
      "url": "https://sciencemastodon.com/@jperkel/110293734810783250",
      "content": "<p>Today <span class=\"h-card\"><a href=\"https://mstdn.social/@Nature\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Nature</span></a></span>, by me: why you might want to do your computing work inside computational environments (e.g., conda, renv). With <span class=\"h-card\"><a href=\"https://genomic.social/@ctb\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ctb</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.online/@fertiglab\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>fertiglab</span></a></span> <span class=\"h-card\"><a href=\"https://fosstodon.org/@minecr\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>minecr</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.social/@benmarwick\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>benmarwick</span></a></span> et al.  <a href=\"https://www.nature.com/articles/d41586-023-01469-0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01469-0</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@minecr",
        "display_name": "Mine \u00c7etinkaya-Rundel"
      },
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02215v1",
    "title": "Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages",
    "latest": "2023-05-04T19:53:24+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312161602284500",
      "content": "<p>\ud83d\udcdd Exploring Linguistic Properties of Monolingual BERTs with Typological Classification Among Languages \ud83d\udcda\ud83d\udc7e</p><p>\"A novel perspective that uses Centered kernel Alignment to measure similarity between layers of different BERT models trained on different languages, and then compare this similarity to the similarity of the linguistic structure of different languages.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02215v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02215v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02176v1",
    "title": "https://arxiv.org/abs/2305.02176v1",
    "latest": "2023-05-04T19:33:26+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312083048198656",
      "content": "<p>\ud83d\udcdd Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity \ud83d\udcda</p><p>\"A stratified mixture of experts (SMoE) model assigns different numbers of experts to tokens based on their complexity, which enables it to be more parameter efficient than previous mixture-of-experts architectures.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/fe1ixxu/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/fe1ixxu/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02176v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02176v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02170v1",
    "title": "A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus",
    "latest": "2023-05-04T19:13:24+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312004279285100",
      "content": "<p>\ud83d\udcdd A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus \ud83d\udcda</p><p>\"Presents a pipeline for a statistical textual exploration, offering a stylometry-based explanation and statistical validation of a hypothesized partition of a text (Fig 1).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02170v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02170v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02151v1",
    "title": "Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space",
    "latest": "2023-05-04T18:33:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311846788797698",
      "content": "<p>\ud83d\udcdd Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Shows evidence that language-specific characteristics have a measurable impact on both representation spaces and cross-lingual transfer performance of multilingual language models (MLLMs), especially for more linguistically distant language pairs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02151v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02151v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.15004",
    "title": "Are Emergent Abilities of Large Language Models a Mirage?",
    "latest": "2023-05-04T18:33:08+00:00",
    "last_post": {
      "url": "https://fediscience.org/@UlrikeHahn/110310857610802064",
      "content": "<p><a href=\"https://fediscience.org/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> <a href=\"https://fediscience.org/tags/NewPreprintThread\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NewPreprintThread</span></a> <a href=\"https://fediscience.org/tags/neuroscience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>neuroscience</span></a> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/cogsci\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cogsci</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/philosophy\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>philosophy</span></a></span> </p><p>1/n</p><p>Really interesting new preprint on emergence in LLMs. It raises a whole number of interesting issues, so some initial, first thoughts in the hope of prompting more discussion.</p><p>I also suspect this paper will generate a fair bit of confusion due to the central notion of 'emergence'</p><p>First off, the paper is looking at the issue of *how model capabilities develop as a function of model size.*</p><p><a href=\"https://arxiv.org/abs/2304.15004\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.15004</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://qoto.org/@mapto",
        "display_name": "mapto"
      },
      {
        "url": "https://sigmoid.social/@troos",
        "display_name": "Teemu Roos"
      },
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      },
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02118v1",
    "title": "https://arxiv.org/abs/2305.02118v1",
    "latest": "2023-05-04T18:23:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311807483100241",
      "content": "<p>\ud83d\udcdd Pay More Attention to Relation Exploration for Knowledge Base Question Answering \ud83d\udcda</p><p>\"Proposes a novel framework RE-KBQA that utilizes relations in the knowledge base to enhance entity representation and introduce additional supervision for knowledge base question answering task with three aspects.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/yongcaoplus/RE-KBQA\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/yongcaoplus/RE-KBQA</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02118v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02118v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02105v1",
    "title": "GPT-RE: In-context Learning for Relation Extraction using Large Language Models",
    "latest": "2023-05-04T18:03:23+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311728994688241",
      "content": "<p>\ud83d\udcdd GPT-RE: In-Context Learning for Relation Extraction Using Large Language Models \ud83d\udcda</p><p>\"GPT-RE leverages task-specific entity representations and reasoning logic to address the two major shortcomings of LLMs in RE: (1) low relevance regarding entity and relation in retrieved demonstrations for in-context learning; and (2) the strong inclination to wrongly classify NULL examples into other pre-defined labels.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02105v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02105v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/proteincell/advance-article/doi/10.1093/procel/pwad024/7147618",
    "title": "best practice for microbiome analysis using R",
    "latest": "2023-05-04T17:35:07+00:00",
    "last_post": {
      "url": "https://mastodon.online/@moorejh/110310716968594800",
      "content": "<p>A review of 324 common R packages for microbiome analysis <a href=\"https://academic.oup.com/proteincell/advance-article/doi/10.1093/procel/pwad024/7147618\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/proteincell/a</span><span class=\"invisible\">dvance-article/doi/10.1093/procel/pwad024/7147618</span></a> <a href=\"https://mastodon.online/tags/microbiome\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>microbiome</span></a> <a href=\"https://mastodon.online/tags/rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rstats</span></a> <a href=\"https://mastodon.online/tags/bioinformatics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>bioinformatics</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02101v1",
    "title": "What makes a good pause? Investigating the turn-holding effects of fillers",
    "latest": "2023-05-04T17:33:18+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311610707513047",
      "content": "<p>\ud83d\udcdd What Makes a Good Pause? Investigating the Turn-Holding Effects of Fillers \ud83d\udcda</p><p>\"Show that, while filled pauses do indeed have a turn holding effect, it is perhaps not as strong as could be expected, probably due to the redundancy of other cues.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02101v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02101v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02036v1",
    "title": "Response-conditioned Turn-taking Prediction",
    "latest": "2023-05-04T17:13:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311532203334152",
      "content": "<p>\ud83d\udcdd Response-Conditioned Turn-Taking Prediction \ud83d\udcda\ud83e\udde0</p><p>\"An extension of the TurnGPT model with a next-speaker prediction task, which conditions the end-of-turn prediction on both conversation history and what the next speaker wants to say.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02036v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02036v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/13530194.2020.1750290",
    "title": "Beirut on the stage: the Great War in melodrama",
    "latest": "2023-05-04T17:13:06+00:00",
    "last_post": {
      "url": "https://hcommons.social/@jcpeyssard/110311531241738223",
      "content": "<p>Beirut on the stage: the Great War in melodrama: British Journal of Middle Eastern Studies: Vol 48, No 3<br><a href=\"https://www.tandfonline.com/doi/full/10.1080/13530194.2020.1750290\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/13530194.2020.1750290</span></a><br>@lebanon <a href=\"https://hcommons.social/tags/lebanon\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>lebanon</span></a></p>"
    },
    "people": [
      {
        "url": "https://hcommons.social/@jcpeyssard",
        "display_name": "Jean-Christophe Peyssard"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1177/17499755231160692",
    "title": "doi.org/10.1177/17499755231160...",
    "latest": "2023-05-04T17:12:30+00:00",
    "last_post": {
      "url": "https://sciences.social/@Giselinde/110311325822219799",
      "content": "<p>New paper alert... <br>To celebrate a successful move to the sciences.social server (surprisingly easy)  I would like to share with you: </p><p>Fashion as \u2018Force for Change\u2019? How Ideologization Reshapes the Work of Intermediaries in the Legitimation of Culture</p><p>With Luuc Brans: <span class=\"h-card\"><a href=\"https://mastodon.social/@luuc\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>luuc</span></a></span> </p><p>In Cultural Sociology: <br><a href=\"https://doi.org/10.1177/17499755231160692\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1177/17499755231160</span><span class=\"invisible\">692</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@dustinstoltz",
        "display_name": "D\u1d1cs\u1d1b\u026a\u0274 S\u1d1b\u1d0f\u029f\u1d1b\u1d22 :tardis:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01778v1",
    "title": "https://arxiv.org/abs/2305.01778v1",
    "latest": "2023-05-04T09:43:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309762776034839",
      "content": "<p>\ud83d\udcdd SLTUNET: A Simple Unified Model for Sign Language Translation \ud83d\udcda\ud83d\udd2d</p><p>\"SLTUNET is a simple unified neural model which consists of a shared encoder and task-specific decoders, such as a sign-to-gloss decoder, a gloss-to-text decoder and a sign-to-text decoder.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/bzhangGo/sltunet\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/bzhangGo/sltunet</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01778v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01778v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01764v1",
    "title": "https://arxiv.org/abs/2305.01764v1",
    "latest": "2023-05-04T09:13:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309644794873110",
      "content": "<p>\ud83d\udcdd Psychologically-Inspired Causal Prompts \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"We take sentiment classifier as an example, and explore the causal relation between the review sentence (X) and sentimental label (Y).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/cogito233/psych-causal-prompt\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/cogito233/psych-cau</span><span class=\"invisible\">sal-prompt</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01764v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01764v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01750v1",
    "title": "https://arxiv.org/abs/2305.01750v1",
    "latest": "2023-05-04T08:23:22+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309448227226842",
      "content": "<p>\ud83d\udcdd Few-Shot in-Context Learning for Knowledge Base Question Answering \ud83d\udcda\ud83d\udc7e</p><p>\"KB-BINDER first leverages large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations, and then grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/castorini/pyserini\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/castorini/pyserini</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01750v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01750v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/nkj3x/",
    "title": "http://osf.io/nkj3x/",
    "latest": "2023-05-04T08:16:48+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309422425531151",
      "content": "<p>Does Lunar Cartography Do the Work of Capitalism? <a href=\"http://osf.io/nkj3x/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/nkj3x/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/bn42s/",
    "title": "http://osf.io/bn42s/",
    "latest": "2023-05-04T08:16:48+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309422447288777",
      "content": "<p>Sustainable social housing retrofit? Circular economy and tenant trade-offs <a href=\"http://osf.io/bn42s/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/bn42s/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/gfxcm/",
    "title": "http://osf.io/gfxcm/",
    "latest": "2023-05-04T08:16:47+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309422395535613",
      "content": "<p>Historical Patterns in the Intergenerational Transmission of Lifespan and Longevity: Evidence from the United States, 1700-1900 <a href=\"http://osf.io/gfxcm/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/gfxcm/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/sud8n/",
    "title": "http://osf.io/sud8n/",
    "latest": "2023-05-04T08:06:03+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309380182196970",
      "content": "<p>On the Fence of a Family Dynamics of Inter-generational Transfers in Stepfamilies <a href=\"http://osf.io/sud8n/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/sud8n/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01735v1",
    "title": "DiffuSum: Generation Enhanced Extractive Summarization with Diffusion",
    "latest": "2023-05-04T08:03:18+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309369316900476",
      "content": "<p>\ud83d\udcdd DiffuSum: Generation Enhanced Extractive Summarization with Diffusion \ud83d\udcda</p><p>\"DiffuSum generates summary sentence representations directly and then extracts sentences based on sentence representation matching, jointly optimize a contrastive sentence encoder with a matching loss for sentence representation alignment and a multi-class contrastive loss for representation diversity.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01735v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01735v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/v4ukj/",
    "title": "http://osf.io/v4ukj/",
    "latest": "2023-05-04T08:01:48+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309363429423188",
      "content": "<p>Biosphere Futures: a database of social-ecological scenarios <a href=\"http://osf.io/v4ukj/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/v4ukj/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/p27hb/",
    "title": "http://osf.io/p27hb/",
    "latest": "2023-05-04T08:01:47+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309363391264916",
      "content": "<p>Pro-Environmental Behavior and Actions: Review of current theories and agenda for future research <a href=\"http://osf.io/p27hb/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/p27hb/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/juxsd/",
    "title": "http://osf.io/juxsd/",
    "latest": "2023-05-04T08:01:47+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309363362211227",
      "content": "<p>Odd Profiles in Conjoint Experimental Designs: Effects on Survey-Taking Attention and Behavior <a href=\"http://osf.io/juxsd/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/juxsd/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/5ecfa/",
    "title": "http://osf.io/5ecfa/",
    "latest": "2023-05-04T08:01:46+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309363286166183",
      "content": "<p>Artificially Precise Extremism: How Internet-Trained LLMs Exaggerate Our Differences <a href=\"http://osf.io/5ecfa/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/5ecfa/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/7c6d2/",
    "title": "http://osf.io/7c6d2/",
    "latest": "2023-05-04T08:01:46+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309363329365689",
      "content": "<p>Have Cycling-Friendly Cities Achieved Cycling Equity? Analyses of the Educational Gradient in Cycling in Dutch and German Cities <a href=\"http://osf.io/7c6d2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/7c6d2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01723v1",
    "title": "https://arxiv.org/abs/2305.01723v1",
    "latest": "2023-05-04T07:43:25+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309291175851625",
      "content": "<p>\ud83d\udcdd Stance Detection with Supervised, Zero-Shot, and Few-Shot Applications \ud83d\udcda</p><p>\"A model is trained on a large text corpus using a combination of unsupervised and supervised methods (e,g, BERT and BiLSTM) to predict the stance of a piece of text.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/MLBurnham/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/MLBurnham/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01723v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01723v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/9acjg/",
    "title": "http://osf.io/9acjg/",
    "latest": "2023-05-04T07:36:44+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309264863719167",
      "content": "<p>Community College to PhD Scholars Program: Short-Term Outcome Evaluation of an Undergraduate Research and PhD Preparation Program <a href=\"http://osf.io/9acjg/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/9acjg/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/fgx7y/",
    "title": "http://osf.io/fgx7y/",
    "latest": "2023-05-04T07:36:44+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309264891691132",
      "content": "<p>Coparenting and conflicts between work and family - between-within analysis of German mothers and fathers <a href=\"http://osf.io/fgx7y/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/fgx7y/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/jdgpx/",
    "title": "http://osf.io/jdgpx/",
    "latest": "2023-05-04T07:31:41+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309245018675917",
      "content": "<p>Review of invitations to publish in predatory scientific journals <a href=\"http://osf.io/jdgpx/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/jdgpx/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/93sn2/",
    "title": "http://osf.io/93sn2/",
    "latest": "2023-05-04T07:31:40+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309244966332013",
      "content": "<p>The Role of GDP Growth in the ESG Approach at World Level <a href=\"http://osf.io/93sn2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/93sn2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/zv8tw/",
    "title": "http://osf.io/zv8tw/",
    "latest": "2023-05-04T07:31:40+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309244990861478",
      "content": "<p>Better guidance is needed for editorial expressions of concern <a href=\"http://osf.io/zv8tw/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/zv8tw/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/tgwm3/",
    "title": "http://osf.io/tgwm3/",
    "latest": "2023-05-04T07:26:18+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309223853765447",
      "content": "<p>Hou Xuan Ren Xue Li Dui De Piao Lu De Ying Xiang ----Yi Tai Wan  2018 Nian Zhi Xia Shi Yi Yuan Xuan Ju Wei Li  <a href=\"http://osf.io/tgwm3/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/tgwm3/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/avkmc/",
    "title": "http://osf.io/avkmc/",
    "latest": "2023-05-04T07:26:18+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309223828643078",
      "content": "<p>Smith at 300: Reading and Rereading \"The Corruption of Moral Sentiments <a href=\"http://osf.io/avkmc/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/avkmc/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01713v1",
    "title": "https://arxiv.org/abs/2305.01713v1",
    "latest": "2023-05-04T07:13:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309172928395565",
      "content": "<p>\ud83d\udcdd Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks \ud83d\udcda\ud83d\udc7e</p><p>\"The INN transforms the distributed hidden space into a semantically disentangled latent space, resulting in better interpretability and controllability when compared to recent state-of-the-art models.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/VLL-HD/FrEIA\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/VLL-HD/FrEIA</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01713v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01713v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01711v1",
    "title": "Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner",
    "latest": "2023-05-04T07:03:23+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309133733320451",
      "content": "<p>\ud83d\udcdd Don't Stop Pretraining? Make Prompt-Based Fine-Tuning Powerful Learner \ud83d\udcda</p><p>\"Proposes Prompt-based Continued Pre-training (PCP), which combines the idea of instruction tuning with conventional continued pre-training on the target task to improve the performance of prompt-based FT.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01711v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01711v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01710v1",
    "title": "Stars Are All You Need: A Distantly Supervised Pyramid Network for Document-Level End-to-End Sentiment Analysis",
    "latest": "2023-05-04T06:23:22+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110308976416338522",
      "content": "<p>\ud83d\udcdd Stars Are All You Need: A Distantly Supervised Pyramid Network for Document-Level End-to-End Sentiment Analysis \ud83d\udcda</p><p>\"Proposes a novel model called Distantly Supervised Pyramid Network (DSPN) that uses only document star rating labels for training to perform end-to-end aspect category detection, sentiment detection, and rating prediction in a unified manner.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01710v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01710v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/mind/article/LIX/236/433/986238",
    "title": "I.\u2014COMPUTING MACHINERY AND INTELLIGENCE",
    "latest": "2023-05-04T04:02:24+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@markgritter/110308422116412340",
      "content": "<p>I wish that we were not in a \"The Turing Test has already been passed\" hype cycle.</p><p>You can read Turing's paper. It's not a tough read! <a href=\"https://academic.oup.com/mind/article/LIX/236/433/986238\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/mind/article/</span><span class=\"invisible\">LIX/236/433/986238</span></a></p><p>Some have argued that it's firmly tongue-in-cheek--- but it lays out a fairly unambiguous protocol, and provides concrete examples of how hard it might be for a computer to pass.</p><p>1. Human C communicates with Human B over a teletype, and computer A over a teletype, without knowing which is which, but told that one of them is a computer.<br>2. After a while, C is asked to guess which session is with a human.<br>3. If C can do no better than 50/50, then A has passed.</p><p>Now, this is mainly a thought experiment, not an actual protocol. But note that it's a question about repeated trials, not a single one! Even the Loebner prize went for lightweight versions of the idea. Arguably the Turing test sets the bar _too_ high.</p><p>But would ChatGPT or the current generation of chatbots pass? Certainly not. It's not the fairly low bar of \"I can't tell if this text was produced by a human or a computer\". It's \"can you adversarially distinguish between human responses and computer ones in a repeated interaction?\"</p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@markgritter",
        "display_name": "Mark Gritter"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.05655",
    "title": "DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering",
    "latest": "2023-05-04T03:13:58+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@mrdrozdov/110307132319678071",
      "content": "<p>RT @roeeaharoni<br>In DisentQA (<a href=\"https://arxiv.org/abs/2211.05655\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.05655</span><span class=\"invisible\"></span></a>) we tackle the problem of disentangling \"internal\" and \"external\" knowledge in LLMs, proposing methods to make models more robust when generating information seeking answers. With @EllaNeeman @OHonovich <span class=\"h-card\"><a href=\"https://sigmoid.social/@LChoshen\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>LChoshen</span></a></span> @AbendOmri  and Idan Szpektor</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02309",
    "title": "https://arxiv.org/abs/2305.02309",
    "latest": "2023-05-04T00:36:20+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110307611817428257",
      "content": "<p>CodeGen2: Lessons for Training LLMs on Programming and Natural Languages</p><p>Releases CodeGen2 models in size 1B, 3.7B, 7B, and, 16B parameters, along with the training framework as open-source.</p><p>repo: <a href=\"https://github.com/salesforce/CodeGen2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/salesforce/CodeGen2</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2305.02309\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02309</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01041",
    "title": "Data-Parallel Algorithms for String Diagrams",
    "latest": "2023-05-04T00:27:14+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ceperez/110307576023942795",
      "content": "<p>RT @statusfailed<br>\ud83d\udea8New paper!\ud83d\udea8<br>Data-Parallel Algorithms for String Diagrams <a href=\"https://arxiv.org/abs/2305.01041\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01041</span><span class=\"invisible\"></span></a></p><p>tl;dr: String diagrams as structured cospans of ACSets = GPU accelerated combinatorial syntax!</p><p>BONUS: natively handling  hypergraph structure gets you optic composition!</p><p>(THREAD)</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01651v1",
    "title": "https://arxiv.org/abs/2305.01651v1",
    "latest": "2023-05-03T23:55:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110307451545895663",
      "content": "<p>\ud83d\udcdd Can LMs Learn New Entities From Descriptions? Challenges in Propagating Injected Knowledge \ud83d\udcda</p><p>\"A pre-trained language model receives a sequence of tokens and then generates the next token(s) in a sequence (language modeling) or performs classification (next word prediction).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/eric-mitchell/mend\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/eric-mitchell/mend</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01651v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01651v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01628v1",
    "title": "The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers",
    "latest": "2023-05-03T21:25:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110306861969483317",
      "content": "<p>\ud83d\udcdd The Benefits of Bad Advice: Autocontrastive Decoding Across Model Layers \ud83d\udcda\ud83e\udde0</p><p>\"Utilizes the contrast between higher and lower model layers to improve text generation outputs and mitigate degenerative behaviors in open-ended generation settings, and show that it improves the quality of generated texts.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01628v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01628v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01625v1",
    "title": "https://arxiv.org/abs/2305.01625v1",
    "latest": "2023-05-03T20:25:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110306625988102071",
      "content": "<p>\ud83d\udcdd Unlimiformer: Long-Range Transformers with Unlimited Length Input \ud83d\udcda</p><p>\"Unlimiformer can be seen as an extension of a pretrained encoder-decoder transformer model, such as BART or Longformer, that enables summarizing even 350k token long books without any input truncation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/abertsch72/unlimiformer\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/abertsch72/unlimifo</span><span class=\"invisible\">rmer</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01625v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01625v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s42803-019-00019-3",
    "title": "What future for digital scholarly editions? From Haute Couture to Pr\u00eat-\u00e0-Porter - International Journal of Digital Humanities",
    "latest": "2023-05-03T20:16:17.345000+00:00",
    "last_post": {
      "url": "https://fedihum.org/@stefan_hessbrueggen/110306426573734616",
      "content": "<p><span class=\"h-card\"><a href=\"https://literatur.social/@type\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>type</span></a></span> <span class=\"h-card\"><a href=\"https://mstdn.social/@quinnanya\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>quinnanya</span></a></span> <span class=\"h-card\"><a href=\"https://digitalcourage.social/@tillgrallert\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>tillgrallert</span></a></span> yes, in principle. This paper by Elena Pierrazzo discusses the limits of this 'haute-couture' approach. The more successful DH becomes, the more we will be obliged to look for generic solutions.<br><a href=\"https://link.springer.com/article/10.1007/s42803-019-00019-3\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s42803-019-00019-3</span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@felwert",
        "display_name": "Frederik Elwert"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3579515",
    "title": "Privacy Legislation as Business Risks: How GDPR and CCPA are Represented in Technology Companies' Investment Risk Disclosures | Proceedings of the ACM on Human-Computer Interaction",
    "latest": "2023-05-03T19:41:09+00:00",
    "last_post": {
      "url": "https://hci.social/@richmondywong/110306355238471452",
      "content": "<p>My <a href=\"https://hci.social/tags/CSCW\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CSCW</span></a> paper with Andrew Chong  and Cooper Aspegren analyzing how GDPR and CCPA are framed in tech companies' investment risk disclosures is now out! (with open access!)</p><p>\"Privacy Legislation as Business Risks\" - <a href=\"https://dl.acm.org/doi/10.1145/3579515\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">dl.acm.org/doi/10.1145/3579515</span><span class=\"invisible\"></span></a>  </p><p>While we might think of privacy laws directly affecting companies through direct legal penalties and fines, our qualitative analysis shows that companies discuss a broader range of direct &amp; indirect business risks related to the legislation (1/n)</p>"
    },
    "people": [
      {
        "url": "https://hci.social/@asb",
        "display_name": "Amy Bruckman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01616v1",
    "title": "FreeLM: Fine-Tuning-Free Language Model",
    "latest": "2023-05-03T19:15:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110306350696886707",
      "content": "<p>\ud83d\udcdd FreeLM: Fine-Tuning-Free Language Model \ud83d\udcda\ud83d\udc7e</p><p>\"FreeLM is trained with both language and strong task-aware teacher signals in an interactive manner, where teacher signals are provided in a unified proposition format and trained via knowledge distillation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01616v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01616v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.00241",
    "title": "When Deep Learning Meets Polyhedral Theory: A Survey",
    "latest": "2023-05-03T19:08:22+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@thserra/110304238382347531",
      "content": "<p>In case you missed Calvin Tsay's tweet, we have just released a survey along with Gonzalo Munoz and Joey Huchette on polyhedral theory in deep learning: <a href=\"https://arxiv.org/abs/2305.00241\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.00241</span><span class=\"invisible\"></span></a></p><p>This thread covers some of the main points, why we did this, and why you should care about it. Read along!</p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01486-z",
    "title": "Mind-reading machines are here: is it time to worry?",
    "latest": "2023-05-03T18:55:29+00:00",
    "last_post": {
      "url": "https://genart.social/@tca/110306271516901223",
      "content": "<p>'Mind-reading machines are here: is it time to worry?</p><p>Neuroethicists are split on whether a study that uses brain scans and AI to decode imagined speech poses a threat to mental privacy.'</p><p><a href=\"https://www.nature.com/articles/d41586-023-01486-z\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01486-z</span></a></p>"
    },
    "people": [
      {
        "url": "https://genart.social/@tca",
        "display_name": "tiago"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01579v1",
    "title": "Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators",
    "latest": "2023-05-03T18:25:36+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110306154046217243",
      "content": "<p>\ud83d\udcdd Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators \ud83d\udcda\ud83d\udc7e</p><p>\"We fine-tuned GPT-3 (Brown et al 2020) as a question answering model (QA model) on NaturalQuestions (Kwiatkowski et al.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01579v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01579v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2105.13120",
    "title": "Sequence Parallelism: Long Sequence Training from System Perspective",
    "latest": "2023-05-03T17:44:09+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110305991056510256",
      "content": "<p>RT @XueFz@twitter.com</p><p>Glad to share our new ACL paper. <a href=\"https://creative.ai/tags/ACL2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ACL2023</span></a></p><p>A Simple but Useful Transformer Training System for Very Long Sequence </p><p>Paper: <a href=\"https://arxiv.org/abs/2105.13120\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2105.13120</span><span class=\"invisible\"></span></a><br>Code: <a href=\"https://github.com/hpcaitech/ColossalAI\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/hpcaitech/ColossalA</span><span class=\"invisible\">I</span></a><br>Video: <a href=\"https://www.youtube.com/watch?v=HLLVKb7Cszs\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">youtube.com/watch?v=HLLVKb7Csz</span><span class=\"invisible\">s</span></a></p><p>1/N <a href=\"https://twitter.com/rasbt/status/1588610792311529472\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/rasbt/status/15886</span><span class=\"invisible\">10792311529472</span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/XueFz/status/1653811286571098112\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/XueFz/status/16538</span><span class=\"invisible\">11286571098112</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01561v1",
    "title": "https://arxiv.org/abs/2305.01561v1",
    "latest": "2023-05-03T17:35:40+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110305957653817448",
      "content": "<p>\ud83d\udcdd OTIEA:Ontology-enhanced Triple Intrinsic-Correlation for Cross-Lingual Entity Alignment \ud83d\udcda</p><p>\"The intrinsic correlations among entity, relation and ontology are mined in ontology-enhanced triple encoder by triple-aware attention mechanism, and role diversity can be further fused in triple-aware entity decoder.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/CodesForNlp/OTIEA\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/CodesForNlp/OTIEA</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01561v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01561v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41593-023-01304-9",
    "title": "Semantic reconstruction of continuous language from non-invasive brain recordings | Nature Neuroscience",
    "latest": "2023-05-03T17:17:14+00:00",
    "last_post": {
      "url": "https://weird.autos/@Mark/110301906753560867",
      "content": "<p>This is a pretty fucking wild paper that came out a few days ago. Language models can use fMRI imagining to read our minds. This has real world medical applications, but I can\u2019t help but worry what will happen when repressive governments, the military, and law enforcement get this kind of technology. This is really straight out of science fiction and I\u2019m not sure it\u2019s getting popular press. </p><p><a href=\"https://www.nature.com/articles/s41593-023-01304-9\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41593-023</span><span class=\"invisible\">-01304-9</span></a></p>"
    },
    "people": [
      {
        "url": "https://wandering.shop/@annaleen",
        "display_name": "Annalee Newitz \ud83c\udf5c"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.00774",
    "title": "Massive Language Models Can Be Accurately Pruned in One-Shot",
    "latest": "2023-05-03T17:15:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110305876602433177",
      "content": "<p>SparseGPT: Language Models Can Be Accurately Pruned in One-Shot - <a href=\"https://arxiv.org/abs/2301.00774\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.00774</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv ML / AI"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2210.09261",
    "title": "http://arxiv.org/abs/2210.09261",
    "latest": "2023-05-03T17:14:47+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110305875584939980",
      "content": "<p>RT @_jasonwei@twitter.com</p><p>Congrats Mirac Suzgun, my intern at Google Brain last summer, on getting this paper into ACL findings: <a href=\"http://arxiv.org/abs/2210.09261\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2210.09261</span><span class=\"invisible\"></span></a></p><p>It doesn't propose new stuff but it comprehensively studied how chain-of-thought emerges with scale and enables models to solve hard reasoning tasks.</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/_jasonwei/status/1653528805359878145\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/_jasonwei/status/1</span><span class=\"invisible\">653528805359878145</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01556v1",
    "title": "https://arxiv.org/abs/2305.01556v1",
    "latest": "2023-05-03T16:55:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110305800167027111",
      "content": "<p>\ud83d\udcdd Type-Enhanced Ensemble Triple Representation via Triple-Aware Attention for Cross-Lingual Entity Alignment \ud83d\udcda\ud83d\udc7e</p><p>\"A novel framework TTEA is proposed to generate triple-enhanced entity representation by mining the relevance of triple elements via embedding-based methods, which pays little attention to triple indivisibility and entity role diversity.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/CodesForNlp/TTEA\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/CodesForNlp/TTEA</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01556v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01556v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/toc/cjsc20/24/1?nav=tocList",
    "title": "Journal of Spanish Cultural Studies",
    "latest": "2023-05-03T16:40:15+00:00",
    "last_post": {
      "url": "https://hcommons.social/@alexsaum/110305739776702103",
      "content": "<p>Querides, el monogr\u00e1fico del Journal of Spanish Cultural Studies que \u00c1lvaro Llosa y una servidora hemos editado sobre los futuros digitales de las Espa\u00f1as posibles YA EST\u00c1 DISPONIBLE!!!! VIVAAAAAAAAA la vida, la tecnolog\u00eda y el amor  <a href=\"https://hcommons.social/tags/elit\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>elit</span></a> <a href=\"https://hcommons.social/tags/dh\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dh</span></a> <a href=\"https://hcommons.social/tags/spain\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>spain</span></a> <a href=\"https://hcommons.social/tags/spanish\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>spanish</span></a> </p><p><a href=\"https://www.tandfonline.com/toc/cjsc20/24/1?nav=tocList\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/toc/cjsc20/24/</span><span class=\"invisible\">1?nav=tocList</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jose_eduardo",
        "display_name": "Jos\u00e9 Eduardo Gonz\u00e1lez"
      },
      {
        "url": "https://hcommons.social/@alexsaum",
        "display_name": "Alex Saum"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01528v1",
    "title": "FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information",
    "latest": "2023-05-03T16:35:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110305721325022668",
      "content": "<p>\ud83d\udcdd FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information \ud83d\udcda\ud83d\udc7e</p><p>\"Contains over 25K unique sessions from real D&amp;D gameplay on Discord with game state info from the Avrae bot, which was developed to aid people in playing D&amp;D online.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01528v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01528v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01195v1",
    "title": "Topic Shift Detection in Chinese Dialogues: Corpus and Benchmark",
    "latest": "2023-05-03T09:35:36+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110304070006341154",
      "content": "<p>\ud83d\udcdd Topic Shift Detection in Chinese Dialogues: Corpus and Benchmark \ud83d\udcda\ud83e\udde0</p><p>\"We first annotate a Chinese Natural Topic Dialogue (CNTD) corpus consisting of 1308 dialogues to fill the gap in the Chinese natural conversation topic corpus.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01195v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01195v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01145v1",
    "title": "ADVISE: AI-accelerated Design of Evidence Synthesis for Global Development",
    "latest": "2023-05-03T09:15:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110303991220918923",
      "content": "<p>\ud83d\udcdd ADVISE: AI-accelerated Design of Evidence Synthesis for Global Development \ud83d\udcda</p><p>\"We develop an AI agent based on a bidirectional encoder representations from transformers (BERT) model and incorporate it into a human team for designing an evidence synthesis product for global development.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01145v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01145v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s10344-023-01678-y",
    "title": "Your place or mine? Exploring birdwatching tourists\u2019 behaviour disturbing birds in a nature reserve - European Journal of Wildlife Research",
    "latest": "2023-05-03T08:39:21+00:00",
    "last_post": {
      "url": "https://mastodon.social/@freakonometrics/110303848774497278",
      "content": "<p>\"Your place or mine? Exploring birdwatching tourists\u2019 behaviour disturbing birds in a nature reserve\" <a href=\"https://link.springer.com/article/10.1007/s10344-023-01678-y\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s10344-023-01678-y</span></a> \"Poorly developed social norms among visitors, in combination with limited presence of surveillance/guide personnel, and strong behavioural control among some visitors (willingness and ability to engage in illegal behaviour) led to occasional breaching of formal rules as well as incidents of inappropriate, potentially disturbing behaviour towards birds\"</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@freakonometrics",
        "display_name": "Arthur Charpentier"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01099v1",
    "title": "https://arxiv.org/abs/2305.01099v1",
    "latest": "2023-05-03T08:25:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110303794793956607",
      "content": "<p>\ud83d\udcdd Logion: Machine Learning for Greek Philology \ud83d\udcda\ud83e\udde0</p><p>\"Trains a BERT model on the largest premodern Greek dataset used for this purpose to date, and then fine tune it for the task at hand in each experiment.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/charliecb/Logion.git\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/charliecb/Logion.gi</span><span class=\"invisible\">t</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01099v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01099v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01028v1",
    "title": "Company classification using zero-shot learning",
    "latest": "2023-05-03T07:35:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110303597726508243",
      "content": "<p>\ud83d\udcdd Company Classification Using Zero-Shot Learning \ud83d\udcda\ud83e\udde0</p><p>\"Uses pre-trained transformer models such as BERT and RoBERTa to extract features from company descriptions, which are then classified into relevant categories using zero-shot learning without the need for training data for each category.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01028v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01028v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s10994-023-06321-0",
    "title": "Faster Riemannian Newton-type optimization\u00a0by subsampling and cubic regularization - Machine Learning",
    "latest": "2023-05-03T07:22:52+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@mlj/110303548061628193",
      "content": "<p>May's here and so are new <a href=\"https://sigmoid.social/tags/MLJ\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MLJ</span></a> online-first papers: \"Faster Riemannian Newton-type optimization by subsampling and cubic regularization\" by Yian Deng &amp; Tingting Mu (<a href=\"https://link.springer.com/article/10.1007/s10994-023-06321-0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s10994-023-06321-0</span></a>) (OA)</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@mlj",
        "display_name": "Machine Learning Journal"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01020v1",
    "title": "https://arxiv.org/abs/2305.01020v1",
    "latest": "2023-05-03T06:57:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110303448854117511",
      "content": "<p>\ud83d\udcdd Evaluating Statistical Language Models as Pragmatic Reasoners \ud83d\udcda\ud83d\udc7e</p><p>\"Evaluates the inferential capacity of LLMs to derive context-grounded, human-like distributions over the interpretations of several complex pragmatic utterances, including threshold estimation, negation, and qualifiers (e.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/benlipkin/probsem\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/benlipkin/probsem</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01020v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01020v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.16292",
    "title": "http://arxiv.org/abs/2303.16292",
    "latest": "2023-05-03T02:32:07+00:00",
    "last_post": {
      "url": "https://hci.social/@orsonxu/110139181620020175",
      "content": "<p><a href=\"https://hci.social/tags/AR\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AR</span></a> is coming. Great!<br><a href=\"https://hci.social/tags/XAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>XAI</span></a> is important. Of course!<br>But how to combine them together?</p><p>Our paper \"XAIR: A Framework of Explainable AI in Augmented Reality\" has won an Honorable Mention award <a href=\"https://hci.social/tags/CHI2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CHI2023</span></a>! Credits to the team at Meta Reality Labs in the summer! <a href=\"https://hci.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://hci.social/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a></p><p>Preprint: <a href=\"http://arxiv.org/abs/2303.16292\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.16292</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@andresmh",
        "display_name": "Andr\u00e9s Monroy-Hern\u00e1ndez"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01115",
    "title": "https://arxiv.org/abs/2305.01115",
    "latest": "2023-05-03T01:00:21+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110302043950108088",
      "content": "<p>In-Context Learning Unlocked for Diffusion Models</p><p>Presents Prompt Diffusion, a framework for enabling in-context learning in diffusion-based generative models.</p><p>proj: <a href=\"https://zhendong-wang.github.io/prompt-diffusion.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">zhendong-wang.github.io/prompt</span><span class=\"invisible\">-diffusion.github.io/</span></a><br>abs: <a href=\"https://arxiv.org/abs/2305.01115\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01115</span><span class=\"invisible\"></span></a><br>github: <a href=\"https://github.com/Zhendong-Wang/Prompt-Diffusion\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/Zhendong-Wang/Promp</span><span class=\"invisible\">t-Diffusion</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01210",
    "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation",
    "latest": "2023-05-03T00:57:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110302031879531691",
      "content": "<p>Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation</p><p>Proposes EvalPlus \u2013 a code synthesis benchmarking framework to rigorously evaluate the functional correctness of LLM-synthesized code.</p><p><a href=\"https://arxiv.org/abs/2305.01210\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01210</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01528",
    "title": "FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information",
    "latest": "2023-05-03T00:45:36+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@laramar/110300592341566774",
      "content": "<p>Yay! 2/2 papers accepted at <a href=\"https://sigmoid.social/tags/ACL2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ACL2023</span></a> !</p><p>First, in the main conference, there's<br>\"FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information\" by <span class=\"h-card\"><a href=\"https://sigmoid.social/@zhuexe\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>zhuexe</span></a></span>, Karmanya Aggarwal, Alex Feng, myself, &amp; <span class=\"h-card\"><a href=\"https://hci.social/@ccb\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ccb</span></a></span> </p><p>Contributions:<br>- A corpus of data from people playing <a href=\"https://sigmoid.social/tags/DnD\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DnD</span></a> on Discord using a bot called <a href=\"https://sigmoid.social/tags/Avrae\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Avrae</span></a>, made by <span class=\"h-card\"><a href=\"https://sigmoid.social/@zhuexe\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>zhuexe</span></a></span> himself. Avrae tracks vital game state information for D&amp;D.<br>- <a href=\"https://sigmoid.social/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> \"translating\" Avrae commands into plain English.</p><p><a href=\"https://arxiv.org/abs/2305.01528\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01528</span><span class=\"invisible\"></span></a></p><p>1/2</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@pbrane",
        "display_name": "Jake Mannix"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3582932",
    "title": "From Online World to Metaverse: The Future of Online Games and Games Research: Games: Research and Practice: Vol 1, No 1",
    "latest": "2023-05-02T20:56:07+00:00",
    "last_post": {
      "url": "https://social.yesterweb.org/@triptych/110301083572989326",
      "content": "<p><a href=\"https://social.yesterweb.org/tags/mmo\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>mmo</span></a> <a href=\"https://social.yesterweb.org/tags/metaverse\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>metaverse</span></a> <a href=\"https://social.yesterweb.org/tags/worlds\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>worlds</span></a> <a href=\"https://social.yesterweb.org/tags/gaming\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gaming</span></a> <a href=\"https://dl.acm.org/doi/10.1145/3582932\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">dl.acm.org/doi/10.1145/3582932</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://social.yesterweb.org/@triptych",
        "display_name": "Andrew Wooldridge"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.10754",
    "title": "CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped Neurosymbolic Reasoning",
    "latest": "2023-05-02T18:54:40+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@laramar/110300606031169968",
      "content": "<p>Next, in Findings of ACL, there's \"CoRRPUS: Codex-Leveraged Structured Representations for Neurosymbolic Story Understanding\" by Yijiang River Dong, myself, &amp; <span class=\"h-card\"><a href=\"https://hci.social/@ccb\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ccb</span></a></span> </p><p>I've mentioned this work before, but now it's published! Here, we used code-based <a href=\"https://sigmoid.social/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> like Codex (RIP) to provide structure in story understanding, which we saw helps the LLM figure out what characters are doing better!</p><p><a href=\"https://arxiv.org/abs/2212.10754\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.10754</span><span class=\"invisible\"></span></a></p><p>2/2 <a href=\"https://sigmoid.social/tags/ACL2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ACL2023</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@Riedl",
        "display_name": "Mark Riedl"
      },
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      },
      {
        "url": "https://sigmoid.social/@laramar",
        "display_name": "Lara J. Martin"
      }
    ]
  },
  {
    "link": "https://doi.org/10.4126/FRL01-006441397",
    "title": "doi.org/10.4126/FRL01-00644139...",
    "latest": "2023-05-02T18:26:47+00:00",
    "last_post": {
      "url": "https://baudigital.social/@KWermbter/110297692210110404",
      "content": "<p>Was macht eigentlich ein <a href=\"https://baudigital.social/tags/DataSteward\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DataSteward</span></a>? \ud83e\udd14 Das Projekt \"Projekt DataStew \u2013 Data Stewardship in deutschen akademischen Forschungsinstitutionen\" (ZB MED &amp; USB K\u00f6ln), das nun seinen Abschlussbericht vorgelegt hat, kommt zu dem Schluss: \"...eine allgemeing\u00fcltige Definition des Berufsbildes Data Steward kann es nicht geben...\" Nichtsdestotrotz lassen sich prototypische Profile und Anforderungen an Data Stewards bestimmen. Der Bericht ist hier nachzulesen: <a href=\"https://doi.org/10.4126/FRL01-006441397\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.4126/FRL01-00644139</span><span class=\"invisible\">7</span></a> <a href=\"https://baudigital.social/tags/FDM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>FDM</span></a> <a href=\"https://baudigital.social/tags/datastewardship\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>datastewardship</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@hauschke",
        "display_name": "hauschke"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/14614448231161880",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-05-02T17:45:31+00:00",
    "last_post": {
      "url": "https://mastodon.social/@tzimmer_history/110300305756282900",
      "content": "<p>In \u201cA review and provocation: On polarization and platforms\u201d (just published and available online!) Shannon McGregor and Daniel Kreiss review the political science literature and formulate a fundamental critique of the polarization narrative and the normative assumptions on which it is built: </p><p><a href=\"https://journals.sagepub.com/doi/10.1177/14614448231161880\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/14614448231161880</span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@bkeegan",
        "display_name": "Brian C. Keegan"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2205.10271",
    "title": "https://arxiv.org/abs/2205.10271",
    "latest": "2023-05-02T09:17:25+00:00",
    "last_post": {
      "url": "https://mastodon.online/@tillmannohm/110298336192268157",
      "content": "<p>Read about our embedding technique: <br><a href=\"https://arxiv.org/abs/2205.10271\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2205.10271</span><span class=\"invisible\"></span></a></p><p>Stay tuned for the Collection Space Navigator release and publication.</p><p>* attributed to George Box<br><a href=\"https://mastodon.online/tags/CollectionSpaceNavigator\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CollectionSpaceNavigator</span></a> <a href=\"https://mastodon.online/tags/CSN\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CSN</span></a> <a href=\"https://mastodon.online/tags/curation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>curation</span></a> <a href=\"https://mastodon.online/tags/museum\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>museum</span></a> <a href=\"https://mastodon.online/tags/visualization\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>visualization</span></a> <a href=\"https://mastodon.online/tags/collections\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>collections</span></a> <a href=\"https://mastodon.online/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a> <a href=\"https://mastodon.online/tags/wikiart\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>wikiart</span></a> <a href=\"https://mastodon.online/tags/digitalhumanities\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>digitalhumanities</span></a> <a href=\"https://mastodon.online/tags/arthistory\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arthistory</span></a> <a href=\"https://mastodon.online/tags/UMAP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>UMAP</span></a> <a href=\"https://mastodon.online/tags/tSNE\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>tSNE</span></a> <a href=\"https://mastodon.online/tags/research\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>research</span></a> <a href=\"https://mastodon.online/tags/complexity\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>complexity</span></a> <a href=\"https://mastodon.online/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <a href=\"https://mastodon.online/tags/embeddings\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>embeddings</span></a> <a href=\"https://mastodon.online/tags/compression\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compression</span></a> <a href=\"https://mastodon.online/tags/science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>science</span></a> <a href=\"https://mastodon.online/tags/dataanalytics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dataanalytics</span></a> <a href=\"https://mastodon.online/tags/dataanalysis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dataanalysis</span></a> <a href=\"https://mastodon.online/tags/aesthetics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>aesthetics</span></a> <a href=\"https://mastodon.online/tags/curating\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>curating</span></a> <a href=\"https://mastodon.online/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a></p><p>3/3</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv ML / AI"
      },
      {
        "url": "https://hci.social/@bkeegan",
        "display_name": "Brian C. Keegan"
      },
      {
        "url": "https://datasci.social/@yy",
        "display_name": "YY Ahn"
      },
      {
        "url": "https://mastodon.online/@tillmannohm",
        "display_name": "Tillmann Ohm"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05206",
    "title": "https://doi.org/10.21105/joss.05206",
    "latest": "2023-05-02T09:08:07+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110298299564103631",
      "content": "<p>Just published in JOSS: 'DL_Track_US: a python package to analyse muscle ultrasonography images' <a href=\"https://doi.org/10.21105/joss.05206\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05206</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/mnras/article/522/2/2393/7028804",
    "title": "Simulation of the Earth\u2019s radio-leakage from mobile towers as seen from selected nearby stellar systems",
    "latest": "2023-05-02T07:50:40+00:00",
    "last_post": {
      "url": "https://aus.social/@CosmicRami/110297961664600323",
      "content": "<p>Ok, so this is a fun paper ... </p><p>Earth's outgoing radio transmission (focus: cellular phone network broadcasts) modelled from 3 stellar viewing points: HD 95735, Barnard\u2019s star, and Alpha Centauri A.</p><p>If Aliens were out there and using a telescope like the Green Bank telescope, then they still wouldn't detect these signals from Earth, out to 10 light-years. </p><p>But what I am finding interesting, is that the modelling takes into account Earth's rotation, and so mobile towers on different continents come in and out of view - so you could sorta 'map' where civilisation resides if you had technology sensitive enough to make the detections. </p><p>A blueprint of where our populations are, for the aliens, basically. But also, the Sun is radio loud when active, so kinda drowns us out, too (unless the aliens have a very big interferometer and can resolve the Earth and Sun individually).</p><p>A fun read!  </p><p><a href=\"https://academic.oup.com/mnras/article/522/2/2393/7028804\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/mnras/article</span><span class=\"invisible\">/522/2/2393/7028804</span></a></p><p><a href=\"https://aus.social/tags/RadioAstronomy\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RadioAstronomy</span></a> <a href=\"https://aus.social/tags/Astrodon\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Astrodon</span></a> <a href=\"https://aus.social/tags/Science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Science</span></a> <a href=\"https://aus.social/tags/Astronomy\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Astronomy</span></a> <a href=\"https://aus.social/tags/SETI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SETI</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@richardvenusfo",
        "display_name": "Richard"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14738v1",
    "title": "Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics",
    "latest": "2023-05-02T07:33:17+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110297926698917533",
      "content": "<p>\ud83d\udcdd Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics \ud83e\udde0\ud83d\udcda\ud83d\udd2d</p><p>\"The proposed Cost-Sensitive Self-Training (CSST) framework extends the self-training based methods to the non-decomposable metric optimization setting using deep neural networks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14738v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14738v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.13712",
    "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond",
    "latest": "2023-05-02T07:28:29+00:00",
    "last_post": {
      "url": "https://mastodon.xyz/@francoisguite/110294861962220918",
      "content": "<p>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond | arXiv <a href=\"https://arxiv.org/abs/2304.13712\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.13712</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14999v1",
    "title": "Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs",
    "latest": "2023-05-02T06:18:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110297631437373587",
      "content": "<p>\ud83d\udcdd Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs \ud83d\udcda\ud83d\udc7e</p><p>\"Parameter-efficient fine-tuning techniques train a small subset of the model parameters and/or modify only a few of the existing parameters while preserving performance of the model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14999v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14999v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@ljvmiranda",
        "display_name": "Lj V. Miranda"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14953v1",
    "title": "CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data",
    "latest": "2023-05-02T04:33:17+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110297218900688936",
      "content": "<p>\ud83d\udcdd CCpdf: Building a High Quality Corpus for Visually Rich Documents From Web Crawl Data \ud83d\udcda</p><p>\"A pipeline for creating a big-scale, diverse, multilingual corpus of PDF files from all over the Internet using Common Crawl, as PDF files are the most canonical types of documents as considered in document understanding.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14953v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14953v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14936v1",
    "title": "https://arxiv.org/abs/2304.14936v1",
    "latest": "2023-05-02T03:03:19+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110296865173215815",
      "content": "<p>\ud83d\udcdd Information Redundancy and Biases in Public Document Information Extraction Benchmarks \ud83d\udcda\ud83d\udc7e</p><p>\"Proposes to adjust the public benchmarks SROIE and FUNSD to better evaluate the generalization of models trained on them, by reducing the overlap between train and test sets, while keeping a high quality.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Seif-Lat\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/Seif-Lat</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14936v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14936v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://osf.io/preprints/socarxiv/yu34t/",
    "title": "osf.io/preprints/socarxiv/yu34...",
    "latest": "2023-05-02T02:49:36+00:00",
    "last_post": {
      "url": "https://mastodon.social/@bthalpin/110275911092207328",
      "content": "<p>Elsevier and other academic publishers have pivoted from oligopolistic publishers to researcher-surveillance vendors. They track everything you do and sell the analysis back to your employers.</p><p>It's about time that academics became more aware of this.</p><p><a href=\"https://osf.io/preprints/socarxiv/yu34t/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">osf.io/preprints/socarxiv/yu34</span><span class=\"invisible\">t/</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@MattCrumpLab",
        "display_name": "Matt Crump"
      },
      {
        "url": "https://mastodon.social/@autiomaa",
        "display_name": "Daniel Schildt"
      },
      {
        "url": "https://dair-community.social/@DrVeronikaCH",
        "display_name": "Veronika Cheplygina"
      },
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14931v1",
    "title": "HQP: A Human-Annotated Dataset for Detecting Online Propaganda",
    "latest": "2023-05-02T02:33:15+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110296746887054840",
      "content": "<p>\ud83d\udcdd HQP: A Human-Annotated Dataset for Detecting Online Propaganda \ud83d\udcda</p><p>\"Consists of a large number of articles (300K) from a wide range of news sources labeled by professional journalists as propagandistic or non-propagandistic.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14931v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14931v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/jpids/article/12/4/198/7099613",
    "title": "academic.oup.com/jpids/article...",
    "latest": "2023-05-02T01:40:14+00:00",
    "last_post": {
      "url": "https://zeroes.ca/@EricCarroll/110296534442124157",
      "content": "<p>Data show <a href=\"https://zeroes.ca/tags/Omicron\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Omicron</span></a> common cause of <a href=\"https://zeroes.ca/tags/COVID19\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>COVID19</span></a> <a href=\"https://zeroes.ca/tags/reinfections\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>reinfections</span></a></p><p>Mean time between <a href=\"https://zeroes.ca/tags/SARS2\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SARS2</span></a> infections was 229 days.</p><p>Minimum time was 45 days.</p><p>Reinfection counts higher during the Omicron era</p><p><a href=\"https://www.cidrap.umn.edu/covid-19/data-show-omicron-common-cause-covid-19-reinfections\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">cidrap.umn.edu/covid-19/data-s</span><span class=\"invisible\">how-omicron-common-cause-covid-19-reinfections</span></a></p><p><a href=\"https://academic.oup.com/jpids/article/12/4/198/7099613\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/jpids/article</span><span class=\"invisible\">/12/4/198/7099613</span></a></p>"
    },
    "people": [
      {
        "url": "https://code4lib.social/@coral",
        "display_name": "Coral \ud83e\udd89"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.09752",
    "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation",
    "latest": "2023-05-02T01:05:13+00:00",
    "last_post": {
      "url": "https://mastodon.lol/@unmeg/110296367556710544",
      "content": "<p>\ud83d\udd25Some more mega-context Transformers: <br>- CoLT5 (64k): <a href=\"https://arxiv.org/abs/2303.09752\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.09752</span><span class=\"invisible\"></span></a><br>- RMT (1M): <a href=\"https://arxiv.org/abs/2304.11062\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.11062</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://mathstodon.xyz/@zachfisher",
        "display_name": "Zach Fisher"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.11062",
    "title": "Scaling Transformer to 1M tokens and beyond with RMT",
    "latest": "2023-05-02T01:05:13+00:00",
    "last_post": {
      "url": "https://mastodon.lol/@unmeg/110296367556710544",
      "content": "<p>\ud83d\udd25Some more mega-context Transformers: <br>- CoLT5 (64k): <a href=\"https://arxiv.org/abs/2303.09752\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.09752</span><span class=\"invisible\"></span></a><br>- RMT (1M): <a href=\"https://arxiv.org/abs/2304.11062\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.11062</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://mastodon.online/@vladiliescu",
        "display_name": "Vlad Iliescu \ud83d\udc2c"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14827v1",
    "title": "ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations",
    "latest": "2023-05-02T01:03:16+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110296393105042545",
      "content": "<p>\ud83d\udcdd ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations \ud83d\udcda</p><p>\"In-context learning (ICL) and zero-shot prompts are used to evaluate its ability on inter-sentential relations, including temporal relations, causal relations, and discourse relations.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14827v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14827v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14796v1",
    "title": "https://arxiv.org/abs/2304.14796v1",
    "latest": "2023-05-01T22:03:14+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110295685182433692",
      "content": "<p>\ud83d\udcdd Are the Best Multilingual Document Embeddings Simply Based on Sentence Embeddings? \ud83d\udcda</p><p>\"Compares input token number truncation, sentence averaging as well as some simple windowing and in some cases new augmented and learnable approaches, on 3 multi- and cross-lingual tasks in 8 languages belonging to 3 different language families.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14796v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14796v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.09103",
    "title": "ChatGPT: Applications, Opportunities, and Threats",
    "latest": "2023-05-01T21:58:05+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ceperez/110295664922831956",
      "content": "<p>Well DUH!!!!!  \"ChatGPT does not possess the same level of understanding, empathy, and creativity as a human and cannot fully replace them in most situations.\"<br><a href=\"https://arxiv.org/abs/2304.09103\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.09103</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14780v1",
    "title": "Training and Evaluation of a Multilingual Tokenizer for GPT-SW3",
    "latest": "2023-05-01T20:33:16+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110295331432183260",
      "content": "<p>\ud83d\udcdd Training and Evaluation of a Multilingual Tokenizer for GPT-SW3 \ud83d\udcda\ud83d\udc7e</p><p>\"The tokenizer uses Byte-Pair-Encoding (BPE) with a vocabulary size of 30,320 tokens trained on the Nordic Pile.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14780v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14780v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41559-023-02038-4",
    "title": "nature.com/articles/s41559-023...",
    "latest": "2023-05-01T20:30:57+00:00",
    "last_post": {
      "url": "https://scholar.social/@animalculum/110294940942343935",
      "content": "<p>Middle Ordovician 'marine dwarf world' found in Castle Bank, Wales <a href=\"https://phys.org/news/2023-05-middle-ordovician-marine-dwarf-world.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">phys.org/news/2023-05-middle-o</span><span class=\"invisible\">rdovician-marine-dwarf-world.html</span></a></p><p>A Middle <a href=\"https://scholar.social/tags/Ordovician\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Ordovician</span></a> <a href=\"https://scholar.social/tags/BurgessShale\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BurgessShale</span></a>-type fauna from Castle Bank, <a href=\"https://scholar.social/tags/Wales\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Wales</span></a> <a href=\"https://www.nature.com/articles/s41559-023-02038-4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41559-023</span><span class=\"invisible\">-02038-4</span></a> </p><p>The site comprises over 150 species, with many of miniaturized body size. It is one of the world's most unexpected <a href=\"https://scholar.social/tags/fossil\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>fossil</span></a> sites. In some <a href=\"https://scholar.social/tags/animals\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>animals</span></a>, internal organs such as digestive systems and even nerves are preserved, together with the limbs of tiny <a href=\"https://scholar.social/tags/arthropods\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arthropods</span></a> and delicate filter-feeding tentacles.</p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@NikaShilobod",
        "display_name": "Nika Shilobod"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/2208917.2229115",
    "title": "Getting What You Measure: Four common pitfalls in using software metrics for project management: Queue: Vol 10, No 5",
    "latest": "2023-05-01T19:57:36+00:00",
    "last_post": {
      "url": "https://fediscience.org/@avandeursen/110295007528619763",
      "content": "<p>I also quite like how the Pluralsight developer productivity study built on our \"Getting What You Measure\" paper, rephrasing our common metric pitfalls as:</p><p>1. We tend to measure things without enough context.<br>2. We're concerned about the appearance, but not really the meaning of what we've measured.<br>3. We have not measured enough things.<br>4. We measure many things, but they do not feel related to each other.</p><p><a href=\"https://dl.acm.org/doi/10.1145/2208917.2229115\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/10.1145/2208917</span><span class=\"invisible\">.2229115</span></a></p><p><a href=\"https://www.pluralsight.com/resource-center/guides/developer-thriving-research-paper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">pluralsight.com/resource-cente</span><span class=\"invisible\">r/guides/developer-thriving-research-paper</span></a></p><p><a href=\"https://fediscience.org/tags/DeveloperProductivity\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeveloperProductivity</span></a> <a href=\"https://fediscience.org/tags/Pluralsight\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Pluralsight</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@grimalkina",
        "display_name": "Cat Hicks"
      },
      {
        "url": "https://mastodon.social/@gvwilson",
        "display_name": "Greg Wilson"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2304.05967.pdf",
    "title": "https://arxiv.org/pdf/2304.05967.pdf",
    "latest": "2023-05-01T19:56:14+00:00",
    "last_post": {
      "url": "https://hci.social/@jbigham/110254367816479894",
      "content": "<p>Watching Sam Robertson present her paper written with Apple colleagues on developing an infovis tool to help translation practitioners find and mitigate errors at <a href=\"https://hci.social/tags/chi2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>chi2023</span></a>, read the paper here <a href=\"https://arxiv.org/pdf/2304.05967.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2304.05967.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://idf.social/@arjen",
        "display_name": "Arjen P. de Vries Timmers \ud83d\udd4a\ufe0f"
      },
      {
        "url": "https://vis.social/@dom",
        "display_name": "Dominik Moritz"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14770v1",
    "title": "RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction",
    "latest": "2023-05-01T18:33:16+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110294859554370504",
      "content": "<p>\ud83d\udcdd RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction \ud83d\udcda</p><p>\"RexUIE is a model that combines explicit schema instruction with recursive extraction and achieves state of the art results on complex schemas such as quadruples and quintuples.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14770v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14770v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14767",
    "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models",
    "latest": "2023-05-01T18:04:55+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@jasmijn/110294355640967244",
      "content": "<p><span class=\"h-card\"><a href=\"https://sigmoid.social/@mega\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mega</span></a></span> <span class=\"h-card\"><a href=\"https://sigmoid.social/@davidbau\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>davidbau</span></a></span> Check out our preprint for more details and analysis: <a href=\"https://arxiv.org/abs/2304.14767\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14767</span><span class=\"invisible\"></span></a> <br> <br>This was a really fun project with <span class=\"h-card\"><a href=\"https://sigmoid.social/@mega\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mega</span></a></span>, Katja Filippova, Amir Globerson! <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/XAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>XAI</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2304.15004.pdf",
    "title": "https://arxiv.org/pdf/2304.15004.pdf",
    "latest": "2023-05-01T17:53:54+00:00",
    "last_post": {
      "url": "https://mas.to/@assaf/110294574185450915",
      "content": "<p>Are Emergent Abilities of Large Language Models a Mirage?</p><p><a href=\"https://arxiv.org/pdf/2304.15004.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2304.15004.pdf</span><span class=\"invisible\"></span></a></p><p>\u201cErgo, emergent abilities may be creations of the researcher\u2019s choices, not a fundamental property of the model family on the specific task. \u201c</p><p>Sometimes people get overly excited about \u201cGPT just proved AGI!\u201d brand of loosely researched posts, most of which won\u2019t replicate, so you want to show them this paper and it probably won\u2019t change their minds but at least you gave it your best</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@eliocamp",
        "display_name": "Elio Campitelli"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14767v1",
    "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models",
    "latest": "2023-05-01T17:18:19+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110294564829733430",
      "content": "<p>\ud83d\udcdd Dissecting Recall of Factual Associations in Auto-Regressive Language Models \ud83d\udcda</p><p>\"Analyzes how a transformer language model extracts factual attributes from a factual triplet (\"Aaron\", \"plays for\", \"Dallas Cowboys\") to answer the query \"Aaron plays for the Dallas Cowboys\".\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14767v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14767v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.13861",
    "title": "Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks",
    "latest": "2023-05-01T09:15:55+00:00",
    "last_post": {
      "url": "https://datasci.social/@lajello/110292566421224490",
      "content": "<p>Is GPT-4 good at augmenting training datasets for supervised tasks for computational social science? The answer is not as clear-cut as you might imagine. New preprint out, feedback is very welcome!<br><a href=\"https://arxiv.org/abs/2304.13861\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.13861</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@mszll",
        "display_name": "Michael Szell"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14511v1",
    "title": "https://arxiv.org/abs/2304.14511v1",
    "latest": "2023-05-01T09:03:15+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110292618154756582",
      "content": "<p>\ud83d\udcdd Visual Referential Games Further the Emergence of Disentangled Representations \ud83d\udcda</p><p>\"Investigates how do compositionality at the level of the emerging languages, disentanglement at the level of the learned representations and systematicity relate to each other in the context of visual referential games.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Near32/ReferentialGym/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/Near32/ReferentialG</span><span class=\"invisible\">ym/</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14511v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14511v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/cr9kp/",
    "title": "http://osf.io/cr9kp/",
    "latest": "2023-05-01T05:16:50+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110291727855151879",
      "content": "<p>Discussion on the originality of the Tune of Yue Fei's \"Manjiang Hong\" and its work analysis: form, style and genre of Tan Huibing's composition <a href=\"http://osf.io/cr9kp/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/cr9kp/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/k5ugr/",
    "title": "http://osf.io/k5ugr/",
    "latest": "2023-05-01T05:11:01+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110291704957546926",
      "content": "<p>Does Interviewers' Age Affect Their Assessment of Respondents' Understanding of Survey Questions? Evidence From the European Social Survey <a href=\"http://osf.io/k5ugr/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/k5ugr/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/326tw/",
    "title": "http://osf.io/326tw/",
    "latest": "2023-05-01T05:11:00+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110291704930445310",
      "content": "<p>Algorithms in Judges' Hands: Incarceration and Inequity in Broward County, Florida <a href=\"http://osf.io/326tw/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/326tw/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/z2bvs/",
    "title": "http://osf.io/z2bvs/",
    "latest": "2023-05-01T05:11:00+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110291704908655073",
      "content": "<p>Gendered Leadership Beliefs and U.S. Presidential Elections <a href=\"http://osf.io/z2bvs/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/z2bvs/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14530",
    "title": "It is all about where you start: Text-to-image generation with seed selection",
    "latest": "2023-05-01T04:11:46+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110291472003758668",
      "content": "<p>It\u2019s all about where you start: Text-to-image generation with seed selection</p><p>Shows that rare concepts can be correctly generated by carefully selecting suitable generation seeds in the noise space, a technique that we call SeedSelect</p><p><a href=\"https://arxiv.org/abs/2304.14530\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14530</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14953",
    "title": "https://arxiv.org/abs/2304.14953",
    "latest": "2023-05-01T04:11:41+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110291471677683654",
      "content": "<p>CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data</p><p>repo: <a href=\"https://github.com/applicaai/CCpdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/applicaai/CCpdf</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2304.14953\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14953</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14979",
    "title": "MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks",
    "latest": "2023-05-01T04:11:38+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110291471495337665",
      "content": "<p>MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks</p><p>Demonstrates that LLM can (i) observe from the existing experiences of ML tasks and (ii) reason effectively to deliver promising results for new tasks.</p><p><a href=\"https://arxiv.org/abs/2304.14979\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14979</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.15010",
    "title": "https://arxiv.org/abs/2304.15010",
    "latest": "2023-05-01T04:11:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110291471046159471",
      "content": "<p>LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model</p><p>Performs open-ended multi-modal instructions by merely introducing 14M parameters over LLaMA.</p><p>spaces: <a href=\"https://huggingface.co/spaces/csuhan/LLaMA-Adapter\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">huggingface.co/spaces/csuhan/L</span><span class=\"invisible\">LaMA-Adapter</span></a><br>repo: <a href=\"https://github.com/ZrrSkywalker/LLaMA-Adapter\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/ZrrSkywalker/LLaMA-</span><span class=\"invisible\">Adapter</span></a><br>abs: <a href=\"https://arxiv.org/abs/2304.15010\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.15010</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3498366.3505816",
    "title": "Situating Search | ACM SIGIR Conference on Human Information Interaction and Retrieval",
    "latest": "2023-05-01T00:54:48+00:00",
    "last_post": {
      "url": "https://dair-community.social/@emilymbender/110290697504921328",
      "content": "<p>This is important in two respects: First, it cuts off people's ability to locate information in context. Chirag Shah and I argued in our 2022 CHIIR paper that is is a big step back for information access systems:</p><p><a href=\"https://dl.acm.org/doi/10.1145/3498366.3505816\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/10.1145/3498366</span><span class=\"invisible\">.3505816</span></a></p><p>&gt;&gt;</p>"
    },
    "people": [
      {
        "url": "https://dair-community.social/@emilymbender",
        "display_name": "Emily M. Bender (she/her)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13808",
    "title": "Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning",
    "latest": "2023-04-30T19:07:30+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110272712889779420",
      "content": "<p>Large Language Models are Versatile Decomposers for Table-based Reasoning</p><p>Surpasses the human performance on Tabfact for the first time by decomposing a large table and leveraging SQL execution to mitigate the hallucination of CoT.</p><p><a href=\"https://arxiv.org/abs/2301.13808\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13808</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s00146-021-01179-z",
    "title": "In search of the moral status of AI: why sentience is a strong argument - AI & SOCIETY",
    "latest": "2023-04-30T18:35:58+00:00",
    "last_post": {
      "url": "https://mastodon.social/@FrankPasquale/110288023309882298",
      "content": "<p>\u201cNo AI system is sentient given the current level of technological development.\u201d<br><a href=\"https://link.springer.com/article/10.1007/s00146-021-01179-z\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s00146-021-01179-z</span></a></p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2304.06364.pdf",
    "title": "https://arxiv.org/pdf/2304.06364.pdf",
    "latest": "2023-04-30T08:47:04+00:00",
    "last_post": {
      "url": "https://qoto.org/@twitskeptic/110194811565622996",
      "content": "<p>Microsoft just published a paper - modestly titled  \"AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models\" - that, no joke, uses readily available *online* sample SAT questions to evaluate the GPT class LLMs. The problem, of course, is that same data was likely used to train the same models. <a href=\"https://arxiv.org/pdf/2304.06364.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2304.06364.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14108v1",
    "title": "DataComp: In search of the next generation of multimodal datasets",
    "latest": "2023-04-30T01:36:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110285199148904947",
      "content": "<p>\ud83d\udcdd DataComp: In Search of the Next Generation of Multimodal Datasets \ud83d\udd2d\ud83d\udcda\ud83e\udde0</p><p>\"A candidate pool is created from Common Crawl data, and filtering techniques are used to create a dataset of 128M to 128B image-text pairs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14108v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14108v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.13343",
    "title": "Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System",
    "latest": "2023-04-30T00:56:56+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110268069340713763",
      "content": "<p>Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System</p><p>Enables LLMs to outperform ChatGPT in scenarios involving ultra-long document summarization or long-term conversations.</p><p><a href=\"https://arxiv.org/abs/2304.13343\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.13343</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14104v1",
    "title": "Learning Human-Human Interactions in Images from Weak Textual Supervision",
    "latest": "2023-04-29T23:56:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110284805989274978",
      "content": "<p>\ud83d\udcdd Learning Human-Human Interactions in Images From Weak Textual Supervision \ud83d\udd2d\ud83d\udcda\ud83e\udde0</p><p>\"Proposes a new paradigm of learning human-human interactions as free text from a single still image, allowing for flexibility in modeling the unlimited space of situations and relationships between people.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14104v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14104v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2206.04615.pdf",
    "title": "https://arxiv.org/pdf/2206.04615.pdf",
    "latest": "2023-04-29T23:46:28+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110284766476620362",
      "content": "<p>[D] \"Knowledge\" vs \"Reasoning\" in LLMs</p><p><a href=\"https://arxiv.org/pdf/2206.04615.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2206.04615.pdf</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/pdf/2206.04615.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/p</span><span class=\"invisible\">df/2206.04615.pdf</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14402v1",
    "title": "LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions",
    "latest": "2023-04-29T20:36:29+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110284019457800961",
      "content": "<p>\ud83d\udcdd LaMini-LM: A Diverse Herd of Distilled Models From Large-Scale Instructions \ud83d\udcda</p><p>\"We first finetune gpt-3 on the set of instructions $\\mathcal{I}$ to obtain a task instruction encoder $\\mathcal{E}$.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14402v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14402v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14395v1",
    "title": "https://arxiv.org/abs/2304.14395v1",
    "latest": "2023-04-29T19:56:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110283862102711976",
      "content": "<p>\ud83d\udcdd String2string: A Modern Python Library for String-to-String Algorithms \ud83d\udcda</p><p>\"The library provides a comprehensive suite of efficient algorithms for a broad range of string-to-string problems, ranging from string alignment problems, to lexical and semantic search, and similarity analysis.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/DL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/stanfordnlp/string2string\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/stanfordnlp/string2</span><span class=\"invisible\">string</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14395v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14395v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14364v1",
    "title": "https://arxiv.org/abs/2304.14364v1",
    "latest": "2023-04-29T18:16:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110283469007852844",
      "content": "<p>\ud83d\udcdd CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Generates training data for a guardrail model by prompting GPT-4 to write rule-violating and rule-conforming examples for a given task and rule.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/curai/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/curai/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.14364v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14364v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  }
]