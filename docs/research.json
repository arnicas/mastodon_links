[
  {
    "link": "https://arxiv.org/abs/2209.01207",
    "title": "Co-Imitation: Learning Design and Behaviour by Imitation",
    "latest": "2023-02-11T22:00:20+00:00",
    "last_post": {
      "url": "https://mastodon.online/@FCAI/109834980490319925",
      "content": "<p>Are you at <a href=\"https://mastodon.online/tags/AAAI23\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AAAI23</span></a> this week? Check out these papers from FCAI:</p><p>*\ufe0f\u20e3 Co-Imitation: Learning Design and Behaviour by Imitation (Rajani et al.) <a href=\"https://arxiv.org/abs/2209.01207\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2209.01207</span><span class=\"invisible\"></span></a> (project website <a href=\"https://sites.google.com/view/co-imitation\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">sites.google.com/view/co-imita</span><span class=\"invisible\">tion</span></a>)</p><p>*\ufe0f\u20e3 Zero-Shot Assistance in Sequential Decision Problems (<span class=\"h-card\"><a href=\"https://ellis.social/@samikaski\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>samikaski</span></a></span> et al.)<br><a href=\"https://arxiv.org/abs/2202.07364\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2202.07364</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2202.07364",
    "title": "https://arxiv.org/abs/2202.07364",
    "latest": "2023-02-11T22:00:20+00:00",
    "last_post": {
      "url": "https://mastodon.online/@FCAI/109834980490319925",
      "content": "<p>Are you at <a href=\"https://mastodon.online/tags/AAAI23\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AAAI23</span></a> this week? Check out these papers from FCAI:</p><p>*\ufe0f\u20e3 Co-Imitation: Learning Design and Behaviour by Imitation (Rajani et al.) <a href=\"https://arxiv.org/abs/2209.01207\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2209.01207</span><span class=\"invisible\"></span></a> (project website <a href=\"https://sites.google.com/view/co-imitation\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">sites.google.com/view/co-imita</span><span class=\"invisible\">tion</span></a>)</p><p>*\ufe0f\u20e3 Zero-Shot Assistance in Sequential Decision Problems (<span class=\"h-card\"><a href=\"https://ellis.social/@samikaski\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>samikaski</span></a></span> et al.)<br><a href=\"https://arxiv.org/abs/2202.07364\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2202.07364</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04542v1",
    "title": "https://arxiv.org/abs/2302.04542v1",
    "latest": "2023-02-11T21:56:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109848334459720776",
      "content": "<p>\ud83d\udcdd Efficient Attention via Control Variates \ud83e\udde0\ud83d\udcda\ud83d\udd2d</p><p>\"A novel random feature based attention mechanism is proposed, and a novel attention mechanism that significantly reduces the approximation gap while maintaining linear complexity is developed by manipulating multiple control variates.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/pytorch/fairseq/blob/master/examples/language_\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/pytorch/fairseq/blo</span><span class=\"invisible\">b/master/examples/language_</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.04542v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04542v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04869v1",
    "title": "https://arxiv.org/abs/2302.04869v1",
    "latest": "2023-02-11T21:38:26+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cv/109848157536546562",
      "content": "<p>\ud83d\udcdd Reversible Vision Transformers \ud83d\udd2d\ud83d\udc7e</p><p>\"Reversible Vision Transformers are a family of architectures that have reversible layers that can be trained without storing hidden activations, reducing the memory requirement for training by up to 15.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/facebookresearch/slowfast\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/sl</span><span class=\"invisible\">owfast</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.04869v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04869v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://osf.io/csdhb/",
    "title": "https://osf.io/csdhb/",
    "latest": "2023-02-11T21:30:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/109848232182696470",
      "content": "<p>Theory of mind may have spontaneously emerged in large language models (2021) - <a href=\"https://osf.io/csdhb/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">osf.io/csdhb/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04862v1",
    "title": "https://arxiv.org/abs/2302.04862v1",
    "latest": "2023-02-11T21:11:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cv/109847803697809062",
      "content": "<p>\ud83d\udcdd Polynomial Neural Fields for Subband Decomposition and Manipulation \ud83d\udd2d\ud83e\udde0</p><p>\"A polynomial neural field (PNF) models a signal with a composition of polynomial functions and neural fields, where the polynomial functions are interpretable components that allow signal manipulation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/stevenygd/PNF\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/stevenygd/PNF</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.04862v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04862v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://osf.io/preprints/socarxiv/jqxb6",
    "title": "osf.io/preprints/socarxiv/jqxb...",
    "latest": "2023-02-11T21:09:18+00:00",
    "last_post": {
      "url": "https://scholar.social/@olivia/109847062879103209",
      "content": "<p>We end on asking you to use our lens where useful to note Pygmalion displacements as a first step towards escaping the cycle of sexist AI-based harm. When a parallel between women and AI is drawn, ask whom does that bait-and-switch serve?</p><p>More here: <a href=\"https://osf.io/preprints/socarxiv/jqxb6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">osf.io/preprints/socarxiv/jqxb</span><span class=\"invisible\">6</span></a></p><p>4/4</p>"
    },
    "people": [
      {
        "url": "https://wandering.shop/@cstross",
        "display_name": "Charlie Stross"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.09261",
    "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them",
    "latest": "2023-02-11T21:03:49+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@lampinen/109846717477807576",
      "content": "<p>And though some particularly challenging BIG-Bench tasks are harder, models can perform better on many of them if given time to produce some reasoning steps before their answer (<a href=\"https://arxiv.org/abs/2210.09261\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.09261</span><span class=\"invisible\"></span></a>). Memorization + rephrasing is not a good explanation of this. 7/</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.04584",
    "title": "Continual Few-Shot Learning Using HyperTransformers",
    "latest": "2023-02-11T20:29:56+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@akhaliq/109673755324555916",
      "content": "<p>Continual Few-Shot Learning Using HyperTransformers </p><p>abs: <a href=\"https://arxiv.org/abs/2301.04584\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.04584</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@cwizprod1",
        "display_name": "Cyberwizard"
      },
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04834v1",
    "title": "FrameBERT: Conceptual Metaphor Detection with Frame Embedding Learning",
    "latest": "2023-02-11T20:26:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109847980576204983",
      "content": "<p>\ud83d\udcdd FrameBERT: Conceptual Metaphor Detection with Frame Embedding Learning \ud83d\udcda</p><p>\"Proposes FrameBERT, an RoBERTa-based model that learns and incorporates FrameNet Embeddings to enhance the metaphor detection model\u2019s ability to capture the semantic meanings of the target words.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.04834v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04834v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02083",
    "title": "Theory of Mind May Have Spontaneously Emerged in Large Language Models",
    "latest": "2023-02-11T20:21:21+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@kbaxter/109847961454605580",
      "content": "<p>\u201cTheory of Mind May Have Spontaneously Emerged in Large Language Models\u201d <a href=\"https://arxiv.org/abs/2302.02083\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02083</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03011",
    "title": "https://arxiv.org/abs/2302.03011",
    "latest": "2023-02-11T09:53:33+00:00",
    "last_post": {
      "url": "https://mastodon.social/@hrbrmstr/109845493423583068",
      "content": "<p>Some impressive new video AI/diffusion kit from Runway.</p><p><a href=\"https://research.runwayml.com/gen1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">research.runwayml.com/gen1</span><span class=\"invisible\"></span></a></p><p><a href=\"https://arxiv.org/abs/2302.03011\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03011</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@hrbrmstr",
        "display_name": "boB Rudis \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://doi.org/10.7554/eLife.84991",
    "title": "https://doi.org/10.7554/eLife.84991",
    "latest": "2023-02-11T09:23:15+00:00",
    "last_post": {
      "url": "https://neuromatch.social/@anneurai/109836831950343245",
      "content": "<p>How to be an academic in a world on fire?</p><p>As scientists concerned about the climate crisis, <span class=\"h-card\"><a href=\"https://mastodon.social/@clarekelly\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>clarekelly</span></a></span> and I set out to rethink the role and goals of the university in tackling the 21st century's challenges. Inspired by Raworth's Doughnut Economics, we propose seven new ways to thinking - not only to help us think, but also to act.</p><p>Read the paper: Urai AE, Kelly C (2023) Rethinking academia in a time of climate crisis. eLife 12:e84991. <a href=\"https://doi.org/10.7554/eLife.84991\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.7554/eLife.84991</span><span class=\"invisible\"></span></a><br>Join us for a discussion at Growing Up in Science Global on 11 April: <a href=\"https://nyu.zoom.us/meeting/register/tJIoc-GsqT8uGNXniBIHPo9u4ibfDwxysLkI\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">nyu.zoom.us/meeting/register/t</span><span class=\"invisible\">JIoc-GsqT8uGNXniBIHPo9u4ibfDwxysLkI</span></a></p><p>... and let us know your thoughts!</p>"
    },
    "people": [
      {
        "url": "https://toot.aquilenet.fr/@rougier",
        "display_name": "Nicolas P. Rougier"
      },
      {
        "url": "https://scholar.social/@researchfairy",
        "display_name": "The research fairy"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1038/s41562-022-01508-2",
    "title": "doi.org/10.1038/s41562-022-015...",
    "latest": "2023-02-11T08:06:46+00:00",
    "last_post": {
      "url": "https://fediscience.org/@MarkRubin/109842274012190197",
      "content": "<p>Fixed-term contracts harm research quality</p><p>Rahal et al. (2023). Quality research needs good working conditions. <a href=\"https://doi.org/10.1038/s41562-022-01508-2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1038/s41562-022-015</span><span class=\"invisible\">08-2</span></a> </p><p><a href=\"https://fediscience.org/tags/ucurising\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ucurising</span></a></p>"
    },
    "people": [
      {
        "url": "https://dair-community.social/@DrVeronikaCH",
        "display_name": "Veronika Cheplygina"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04089v1",
    "title": "ZipLM: Hardware-Aware Structured Pruning of Language Models",
    "latest": "2023-02-11T07:15:29+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109844871888441708",
      "content": "<p>\ud83d\udcdd ZipLM: Hardware-Aware Structured Pruning of Language Models \ud83e\udde0\ud83d\udcda</p><p>\"Proposes a new structured compression method for LLMs, based on new structured pruning and knowledge distillation techniques, that can be applied in both, post-training as well as gradual compression setting.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.04089v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04089v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03988",
    "title": "On Cosmological Low Entropy After the Big Bang: Universal Expansion and Nucleosynthesis",
    "latest": "2023-02-11T06:35:16+00:00",
    "last_post": {
      "url": "https://mas.to/@stephenserjeant/109837178899745681",
      "content": "<p>Absolutely the best Acknowledgments section of a paper I\u2019ve read. From <a href=\"https://arxiv.org/abs/2302.03988\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03988</span><span class=\"invisible\"></span></a> <a href=\"https://mas.to/tags/astrodon\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>astrodon</span></a> / h/t <span class=\"h-card\"><a href=\"https://mstdn.social/@playingwithdust\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>playingwithdust</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://data-folks.masto.host/@Leena",
        "display_name": "Leena"
      },
      {
        "url": "https://mstdn.social/@arnicas",
        "display_name": "arnicas"
      },
      {
        "url": "https://mstdn.social/@felwert",
        "display_name": "Frederik Elwert"
      },
      {
        "url": "https://fediscience.org/@NikaShilobod",
        "display_name": "Nika Shilobod"
      },
      {
        "url": "https://mastodon.cloud/@seatrout",
        "display_name": "Andrew Brown"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04197v1",
    "title": "https://arxiv.org/abs/2302.04197v1",
    "latest": "2023-02-11T05:45:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109844518066487484",
      "content": "<p>\ud83d\udcdd Hierarchical Event Grounding \ud83d\udcda</p><p>\"Leverages event hierarchy through an auxiliary hierarchical loss during retrieval of candidates to be re-ranked using cross-encoder model (BERT) (Devlin, Chang, and Lee 2019).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/JefferyO/HierarchicalEvent-Grounding\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/JefferyO/Hierarchic</span><span class=\"invisible\">alEvent-Grounding</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.04197v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04197v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://onlinelibrary.wiley.com/doi/full/10.1111/1745-9133.12558",
    "title": "onlinelibrary.wiley.com/doi/fu...",
    "latest": "2023-02-11T04:21:56+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@mekkaokereke/109842660353796642",
      "content": "<p>In Chicago, fewer than 4% of DUI checkpoints are in majority white neighborhoods, but 25% of drunk driving accidents are in white neighborhoods. \ud83d\ude42\ud83d\ude43</p><p>In California, fewer than 1% of drunk driving arrests come from checkpoints.\ud83e\udd26\ud83c\udfff\u200d\u2642\ufe0f</p><p>Cops are using DUI checkpoints as an excuse to stop Black drivers, then searching them and arresting them for other things. Because policing in America. Because racism.</p><p><a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/1745-9133.12558\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">onlinelibrary.wiley.com/doi/fu</span><span class=\"invisible\">ll/10.1111/1745-9133.12558</span></a></p>"
    },
    "people": [
      {
        "url": "https://octodon.social/@craignicol",
        "display_name": "Craig Nicol"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2302.04761",
    "title": "http://arxiv.org/abs/2302.04761",
    "latest": "2023-02-10T22:02:42+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109842698238665198",
      "content": "<p>RT @timo_schick@twitter.com</p><p>\ud83c\udf89 New paper \ud83c\udf89 Introducing the Toolformer, a language model that teaches itself to use various tools in a self-supervised way. This significantly improves zero-shot performance and enables it to outperform much larger models. \ud83e\uddf0</p><p>\ud83d\udd17 Link: <a href=\"http://arxiv.org/abs/2302.04761\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2302.04761</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/timo_schick/status/1624058382142345216\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/timo_schick/status</span><span class=\"invisible\">/1624058382142345216</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04023",
    "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",
    "latest": "2023-02-10T21:47:31+00:00",
    "last_post": {
      "url": "https://mastodon.social/@bruienne/109842637721687231",
      "content": "<p>Besides anecdotal casual writeups about ChatGPT's tendency to make stuff up (or officially: hallucinates), this scientific paper goes into the topic deeper, I found it a good read: <a href=\"https://arxiv.org/abs/2302.04023\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04023</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03693v1",
    "title": "https://arxiv.org/abs/2302.03693v1",
    "latest": "2023-02-10T21:00:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109842453895671637",
      "content": "<p>\ud83d\udcdd Concept Algebra for Text-Controlled Vision Models \ud83d\udcda\ud83e\udde0</p><p>\"Concept algebra is a way to directly manipulate concepts that the output depends on by using algebraic operations on a suitably defined representation of input prompts (the concept representation).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/zihao12/concept-algebra\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/zihao12/concept-alg</span><span class=\"invisible\">ebra</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03693v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03693v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.2307/3185496",
    "title": "https://doi.org/10.2307/3185496",
    "latest": "2023-02-10T20:12:07+00:00",
    "last_post": {
      "url": "https://post.lurk.org/@samplereality/109842263420300222",
      "content": "<p>Okay! So not just a hunch, but confirmed! In this 2001 interview Butler refers to The Turner Diaries before talking about her motivations for Parable of the Sower: <a href=\"https://doi.org/10.2307/3185496\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.2307/3185496</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://post.lurk.org/@samplereality",
        "display_name": "Mark Sample"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01339",
    "title": "Creating a Large Language Model of a Philosopher",
    "latest": "2023-02-10T09:56:48+00:00",
    "last_post": {
      "url": "https://scholar.social/@davidschlangen/109839843589980839",
      "content": "<p>DANIEL DENNETT MAY HAVE SPONTANEOUSLY EMERGED IN LARGE LANGUAGE MODELS</p><p><a href=\"https://arxiv.org/abs/2302.01339\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01339</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2112.00183",
    "title": "Descriptive vs. inferential community detection in networks: pitfalls, myths, and half-truths",
    "latest": "2023-02-10T09:40:15+00:00",
    "last_post": {
      "url": "https://social.skewed.de/@tiago/107405344003726323",
      "content": "<p>New blog post!</p><p>\"No free lunch in community detection?\"</p><p>NFL theorems are tricky to interpret, and are often misunderstood.</p><p>No, it does not mean that all community detection algorithms are equally good. 1/9</p><p>(Based on <a href=\"https://arxiv.org/abs/2112.00183\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2112.00183</span><span class=\"invisible\"></span></a>)</p><p><a href=\"https://skewed.de/tiago/blog/free-lunch\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">skewed.de/tiago/blog/free-lunc</span><span class=\"invisible\">h</span></a></p><p><span class=\"h-card\"><a href=\"https://a.gup.pe/u/networkscience\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>networkscience</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03668v1",
    "title": "https://arxiv.org/abs/2302.03668v1",
    "latest": "2023-02-10T09:37:52+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109839769407887837",
      "content": "<p>\ud83d\udcdd Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery \ud83e\udde0\ud83d\udcda</p><p>\"An efficient, gradient-based optimization technique that optimizes a discrete prompt by relaxing it into a continuous embedding, which can be backpropagated through a discrete sequence to sequence (seq2seq) model such as a language model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/pharmapsychotic/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/pharmapsychotic/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03668v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03668v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s10994-023-06301-4",
    "title": "PAC-learning with approximate predictors - Machine Learning",
    "latest": "2023-02-10T09:31:13+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@mlj/109839743259907128",
      "content": "<p>The days stay cold but you can huddle up with an <a href=\"https://sigmoid.social/tags/MLJ\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MLJ</span></a> online-first <a href=\"https://sigmoid.social/tags/NewPaper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NewPaper</span></a>: \"PAC-learning with approximate predictors\" by Andrew J. Turner &amp; Ata Kab\u00e1n (<a href=\"https://link.springer.com/article/10.1007/s10994-023-06301-4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s10994-023-06301-4</span></a>) (OA)</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@mlj",
        "display_name": "Machine Learning Journal"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s10994-022-06289-3",
    "title": "Large scale multi-output multi-class classification using Gaussian processes - Machine Learning",
    "latest": "2023-02-10T09:31:13+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@mlj/109839743291058189",
      "content": "<p>Or two: \"Large scale multi-output multi-class classification using Gaussian processes\" by Chunchao Ma &amp; Mauricio A. \u00c1lvarez (<a href=\"https://link.springer.com/article/10.1007/s10994-022-06289-3\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s10994-022-06289-3</span></a>) (OA)</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@mlj",
        "display_name": "Machine Learning Journal"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03589v1",
    "title": "CALaMo: a Constructionist Assessment of Language Models",
    "latest": "2023-02-10T09:07:52+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109839651450335420",
      "content": "<p>\ud83d\udcdd CALaMo: A Constructionist Assessment of Language Models \ud83d\udcda</p><p>\"Given a corpus of sentences, the linguist can choose a set of relevant constructions that capture the linguistic phenomena of interest for that corpus (e,g, relative clauses, prepositional phrases, idioms).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03589v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03589v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/full/10.1177/09567976221140828",
    "title": "journals.sagepub.com/doi/full/...",
    "latest": "2023-02-10T08:32:55+00:00",
    "last_post": {
      "url": "https://nerdculture.de/@cruwell/109818820343409305",
      "content": "<p>Very happy to see our paper on the Open Data badge at Psych Science published *in* Psych Science! It even received the honour of an extended editor's note -- a first for the journal. Give it a read and let us know what you think!</p><p><a href=\"https://journals.sagepub.com/doi/full/10.1177/09567976221140828\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/full/</span><span class=\"invisible\">10.1177/09567976221140828</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      },
      {
        "url": "https://scholar.social/@researchfairy",
        "display_name": "The research fairy"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03512v1",
    "title": "A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and Future Trends",
    "latest": "2023-02-10T08:22:52+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109839474510903800",
      "content": "<p>\ud83d\udcdd A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and Future Trends \ud83d\udcda</p><p>\"Introduces the background of Arabic NER, including the characteristics of Arabic and existing resources for Arabic NER, and then systematically review the recent development of Arabic NER, including deep learning methods, pre-trained language model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03512v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03512v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04273",
    "title": "Debris Disk Color with the Hubble Space Telescope",
    "latest": "2023-02-10T08:20:33+00:00",
    "last_post": {
      "url": "https://mastodon.social/@mattkenworthy/109839186469802765",
      "content": "<p>A beautiful gallery of disks around nearby stars taken with the <a href=\"https://mastodon.social/tags/HST\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>HST</span></a> - these images are breathtaking to me - the structures are generated by asteroid collisions, sculpted by the dynamics of (unseen) exoplanets and scoured by the photon pressure from the star. The deep analysis and discussion about the resultant properties of the dust is by Ren, Rebodillo et al. \"Debris Disk Color with the Hubble Space Telescope\" <a href=\"https://arxiv.org/abs/2302.04273\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04273</span><span class=\"invisible\"></span></a> <a href=\"https://mastodon.social/tags/astronomy\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>astronomy</span></a> <a href=\"https://mastodon.social/tags/astrodon\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>astrodon</span></a> <a href=\"https://mastodon.social/tags/exoplanets\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>exoplanets</span></a> <a href=\"https://mastodon.social/tags/HST\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>HST</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jradavenport",
        "display_name": "James Davenport \ud83d\udd2d\u2615\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03507v1",
    "title": "https://arxiv.org/abs/2302.03507v1",
    "latest": "2023-02-10T07:52:49+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109839356384754159",
      "content": "<p>\ud83d\udcdd Meta-Learning Siamese Network for Few-Shot Text Classification \ud83d\udcda\ud83d\udc7e</p><p>\"Meta-SN learns the prototype vectors from external knowledge for class labels, and uses a novel sampling strategy for constructing meta-tasks, which assigns higher sampling probabilities to hard-to-classify samples.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/hccngu/Meta-SN\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/hccngu/Meta-SN</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03507v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03507v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/25785648.2023.2168939",
    "title": "Wikipedia\u2019s Intentional Distortion of the History of the Holocaust",
    "latest": "2023-02-10T07:33:13+00:00",
    "last_post": {
      "url": "https://mastodon.social/@iramjohn/109836742784869642",
      "content": "<p>\"Wikipedia\u2019s Intentional Distortion of the History of the Holocaust\" (OA)</p><p>This article is likely to create ripples, if not waves. It's one of the most detailed looks I've come across at misinformation on Wikipedia, and how community processes have failed to address a lot of concerns. And how that has impacted Holocaust history, a topic I'd hope we'd be especially careful to get right</p><p>(I provided feedback on a draft a few months ago, but just skimmed the final version.)</p><p><a href=\"https://www.tandfonline.com/doi/full/10.1080/25785648.2023.2168939\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/25785648.2023.2168939</span></a></p>"
    },
    "people": [
      {
        "url": "https://bbq.snoot.com/@ProgGrrl",
        "display_name": "ProgGrrl"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03494v1",
    "title": "A Categorical Archive of ChatGPT Failures",
    "latest": "2023-02-10T07:22:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109839238713637082",
      "content": "<p>\ud83d\udcdd A Categorical Archive of ChatGPT Failures \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"ChatGPT is trained on massive amounts of text from the internet and is able to answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03494v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03494v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001967",
    "title": "journals.plos.org/plosbiology/...",
    "latest": "2023-02-10T06:47:16+00:00",
    "last_post": {
      "url": "https://zeroes.ca/@EricCarroll/109839011497075052",
      "content": "<p>Scientists discover receptor that blocks <a href=\"https://zeroes.ca/tags/COVID19\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>COVID19</span></a> infection</p><p>The research opens up an entirely new area of immunology research around LRRC15 and offers a promising pathway to develop new drugs to prevent viral infection from coronaviruses like <a href=\"https://zeroes.ca/tags/COVID19\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>COVID19</span></a> or deal with fibrosis in the lungs.</p><p><a href=\"https://www.sydney.edu.au/news-opinion/news/2023/02/10/scientists-discover-receptor-that-blocks-covid-19-infection.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">sydney.edu.au/news-opinion/new</span><span class=\"invisible\">s/2023/02/10/scientists-discover-receptor-that-blocks-covid-19-infection.html</span></a></p><p><a href=\"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001967\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.plos.org/plosbiology/</span><span class=\"invisible\">article?id=10.1371/journal.pbio.3001967</span></a></p><p><a href=\"https://zeroes.ca/tags/sarscov2\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>sarscov2</span></a> <a href=\"https://zeroes.ca/tags/SARS2\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SARS2</span></a></p>"
    },
    "people": [
      {
        "url": "https://bbq.snoot.com/@ProgGrrl",
        "display_name": "ProgGrrl"
      },
      {
        "url": "https://mastodon.lol/@morgandawn",
        "display_name": "Morgan Dawn"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03488v1",
    "title": "APAM: Adaptive Pre-training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-tailed Learning",
    "latest": "2023-02-10T06:07:50+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109838943538163389",
      "content": "<p>\ud83d\udcdd APAM: Adaptive Pre-Training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-Tailed Learning \ud83d\udcda\ud83d\udc7e</p><p>\"A combination of a pre-training model, a re-weighting module, and a fine-tuning model for text classification tasks with long-tail and noisy labels.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03488v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03488v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04752",
    "title": "Benchmarks for Automated Commonsense Reasoning: A Survey",
    "latest": "2023-02-10T06:00:10+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@timfinin/109838371307536704",
      "content": "<p>Prof. Ernest Davis (NYU) has a new survey paper on benchmarks for automated commonsense reasoning. It discusses the nature of common sense, its role in AI, desirable features of commonsense benchmarks, and makes recommendations for future development. <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://arxiv.org/abs/2302.04752\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04752</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/23294965221105664",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-02-09T20:37:38+00:00",
    "last_post": {
      "url": "https://mastodon.social/@msomashe/109835701439793378",
      "content": "<p>Did you know that, in the U.S., it is illegal to *employ* an undocumented immigrant but legal for undocumented immigrants to *own* businesses? I contend with this issue in my latest paper, just published in the latest issue of Social Currents <a href=\"https://journals.sagepub.com/doi/10.1177/23294965221105664\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/23294965221105664</span></a></p>"
    },
    "people": [
      {
        "url": "https://sciences.social/@bernardforgues",
        "display_name": "Bernard Forgues"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2302.03764",
    "title": "http://arxiv.org/abs/2302.03764",
    "latest": "2023-02-09T09:47:00+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109834143022014446",
      "content": "<p>RT @FeinbergVlad@twitter.com</p><p>New work is out! <a href=\"http://arxiv.org/abs/2302.03764\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2302.03764</span><span class=\"invisible\"></span></a></p><p>Sketching for low-memory second-order optimization. w/ @XinyiChen2@twitter.com Jennifer Sun @_arohan_@twitter.com @HazanPrinceton@twitter.com </p><p>Most networks have &gt;99% of mass in the top 25% of (factored) gradient cov's eigenvalues. Let's exploit this. 1/n</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/FeinbergVlad/status/1623540032832413696\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/FeinbergVlad/statu</span><span class=\"invisible\">s/1623540032832413696</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03764",
    "title": "Sketchy: Memory-efficient Adaptive Regularization with Frequent Directions",
    "latest": "2023-02-09T09:46:59+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109834142967628081",
      "content": "<p>Sketchy: Memory-efficient Adaptive Regularization with Frequent Directions</p><p>Develops a practical, memory-efficient algorithm which approximately recovers Shampoo performance in three modern DL settings (ImageNet, Librispeech, etc).</p><p><a href=\"https://arxiv.org/abs/2302.03764\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03764</span><span class=\"invisible\"></span></a> </p><p>RT @_arohan_@twitter.com</p><p>Adam is the past? <a href=\"https://arxiv.org/abs/2302.03764\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03764</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/_arohan_/status/1623539709409640449\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/_arohan_/status/16</span><span class=\"invisible\">23539709409640449</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04166",
    "title": "GPTScore: Evaluate as You Desire",
    "latest": "2023-02-09T09:46:52+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109834142521603954",
      "content": "<p>GPTScore: Evaluate as You Desire</p><p>Proposes a novel evaluation framework, GPTSCORE, which utilizes the emergent abilities (e.g., zero-shot instruction) from generative pre-trained models to score generated texts.</p><p><a href=\"https://arxiv.org/abs/2302.04166\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04166</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.10559v2",
    "title": "https://arxiv.org/abs/2212.10559v2",
    "latest": "2023-02-09T09:46:46+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109834142119731146",
      "content": "<p>RT @AlphaSignalAI@twitter.com</p><p>Large Language Models are fascinating.</p><p>1. They can store and simulate other NNs inside their hidden layers and adapt to new tasks without new data.<br>\ud83d\udcc4<a href=\"https://news.mit.edu/2023/large-language-models-in-context-learning-0207\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">news.mit.edu/2023/large-langua</span><span class=\"invisible\">ge-models-in-context-learning-0207</span></a></p><p>2. They can secretly perform gradient descent as Meta-Optimizers.<br>\ud83d\udcc4 <a href=\"https://arxiv.org/abs/2212.10559v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.10559v2</span><span class=\"invisible\"></span></a></p><p>*jaw drop*</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/AlphaSignalAI/status/1623391318415122441\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/AlphaSignalAI/stat</span><span class=\"invisible\">us/1623391318415122441</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04264",
    "title": "Nerfstudio: A Modular Framework for Neural Radiance Field Development",
    "latest": "2023-02-09T09:30:47+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@kornia_foss/109834078683727474",
      "content": "<p>Nerfstudio: A Modular Framework for Neural Radiance Field Development</p><p>Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li, Brent Yi, Justin Kerr, Terrance Wang, Alexander Kristoffersen, Jake Austin, Kamyar Salahi, Abhik Ahuja, David McAllister, Angjoo Kanazawa</p><p><a href=\"https://arxiv.org/abs/2302.04264\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04264</span><span class=\"invisible\"></span></a></p><p>tl;dr: home to your NERFs. Pipeline, modular components, web-viewer</p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/opensource\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>opensource</span></a> <a href=\"https://sigmoid.social/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a> <a href=\"https://sigmoid.social/tags/PyTorch\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PyTorch</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03145v1",
    "title": "https://arxiv.org/abs/2302.03145v1",
    "latest": "2023-02-09T09:22:49+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109834047943489717",
      "content": "<p>\ud83d\udcdd Techniques to Improve Neural Math Word Problem Solvers \ud83d\udcda</p><p>\"A new encoder-decoder architecture that fully leverages the question text and preserves step-wise commutative law, and generates question-aware expression representations that are invariant under any permutation of quantities.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/SC\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SC</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/sophistz/Question-Aware-Deductive-MWP\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/sophistz/Question-A</span><span class=\"invisible\">ware-Deductive-MWP</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.03145v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03145v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2206.00665.pdf",
    "title": "MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction",
    "latest": "2023-02-09T09:21:21+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/109834042194245579",
      "content": "<p>Thanks to SDF Studio, I have discovered Omnidata depth &amp; normals model.<br>Source: MonoSDF paper<br><a href=\"https://arxiv.org/abs/2206.00665.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2206.00665.pdf</span><span class=\"invisible\"></span></a><br>Omnidata paper: <a href=\"https://arxiv.org/abs/2110.04994\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2110.04994</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2110.04994",
    "title": "https://arxiv.org/abs/2110.04994",
    "latest": "2023-02-09T09:21:21+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/109834042194245579",
      "content": "<p>Thanks to SDF Studio, I have discovered Omnidata depth &amp; normals model.<br>Source: MonoSDF paper<br><a href=\"https://arxiv.org/abs/2206.00665.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2206.00665.pdf</span><span class=\"invisible\"></span></a><br>Omnidata paper: <a href=\"https://arxiv.org/abs/2110.04994\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2110.04994</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.01339.pdf",
    "title": "https://arxiv.org/pdf/2302.01339.pdf",
    "latest": "2023-02-09T09:20:37+00:00",
    "last_post": {
      "url": "https://fediscience.org/@alexh/109834038873379407",
      "content": "<p>Can large language models be trained to produce philosophical texts that are difficult to distinguish from texts produced by human philosophers? Yes, at least in the case of Dan Dennett <a href=\"https://arxiv.org/pdf/2302.01339.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.01339.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01973v1",
    "title": "Measuring The Impact Of Programming Language Distribution",
    "latest": "2023-02-09T09:01:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109833962822779453",
      "content": "<p>\ud83d\udcdd Measuring the Impact of Programming Language Distribution \ud83e\udde0\ud83d\udcda</p><p>\"The BabelCode framework enables evaluation of any benchmark on any programming language with the only requirement being a compiler to translate to the language's intermediate representation (IR).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/PL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.01973v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01973v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02275v1",
    "title": "https://arxiv.org/abs/2302.02275v1",
    "latest": "2023-02-09T07:31:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109833608736461468",
      "content": "<p>\ud83d\udcdd Unleashing the True Potential of Sequence-to-Sequence Models for Sequence Tagging and Structure Parsing \ud83d\udcda</p><p>\"Works on four core tasks with contained decoding on four core tasks: part-of-speech tagging, named entity recognition, constituency and dependency parsing, to develop efficient exploitation methods costing zero extra parameters.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/emorynlp/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/emorynlp/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.02275v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02275v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12490",
    "title": "How does HCI Understand Human Autonomy and Agency?",
    "latest": "2023-02-09T07:28:55+00:00",
    "last_post": {
      "url": "https://hci.social/@dan_bennett/109829755172136714",
      "content": "<p>A \ud83e\uddf5 on our new paper accepted at <a href=\"https://hci.social/tags/CHI2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CHI2023</span></a> - by myself, <span class=\"h-card\"><a href=\"https://hci.social/@elisamekler\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>elisamekler</span></a></span>, Oussama Metatla and Anne Roudaut</p><p>How does HCI Understand Human Agency and Autonomy?</p><p>We analysed 30 years of HCI research, identifying theoretical, practical &amp; ethical issues. We outline conceptual schemes &amp; practical steps to move forward</p><p><a href=\"https://arxiv.org/abs/2301.12490\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12490</span><span class=\"invisible\"></span></a></p><p><a href=\"https://www.youtube.com/watch?v=whfaVQwZlUg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">youtube.com/watch?v=whfaVQwZlU</span><span class=\"invisible\">g</span></a></p>"
    },
    "people": [
      {
        "url": "https://hci.social/@DBuschek",
        "display_name": "Daniel Buschek"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02178v1",
    "title": "Construction Grammar Provides Unique Insight into Neural Language Models",
    "latest": "2023-02-09T06:31:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109833372714638142",
      "content": "<p>\ud83d\udcdd Construction Grammar Provides Unique Insight Into Neural Language Models \ud83d\udcda</p><p>\"CxG aims to describe how language is used in real-world contexts, rather than how it is structured, as in syntax and semantics (Goldberg, 2020).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.02178v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02178v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02169v1",
    "title": "https://arxiv.org/abs/2302.02169v1",
    "latest": "2023-02-08T21:31:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109831249621006594",
      "content": "<p>\ud83d\udcdd How Many and Which Training Points Would Need to Be Removed to Flip This Prediction? \ud83e\udde0\ud83d\udc7e\ud83d\udcda</p><p>\"Considers the problem of identifying a minimal subset of training data such that if these instances had been removed prior to training, the categorization of a given test point would have been different.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/ecielyang/Smallest_set\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/ecielyang/Smallest_</span><span class=\"invisible\">set</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.02169v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02169v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5281/zenodo.7622601",
    "title": "https://doi.org/10.5281/zenodo.7622601",
    "latest": "2023-02-08T21:07:50+00:00",
    "last_post": {
      "url": "https://discuss.systems/@rebeccawb/109830763818154586",
      "content": "<p>I've just published to Zenodo (open access archives) my Pattern Languages of Programs 2020 (PLoP'20) essay, Should we stop writing design patterns? </p><p>This essay reflects on my experiences of the past 15 years writing software design patterns. In short, if the patterns community wants to broadly increase pattern literacy, relevancy, and long-term impact, some things need to change. Those changes need to start with pattern writers\u2014like me. Instead of indiscriminately writing ever more patterns, we should focus more on connecting, relating, and refreshing the abundance of existing impactful patterns. </p><p>Here's the link to the zenodo archived version: <a href=\"https://doi.org/10.5281/zenodo.7622601\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.7622601</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@gvwilson",
        "display_name": "Greg Wilson"
      }
    ]
  },
  {
    "link": "https://royalsocietypublishing.org/doi/10.1098/rspb.2022.2423",
    "title": "royalsocietypublishing.org/doi...",
    "latest": "2023-02-08T20:31:31+00:00",
    "last_post": {
      "url": "https://mastodon.social/@freakonometrics/109830387346960065",
      "content": "<p>\"The geometry of evolutionary conflict\" <a href=\"https://royalsocietypublishing.org/doi/10.1098/rspb.2022.2423\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">royalsocietypublishing.org/doi</span><span class=\"invisible\">/10.1098/rspb.2022.2423</span></a> \"(i) conflict can drive evolving traits arbitrarily far away from all parties' optima and, indeed, if all mutations are equally likely then contested traits are more often than not driven outwith the zone of actual conflict; (ii) evolutionary conflicts drive persistent maladaptation of orthogonal, non-contested traits; and (iii) modular design greatly ameliorates conflict-driven maladaptation\"</p>"
    },
    "people": [
      {
        "url": "https://colliderbias.net/@conjugateprior",
        "display_name": "Will Lowe"
      }
    ]
  },
  {
    "link": "https://onlinelibrary.wiley.com/doi/epdf/10.1111/1753-0407.13354",
    "title": "onlinelibrary.wiley.com/doi/ep...",
    "latest": "2023-02-08T09:44:03+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@kornia_foss/109828468138953576",
      "content": "<p>Nailfold capillaroscopy and deep learning in diabetes</p><p>Reema Shah, Jeremy Petch, Walter Nelson, Karsten Roth, Michael D Noseworthy, Marzyeh Ghassemi, Hertzel C Gerstein</p><p>tl;dr: CNNs for diabetes detection from nailfold photos. <a href=\"https://sigmoid.social/tags/kornia\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>kornia</span></a> used for data augmentation</p><p><a href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1111/1753-0407.13354\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">onlinelibrary.wiley.com/doi/ep</span><span class=\"invisible\">df/10.1111/1753-0407.13354</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1007/s00432-022-04200-0",
    "title": "doi.org/10.1007/s00432-022-042...",
    "latest": "2023-02-08T09:16:16+00:00",
    "last_post": {
      "url": "https://chaos.social/@umblaetterer/109828359909270087",
      "content": "<p>Looks like our <a href=\"https://chaos.social/tags/DigitalHumanities\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DigitalHumanities</span></a> web app <a href=\"https://chaos.social/tags/ezlinavis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ezlinavis</span></a> (<a href=\"https://ezlinavis.dracor.org/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">ezlinavis.dracor.org/</span><span class=\"invisible\"></span></a>), originally intended for extracting co-occurrence network data from literary texts, is also used in medical research. \ud83d\ude2f <span class=\"h-card\"><a href=\"https://mastodon.social/@cmil\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cmil</span></a></span></p><p><a href=\"https://doi.org/10.1007/s00432-022-04200-0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1007/s00432-022-042</span><span class=\"invisible\">00-0</span></a><br><a href=\"https://doi.org/10.21873/invivo.12976\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21873/invivo.12976</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://chaos.social/@umblaetterer",
        "display_name": "Frank Fischer"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21873/invivo.12976",
    "title": "https://doi.org/10.21873/invivo.12976",
    "latest": "2023-02-08T09:16:16+00:00",
    "last_post": {
      "url": "https://chaos.social/@umblaetterer/109828359909270087",
      "content": "<p>Looks like our <a href=\"https://chaos.social/tags/DigitalHumanities\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DigitalHumanities</span></a> web app <a href=\"https://chaos.social/tags/ezlinavis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ezlinavis</span></a> (<a href=\"https://ezlinavis.dracor.org/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">ezlinavis.dracor.org/</span><span class=\"invisible\"></span></a>), originally intended for extracting co-occurrence network data from literary texts, is also used in medical research. \ud83d\ude2f <span class=\"h-card\"><a href=\"https://mastodon.social/@cmil\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cmil</span></a></span></p><p><a href=\"https://doi.org/10.1007/s00432-022-04200-0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1007/s00432-022-042</span><span class=\"invisible\">00-0</span></a><br><a href=\"https://doi.org/10.21873/invivo.12976\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21873/invivo.12976</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://chaos.social/@umblaetterer",
        "display_name": "Frank Fischer"
      }
    ]
  },
  {
    "link": "http://osf.io/v8qh9/",
    "title": "http://osf.io/v8qh9/",
    "latest": "2023-02-08T08:31:38+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828184350737137",
      "content": "<p>Searching for a positive theory of power <a href=\"http://osf.io/v8qh9/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/v8qh9/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/kt6f8/",
    "title": "http://osf.io/kt6f8/",
    "latest": "2023-02-08T08:31:37+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828184306206773",
      "content": "<p>Understanding value through Deleuze and Guattari's metaphysical and ethical foundations <a href=\"http://osf.io/kt6f8/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/kt6f8/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/w2j7k/",
    "title": "http://osf.io/w2j7k/",
    "latest": "2023-02-08T08:26:11+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828162958192365",
      "content": "<p>Open Innovation in Digital Health: A Design Science Approach <a href=\"http://osf.io/w2j7k/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/w2j7k/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/uf5dh/",
    "title": "http://osf.io/uf5dh/",
    "latest": "2023-02-08T08:21:17+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828143682684088",
      "content": "<p>Disrupting the governance of social-ecological rigidity traps: Can pluralism foster change towards sustainability? <a href=\"http://osf.io/uf5dh/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/uf5dh/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/pszrx/",
    "title": "http://osf.io/pszrx/",
    "latest": "2023-02-08T08:16:34+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828125101372219",
      "content": "<p>The Absence of Communism in Soviet Economic Planning <a href=\"http://osf.io/pszrx/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/pszrx/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/3pheu/",
    "title": "http://osf.io/3pheu/",
    "latest": "2023-02-08T08:11:45+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828106206494875",
      "content": "<p>Three propositions for realising collective value <a href=\"http://osf.io/3pheu/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/3pheu/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01823v1",
    "title": "Lexical Simplification using multi level and modular approach",
    "latest": "2023-02-08T08:05:20+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109828080990039684",
      "content": "<p>\ud83d\udcdd Lexical Simplification Using Multi Level and Modular Approach \ud83d\udcda</p><p>\"Our team \"teamPN\" for English sub task, created a modular pipeline that combines modern day transformers based models with traditional NLP methods like paraphrasing and verb sense disambiguation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.01823v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01823v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/ghmbk/",
    "title": "http://osf.io/ghmbk/",
    "latest": "2023-02-08T08:01:53+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828067386819587",
      "content": "<p>The French constitution of 1958 and the Russian constitution of 1993: a comparison <a href=\"http://osf.io/ghmbk/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ghmbk/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/u8zcx/",
    "title": "http://osf.io/u8zcx/",
    "latest": "2023-02-08T08:01:53+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109828067408732267",
      "content": "<p>Why we struggle to realise the value of data <a href=\"http://osf.io/u8zcx/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/u8zcx/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13867",
    "title": "Mathematical Capabilities of ChatGPT",
    "latest": "2023-02-08T07:11:22+00:00",
    "last_post": {
      "url": "https://mastodon.social/@dougholton/109827868772183197",
      "content": "<p>A comprehensive listing of the types of things <a href=\"https://mastodon.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a> can't do well (or fails at), including reasoning, factual errors, math, coding, and bias <a href=\"https://arxiv.org/abs/2302.03494\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03494</span><span class=\"invisible\"></span></a><br>See also this GitHub repository: <a href=\"https://github.com/giuven95/chatgpt-failures\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/giuven95/chatgpt-fa</span><span class=\"invisible\">ilures</span></a><br>And this other paper analyzing the Mathematical Capabilities of ChatGPT <a href=\"https://arxiv.org/abs/2301.13867\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13867</span><span class=\"invisible\"></span></a><br><a href=\"https://mastodon.social/tags/EdTech\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>EdTech</span></a> <a href=\"https://mastodon.social/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> <a href=\"https://mastodon.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://mastodon.social/tags/MathEd\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MathEd</span></a></p>"
    },
    "people": [
      {
        "url": "https://idf.social/@arjen",
        "display_name": "Arjen P. de Vries Timmers \ud83d\udd4a\ufe0f"
      },
      {
        "url": "https://mastodon.social/@dougholton",
        "display_name": "Doug Holton"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03494",
    "title": "A Categorical Archive of ChatGPT Failures",
    "latest": "2023-02-08T07:11:22+00:00",
    "last_post": {
      "url": "https://mastodon.social/@dougholton/109827868772183197",
      "content": "<p>A comprehensive listing of the types of things <a href=\"https://mastodon.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a> can't do well (or fails at), including reasoning, factual errors, math, coding, and bias <a href=\"https://arxiv.org/abs/2302.03494\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03494</span><span class=\"invisible\"></span></a><br>See also this GitHub repository: <a href=\"https://github.com/giuven95/chatgpt-failures\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/giuven95/chatgpt-fa</span><span class=\"invisible\">ilures</span></a><br>And this other paper analyzing the Mathematical Capabilities of ChatGPT <a href=\"https://arxiv.org/abs/2301.13867\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13867</span><span class=\"invisible\"></span></a><br><a href=\"https://mastodon.social/tags/EdTech\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>EdTech</span></a> <a href=\"https://mastodon.social/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> <a href=\"https://mastodon.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://mastodon.social/tags/MathEd\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MathEd</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@dougholton",
        "display_name": "Doug Holton"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3575693.3575710",
    "title": "Junkyard Computing: Repurposing Discarded Smartphones to Minimize Carbon | Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2",
    "latest": "2023-02-08T06:54:41+00:00",
    "last_post": {
      "url": "https://discuss.systems/@adrian/109824918369762154",
      "content": "<p>Thoroughly bonkers upcoming ASPLOS paper from some UCSD folks: making competitive cloud servers out of old Android phones they bought on eBay. <a href=\"https://dl.acm.org/doi/10.1145/3575693.3575710\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/10.1145/3575693</span><span class=\"invisible\">.3575710</span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.ca/@hlabrande",
        "display_name": "Hugo Labrande"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2205.00415",
    "title": "http://arxiv.org/abs/2205.00415",
    "latest": "2023-02-08T06:42:27+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/17c59cfe-62f3-4f6d-8b97-0614ee084d7b",
      "content": "\"Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions. (arXiv:2205.00415v2 [cs.CL] UPDATED)\" \u2014 A hypothesis that annotators pick up on patterns in the crowdsourcing instructions, which bias them to write many similar examples that are then over-represented in the collected data and a study of this bias in 14 recent Natural Language Understanding (NLU) benchmarks.<br><br>Paper: <a href=\"http://arxiv.org/abs/2205.00415\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2205.00415</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01530v1",
    "title": "https://arxiv.org/abs/2302.01530v1",
    "latest": "2023-02-08T06:35:23+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109827727250589521",
      "content": "<p>\ud83d\udcdd Revisiting Intermediate Layer Distillation for Compressing Language Models: An Overfitting Perspective \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Consistency-regularized ILD prevents the student model from overfitting to the training dataset, and it transfers more information than the original KD while maintaining high performance efficiency compared to other KD approaches.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/jongwooko/CR-ILD\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/jongwooko/CR-ILD</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.01530v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01530v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.01324",
    "title": "eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers",
    "latest": "2023-02-07T21:52:56+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@gowthami/109677111409955588",
      "content": "<p>eDiff-I: A new text-to-image <a href=\"https://sigmoid.social/tags/diffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>diffusion</span></a> model. Uses T5 and both CLIP encoders for conditioning. Instead of using the same denoising model for all steps, they propose using multiple specialized ones. A \ud83e\uddf5</p><p>Paper: <a href=\"https://arxiv.org/abs/2211.01324\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.01324</span><span class=\"invisible\"></span></a></p><p>Day 11 <a href=\"https://sigmoid.social/tags/30daysofDiffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>30daysofDiffusion</span></a> <a href=\"https://sigmoid.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@andrey",
        "display_name": "Andrey Kurenkov"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02596",
    "title": "Ten Lessons We Have Learned in the New \"Sparseland\": A Short Handbook for Sparse Neural Network Researchers",
    "latest": "2023-02-07T21:02:03+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@at/109824560751869598",
      "content": "<p>Ten Lessons We Have Learned in the New \"Sparseland\": A Short Handbook for Sparse Neural Network Researchers<br>Shiwei Liu, Zhangyang Wang </p><p>What a beautifully-written, kind, and academically-funny abstract!</p><p>favorite part: \"At the very least ... if you are writing/planning to write a<br>paper or rebuttal in the field of SNNs, we hope some of our answers could help<br>you! </p><p>abs: <a href=\"https://arxiv.org/abs/2302.02596\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02596</span><span class=\"invisible\"></span></a> <br>pdf: <a href=\"https://arxiv.org/pdf/2302.02596.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.02596.pdf</span><span class=\"invisible\"></span></a> </p><p><a href=\"https://sigmoid.social/tags/arXiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arXiv</span></a> <a href=\"https://sigmoid.social/tags/SNNs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SNNs</span></a> <a href=\"https://sigmoid.social/tags/AmyPostsPapers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AmyPostsPapers</span></a></p>"
    },
    "people": [
      {
        "url": "https://indieweb.social/@dnnydnl",
        "display_name": "Donny Daniel :mastodon:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.02596.pdf",
    "title": "https://arxiv.org/pdf/2302.02596.pdf",
    "latest": "2023-02-07T21:02:03+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@at/109824560751869598",
      "content": "<p>Ten Lessons We Have Learned in the New \"Sparseland\": A Short Handbook for Sparse Neural Network Researchers<br>Shiwei Liu, Zhangyang Wang </p><p>What a beautifully-written, kind, and academically-funny abstract!</p><p>favorite part: \"At the very least ... if you are writing/planning to write a<br>paper or rebuttal in the field of SNNs, we hope some of our answers could help<br>you! </p><p>abs: <a href=\"https://arxiv.org/abs/2302.02596\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02596</span><span class=\"invisible\"></span></a> <br>pdf: <a href=\"https://arxiv.org/pdf/2302.02596.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.02596.pdf</span><span class=\"invisible\"></span></a> </p><p><a href=\"https://sigmoid.social/tags/arXiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arXiv</span></a> <a href=\"https://sigmoid.social/tags/SNNs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SNNs</span></a> <a href=\"https://sigmoid.social/tags/AmyPostsPapers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AmyPostsPapers</span></a></p>"
    },
    "people": [
      {
        "url": "https://indieweb.social/@dnnydnl",
        "display_name": "Donny Daniel :mastodon:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2111.09839",
    "title": "https://arxiv.org/abs/2111.09839",
    "latest": "2023-02-07T21:00:27+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/109825466521239393",
      "content": "<p>RT @colinraffel@twitter.com</p><p>Announcing a new research focus in my lab: Developing tools to enable collaboratively-built and continually-improved models.</p><p>Blog post: <a href=\"https://colinraffel.com/blog/a-call-to-build-models-like-we-build-open-source-software.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">colinraffel.com/blog/a-call-to</span><span class=\"invisible\">-build-models-like-we-build-open-source-software.html</span></a><br>Paper on model \"patches\": <a href=\"https://arxiv.org/abs/2111.09839\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2111.09839</span><span class=\"invisible\"></span></a><br>Paper on \"merging\" models: <a href=\"https://arxiv.org/abs/2111.09832\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2111.09832</span><span class=\"invisible\"></span></a><br>Thread \u2b07\ufe0f (1/11)</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/colinraffel/status/1468618801134592012\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/colinraffel/status</span><span class=\"invisible\">/1468618801134592012</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2111.09832",
    "title": "https://arxiv.org/abs/2111.09832",
    "latest": "2023-02-07T21:00:27+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/109825466521239393",
      "content": "<p>RT @colinraffel@twitter.com</p><p>Announcing a new research focus in my lab: Developing tools to enable collaboratively-built and continually-improved models.</p><p>Blog post: <a href=\"https://colinraffel.com/blog/a-call-to-build-models-like-we-build-open-source-software.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">colinraffel.com/blog/a-call-to</span><span class=\"invisible\">-build-models-like-we-build-open-source-software.html</span></a><br>Paper on model \"patches\": <a href=\"https://arxiv.org/abs/2111.09839\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2111.09839</span><span class=\"invisible\"></span></a><br>Paper on \"merging\" models: <a href=\"https://arxiv.org/abs/2111.09832\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2111.09832</span><span class=\"invisible\"></span></a><br>Thread \u2b07\ufe0f (1/11)</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/colinraffel/status/1468618801134592012\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/colinraffel/status</span><span class=\"invisible\">/1468618801134592012</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03027",
    "title": "Zero-shot Image-to-Image Translation",
    "latest": "2023-02-07T09:59:41+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/109822868291657684",
      "content": "<p>Zero-shot Image-to-Image Translation</p><p>Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, Jun-Yan Zhu</p><p>tl;dr: Stable diffusion for high-quality text-based editing, prompt-free.</p><p><a href=\"https://arxiv.org/abs/2302.03027\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03027</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01881",
    "title": "IKEA-Manual: Seeing Shape Assembly Step by Step",
    "latest": "2023-02-07T09:52:43+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/109822840873518098",
      "content": "<p>IKEA-Manual: Seeing Shape Assembly Step by Step</p><p>Ruocheng Wang, Yunzhi Zhang, Jiayuan Mao, Ran Zhang, Chin-Yi Cheng, Jiajun Wu</p><p>tl;dr: dataset for IKEA-assembling robots :)<br><a href=\"https://arxiv.org/abs/2302.01881\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01881</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01313v1",
    "title": "Double Permutation Equivariance for Knowledge Graph Completion",
    "latest": "2023-02-07T09:44:08+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109822807160870714",
      "content": "<p>\ud83d\udcdd Double Permutation Equivariance for Knowledge Graph Completion \ud83e\udde0\ud83d\udc7e\ud83d\udcda</p><p>\"Define a new class of graphs, called Knowledge Graphs (KGs), with the property of double-permutation equivariance: node and pairwise representation must be equivariant to permutations of both node ids and edge (and node) attributes.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.01313v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01313v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5061/dryad.qz612jmjw",
    "title": "doi.org/10.5061/dryad.qz612jmj...",
    "latest": "2023-02-07T09:37:21+00:00",
    "last_post": {
      "url": "https://mastodon.online/@ijonsen/109784120771995462",
      "content": "<p>For those using {aniMotum} - the R \ud83d\udce6formerly known as {foieGras} - here's a new paper where we outline its main features and provide example applications. </p><p><a href=\"https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14060\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">besjournals.onlinelibrary.wile</span><span class=\"invisible\">y.com/doi/10.1111/2041-210X.14060</span></a></p><p>Full R code for the applications is available in supplementary files and on GitHub - </p><p><a href=\"https://github.com/ianjonsen/foieGras.paper/tree/main/SI\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/ianjonsen/foieGras.</span><span class=\"invisible\">paper/tree/main/SI</span></a></p><p>Data are available on Dryad - </p><p><a href=\"https://doi.org/10.5061/dryad.qz612jmjw\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.5061/dryad.qz612jmj</span><span class=\"invisible\">w</span></a></p><p><a href=\"https://mastodon.online/tags/rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rstats</span></a> <a href=\"https://mastodon.online/tags/rspatial\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rspatial</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@mdsumner",
        "display_name": "mdsumner"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13296v1",
    "title": "Addressing Deep Learning Model Calibration Using Evidential Neural Networks and Uncertainty-Aware Training",
    "latest": "2023-02-07T08:42:19+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@AtoAndyKing/109816633931915680",
      "content": "<p>New <a href=\"https://sigmoid.social/tags/ISBI2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ISBI2023</span></a> paper by Tareen Dawood:</p><p><a href=\"https://arxiv.org/abs/2301.13296v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13296v1</span><span class=\"invisible\"></span></a></p><p>We focus on the idea of <a href=\"https://sigmoid.social/tags/DeepLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeepLearning</span></a> <a href=\"https://sigmoid.social/tags/uncertainty\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>uncertainty</span></a> <a href=\"https://sigmoid.social/tags/calibration\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>calibration</span></a>, i.e. improving the relationship between a classification model's <a href=\"https://sigmoid.social/tags/accuracy\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>accuracy</span></a> and <a href=\"https://sigmoid.social/tags/confidence\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>confidence</span></a>.</p><p>We explore the idea of uncertainty-aware training -including calibration performance in the learning objective of the model - and also evaluate the calibration performance of evidential neural networks (ENNs).</p>"
    },
    "people": [
      {
        "url": "https://masto.ai/@cheng",
        "display_name": "Cheng Soon Ong"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.17192",
    "title": "Fast Inference from Transformers via Speculative Decoding",
    "latest": "2023-02-07T08:22:28+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@LChoshen/109822485999968359",
      "content": "<p>Apparently something quite similar was proposed in November, getting hot in here<br><a href=\"https://arxiv.org/abs/2211.17192\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.17192</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2209.09513",
    "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering",
    "latest": "2023-02-07T08:08:16+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@LChoshen/109822430162591230",
      "content": "<p><span class=\"h-card\"><a href=\"https://sigmoid.social/@smolix\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>smolix</span></a></span> Let's stop here for a moment to appreciate the only dataset for multimodal Chain of Thought<br>21K questions, categorized to topic skills and more</p><p>Didn't use it, but on the face of it, it looks like a job well done</p><p> <br> <a href=\"https://arxiv.org/abs/2209.09513\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2209.09513</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00923",
    "title": "Multimodal Chain-of-Thought Reasoning in Language Models",
    "latest": "2023-02-07T08:06:02+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@LChoshen/109822421424835221",
      "content": "<p>Chain of Thought for vision<br>beating GPT3 by 16% and supposedly humans</p><p>Text and captions are not enough, but <br>with vision CoT does really well</p><p>@zhangzhuosheng<br> <br>@astonzhangAZ<br> <br>@mli65<br> Hai Zhao <br>@karypis<br> <br><span class=\"h-card\"><a href=\"https://sigmoid.social/@smolix\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>smolix</span></a></span></p><p><a href=\"https://arxiv.org/abs/2302.00923\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00923</span><span class=\"invisible\"></span></a><br>sigmoid.social/@smolix<br>(any simple way of finding author handles anyone?)</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.06627",
    "title": "Dissociating language and thought in large language models: a cognitive perspective",
    "latest": "2023-02-07T08:04:42+00:00",
    "last_post": {
      "url": "https://uddannelse.social/@Ove/109822369596300525",
      "content": "<p>Chatbots kan tale, fordi de baserer sig p\u00e5 sprogmodeller, men de ligner ikke t\u00e6nkning, der er mere en sproglig - jf. Vygotsky :<br>Dissociating language and thought in large language models: a cognitive perspective<br>Af Kyle Mahowald, Anna A. Ivanova, Idan A. Blank, Nancy Kanwisher, Joshua B. Tenenbaum, Evelina Fedorenko <a href=\"https://arxiv.org/abs/2301.06627\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.06627</span><span class=\"invisible\"></span></a></p><p><a href=\"https://uddannelse.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://uddannelse.social/tags/skolechat\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>skolechat</span></a> <a href=\"https://uddannelse.social/tags/teknologiforst%C3%A5else\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>teknologiforst\u00e5else</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01318",
    "title": "Accelerating Large Language Model Decoding with Speculative Sampling",
    "latest": "2023-02-07T08:01:14+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@LChoshen/109822402530618738",
      "content": "<p>Parallel generation from auto regressive LMs<br>Para ll el!<br>Well not exactly, use a fast LM to propose the next words first<br><a href=\"https://arxiv.org/abs/2302.01318\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01318</span><span class=\"invisible\"></span></a><br><a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/Generation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Generation</span></a> <a href=\"https://sigmoid.social/tags/inference\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>inference</span></a><br><a href=\"https://sigmoid.social/tags/DeepMind\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeepMind</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.03551",
    "title": "Talking About Large Language Models",
    "latest": "2023-02-07T07:54:40+00:00",
    "last_post": {
      "url": "https://mastodon.social/@BartSchellekens/109822376343892520",
      "content": "<p>We moeten het hebben over hoe we we het hebben over <a href=\"https://mastodon.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a>.  </p><p>\"The more adept LLMs become at mimicking human language, the more vulnerable we become to anthropomorphism, to seeing the systems in which they are embedded as more human like than they really are. This trend is amplified by the natural tendency to use philosophically loaded terms, such as \"knows\", \"believes\", and \"thinks\", when describing these systems.\"</p><p>Great paper by <span class=\"h-card\"><a href=\"https://sigmoid.social/@mshanahan\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mshanahan</span></a></span> </p><p>\u27a1<a href=\"https://arxiv.org/abs/2212.03551\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.03551</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@datatherapist",
        "display_name": "The Data Therapist"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2201.06009",
    "title": "https://arxiv.org/abs/2201.06009",
    "latest": "2023-02-07T07:37:07+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@solyarisoftware/109643904474311497",
      "content": "<p>MemPrompt</p><p>TLDR: A method to \"fix\" <a href=\"https://sigmoid.social/tags/GPT3\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GPT3</span></a> After Deployment with user interaction.</p><p>MemPrompt maintains a memory of errors and user feedback, and uses them to prevent repetition of mistakes.</p><p>home: <a href=\"https://memprompt.com\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">memprompt.com</span><span class=\"invisible\"></span></a><br>paper: <a href=\"https://arxiv.org/abs/2201.06009\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2201.06009</span><span class=\"invisible\"></span></a></p><p>via <br>@LangChainAI<br> !</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00763v1",
    "title": "https://arxiv.org/abs/2302.00763v1",
    "latest": "2023-02-07T06:24:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109822020610667529",
      "content": "<p>\ud83d\udcdd Collaborating with Language Models for Embodied Reasoning \ud83e\udde0\ud83d\udc7e\ud83d\udcda</p><p>\"The planner is a large-scale language model (e,g, GPT-3) that can issue commands to an embodied agent (e,g, a TurtleBot) that is placed in the environment, which then performs the actions in the command.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/deepmind/pycolab\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/deepmind/pycolab</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00763v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00763v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2209.12330",
    "title": "Personalizing Text-to-Image Generation via Aesthetic Gradients",
    "latest": "2023-02-06T21:48:19+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@gowthami/109654418272674943",
      "content": "<p>Get the average CLIP image model embeddings of an \"Aesthetic\" dataset, optimize the clip text encoder to align with this embedding, and plug it into SD to get better-looking images!</p><p>A tiny \ud83e\uddf6</p><p>Paper: <a href=\"https://arxiv.org/abs/2209.12330\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2209.12330</span><span class=\"invisible\"></span></a></p><p>Day 7 <a href=\"https://sigmoid.social/tags/30daysofDiffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>30daysofDiffusion</span></a> <a href=\"https://sigmoid.social/tags/Diffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Diffusion</span></a> <a href=\"https://sigmoid.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2202.01698.pdf",
    "title": "https://arxiv.org/pdf/2202.01698.pdf",
    "latest": "2023-02-06T21:03:17+00:00",
    "last_post": {
      "url": "https://hci.social/@andresmh/109399381836057752",
      "content": "<p>... a study of what people enjoy doing when they hang out in person and how it could inspire technology design. We learned about the importance of piggybacking on activities that involve people's close ties and that rely on their physical environment, their bodies, and even their pets. </p><p>Also, counterintuitively, one might use technology as the center of activities, similar to how board games facilitate interactions.</p><p>\ud83d\udcc4 PDF: <a href=\"https://arxiv.org/pdf/2202.01698.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2202.01698.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00894v1",
    "title": "How to choose \"Good\" Samples for Text Data Augmentation",
    "latest": "2023-02-06T20:24:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109819661364356213",
      "content": "<p>\ud83d\udcdd How to Choose \"Good\" Samples for Text Data Augmentation \ud83d\udcda</p><p>\"The proposed self-training selection framework has two selectors which are used to select the high-quality samples from data augmentation for text classification models training with two different views.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00894v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00894v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01308v1",
    "title": "What Language Reveals about Perception: Distilling Psychophysical Knowledge from Large Language Models",
    "latest": "2023-02-06T08:44:09+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109816908968694447",
      "content": "<p>\ud83d\udcdd What Language Reveals About Perception: Distilling Psychophysical Knowledge From Large Language Models \ud83d\udcda\ud83e\udde0</p><p>\"Uses the prompt auto-completion functionality of GPT3 to elicit similarity scores between stimuli and then apply multidimensional scaling to uncover their underlying psychological space of stimuli representation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.01308v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01308v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01560",
    "title": "Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents",
    "latest": "2023-02-06T08:37:22.041000+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109815906823098338",
      "content": "<p>RT @jeasinema@twitter.com</p><p>Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents</p><p>Can ChatGPT help with open-world game playing, like Minecraft? It sure can!  \ud83e\uddf5\ud83d\udc47</p><p><a href=\"https://arxiv.org/abs/2302.01560\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01560</span><span class=\"invisible\"></span></a><br><a href=\"https://github.com/CraftJarvis\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/CraftJarvis</span><span class=\"invisible\"></span></a>(code will be shipped soon)</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/jeasinema/status/1622428535897067521\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/jeasinema/status/1</span><span class=\"invisible\">622428535897067521</span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@arnicas",
        "display_name": "arnicas"
      }
    ]
  },
  {
    "link": "https://doi.org/10.48550/arXiv.2302.00345",
    "title": "doi.org/10.48550/arXiv.2302.00...",
    "latest": "2023-02-06T08:24:01+00:00",
    "last_post": {
      "url": "https://mastodon.social/@RonaldSnijder/109816829827263806",
      "content": "<p>Taylor, M. (2023). Slow, slow, quick, quick, slow: Five <a href=\"https://mastodon.social/tags/altmetric\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>altmetric</span></a> sources observed over a decade show evolving trends, by research age, attention source maturity and <a href=\"https://mastodon.social/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> status (arXiv:2302.00345). arXiv. <a href=\"https://doi.org/10.48550/arXiv.2302.00345\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.48550/arXiv.2302.00</span><span class=\"invisible\">345</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@RonaldSnijder",
        "display_name": "Ronald Snijder"
      }
    ]
  },
  {
    "link": "https://doi.org/10.31274/jlsc.14074",
    "title": "https://doi.org/10.31274/jlsc.14074",
    "latest": "2023-02-06T08:12:50+00:00",
    "last_post": {
      "url": "https://mastodon.social/@RonaldSnijder/109816785832820401",
      "content": "<p>Salisbury, F., Julien, B., Loch, B., Chang, S., &amp; Lexis, L. (2023). From Knowledge Curator to Knowledge Creator: Academic Libraries and Open Access Textbook Publishing. Journal of Librarianship and Scholarly Communication, 11(1).<br><a href=\"https://doi.org/10.31274/jlsc.14074\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.31274/jlsc.14074</span><span class=\"invisible\"></span></a><br><a href=\"https://mastodon.social/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://mastodon.social/tags/Textbooks\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Textbooks</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@RonaldSnijder",
        "display_name": "Ronald Snijder"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01398",
    "title": "The unreasonable effectiveness of few-shot learning for machine translation",
    "latest": "2023-02-06T08:08:33+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109815591968501084",
      "content": "<p>The unreasonable effectiveness of few-shot learning for machine translation</p><p>Outperforms the best performing system on the WMT\u201921 English\u2212Chinese news translation task by only using five examples of English\u2212Chinese parallel data at inference.</p><p><a href=\"https://arxiv.org/abs/2302.01398\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01398</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01496",
    "title": "Efficient Domain Adaptation for Speech Foundation Models",
    "latest": "2023-02-06T06:08:31+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109815353337837905",
      "content": "<p>Efficient Domain Adaptation for Speech Foundation Models</p><p>Achieves the same quality with only 21.6M supervised<br>in-domain data and 130.8M finetuned parameters, compared to the 731.1M model trained from scratch on additional 300M supervised in-domain data.</p><p><a href=\"https://arxiv.org/abs/2302.01496\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01496</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00944v1",
    "title": "TransFool: An Adversarial Attack against Neural Machine Translation Models",
    "latest": "2023-02-06T05:44:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109816201349025782",
      "content": "<p>\ud83d\udcdd TransFool: An Adversarial Attack Against Neural Machine Translation Models \ud83d\udcda</p><p>\"TransFool builds on a multi-term optimization problem and a gradient projection step to generate adversarial examples in the source language that maintain a high level of semantic similarity with the clean samples.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00944v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00944v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.06499",
    "title": "Social Construction of XAI: Do We Need One Definition to Rule Them All?",
    "latest": "2023-02-05T21:47:03+00:00",
    "last_post": {
      "url": "https://hci.social/@upol/109485305239207448",
      "content": "<p>\ud83e\udd14 Do we need one definition of Explainable AI to rule them all?</p><p>\ud83d\udca1 No, not right now. Why? This is where bicycles come in. </p><p>\ud83d\udccd What am I talking about? <br>Join me &amp; <span class=\"h-card\"><a href=\"https://sigmoid.social/@Riedl\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Riedl</span></a></span> at the Human-centered AI (HCAI) workshop at <span class=\"h-card\"><a href=\"https://mastodon.social/@NeuripsConf\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>NeuripsConf</span></a></span> to learn more! </p><p>\ud83d\udd25 We argue why a singular definition of XAI is neither feasible nor desirable at this stage of XAI's development. </p><p>But why? A thread \ud83e\uddf5 \ud83d\udc47 </p><p>\ud83d\udcdc<a href=\"https://arxiv.org/abs/2211.06499\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.06499</span><span class=\"invisible\"></span></a></p><p><a href=\"https://hci.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://hci.social/tags/ExplainableAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ExplainableAI</span></a> <a href=\"https://hci.social/tags/XAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>XAI</span></a> <a href=\"https://hci.social/tags/NeurIPS\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NeurIPS</span></a> <a href=\"https://hci.social/tags/HCI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>HCI</span></a> <a href=\"https://hci.social/tags/algorithms\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>algorithms</span></a> <a href=\"https://hci.social/tags/bicycles\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>bicycles</span></a></p><p>1/6</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "http://osf.io/r8ygd/",
    "title": "http://osf.io/r8ygd/",
    "latest": "2023-02-05T21:31:42+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109814264819921247",
      "content": "<p>Measuring Cybercrime and Cyberdeviance in Surveys <a href=\"http://osf.io/r8ygd/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/r8ygd/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.09800",
    "title": "InstructPix2Pix: Learning to Follow Image Editing Instructions",
    "latest": "2023-02-05T21:01:59+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@gowthami/109660142850647636",
      "content": "<p>InstructPix2Pix: Edit an image using text guidance using a single forward pass. Why use any inversion or other stuff,just create a dataset using inversion techniques and train a new model.</p><p>A \ud83e\uddf6</p><p>Paper: <a href=\"https://arxiv.org/abs/2211.09800\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.09800</span><span class=\"invisible\"></span></a></p><p>Day 8 <a href=\"https://sigmoid.social/tags/30daysofDiffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>30daysofDiffusion</span></a> <a href=\"https://sigmoid.social/tags/Diffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Diffusion</span></a> <a href=\"https://sigmoid.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2101.03989",
    "title": "Technology Readiness Levels for Machine Learning Systems",
    "latest": "2023-02-05T20:16:57+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@jaydee829/109662013884716467",
      "content": "<p>I run a reading group at my work focused on <a href=\"https://sigmoid.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a> <a href=\"https://sigmoid.social/tags/reinforcementlearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>reinforcementlearning</span></a> and <a href=\"https://sigmoid.social/tags/artificialintelligence\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>artificialintelligence</span></a> , affectionately dubbed Merrick Monday. Today we discussed \"Technology Readiness Levels for Machine Learning Systems\" (<a href=\"https://arxiv.org/abs/2101.03989\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2101.03989</span><span class=\"invisible\"></span></a>).</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "http://osf.io/sqwb2/",
    "title": "http://osf.io/sqwb2/",
    "latest": "2023-02-05T20:11:51+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109813950793974614",
      "content": "<p>A Bayesian cohort model for estimating out-of-school rates and populations <a href=\"http://osf.io/sqwb2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/sqwb2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.07476",
    "title": "The Infinite Index: Information Retrieval on Generative Text-To-Image Models",
    "latest": "2023-02-05T19:44:54+00:00",
    "last_post": {
      "url": "https://idf.social/@potthast/109536200413883978",
      "content": "<p>From an information retrieval perspective, <a href=\"https://idf.social/tags/StableDiffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>StableDiffusion</span></a> can be seen as an index of images queried with a prompt\u2014an Infinite Index!</p><p>At <br>@ACM_CHIIR@twitter.com<br> <a href=\"https://idf.social/tags/CHIIR2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CHIIR2023</span></a> we\u2019ll present our perspective on IR on an Infinite Index. See thread below\u2026 (1/8)</p><p>Preprint: <a href=\"https://arxiv.org/abs/2212.07476\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.07476</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@chengyjonathan",
        "display_name": "Jonathan Cheng"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00455v1",
    "title": "HunSum-1: an Abstractive Summarization Dataset for Hungarian",
    "latest": "2023-02-05T08:44:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109811249620401250",
      "content": "<p>\ud83d\udcdd HunSum-1: An Abstractive Summarization Dataset for Hungarian \ud83d\udcda</p><p>\"The dataset is collected from the top Hungarian news websites using CommonCrawl and filtered by removing near-duplicates and low-quality data, as well as articles with less than 100 or more than 8000 characters.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00455v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00455v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.23915/distill.00017",
    "title": "https://doi.org/10.23915/distill.00017",
    "latest": "2023-02-05T08:11:26+00:00",
    "last_post": {
      "url": "https://bayes.club/@shihchingfu/109810980687305862",
      "content": "<p>I'm eyeballs deep into understanding <a href=\"https://bayes.club/tags/GaussianProcesses\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GaussianProcesses</span></a> (GPs). There are great resources out there but I can thoroughly recommend this introductory paper on <a href=\"https://bayes.club/tags/Distill\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Distill</span></a> by G\u00f6rtler et al. The interactive plots are a great <a href=\"https://doi.org/10.23915/distill.00017\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.23915/distill.00017</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://astrodon.social/@harcel",
        "display_name": "Marcel Haas"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00412v1",
    "title": "KNNs of Semantic Encodings for Rating Prediction",
    "latest": "2023-02-05T06:44:57+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109810777925821770",
      "content": "<p>\ud83d\udcdd KNNs of Semantic Encodings for Rating Prediction \ud83d\udcda</p><p>\"Encodes users' preferences as a graph of semantically similar textual snippets from reviews, where the edges are defined by semantic similarity between the snippets.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00412v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00412v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@arnicas",
        "display_name": "arnicas"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00763",
    "title": "Collaborating with language models for embodied reasoning",
    "latest": "2023-02-05T06:38:49+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@kbaxter/109807888752357557",
      "content": "<p>\u201cCollaborating with language models for embodied reasoning\u201d: <a href=\"https://arxiv.org/abs/2302.00763\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00763</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@andrey",
        "display_name": "Andrey Kurenkov"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-021-02990-w",
    "title": "Top climate scientists are sceptical that nations will rein in global warming",
    "latest": "2023-02-05T05:11:44+00:00",
    "last_post": {
      "url": "https://climatejustice.social/@breadandcircuses/109642315870697356",
      "content": "<p>When leading climate scientists are asked anonymously or off-the-record what they actually expect we will have to endure in the decades ahead, you'll find they are not very optimistic.</p><p>In 2021, the journal Nature conducted an anonymous survey of IPCC authors and received responses from 92 scientists. Their answers suggest strong skepticism that governments will significantly slow the pace of global heating, despite all those fancy promises we've heard (\"blah-blah-blah\").</p><p>Six in ten of the survey respondents expect the world to warm by at least 3\u00b0C by the end of the century. Some think 4\u00b0C or even 5\u00b0C is where we're headed. Fewer than 5% of these scientists believe we will stay under 1.5\u00b0C, which is the optimistic \u2014 and totally unrealistic \u2014 outcome that politicians and the major media want you to swallow.</p><p><a href=\"https://climatejustice.social/tags/ClimateCrisis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ClimateCrisis</span></a> </p><p><a href=\"https://www.nature.com/articles/d41586-021-02990-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-021</span><span class=\"invisible\">-02990-w</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@ryanschultz",
        "display_name": "Ryan Schultz"
      },
      {
        "url": "https://hci.social/@cbecker",
        "display_name": "Christoph Becker"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2110.08207",
    "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
    "latest": "2023-02-05T05:03:14+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@groby/109810219243246530",
      "content": "<p><span class=\"h-card\"><a href=\"https://fedi.simonwillison.net/@simon\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>simon</span></a></span> What if you asked an LLM to efficiently summarize its entire input corpus and then trained based on that? ;) (I'm not sure if I'm kidding, actually)</p><p>But if we set that aside, IIRC the smalles model supporting Chain-Of-Thought is currently Flan-T5, and that's 700GB. So about an order of magnitude away. There's some research showing that might happen: <a href=\"https://arxiv.org/abs/2110.08207\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2110.08207</span><span class=\"invisible\"></span></a></p><p>(OK, it's an order of mag down for ChatGPT3, but..)</p>"
    },
    "people": [
      {
        "url": "https://fedi.simonwillison.net/@simon",
        "display_name": "Simon Willison"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00340v1",
    "title": "https://arxiv.org/abs/2302.00340v1",
    "latest": "2023-02-05T04:44:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109810305892260486",
      "content": "<p>\ud83d\udcdd Attention Link: An Efficient Attention-Based Low Resource Machine Translation Architecture \ud83d\udcda\ud83d\udc7e</p><p>\"A novel architecture named as attention link to help improve transformer models' performance, especially in low training resources, by providing more information in each transformer block for low training resources.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/facebookresearch/fairseq\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/fa</span><span class=\"invisible\">irseq</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00340v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00340v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2204.11824",
    "title": "Semi-Parametric Neural Image Synthesis",
    "latest": "2023-02-04T20:58:09+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@gowthami/109671560715911107",
      "content": "<p>Retrieval Augmented <a href=\"https://sigmoid.social/tags/Diffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Diffusion</span></a> (RDM) models: Smaller diffusion models can generate high-quality generations by accessing an external memory to guide the generation. Inspired by Deepmind's RETRO.</p><p>A \ud83e\uddf6</p><p>Paper: <a href=\"https://arxiv.org/abs/2204.11824\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2204.11824</span><span class=\"invisible\"></span></a></p><p>Day 10 <a href=\"https://sigmoid.social/tags/30daysofDiffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>30daysofDiffusion</span></a> <a href=\"https://sigmoid.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00618v1",
    "title": "Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models",
    "latest": "2023-02-04T20:24:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109808339799067393",
      "content": "<p>\ud83d\udcdd Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models \ud83d\udcda</p><p>\"Synthetic prompting is a method that leverages a few handcrafted examples to prompt the model to generate more examples by itself, and selects effective demonstrations to elicit better reasoning.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00618v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00618v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/1910.02822",
    "title": "A mathematical theory of cooperative communication",
    "latest": "2023-02-04T20:13:07+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@shafto/109665717304973674",
      "content": "<p>Wang, P., Wang, J., Paranamana, P., &amp; Shafto, P. (2020). A mathematical theory of cooperative communication. Advances in Neural Information Processing Systems (NeurIPS). </p><p><a href=\"https://arxiv.org/abs/1910.02822\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1910.02822</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00241-8",
    "title": "Academia\u2019s culture of overwork almost broke me, so I\u2019m working to undo it",
    "latest": "2023-02-04T08:48:54+00:00",
    "last_post": {
      "url": "https://mastodon.social/@vicgrinberg/109805329964735858",
      "content": "<p>\"But I now realize that, by hiding behind passion, I was excusing my contribution to a toxic burnout culture in research. And for me and many others like me \u2014 female, immigrant, non-native English speakers \u2014 the pressures are even greater. It\u2019s time to speak out.\"</p><p><a href=\"https://www.nature.com/articles/d41586-023-00241-8\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00241-8</span></a></p><p><a href=\"https://mastodon.social/tags/academia\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>academia</span></a> <a href=\"https://mastodon.social/tags/AcademicChatter\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AcademicChatter</span></a></p>"
    },
    "people": [
      {
        "url": "https://tech.lgbt/@_dmh",
        "display_name": "Dave Howcroft \ud83e\udd94"
      },
      {
        "url": "https://fediscience.org/@tschfflr",
        "display_name": "Tatjana Scheffler"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00093v1",
    "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context",
    "latest": "2023-02-04T08:44:57+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109805587506898537",
      "content": "<p>\ud83d\udcdd Large Language Models Can Be Easily Distracted by Irrelevant Context \ud83d\udcda\ud83d\udc7e</p><p>\"Large language models are evaluated on benchmarks where they need to understand the task and solve it based on the provided information without any distractors that might mislead the model to make a wrong prediction.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2302.00093v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00093v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2206.13932",
    "title": "https://arxiv.org/pdf/2206.13932",
    "latest": "2023-02-04T07:27:32+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@JulienTierny/109680862035393105",
      "content": "<p>Topological persistence is an importance measure in <a href=\"https://fosstodon.org/tags/PersistentHomology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PersistentHomology</span></a>, with a strong practical utility for noise removal in various applications: <a href=\"https://fosstodon.org/tags/Imaging\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Imaging</span></a>, <a href=\"https://fosstodon.org/tags/Clustering\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Clustering</span></a>, <a href=\"https://fosstodon.org/tags/ClimateScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ClimateScience</span></a>, <a href=\"https://fosstodon.org/tags/Geophysics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Geophysics</span></a>, <a href=\"https://fosstodon.org/tags/MaterialScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MaterialScience</span></a> and more! \ud83d\udc47<br><a href=\"https://arxiv.org/pdf/2206.13932\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2206.13932</span><span class=\"invisible\"></span></a><br><a href=\"https://fosstodon.org/tags/TopologicalDataAnalysis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>TopologicalDataAnalysis</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.09527",
    "title": "Ignore Previous Prompt: Attack Techniques For Language Models",
    "latest": "2023-02-04T06:42:30+00:00",
    "last_post": {
      "url": "https://dair-community.social/@leon/109660781343915036",
      "content": "<p>\"Ignore Previous Prompt: Attack Techniques For Language Models\"</p><p>A structured and well-thought-through framework for probing language model vulnerability to prompt hijacking and goal leaking</p><p><a href=\"https://arxiv.org/abs/2211.09527\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.09527</span><span class=\"invisible\"></span></a> <a href=\"https://dair-community.social/tags/nlp\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>nlp</span></a> <a href=\"https://dair-community.social/tags/nlproc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>nlproc</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2208.08988",
    "title": "The 8-Point Algorithm as an Inductive Bias for Relative Pose Prediction by ViTs",
    "latest": "2023-02-04T05:57:28+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@at/109751636788268912",
      "content": "<p>The 8-Point Algorithm as an Inductive Bias for Relative Pose Prediction by ViTs</p><p>Chris Rockwell, Justin Johnson, David F. Fouhey</p><p>accepted 2022.</p><p>Baseline for learned relative pose estimation, using a modified ViT.</p><p><a href=\"https://sigmoid.social/tags/arXiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arXiv</span></a> <a href=\"https://sigmoid.social/tags/AmyPostsPapers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AmyPostsPapers</span></a> <a href=\"https://sigmoid.social/tags/ComputerVision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ComputerVision</span></a>  1/</p><p>abs: <a href=\"https://arxiv.org/abs/2208.08988\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2208.08988</span><span class=\"invisible\"></span></a><br>GH: <a href=\"https://github.com/crockwell/rel_pose\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/crockwell/rel_pose</span><span class=\"invisible\"></span></a><br>web: <a href=\"https://crockwell.github.io/rel_pose/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">crockwell.github.io/rel_pose/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04468",
    "title": "https://doi.org/10.21105/joss.04468",
    "latest": "2023-02-03T21:56:04+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109802409457111787",
      "content": "<p>Just published in JOSS: 'ParMOO: A Python library for parallel multiobjective simulation optimization' <a href=\"https://doi.org/10.21105/joss.04468\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04468</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@edzer",
        "display_name": "Edzer Pebesma"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13310v1",
    "title": "Alternating Updates for Efficient Transformers",
    "latest": "2023-02-03T21:55:16+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109803032842392163",
      "content": "<p>\ud83d\udcdd Alternating Updates for Efficient Transformers \ud83e\udde0\ud83d\udcda</p><p>\"Enables the widening of the learned representation without increasing the computation time by working on a subblock of the representation at each layer of a transformer model, and updating it.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.13310v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13310v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2212.14486.pdf",
    "title": "https://arxiv.org/pdf/2212.14486.pdf",
    "latest": "2023-02-03T21:42:07+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@myrthe/109665361554307171",
      "content": "<p>Loved this social science theory-heavy (\u2728) <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> paper from EMNLP+CSS @ EMNLP 2022: \"Examining Political Rhetoric with Epistemic Stance Detection\" by Ankita Gupta, Su Lin Blodgett, and political and social science colleagues!</p><p>An observation: I often find workshops papers more interesting than main conference ones! \ud83d\ude0c More unique, innovative, and interdisciplinary work that is less afraid to do something else than 'straightforward' benchmark-breaking work. </p><p><a href=\"https://arxiv.org/pdf/2212.14486.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2212.14486.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.08698",
    "title": "Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models",
    "latest": "2023-02-03T20:57:04+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@gowthami/109648785319779871",
      "content": "<p>Diffusion Disentanglement: Yet another prompt-based image editing method. Learn the interpolation coefficients between old and new prompts by means of optimization and uses that to perform the edits.</p><p>A \ud83e\uddf6</p><p>Paper: <a href=\"https://arxiv.org/abs/2212.08698\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.08698</span><span class=\"invisible\"></span></a></p><p>Day 6 <a href=\"https://sigmoid.social/tags/30daysofDiffusion\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>30daysofDiffusion</span></a> <a href=\"https://sigmoid.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2301.01379.pdf",
    "title": "https://arxiv.org/pdf/2301.01379.pdf",
    "latest": "2023-02-03T20:12:02+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@alissonmasoares/109644605673459784",
      "content": "<p>Interested in Reinforcement Learning?</p><p>A Succinct Summary of Reinforcement Learning. 2023, 18p.</p><p><a href=\"https://arxiv.org/pdf/2301.01379.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2301.01379.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fosstodon.org/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a> <a href=\"https://fosstodon.org/tags/reinforcementLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>reinforcementLearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://royalsocietypublishing.org/doi/10.1098/rspb.2022.2293",
    "title": "royalsocietypublishing.org/doi...",
    "latest": "2023-02-03T19:47:53+00:00",
    "last_post": {
      "url": "https://ecoevo.social/@gcbias/109801923008663936",
      "content": "<p>Congrats to moria robinson et al <br>Macroevolution of protective coloration across caterpillars reflects relationships with host plants  <a href=\"https://ecoevo.social/tags/EvolutionPaper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>EvolutionPaper</span></a> <br><a href=\"https://royalsocietypublishing.org/doi/10.1098/rspb.2022.2293\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">royalsocietypublishing.org/doi</span><span class=\"invisible\">/10.1098/rspb.2022.2293</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@SherlockpHolmes",
        "display_name": "Susan Holmes"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00288-7",
    "title": "ChatGPT: five priorities for research",
    "latest": "2023-02-03T10:02:04+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@wzuidema/109800228409980937",
      "content": "<p>We're in Nature with an opinion piece on how researchers should respond to <a href=\"https://sigmoid.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a> and conversational AI technology more generally!</p><p>It's been an interesting experience to reach consensus in an interdisciplinary team of scholars (2 psychologists, 1 computer scientist, 1 philosopher and me, an NLP-er). </p><p>We list 5 priorities:<br>1. Hold on to human verification<br>2. Develop rules for accountability<br>3. Invest in truly open LLMs<br>4. Embrace the benefits of AI<br>5. Widen the debate</p><p><a href=\"https://www.nature.com/articles/d41586-023-00288-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00288-7</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@wzuidema",
        "display_name": "Jelle Zuidema"
      }
    ]
  },
  {
    "link": "https://doi.org/10.25798/vdda-f287",
    "title": "https://doi.org/10.25798/vdda-f287",
    "latest": "2023-02-03T09:42:14+00:00",
    "last_post": {
      "url": "https://mastodon.social/@hauschke/109800150437179248",
      "content": "<p>Attention, attention! We had a mistake on the website! My fault!</p><p>OF COURSE the workshop takes place on next Monday, it's corrected now.</p><p>For reliable metadata on conferences don't ask me, ask confIDent ( <span class=\"h-card\"><a href=\"https://openbiblio.social/@tibhannover\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>tibhannover</span></a></span>) and/or <span class=\"h-card\"><a href=\"https://openbiblio.social/@datacite\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>datacite</span></a></span> : <a href=\"https://doi.org/10.25798/vdda-f287\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.25798/vdda-f287</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@hauschke",
        "display_name": "hauschke"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01327.pdf",
    "title": "Dual PatchNorm",
    "latest": "2023-02-03T09:32:10+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/109800110853092058",
      "content": "<p>Dual PatchNorm</p><p>Manoj Kumar, Mostafa Dehghani, Neil Houlsby</p><p>tl;dr: normalizing patches is good for your health.</p><p><a href=\"https://arxiv.org/abs/2302.01327.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01327.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00739",
    "title": "Inference of Partial Colexifications from Multilingual Wordlists",
    "latest": "2023-02-03T09:30:23+00:00",
    "last_post": {
      "url": "https://social.mpdl.mpg.de/@lingulist/109800103530640021",
      "content": "<p>A preprint for a study under review, titled \"Inference of partial colexifications from multilingual wordlists\" just appeared on arXiv.</p><p><a href=\"https://arxiv.org/abs/2302.00739\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00739</span><span class=\"invisible\"></span></a></p><p>It is a first attempt to shift the focus from \"full\" colexification networks to the analysis of partial colexification networks in comparative linguistics and lexical typology.</p><p>Data and code are available on GitHub.</p><p><a href=\"https://github.com/lingpy/pacs/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/lingpy/pacs/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04962",
    "title": "https://doi.org/10.21105/joss.04962",
    "latest": "2023-02-03T08:56:32+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109799970746870352",
      "content": "<p>Just published in JOSS: 'py-sc-fermi: self-consistent Fermi energies and defect concentrations from electronic structure calculations' <a href=\"https://doi.org/10.21105/joss.04962\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04962</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04955",
    "title": "https://doi.org/10.21105/joss.04955",
    "latest": "2023-02-03T08:46:41+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109799931999837160",
      "content": "<p>Just published in JOSS: 'RCaNmodel: An R package for Chance and Necessity modelling' <a href=\"https://doi.org/10.21105/joss.04955\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04955</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01330",
    "title": "https://arxiv.org/abs/2302.01330",
    "latest": "2023-02-03T08:45:46.085000+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109798235472608558",
      "content": "<p>SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections</p><p>proj: <a href=\"https://scene-dreamer.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">scene-dreamer.github.io/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2302.01330\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01330</span><span class=\"invisible\"></span></a><br>video: <a href=\"https://www.youtube.com/watch?v=AjtOlDHsiyU&amp;feature=youtu.be\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">youtube.com/watch?v=AjtOlDHsiy</span><span class=\"invisible\">U&amp;feature=youtu.be</span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@arnicas",
        "display_name": "arnicas"
      }
    ]
  },
  {
    "link": "https://ieeexplore.ieee.org/document/9263265",
    "title": "The Origin of the \u201cMIT License\u201d",
    "latest": "2023-02-03T08:00:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/109799748606040307",
      "content": "<p>The Origin of the \u201cMIT License\u201d (2020) - <a href=\"https://ieeexplore.ieee.org/document/9263265\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">ieeexplore.ieee.org/document/9</span><span class=\"invisible\">263265</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13714v1",
    "title": "Recursive Neural Networks with Bottlenecks Diagnose (Non-)Compositionality",
    "latest": "2023-02-03T07:15:16+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109799572510771831",
      "content": "<p>\ud83d\udcdd Recursive Neural Networks with Bottlenecks Diagnose (Non-)Compositionality \ud83d\udcda</p><p>\"The bottleneck compositionality metric (BCM) compares the representations of a given dataset obtained from a model with a bottleneck to those from a model without a bottleneck.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.13714v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13714v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01329",
    "title": "https://arxiv.org/abs/2302.01329",
    "latest": "2023-02-03T06:45:57+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109798242944159165",
      "content": "<p>Dreamix: Video Diffusion Models are General Video Editors</p><p>proj: <a href=\"https://dreamix-video-editing.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dreamix-video-editing.github.i</span><span class=\"invisible\">o/</span></a><br>abs: <a href=\"https://arxiv.org/abs/2302.01329\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01329</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@vh",
        "display_name": "Vincent HETRU"
      }
    ]
  },
  {
    "link": "https://royalsocietypublishing.org/doi/10.1098/rsos.191375",
    "title": "Raising the value of research studies in psychological science by increasing the credibility of research reports: the transparent Psi project | Royal Society Open Science",
    "latest": "2023-02-03T06:19:22+00:00",
    "last_post": {
      "url": "https://scicomm.xyz/@nicebread/109795089383982590",
      "content": "<p>Remember Bem's \"Feeling the future\", one of the events that kicked off the <a href=\"https://scicomm.xyz/tags/replicationCrisis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>replicationCrisis</span></a> in <a href=\"https://scicomm.xyz/tags/psychology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>psychology</span></a> in 2011?</p><p>Now <span class=\"h-card\"><a href=\"https://mstdn.science/@kekecsz\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>kekecsz</span></a></span> et al published a replication report that showcases best practices (<a href=\"https://royalsocietypublishing.org/doi/10.1098/rsos.191375\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">royalsocietypublishing.org/doi</span><span class=\"invisible\">/10.1098/rsos.191375</span></a>):<br>* Consensus protocol based on adversarial collaboration<br>* born open data<br>* Video-verified training<br>* real-time updating report<br>* external audit<br>* ...</p><p>Great work. It's amazing to compare the <a href=\"https://scicomm.xyz/tags/researchQuality\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>researchQuality</span></a> of 2011 with this cutting edge showcase. How far we have come!</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.12017",
    "title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization",
    "latest": "2023-02-03T06:02:04+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109797446193645583",
      "content": "<p>RT @sriniiyer88@twitter.com</p><p>Exciting updates on OPT-IML (<a href=\"https://arxiv.org/abs/2212.12017\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.12017</span><span class=\"invisible\"></span></a>)!</p><p>1. The 175B models are now available to request for research purposes. Request here: (<a href=\"https://github.com/facebookresearch/metaseq/tree/main/projects/OPT-IML\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/me</span><span class=\"invisible\">taseq/tree/main/projects/OPT-IML</span></a>).<br>2. OPT-IML 30B and 1.3B models are now available on huggingface (<a href=\"https://huggingface.co/facebook/opt-iml-30b\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">huggingface.co/facebook/opt-im</span><span class=\"invisible\">l-30b</span></a>)!</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/sriniiyer88/status/1621207942304509952\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/sriniiyer88/status</span><span class=\"invisible\">/1621207942304509952</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      },
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      },
      {
        "url": "https://sigmoid.social/@vh",
        "display_name": "Vincent HETRU"
      }
    ]
  },
  {
    "link": "http://osf.io/5p8u2/",
    "title": "http://osf.io/5p8u2/",
    "latest": "2023-02-02T21:56:41+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109797376130188271",
      "content": "<p>Participation in formal adult education and family life - a gendered story <a href=\"http://osf.io/5p8u2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/5p8u2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/epub/10.1177/09637214221121570",
    "title": "journals.sagepub.com/doi/epub/...",
    "latest": "2023-02-02T21:40:09+00:00",
    "last_post": {
      "url": "https://assemblag.es/@sparks/109677853942526283",
      "content": "<p>I've long had a vague sense that ~all this~ is from a lack of some key social immune system that eventually we'd develop. On the other side of that, modern misinformation would look as goofy as old-timey scams.</p><p>ANYWAY: *Critical Ignoring as a Core Competence for Digital Citizens*</p><p>\"Resisting certain types of information and actors online requires people to adopt new mental habits that help them avoid being tempted by attention-grabbing and potentially harmful content.\"</p><p><a href=\"https://journals.sagepub.com/doi/epub/10.1177/09637214221121570\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/epub/</span><span class=\"invisible\">10.1177/09637214221121570</span></a></p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      },
      {
        "url": "https://zirk.us/@matthewbattles",
        "display_name": "Matthew Battles"
      }
    ]
  },
  {
    "link": "https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1927.0039",
    "title": "royalsocietypublishing.org/doi...",
    "latest": "2023-02-02T21:10:08+00:00",
    "last_post": {
      "url": "https://mastodon.social/@mcnees/109797070989166086",
      "content": "<p>Paul Dirac's paper on quantum emission and absorption of radiation was submitted to the Royal Society <a href=\"https://mastodon.social/tags/OTD\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OTD</span></a> in 1927. It advanced the first quantum mechanical theory of electrodynamics and is considered by many to mark the birth of \u2728Quantum Field Theory\u2728<br><a href=\"https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1927.0039\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">royalsocietypublishing.org/doi</span><span class=\"invisible\">/abs/10.1098/rspa.1927.0039</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@caderoux",
        "display_name": "Cade Roux"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s13347-020-00405-8",
    "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence - Philosophy & Technology",
    "latest": "2023-02-02T20:41:39+00:00",
    "last_post": {
      "url": "https://mastodon.social/@Colarusso/109796263362720734",
      "content": "<p>2/12) Second, it's important to look not just at what this tech can do but also how it was built. See e.g., <a href=\"https://link.springer.com/article/10.1007/s13347-020-00405-8\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s13347-020-00405-8</span></a> (providing an exploration of AI practices through a decolonial lens)</p><p>That being said, we have to understand something before we can intelligently talk about it. So, for the moment my goal is explaining <a href=\"https://mastodon.social/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> to <a href=\"https://mastodon.social/tags/LawProfs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LawProfs</span></a></p><p>So, here we go...</p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s13347-023-00607-w",
    "title": "Egalitarianism and Algorithmic Fairness - Philosophy & Technology",
    "latest": "2023-02-02T09:51:30+00:00",
    "last_post": {
      "url": "https://someone.elses.computer/@RDBinns/109794518748908581",
      "content": "<p>Interesting paper from Sune Holm on 'Egalitarianism and Algorithmic Fairness' <a href=\"https://link.springer.com/article/10.1007/s13347-023-00607-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s13347-023-00607-w</span></a></p><p>And of course, it's always nice to be credited with being first to what's now a very crowded area:</p><p>\"The task of articulating the philosophical rationale behind statistical criteria of algorithmic fairness was to my knowledge first considered by Binns 2017, who provides an excellent introduction to the problem of fairness in machine learning\" \ud83d\ude0a</p>"
    },
    "people": [
      {
        "url": "https://mastodon.online/@manuchis",
        "display_name": "manuchis"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13294v1",
    "title": "Adaptive Machine Translation with Large Language Models",
    "latest": "2023-02-02T08:35:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109794224400613301",
      "content": "<p>\ud83d\udcdd Adaptive Machine Translation with Large Language Models \ud83d\udcda</p><p>\"First fine-tunes an LLM on a set of in-domain sentence pairs / terminology (few-shot prompt), and then translates a new sentence.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.13294v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13294v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.11305v1",
    "title": "https://arxiv.org/abs/2301.11305v1",
    "latest": "2023-02-02T08:27:53+00:00",
    "last_post": {
      "url": "https://mastodon.social/@SebRaschka/109792908484027576",
      "content": "<p>Here are the links to the 4 different methods referenced above: </p><p>(1) OpenAI AI classifier: <a href=\"https://platform.openai.com/ai-text-classifier\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">platform.openai.com/ai-text-cl</span><span class=\"invisible\">assifier</span></a></p><p>(2) Detect GPT: <a href=\"https://arxiv.org/abs/2301.11305v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11305v1</span><span class=\"invisible\"></span></a></p><p>(3) GPTZero: <a href=\"https://gptzero.substack.com/p/gptzero-update-v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">gptzero.substack.com/p/gptzero</span><span class=\"invisible\">-update-v1</span></a></p><p>(4) Watermarking: <a href=\"https://arxiv.org/abs/2301.10226v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.10226v2</span><span class=\"invisible\"></span></a></p><p>And a slightly more verbose blog post: <a href=\"https://sebastianraschka.com/blog/2023/detect-ai.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">sebastianraschka.com/blog/2023</span><span class=\"invisible\">/detect-ai.html</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://sigmoid.social/@vh",
        "display_name": "Vincent HETRU"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.10226v2",
    "title": "https://arxiv.org/abs/2301.10226v2",
    "latest": "2023-02-02T08:27:53+00:00",
    "last_post": {
      "url": "https://mastodon.social/@SebRaschka/109792908484027576",
      "content": "<p>Here are the links to the 4 different methods referenced above: </p><p>(1) OpenAI AI classifier: <a href=\"https://platform.openai.com/ai-text-classifier\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">platform.openai.com/ai-text-cl</span><span class=\"invisible\">assifier</span></a></p><p>(2) Detect GPT: <a href=\"https://arxiv.org/abs/2301.11305v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11305v1</span><span class=\"invisible\"></span></a></p><p>(3) GPTZero: <a href=\"https://gptzero.substack.com/p/gptzero-update-v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">gptzero.substack.com/p/gptzero</span><span class=\"invisible\">-update-v1</span></a></p><p>(4) Watermarking: <a href=\"https://arxiv.org/abs/2301.10226v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.10226v2</span><span class=\"invisible\"></span></a></p><p>And a slightly more verbose blog post: <a href=\"https://sebastianraschka.com/blog/2023/detect-ai.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">sebastianraschka.com/blog/2023</span><span class=\"invisible\">/detect-ai.html</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@vh",
        "display_name": "Vincent HETRU"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13823",
    "title": "http://arxiv.org/abs/2301.13823",
    "latest": "2023-02-02T07:20:47+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/3b64e4e5-d24e-44e8-a736-3d4f02dd2f60",
      "content": "\"Grounding Language Models to Images for Multimodal Generation. (arXiv:2301.13823v1 [cs.CL])\" \u2014 An efficient method to ground pretrained text-only language models to the visual domain, enabling them to process and generate arbitrarily interleaved image-and-text data. This approach apparently works with any off-the-shelf language model.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13823\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13823</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/be063306274005728c81d3b3b530cdd0fbca8749ba1625886edefab9497ea6b1.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Our method grounds a language m\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3340531.3412777",
    "title": "Falcon 2.0 | Proceedings of the 29th ACM International Conference on Information & Knowledge Management",
    "latest": "2023-02-02T06:17:56+00:00",
    "last_post": {
      "url": "https://mastodon.social/@wikiresearch/109793684805840395",
      "content": "<p>Online demo and web APIs for \"Falcon 2.0: An Entity and Relation Linking Tool over Wikidata\" (<a href=\"https://dl.acm.org/doi/10.1145/3340531.3412777\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/10.1145/3340531</span><span class=\"invisible\">.3412777</span></a> ) <br>---<br>RT @TIB_SDM<br><a href=\"https://mastodon.social/tags/FALCON\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>FALCON</span></a> 2.0 maps the surface forms within a short text T into entities and relations in <br>@dbpedia and <span class=\"h-card\"><a href=\"https://mastodon.social/@wikiresearch\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>wikiresearch</span></a></span>  </p><p>\u27a1\ufe0fVisit our <a href=\"https://mastodon.social/tags/demo\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>demo</span></a>: <a href=\"http://ow.ly/CBrW50MGARo\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">ow.ly/CBrW50MGARo</span><span class=\"invisible\"></span></a> </p><p>\u27a1\ufe0fUse our Web APIs: <a href=\"http://ow.ly/yxlJ50MGARp\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">ow.ly/yxlJ50MGARp</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.social/tags/BigData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BigData</span></a> <a href=\"https://mastodon.social/tags/MEDICINE\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MEDICINE</span></a> <a href=\"https://mastodon.social/tags/HEALTHCARE\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>HEALTHCARE</span></a> <a href=\"https://mastodon.social/tags/WikiData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>WikiData</span></a> <br><a href=\"https://twitter.com/TIB_SDM/status/1620799287062847488\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/TIB_SDM/status/162</span><span class=\"invisible\">0799287062847488</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@wikiresearch",
        "display_name": "WikiResearch"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12314v1",
    "title": "Progressive Prompts: Continual Learning for Language Models",
    "latest": "2023-02-02T06:04:09+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109793630587864610",
      "content": "<p>\ud83d\udcdd Progressive Prompts: Continual Learning for Language Models \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Progressive Prompts learns a new soft prompt for each task and sequentially concatenates it with the previously learned prompts, while keeping the base model frozen and without relying on data replay.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.12314v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12314v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00093",
    "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context",
    "latest": "2023-02-02T05:32:16+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/109792623602660767",
      "content": "<p>Large Language Models Can Be Easily Distracted by Irrelevant Context</p><p><a href=\"https://arxiv.org/abs/2302.00093\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00093</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12217v1",
    "title": "https://arxiv.org/abs/2301.12217v1",
    "latest": "2023-02-01T21:24:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109791585686959534",
      "content": "<p>\ud83d\udcdd Semantic Parsing for Conversational Question Answering Over Knowledge Graphs \ud83d\udcda</p><p>\"Trains a BART-based semantic parser, which learns to map utterances into a sequence of Sparql query actions (\u00a7 ), and then augment it with a conversational context encoder to model conversational history as an attention memory (\u00a7 ).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/EdinburghNLP/SPICE\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/EdinburghNLP/SPICE</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.12217v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12217v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13188",
    "title": "Extracting Training Data from Diffusion Models",
    "latest": "2023-02-01T21:00:27+00:00",
    "last_post": {
      "url": "https://mastodon.gamedev.place/@BartWronski/109791007952642557",
      "content": "<p>This time Google does the right thing - while shareholders grill them over \"competition\" with ChatGPT (not really...), they research and publish how useful and privacy preserving large models are.</p><p>It turns out, as suspected, they are not very useful for actual professional writers who understand \"something\" about writing: <a href=\"https://arxiv.org/abs/2211.05030\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.05030</span><span class=\"invisible\"></span></a></p><p>...and leak the dataset/private data, 2x worse with diffusion than GANs: <a href=\"https://arxiv.org/abs/2301.13188\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13188</span><span class=\"invisible\"></span></a></p><p>No wonder Google is hesitant to use them. :)</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jenlowe",
        "display_name": "Jen Lowe"
      },
      {
        "url": "https://mastodon.social/@MattHodges",
        "display_name": "Matt Hodges"
      },
      {
        "url": "https://mastodon.social/@ojala",
        "display_name": "Luis Apiolaza"
      },
      {
        "url": "https://sigmoid.social/@roban",
        "display_name": "Roban Hultman Kramer"
      },
      {
        "url": "https://sigmoid.social/@nsaphra",
        "display_name": "Naomi Saphra"
      },
      {
        "url": "https://scholar.social/@electricarchaeo",
        "display_name": "Shawn Graham"
      },
      {
        "url": "https://mstdn.social/@olihawkins",
        "display_name": "Oli Hawkins"
      },
      {
        "url": "https://octodon.social/@craignicol",
        "display_name": "Craig Nicol"
      },
      {
        "url": "https://hci.social/@chrisamaphone",
        "display_name": "chris martens (they/them)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.05030",
    "title": "Creative Writing with an AI-Powered Writing Assistant: Perspectives from Professional Writers",
    "latest": "2023-02-01T21:00:27+00:00",
    "last_post": {
      "url": "https://mastodon.gamedev.place/@BartWronski/109791007952642557",
      "content": "<p>This time Google does the right thing - while shareholders grill them over \"competition\" with ChatGPT (not really...), they research and publish how useful and privacy preserving large models are.</p><p>It turns out, as suspected, they are not very useful for actual professional writers who understand \"something\" about writing: <a href=\"https://arxiv.org/abs/2211.05030\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.05030</span><span class=\"invisible\"></span></a></p><p>...and leak the dataset/private data, 2x worse with diffusion than GANs: <a href=\"https://arxiv.org/abs/2301.13188\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13188</span><span class=\"invisible\"></span></a></p><p>No wonder Google is hesitant to use them. :)</p>"
    },
    "people": [
      {
        "url": "https://octodon.social/@craignicol",
        "display_name": "Craig Nicol"
      },
      {
        "url": "https://hci.social/@chrisamaphone",
        "display_name": "chris martens (they/them)"
      }
    ]
  },
  {
    "link": "http://osf.io/jwmx9/",
    "title": "http://osf.io/jwmx9/",
    "latest": "2023-02-01T20:18:41+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109791328417569781",
      "content": "<p>Folgen der Inflation in Deutschland <a href=\"http://osf.io/jwmx9/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/jwmx9/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/p3hz2/",
    "title": "http://osf.io/p3hz2/",
    "latest": "2023-02-01T10:03:19+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109788908685032164",
      "content": "<p>Differential grandparental investment when maternal grandmothers are dead vs alive <a href=\"http://osf.io/p3hz2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/p3hz2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/f6pnz/",
    "title": "http://osf.io/f6pnz/",
    "latest": "2023-02-01T10:03:18+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109788908664158410",
      "content": "<p>How do researchers generate scientific and societal impacts? Toward an analytical and operational framework <a href=\"http://osf.io/f6pnz/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/f6pnz/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/4ez3k/",
    "title": "http://osf.io/4ez3k/",
    "latest": "2023-02-01T09:58:09+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109788888381298588",
      "content": "<p>Teacher Morale, Job Satisfaction, and Burnout in Schools of Choice Following the COVID-19 Pandemic <a href=\"http://osf.io/4ez3k/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/4ez3k/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2112.01716",
    "title": "Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research",
    "latest": "2023-02-01T09:51:56+00:00",
    "last_post": {
      "url": "https://mastodon.social/@baxterkb/109786692814808438",
      "content": "<p>The world according to the data AI sees. 50% of datasets are connected to 12 institutions. Analysis of 4384 datasets and 60647 papers.<br>Read the report: <a href=\"https://arxiv.org/abs/2112.01716\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2112.01716</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://genart.social/@guidoschmidt",
        "display_name": "Guido Schmidt"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12004v1",
    "title": "Understanding the Effectiveness of Very Large Language Models on Dialog Evaluation",
    "latest": "2023-02-01T08:24:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109788518618863545",
      "content": "<p>\ud83d\udcdd Understanding the Effectiveness of Very Large Language Models on Dialog Evaluation \ud83d\udcda</p><p>\"The task is to rank a set of dialogues with respect to their suitability for the given context (efficiently or informatively), where each dialogue is represented as an unordered set of utterances.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.12004v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12004v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.13823",
    "title": "Grounding Language Models to Images for Multimodal Generation",
    "latest": "2023-02-01T08:20:38+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@jy/109787132746988574",
      "content": "<p>This paper is joint work with Russ Salakhutdinov and <span class=\"h-card\"><a href=\"https://sigmoid.social/@dan_fried\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>dan_fried</span></a></span> at CMU!</p><p>Paper: <a href=\"https://arxiv.org/abs/2301.13823\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.13823</span><span class=\"invisible\"></span></a><br>Project website: <a href=\"https://jykoh.com/fromage\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">jykoh.com/fromage</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1177/00016993221151118",
    "title": "doi.org/10.1177/00016993221151...",
    "latest": "2023-02-01T07:09:28+00:00",
    "last_post": {
      "url": "https://sciences.social/@actasociologica/109782905516306976",
      "content": "<p>Google Trends stinks!</p><p>While frequently used by researchers Google Trends seems to be a highly unreliable source of historical trends, Alexandra Franz\u00e9n argues based on an experiment revealing Google Trends inability to replicate.</p><p>Compare for instance the two identical searches conducted at different times below.</p><p>\"Big data, big problems: Why scientists should refrain from using Google Trends\": <a href=\"https://doi.org/10.1177/00016993221151118\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1177/00016993221151</span><span class=\"invisible\">118</span></a></p><p><span class=\"h-card\"><a href=\"https://a.gup.pe/u/sociology\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>sociology</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/dh\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>dh</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/politicalscience\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>politicalscience</span></a></span><br><span class=\"h-card\"><a href=\"https://a.gup.pe/u/academicchatter\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>academicchatter</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/communicationscholars\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>communicationscholars</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://social.juanlu.space/@astrojuanlu",
        "display_name": "Juan Luis"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.11997v1",
    "title": "https://arxiv.org/abs/2301.11997v1",
    "latest": "2023-02-01T06:24:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109788046707886276",
      "content": "<p>\ud83d\udcdd Prompt-Based Editing for Text Style Transfer \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"A textual prompt is used to query a pretrained language model to generate style-transferred text word by word in an autoregressive manner, where the generation process less controllable and early prediction errors may affect future word prediction.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/kingoflolz/mesh-transformer-jax\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/kingoflolz/mesh-tra</span><span class=\"invisible\">nsformer-jax</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.11997v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11997v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2012.12311",
    "title": "http://arxiv.org/abs/2012.12311",
    "latest": "2023-02-01T05:34:13.423000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/cfdc6f1b-7deb-4280-8201-d457f97f85d8",
      "content": "\"Video Influencers: Unboxing the Mystique. (arXiv:2012.12311v2 [cs.LG] UPDATED)\" \u2014 A study and analysis of YouTube influencers and their unstructured video data across text, audio and images using a novel \"interpretable deep learning\" framework to determine the effectiveness of their constituent elements in explaining video engagement.<br><br>Paper: <a href=\"http://arxiv.org/abs/2012.12311\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2012.12311</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/a0bdc363051c3abb3652e19b1af10b27ab38adfd1e5463c92746cd8a7abc90c2.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Gradient heat map in video fram\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13826",
    "title": "http://arxiv.org/abs/2301.13826",
    "latest": "2023-02-01T05:26:19.827000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/d462c817-0c88-4b27-a876-aeef6e40867c",
      "content": "\"Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models. (arXiv:2301.13826v1 [cs.CV])\" \u2014 A process which intervenes in the generative process of diffusion models on the fly during inference time to improve the faithfulness of the generated images to guide the model to refine the cross-attention units to attend to all subject tokens in the text prompt and strengthen - or excite - their activations, encouraging the model to generate all subjects described in the text prompt.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13826\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13826</a><br>Code: <a href=\"https://github.com/AttendAndExcite/Attend-and-Excite\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/AttendAndExcite/Attend-and-Excite</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/ac9e09bfc8e38ff40ac38e86732a6d324eb10d07d59adaf1631507574d86689d.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Given a pre-trained text-to-ima\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13741",
    "title": "http://arxiv.org/abs/2301.13741",
    "latest": "2023-02-01T05:16:26.292000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/52b2e507-8444-4fd4-a116-3b6f5836a3c1",
      "content": "\"UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers. (arXiv:2301.13741v1 [cs.CV])\" \u2014 A universal vison-language Transformer compression framework which can handle multiple generative and discriminative vision-language tasks such as Visual Reasoning, Image Caption, Visual Question Answer, Image-Text Retrieval, Text-Image Retrieval, and Image Classification.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13741\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13741</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/df0d24364bffab556d7f154cc2a76d9a3479c780da379e822ad18b113cbfc15d.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Comparison between the Mask-bas\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13721",
    "title": "http://arxiv.org/abs/2301.13721",
    "latest": "2023-02-01T04:51:56.158000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/978632c8-c7d2-4052-b887-928469032d29",
      "content": "\"DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models. (arXiv:2301.13721v1 [cs.CV])\" \u2014 A new task to take advantage of the remarkable modeling ability of diffusion probabilistic models (DPM) using an unsupervised approach.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13721\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13721</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/b840c18b363e395aa00fadb026587d04e6da6a771beb8f7ffb12dbb3490461bb.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Illustration of disentanglement\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13622",
    "title": "http://arxiv.org/abs/2301.13622",
    "latest": "2023-02-01T04:43:30.633000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/1ee247f3-131d-4957-adf0-8a1414da6335",
      "content": "\"Learning Data Representations with Joint Diffusion Models. (arXiv:2301.13622v1 [cs.LG])\" \u2014 A joint diffusion model that simultaneously learns meaningful internal representations fit for both generative and predictive tasks and which has superior performance across various tasks, including generative modeling, semi-supervised classification, and domain adaptation.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13622\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13622</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/bf4f0f1f162a5ff055069810fd74efc62f6436f849c3f254ea102a8a59413c24.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Data representation zt in a UNe\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13569",
    "title": "http://arxiv.org/abs/2301.13569",
    "latest": "2023-02-01T04:41:02.131000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/db98720c-df12-4b05-a6c3-8587d51e21bf",
      "content": "\"NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning. (arXiv:2301.13569v1 [cs.CV])\" \u2014 Adapting neural processes (NPs) for semi-supervised image classification tasks to arrive at a solution with much less computational overhead, which can save time at both the training and the testing phases.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13569\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13569</a><br>Code: <a href=\"https://github.com/jianf-wang/np-match\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/jianf-wang/np-match</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/c75678bab60bc0a4f90a982b620181ace71e595452d06ca80801cb5e8da99a5b.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Overview of NP-Match: it contai\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13530",
    "title": "http://arxiv.org/abs/2301.13530",
    "latest": "2023-02-01T04:37:27.346000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/c8489f1a-d254-415e-b741-9a07c89a1e25",
      "content": "\"Domain-Generalizable Multiple-Domain Clustering. (arXiv:2301.13530v1 [cs.LG])\" \u2014 Given unlabeled samples from multiple source domains, an attempt to learn a shared classifier that assigns the examples to various clusters by using the classifier for predicting cluster assignments in a previously unseen domain.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13530\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13530</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/addc02262079ba76bbfb058b8c829a57b71642c725216b346aaad9b222b092da.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Problem statement - given unlab\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/20563051221150412",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-02-01T04:35:59+00:00",
    "last_post": {
      "url": "https://hci.social/@Mor/109784043751315609",
      "content": "<p>Misinformation on Misinformation. A solid (but debatable) argument. </p><p>[I wish I could say this paper was all wrong, in which case it would be... you know] </p><p><a href=\"https://journals.sagepub.com/doi/10.1177/20563051221150412\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/20563051221150412</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      },
      {
        "url": "https://hci.social/@axz",
        "display_name": "Amy Zhang"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2301.13514",
    "title": "http://arxiv.org/abs/2301.13514",
    "latest": "2023-02-01T04:34:17.955000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/1cbeb925-8d67-48f4-8ad8-804eb4e939bb",
      "content": "\"Fourier Sensitivity and Regularization of Computer Vision Models. (arXiv:2301.13514v1 [cs.CV])\" \u2014 A study of the frequency sensitivity characteristics of deep neural networks using a principled approach due to recent work showing that deep neural networks latch on to the Fourier statistics of training data and show increased sensitivity to Fourier-basis directions in the input.<br><br>Paper: <a href=\"http://arxiv.org/abs/2301.13514\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2301.13514</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/5fbf40bb06af470c4c83f181d64b65c18a68d43fe9b954c984770f505294d598.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Computing Fourier-sensitivity. \u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/bjd/article/188/1/1/6795460",
    "title": "watershed moment for the BJD: Authors retain their article copyright",
    "latest": "2023-01-31T21:41:35+00:00",
    "last_post": {
      "url": "https://fediscience.org/@petersuber/109784686866640806",
      "content": "<p>The British Journal of Dermatology just moved from <a href=\"https://fediscience.org/tags/Wiley\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Wiley</span></a> to <a href=\"https://fediscience.org/tags/OUP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OUP</span></a>. As part of the move, it's adding plain language summaries (<a href=\"https://fediscience.org/tags/PLS\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PLS</span></a>) and allowing authors to retain <a href=\"https://fediscience.org/tags/copyright\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>copyright</span></a> in their articles.<br><a href=\"https://academic.oup.com/bjd/article/188/1/1/6795460\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/bjd/article/1</span><span class=\"invisible\">88/1/1/6795460</span></a></p><p>The journal remains <a href=\"https://fediscience.org/tags/hybrid\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>hybrid</span></a>, not full <a href=\"https://fediscience.org/tags/openaccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>openaccess</span></a>. But note that the key <a href=\"https://fediscience.org/tags/RightsRetention\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RightsRetention</span></a> step was voluntarily adopted by a <a href=\"https://fediscience.org/tags/society\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>society</span></a> (British Association of Dermatologists) and a <a href=\"https://fediscience.org/tags/UniversityPress\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>UniversityPress</span></a>. Kudos to them both.</p><p><a href=\"https://fediscience.org/tags/nonprofit\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>nonprofit</span></a></p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      }
    ]
  },
  {
    "link": "https://link.springer.com/book/10.1007/978-3-031-16624-2",
    "title": "link.springer.com/book/10.1007...",
    "latest": "2023-01-31T21:25:10+00:00",
    "last_post": {
      "url": "https://mastodon.world/@bekieark/109783892164606868",
      "content": "<p>Two cool, new <a href=\"https://mastodon.world/tags/books\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>books</span></a> for <a href=\"https://mastodon.world/tags/dataScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dataScience</span></a>, <a href=\"https://mastodon.world/tags/bigData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>bigData</span></a> and <a href=\"https://mastodon.world/tags/computationalSocialScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computationalSocialScience</span></a>. In <a href=\"https://mastodon.world/tags/Python\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Python</span></a> - but not only:</p><p><a href=\"https://pragprog.com/titles/dzcnapy/complex-network-analysis-in-python\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">pragprog.com/titles/dzcnapy/co</span><span class=\"invisible\">mplex-network-analysis-in-python</span></a></p><p><a href=\"https://link.springer.com/book/10.1007/978-3-031-16624-2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/book/10.1007</span><span class=\"invisible\">/978-3-031-16624-2</span></a></p><p>Links via <span class=\"h-card\"><a href=\"https://techhub.social/@pragprog\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>pragprog</span></a></span> and <span class=\"h-card\"><a href=\"https://hci.social/@bkeegan\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>bkeegan</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@mszll",
        "display_name": "Michael Szell"
      },
      {
        "url": "https://hci.social/@bkeegan",
        "display_name": "Brian C. Keegan"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.11843v1",
    "title": "Reading and Reasoning over Chart Images for Evidence-based Automated Fact-Checking",
    "latest": "2023-01-31T21:19:09+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109785903915539182",
      "content": "<p>\ud83d\udcdd Reading and Reasoning Over Chart Images for Evidence-Based Automated Fact-Checking \ud83d\udcda\ud83d\udd2d</p><p>\"ChartBERT leverages textual, structural and visual information of charts to determine the veracity of textual claims in a multi-modal approach (VL-BERT) that combines textual and visual embeddings.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.11843v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11843v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/epub/10.1177/20563051221150412",
    "title": "journals.sagepub.com/doi/epub/...",
    "latest": "2023-01-31T21:08:21+00:00",
    "last_post": {
      "url": "https://mastodon.social/@judell/109785861402104604",
      "content": "<p>Thanks, <span class=\"h-card\"><a href=\"https://hci.social/@Mor\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Mor</span></a></span>, for pointing me to <a href=\"https://journals.sagepub.com/doi/epub/10.1177/20563051221150412\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/epub/</span><span class=\"invisible\">10.1177/20563051221150412</span></a> (Misinformation on Misinformation).</p><p>I always appreciate being invited to reconsider what I think I know, and this paper does that very well. </p><p>Paging <a href=\"https://yourewrongabout.com/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">yourewrongabout.com/</span><span class=\"invisible\"></span></a>!</p><p><a href=\"https://mastodon.social/tags/Misinformation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Misinformation</span></a> <a href=\"https://mastodon.social/tags/SocialScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SocialScience</span></a> <a href=\"https://mastodon.social/tags/SocialMedia\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SocialMedia</span></a> <a href=\"https://mastodon.social/tags/AlternateNarrative\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AlternateNarrative</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@judell",
        "display_name": "Jon Udell"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12652",
    "title": "REPLUG: Retrieval-Augmented Black-Box Language Models",
    "latest": "2023-01-31T09:58:50+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@akhaliq/109781427359085984",
      "content": "<p>REPLUG: Retrieval-Augmented Black-Box Language Models </p><p>abs: <a href=\"https://arxiv.org/abs/2301.12652\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12652</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12597",
    "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
    "latest": "2023-01-31T09:31:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/109783119609775103",
      "content": "<p>RT @mrdbourke@twitter.com</p><p>2022: text-to-image models \ud83d\udcc8</p><p>2023: let\u2019s reverse it \ud83d\udd04</p><p>BLIP-2 introduces image-to-text!</p><p>Combine vision encoder (eg ViT) &amp; bring your own language model (eg FlanT5) to converse with the image!</p><p>Paper: <a href=\"https://arxiv.org/abs/2301.12597\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12597</span><span class=\"invisible\"></span></a><br>Code: <a href=\"https://github.com/salesforce/LAVIS\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/salesforce/LAVIS</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/mrdbourke/status/1620353263651688448\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/mrdbourke/status/1</span><span class=\"invisible\">620353263651688448</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12971",
    "title": "Quantifying Context Mixing in Transformers",
    "latest": "2023-01-31T09:03:44+00:00",
    "last_post": {
      "url": "https://mastodon.social/@gsarti/109783010296333151",
      "content": "<p>Shout-out to @hmohebbi75@twitter.com et al. from our <a href=\"https://mastodon.social/tags/InDeep\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>InDeep</span></a> consortium for their awesome work \"Quantifying Context Mixing in Transformers\", introducing Value Zeroing as a new promising post-hoc interpretability approach for NLP! \ud83c\udf89 Paper: <a href=\"https://arxiv.org/abs/2301.12971\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12971</span><span class=\"invisible\"></span></a> <a href=\"https://t.co/RxX2LenHqv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">t.co/RxX2LenHqv</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/full/10.1177/02637758231153399",
    "title": "journals.sagepub.com/doi/full/...",
    "latest": "2023-01-31T09:01:53+00:00",
    "last_post": {
      "url": "https://saturation.social/@shannonmattern/109783004863495741",
      "content": "<p>\u201c\u2026the paper explores how practices of thermal comfort for particular, often privileged, bodies may be understood as sensory enablers of climate change denial.\u201d </p><p><a href=\"https://journals.sagepub.com/doi/full/10.1177/02637758231153399\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/full/</span><span class=\"invisible\">10.1177/02637758231153399</span></a></p>"
    },
    "people": [
      {
        "url": "https://saturation.social/@shannonmattern",
        "display_name": "Shannon Mattern"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/0804.2996",
    "title": "http://arxiv.org/abs/0804.2996",
    "latest": "2023-01-31T08:38:22+00:00",
    "last_post": {
      "url": "https://social.skewed.de/@tiago/109782912390753303",
      "content": "<p>RT @docmilanfar@twitter.com</p><p>Think you understand Maximum Likelihood? Think again.</p><p>It seems like such a natural idea, but there\u2019s an epic and turbulent history with numerous assaults on the core idea, culminating in a beautiful and complicated theory.</p><p>A highly entertaining account:</p><p><a href=\"http://arxiv.org/abs/0804.2996\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/0804.2996</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/docmilanfar/status/1620292922313945089\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/docmilanfar/status</span><span class=\"invisible\">/1620292922313945089</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.11660v1",
    "title": "Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning Methods",
    "latest": "2023-01-31T08:19:08+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109782836755899086",
      "content": "<p>\ud83d\udcdd Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning Methods \ud83d\udcda</p><p>\"PETL can help OOD detection tasks by fine-tuning or learning small task-specific modules in a pre-trained language model (PLM), and the OOD detection performances increase as the size of the PLM is increased.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.11660v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11660v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.12636",
    "title": "Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays",
    "latest": "2023-01-31T08:13:41+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@kornia_foss/109782807730251053",
      "content": "<p>Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays</p><p>Rogier van der Sluijs, Nandita Bhaskhar, Daniel Rubin, Curtis Langlotz, Akshay Chaudhari</p><p>tl;dr: <a href=\"https://sigmoid.social/tags/kornia\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>kornia</span></a> RandomResizedCrop+Contrast+Brightness are good for X-Ray representation learning</p><p><a href=\"https://arxiv.org/abs/2301.12636\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.12636</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.11462",
    "title": "How poor is the stimulus? Evaluating hierarchical generalization in neural networks trained on child-directed speech",
    "latest": "2023-01-31T06:53:51+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@LChoshen/109782501397546745",
      "content": "<p>Poor stimulus\ud83d\ude30<br>it is not enough for learning</p><p>Training on child-like data<br>Networks fail to form valid questions<br>implying they lack the prebuilt assumptions(inductive bias) that children possess</p><p><a href=\"https://arxiv.org/abs/2301.11462\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11462</span><span class=\"invisible\"></span></a><br><span class=\"h-card\"><a href=\"https://birdsite.wilde.cloud/users/tallinzen\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>tallinzen</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      }
    ]
  },
  {
    "link": "http://journals.sagepub.com/doi/10.1037/gpr0000157",
    "title": "journals.sagepub.com/doi/10.10...",
    "latest": "2023-01-31T05:46:35+00:00",
    "last_post": {
      "url": "https://hci.social/@katyilonka/109778887545244208",
      "content": "<p>\ud83d\udcd1\ud83d\udcd1\ud83d\udcd1 </p><p>Interesting papers I've read recently:</p><p>1. The Enigma of Being Yourself: A Critical Examination of the Concept of Authenticity<br><a href=\"http://journals.sagepub.com/doi/10.1037/gpr0000157\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.10</span><span class=\"invisible\">37/gpr0000157</span></a></p><p>Wow, amazing. Reviews and examines (and critiques) how authenticity is studied in psychology. Lots of interesting ideas; would love to take some and use it to study human-AI collaboration and authenticity.</p>"
    },
    "people": [
      {
        "url": "https://lingo.lol/@grvsmth",
        "display_name": "Dr. Angus Andrea Grieve-Smith"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2212.08861",
    "title": "http://arxiv.org/abs/2212.08861",
    "latest": "2023-01-31T05:42:42.879000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/a687ca76-b1d5-4b5b-8d92-a875243261cb",
      "content": "\"DAG: Depth-Aware Guidance with Denoising Diffusion Probabilistic Models. (arXiv:2212.08861v2 [cs.CV] UPDATED)\" \u2014 A guidance method for diffusion models that uses estimated depth information derived from the rich intermediate representations of diffusion models.<br><br>Paper: <a href=\"http://arxiv.org/abs/2212.08861\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2212.08861</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/45818d5a0cc7a3a44dbaf910e6313c26fb5afce6bf75193eed978937162abec6.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Qualitative comparisons of synt\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2212.05032",
    "title": "http://arxiv.org/abs/2212.05032",
    "latest": "2023-01-31T05:39:11.747000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/b1aca62f-dfc5-4997-bda8-ad0c73c2eb0d",
      "content": "\"Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis. (arXiv:2212.05032v2 [cs.CV] UPDATED)\" \u2014 Improving the compositional skills of text-to-image models; specifically, obtainining more accurate attribute binding and better image compositions by incorporating linguistic structures with the diffusion guidance process based on the controllable properties of manipulating cross-attention layers in diffusion-based models.<br><br>Paper: <a href=\"http://arxiv.org/abs/2212.05032\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2212.05032</a><br>Code: <a href=\"https://github.com/weixi-feng/structured-diffusion-guidance\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/weixi-feng/structured-diffusion-guidance</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/5aea94c9a97e3432a43d1ca1873ff93db33de659d2406e5c65e0ebe10264c142.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Three challenging phenomena in \u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.11621v1",
    "title": "https://arxiv.org/abs/2301.11621v1",
    "latest": "2023-01-31T05:39:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/109782207725374486",
      "content": "<p>\ud83d\udcdd Event Causality Extraction with Event Argument Correlations \ud83d\udcda</p><p>\"Proposes a method with a dual grid tagging scheme to capture the intra- and inter-event argument correlations for ECE, and design an event type-enhanced model architecture to realize the proposed dual grid tagging scheme.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/cuishiyao96/ECE\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/cuishiyao96/ECE</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2301.11621v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11621v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2211.17091",
    "title": "http://arxiv.org/abs/2211.17091",
    "latest": "2023-01-31T05:35:04.216000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/a389f669-a892-4e7b-969a-9b678ed256f0",
      "content": "\"Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models. (arXiv:2211.17091v2 [cs.CV] UPDATED)\" \u2014  A generative SDE with score adjustment using an auxiliary discriminator with the goal of improving the original generative process of a pre-trained diffusion model by estimating the gap between the pre-trained score estimation and the true data score.<br><br>Paper: <a href=\"http://arxiv.org/abs/2211.17091\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2211.17091</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/edbdf6bbd43c45b4ea4a056121adda15ee52fe00f44ca02522c21f4fe2a8223d.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Comparison of the denoising pro\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2211.11378",
    "title": "http://arxiv.org/abs/2211.11378",
    "latest": "2023-01-31T05:32:38.577000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/d5e13a17-b87e-4a65-819b-fe2edae372f0",
      "content": "\"Learning on tree architectures outperforms a convolutional feedforward network. (arXiv:2211.11378v3 [cs.CV] UPDATED)\" \u2014 A 3-layer tree architecture inspired by experimental-based dendritic tree adaptations is developed and applied to the offline and online learning of the CIFAR-10 database to show that this architecture outperforms the achievable success rates of the 5-layer convolutional LeNet.<br><br>Paper: <a href=\"http://arxiv.org/abs/2211.11378\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2211.11378</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/8ffed1f7c6edf1ef08866b0b3628abfbb66df98ede9ef7ca3039d95baf0763d3.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Comparison of offline and onlin\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2210.05398",
    "title": "http://arxiv.org/abs/2210.05398",
    "latest": "2023-01-31T05:26:18.573000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/103d9789-96fa-494c-8434-f8e33671e165",
      "content": "\"Continual Learning by Modeling Intra-Class Variation. (arXiv:2210.05398v2 [cs.LG] UPDATED)\" \u2014 An examination of memory-based continual learning which identifies that large variation in the representation space is crucial for avoiding catastrophic forgetting. <br><br>Paper: <a href=\"http://arxiv.org/abs/2210.05398\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2210.05398</a><br>Code: <a href=\"https://github.com/yulonghui/moca\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/yulonghui/moca</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/f138d120a2ba79e19900018d17aa1ef14cdd89f485ddacc9566003f2a8b2e68b.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Average intra-class angle devia\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2209.13603",
    "title": "http://arxiv.org/abs/2209.13603",
    "latest": "2023-01-31T05:23:29.338000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/bf694a3c-ebda-4adc-bfe6-4e7197940603",
      "content": "\"Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO) Convolutions. (arXiv:2209.13603v3 [cs.CV] UPDATED)\" \u2014 A hybrid discrete-continuous (DISCO) group convolution for spherical convolutional neural networks (CNN) that is simultaneously equivariant and computationally scalable to high-resolution.<br><br>Paper: <a href=\"http://arxiv.org/abs/2209.13603\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2209.13603</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/ce9e072bf049b58742e892751023c01042cee14900b19300ba5f68e81292b1c8.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Spherical\nCNN categorization</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2109.08275",
    "title": "http://arxiv.org/abs/2109.08275",
    "latest": "2023-01-31T05:15:01.200000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/2325e07a-2625-4c3c-bbf8-5d0eb1637a60",
      "content": "\"Multi-Level Visual Similarity Based Personalized Tourist Attraction Recommendation Using Geo-Tagged Photos. (arXiv:2109.08275v2 [cs.MM] UPDATED)\" \u2014 A geo-tagged photo based tourist attraction recommendation system which utilizes the visual contents of photos and interaction behavior data to obtain the final embeddings of users and tourist attractions, which are then used to predict the visit probabilities.<br><br>Paper: <a href=\"http://arxiv.org/abs/2109.08275\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2109.08275</a><br>Code: <a href=\"https://github.com/revaludo/MEAL\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://github.com/revaludo/MEAL</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/3b90fcd68064bf931c4d68318a7130a5bd8bdb2607616ebddca4904203ce2d2f.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">An illustration of the multi-le\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2106.11396",
    "title": "http://arxiv.org/abs/2106.11396",
    "latest": "2023-01-31T05:12:20.699000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/1081aa94-190c-4cc1-b278-560bdd4844da",
      "content": "\"BiAdam: Fast Adaptive Bilevel Optimization Methods. (arXiv:2106.11396v3 [math.OC] UPDATED)\" \u2014 A novel fast adaptive bilevel framework to solve stochastic bilevel optimization problems that the outer problem is possibly nonconvex and the inner problem is strongly convex.<br><br>Paper: <a href=\"http://arxiv.org/abs/2106.11396\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2106.11396</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/b502efeae0e03c8945ba72c0fae6105db089ba7abe4cd2faa9401ea9a26baa09.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">The basic idea of the convergen\u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2104.02922",
    "title": "http://arxiv.org/abs/2104.02922",
    "latest": "2023-01-31T04:38:09.185000+00:00",
    "last_post": {
      "url": "https://a.farook.org/objects/ae13c5e3-6314-4b32-97f9-866743f73e54",
      "content": "\"Sparse Oblique Decision Trees: A Tool to Understand and Manipulate Neural Net Features. (arXiv:2104.02922v2 [cs.LG] UPDATED)\" \u2014 An effort to understanding which of the internal features computed by the neural net are responsible for a particular class, by mimicking part of the neural net with an oblique decision tree having sparse weight vectors at the decision nodes.<br><br>Paper: <a href=\"http://arxiv.org/abs/2104.02922\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">http://arxiv.org/abs/2104.02922</a><br><br><a class=\"hashtag\" href=\"https://a.farook.org/tag/ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#AI</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#CV</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/newpaper\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#NewPaper</a> <a class=\"hashtag\" href=\"https://a.farook.org/tag/deeplearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#DeepLearning</a>  <a class=\"hashtag\" href=\"https://a.farook.org/tag/machinelearning\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#MachineLearning</a><br><br>&lt;&lt;Find this useful? Please boost so that others can benefit too \ud83d\ude42&gt;&gt;<br><a href=\"https://a.farook.org/media/ffd44ebcdcb0569ed0bf85d0864b4959c212f0e41fa38f3d6155add4affe7d27.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Mimicking part of a neural net \u2026</a>"
    },
    "people": [
      {
        "url": "https://a.farook.org/users/f",
        "display_name": "Fahim Farook"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04900",
    "title": "https://doi.org/10.21105/joss.04900",
    "latest": "2023-01-30T21:54:30+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/109780380587686818",
      "content": "<p>Just published in JOSS: 'PyKronecker: A Python Library for the Efficient Manipulation of Kronecker Products and Related Structures' <a href=\"https://doi.org/10.21105/joss.04900\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04900</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/abs/10.1080/13562517.2013.774354",
    "title": "tandfonline.com/doi/abs/10.108...",
    "latest": "2023-01-30T20:41:40+00:00",
    "last_post": {
      "url": "https://mastodon.social/@iramjohn/109780061522194253",
      "content": "<p>\"Five critiques of the open educational resources movement\" </p><p>* 48 hours access to article: $50<br>* 30 days online access to complete issue: $390<br>* Publishing your critique of OER in a close access journal: priceless</p><p><a href=\"https://www.tandfonline.com/doi/abs/10.1080/13562517.2013.774354\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/abs/10.108</span><span class=\"invisible\">0/13562517.2013.774354</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@ojala",
        "display_name": "Luis Apiolaza"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2003.06278",
    "title": "Default Bayes Factors for Testing the (In)equality of Several Population Variances",
    "latest": "2023-01-30T20:41:03+00:00",
    "last_post": {
      "url": "https://mastodon.social/@EJWagenmakers/109778988582957471",
      "content": "<p>Card-carrying Bayesians at last: <br>Dablander, F., van den Bergh, D., Ly, A., &amp; Wagenmakers, E.-J. (in press). Default Bayes factors for testing the (in)equality of several population variances. Bayesian Analysis. Preprint: <a href=\"https://arxiv.org/abs/2003.06278\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2003.06278</span><span class=\"invisible\"></span></a><br>[the less I contribute to a paper, the more proud I seem to be of its contents...this may be a bad sign...]</p>"
    },
    "people": [
      {
        "url": "https://astrodon.social/@harcel",
        "display_name": "Marcel Haas"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.09260",
    "title": "https://arxiv.org/abs/2211.09260",
    "latest": "2023-01-30T20:00:05+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ceperez/109779930648547001",
      "content": "<p>An innteresting new large LLM tuned to spit out a search engine query in response to a question.</p><p>RT @AkariAsai@twitter.com</p><p>@_lewtun@twitter.com @AiEleuther@twitter.com We have instruction-tuned LMs that learn to retrieve *documents* following users' instructions (e.g., retrieve corresponding code/an answer to a technical question) </p><p><a href=\"https://huggingface.co/facebook/tart-full-flan-t5-xl\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">huggingface.co/facebook/tart-f</span><span class=\"invisible\">ull-flan-t5-xl</span></a><br><a href=\"https://huggingface.co/facebook/tart-full-t0-3b\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">huggingface.co/facebook/tart-f</span><span class=\"invisible\">ull-t0-3b</span></a></p><p>paper: <a href=\"https://arxiv.org/abs/2211.09260\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.09260</span><span class=\"invisible\"></span></a> <br>GitHub: <a href=\"https://github.com/facebookresearch/tart\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/ta</span><span class=\"invisible\">rt</span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/AkariAsai/status/1620115280268783616\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/AkariAsai/status/1</span><span class=\"invisible\">620115280268783616</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      }
    ]
  },
  {
    "link": "http://osf.io/sedh8/",
    "title": "http://osf.io/sedh8/",
    "latest": "2023-01-30T19:58:12+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109779923300140399",
      "content": "<p>'We' the people--Collective lyric self in twenty-first-century poetry <a href=\"http://osf.io/sedh8/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/sedh8/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/bc7er/",
    "title": "http://osf.io/bc7er/",
    "latest": "2023-01-30T19:58:12+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/109779923266782118",
      "content": "<p>Effectiveness of using digital and non-digital games in primary mathematics teaching: A meta-analysis study <a href=\"http://osf.io/bc7er/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/bc7er/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  }
]