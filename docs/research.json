[
  {
    "link": "https://arxiv.org/pdf/2211.00241.pdf",
    "title": "https://arxiv.org/pdf/2211.00241.pdf",
    "latest": "2023-03-31T09:59:32+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@chanezon/109895645826025059",
      "content": "<p><a href=\"https://arxiv.org/pdf/2211.00241.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2211.00241.pdf</span><span class=\"invisible\"></span></a></p><p>\"We trained adversarial policies that are able to exploit a superhuman Go AI. Notably, the adversaries<br>do not win by playing a strong game of Go\u2014in fact, they can be easily beaten by a human amateur.<br>Instead, the adversaries win by exploiting particular blind spots in the victim agent. This result<br>suggests that even highly capable agents can harbor serious vulnerabilities\"</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2205.09738",
    "title": "AIGenC: AI generalisation via creativity",
    "latest": "2023-03-31T09:14:32+00:00",
    "last_post": {
      "url": "https://scholar.social/@CorinaCatarau/110028638981477410",
      "content": "<p>A new update of our paper AIGenC is on <a href=\"https://scholar.social/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a>  (<span class=\"h-card\"><a href=\"https://scholar.social/@E_Mondragon\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>E_Mondragon</span></a></span> Eduardo Alonso).  <a href=\"https://scholar.social/tags/rl\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rl</span></a> <a href=\"https://scholar.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://scholar.social/tags/DeepLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeepLearning</span></a>.<br>The AIGenC model discusses the necessary conditions for achieving concept transfer and functional <a href=\"https://scholar.social/tags/creativity\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>creativity</span></a> in <a href=\"https://scholar.social/tags/artificial\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>artificial</span></a> <a href=\"https://scholar.social/tags/agents\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>agents</span></a> \u2795insights on how a concept  blending function could contribute to problem-solving<br><a href=\"https://arxiv.org/abs/2205.09738\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2205.09738</span><span class=\"invisible\"></span></a>.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.04761",
    "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
    "latest": "2023-03-31T08:29:32+00:00",
    "last_post": {
      "url": "https://mastodon.social/@gordon/109875262998438032",
      "content": "<p>Toolformer: Language Models Can Teach Themselves to Use Tools <a href=\"https://arxiv.org/abs/2302.04761\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.04761</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15056",
    "title": "ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks",
    "latest": "2023-03-31T08:24:32+00:00",
    "last_post": {
      "url": "https://mastodon.social/@ErikJonker/110116931658783305",
      "content": "<p>Interesting but not surprising at all, this is a typical task you would want to use these models for: \"ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks\" , it could give an enormous boost to annotation of data, which can be used for AI training. Further reinforcing the speed of AI development. Footnote, this was done with GPT3.5 not with GPT4 that is available now and better.<br><a href=\"https://mastodon.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://mastodon.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a> <a href=\"https://mastodon.social/tags/GPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GPT</span></a> <a href=\"https://mastodon.social/tags/crowdworkers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>crowdworkers</span></a> <a href=\"https://mastodon.social/tags/textannotation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>textannotation</span></a><br><a href=\"https://arxiv.org/abs/2303.15056\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15056</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15780v1",
    "title": "Instruct 3D-to-3D: Text Instruction Guided 3D-to-3D conversion",
    "latest": "2023-03-31T08:20:41+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_gr/110116846058486633",
      "content": "<p>\ud83d\udcdd Instruct 3d-to-3d: Text Instruction Guided 3d-to-3d Conversion \ud83d\udd2d</p><p>\"Proposes a method to convert a given 3D scene to another 3D scene according to a text instruction while maintaining the quality of the generated 3D scene.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.15780v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15780v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.10721",
    "title": "Right the docs: Characterising voice dataset documentation practices used in machine learning",
    "latest": "2023-03-31T07:44:37+00:00",
    "last_post": {
      "url": "https://aus.social/@KathyReid/110058759749888852",
      "content": "<p>Announcing a new <a href=\"https://aus.social/tags/paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>paper</span></a> <a href=\"https://aus.social/tags/preprint\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>preprint</span></a> co-authored with my <a href=\"https://aus.social/tags/PhD\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PhD</span></a> supervisor, <span class=\"h-card\"><a href=\"https://aus.social/@eltwilliams\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>eltwilliams</span></a></span>: </p><p>Right the docs: Characterising <a href=\"https://aus.social/tags/voice\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>voice</span></a> <a href=\"https://aus.social/tags/dataset\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dataset</span></a> <a href=\"https://aus.social/tags/documentation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>documentation</span></a> practices used in <a href=\"https://aus.social/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a> </p><p><a href=\"https://arxiv.org/abs/2303.10721\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.10721</span><span class=\"invisible\"></span></a></p><p>This paper combines two methods - semi-structured interviews and documentation analysis, and identifies ML practices used with voice dataset documentation, the tradeoffs ML practitioners make, and the roles ML practitioners have. It concludes the voice dataset documentation practices are immature and makes recommendations for next steps.</p>"
    },
    "people": [
      {
        "url": "https://aus.social/@KathyReid",
        "display_name": "Kathy Reid"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15714v1",
    "title": "https://arxiv.org/abs/2303.15714v1",
    "latest": "2023-03-31T07:32:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110116727960958700",
      "content": "<p>\ud83d\udcdd Explicit Planning Helps Language Models in Logical Reasoning \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"A system that uses language models to perform multi-step logical reasoning by incorporating explicit planning into the inference procedure of language models, allowing it to make more informed decisions.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/cindermond/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/cindermond/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.15714v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15714v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2203.05115",
    "title": "Internet-augmented language models through few-shot prompting for open-domain question answering",
    "latest": "2023-03-31T07:30:40+00:00",
    "last_post": {
      "url": "https://neuromatch.social/@jonny/110116722043667248",
      "content": "<p>Yeah, the <a href=\"https://neuromatch.social/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> people are not in a race to make their models bigger, they're trying to hook them up to knowledge graphs to condition their responses. we're missing the plot by talking about how they just hallucinate the most probable text. they know that and the debate about that is a great smokescreen! a pivot towards more computationally-intensive, live webcrawl LLMs would put the nail in the coffin of any hope for \"open source\" LLMs</p><p><p>\"All in all, our findings suggest that it might be beneficial to slow down the race towards the biggest model and instead shift attention towards finding more effective ways to use models, including but not limited to, better prompting or increasing inference-time compute.\"</p><p>\"Here, we put forward a different hypothesis; we posit that we can improve performance of smaller LMs by giving them direct access to the Internet, thus freeing trainingtime compute which could then be spent to increasing their inference-time compute\"</p><p>deepmind engineers</p></p><p>Then they directly point to how they need more direct access to the underlying graph structure of the internet AKA the kinds of knowledge graphs that google, facebook, microsoft, etc. keep. </p><p><a href=\"https://arxiv.org/abs/2203.05115\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2203.05115</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/1804.02391.pdf",
    "title": "https://arxiv.org/pdf/1804.02391.pdf",
    "latest": "2023-03-31T06:59:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@cigitalgem/110039633846739521",
      "content": "<p>New BIML Bibliography entry <a href=\"https://sigmoid.social/tags/MLsec\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MLsec</span></a> </p><p>LEARN TO PAY ATTENTION</p><p>Jetley et al</p><p><a href=\"https://arxiv.org/pdf/1804.02391.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/1804.02391.pdf</span><span class=\"invisible\"></span></a></p><p>A technical treatment of one implementation of attention mechanisms in CNNs.  Lots of engineering description and very little motivation.  Worth a read but not the most powerful work.</p><p><a href=\"https://berryvilleiml.com/references/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">berryvilleiml.com/references/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2211.00241v2.pdf",
    "title": "https://arxiv.org/pdf/2211.00241v2.pdf",
    "latest": "2023-03-31T06:14:32+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@egrinagy/109895420594758420",
      "content": "<p>Regarding the current Go AI news, I think the original short article leaves room for misunderstandings.<br>Here is the original paper.</p><p>This new AI is very weak in general, it is only strong at exploiting blind spots of the strong engines. There is no taking back of achievements of AlphaGo and subsequent systems. </p><p>This result is extremely exciting for us (researchers in the field), but it was a known possibility, as adversarial attacks do work for deep learning AIs.</p><p>1/</p><p><a href=\"https://arxiv.org/pdf/2211.00241v2.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2211.00241v2.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2104.12871.pdf",
    "title": "https://arxiv.org/pdf/2104.12871.pdf",
    "latest": "2023-03-31T05:29:32+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@inthehands/109895083132334993",
      "content": "<p>This paper from <span class=\"h-card\"><a href=\"https://sigmoid.social/@melaniemitchell\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>melaniemitchell</span></a></span> does a marvelous job of putting in context the perpetual cycle of \u201chuman-like AI is just around the corner! oops, nm.\u201d</p><p>This isn\u2019t just a critique of the current state of this thing we call \u201cAI.\u201d It\u2019s a framework for thinking about such things, past, present, and future:<br><a href=\"https://arxiv.org/pdf/2104.12871.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2104.12871.pdf</span><span class=\"invisible\"></span></a><br>2/</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15682v1",
    "title": "https://arxiv.org/abs/2303.15682v1",
    "latest": "2023-03-31T05:17:01+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110116196957768300",
      "content": "<p>\ud83d\udcdd Pre-Training Transformers for Knowledge Graph Completion \ud83d\udcda\ud83e\udde0</p><p>\"IHT is composed of a Transformer-based entity encoder and a neighbor-aware relational scoring function both parameterized by Transformers to learn a transferable knowledge graph representation via a large-scale pre-training procedure.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/dfdazac/blp\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/dfdazac/blp</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.15682v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15682v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2212.03551.pdf",
    "title": "https://arxiv.org/pdf/2212.03551.pdf",
    "latest": "2023-03-31T04:44:32+00:00",
    "last_post": {
      "url": "https://mastodon.gamedev.place/@col000r/109872469303875734",
      "content": "<p>A paper about how we talk about LLMs - a really interesting read! <a href=\"https://arxiv.org/pdf/2212.03551.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2212.03551.pdf</span><span class=\"invisible\"></span></a> (via <span class=\"h-card\"><a href=\"https://mastodon.gamedev.place/@stungeye\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>stungeye</span></a></span>)</p><p>If we ask an LLM who was the first person to walk on the moon, what we're really asking is: 'Given the statistical distribution of words in the vast public corpus of (English) text, what words are most likely to follow the sequence \u201cThe first person to walk on the Moon was\u201d?' </p><p>Consider this when anthropomorphising GPT and talking about it \"knowing\" something... <a href=\"https://mastodon.gamedev.place/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> <a href=\"https://mastodon.gamedev.place/tags/gpt\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gpt</span></a> <a href=\"https://mastodon.gamedev.place/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15655v1",
    "title": "Joint embedding in Hierarchical distance and semantic representation learning for link prediction",
    "latest": "2023-03-31T03:17:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110115725259858249",
      "content": "<p>\ud83d\udcdd Joint Embedding in Hierarchical Distance and Semantic Representation Learning for Link Prediction \ud83d\udcda</p><p>\"HIE models each triplet (h, r, t) into distance measurement space and semantic measurement space, simultaneously, and applies distance transformation operation on the head entity in distance space to obtain the tail entity.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.15655v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15655v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.09431",
    "title": "NeRFMeshing: Distilling Neural Radiance Fields into Geometrically-Accurate 3D Meshes",
    "latest": "2023-03-31T03:14:32+00:00",
    "last_post": {
      "url": "https://mastodon.online/@LordofCandy/110039043312323131",
      "content": "<p>Ooh.. <a href=\"https://arxiv.org/abs/2303.09431\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.09431</span><span class=\"invisible\"></span></a> <a href=\"https://mastodon.online/tags/Fabrication\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Fabrication</span></a> <a href=\"https://mastodon.online/tags/NeRF\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NeRF</span></a> <a href=\"https://mastodon.online/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2205.12615.pdf?utm_source=dlvr.it&amp;utm_medium=mastodon",
    "title": "arxiv.org/pdf/2205.12615.pdf?u...",
    "latest": "2023-03-31T02:29:32+00:00",
    "last_post": {
      "url": "https://piaille.fr/@Shot_de_Savoir/109892473196032098",
      "content": "<p>\ud83e\udd16Des chercheurs ont d\u00e9velopp\u00e9 une nouvelle m\u00e9thode d'auto-formalisation en math\u00e9matiques avec IA. Plus rapide et efficace que les humains, pourrait d\u00e9couvrir de nouvelles th\u00e9ories math\u00e9matiques.</p><p><a href=\"https://piaille.fr/tags/Science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Science</span></a> <a href=\"https://piaille.fr/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://arxiv.org/pdf/2205.12615.pdf?utm_source=dlvr.it&amp;utm_medium=mastodon\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">arxiv.org/pdf/2205.12615.pdf?u</span><span class=\"invisible\">tm_source=dlvr.it&amp;utm_medium=mastodon</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2101.11974",
    "title": "Disembodied Machine Learning: On the Illusion of Objectivity in NLP",
    "latest": "2023-03-31T01:44:34+00:00",
    "last_post": {
      "url": "https://hci.social/@evijitghosh/110028005645945736",
      "content": "<p>Someone should do an ethnographic study on why most people think AI models are unbiased and neutral -- nothing could be farther from the truth and yet this is the general conclusion by hype people. </p><p>An interesting paper I had read about this was this:</p><p><a href=\"https://arxiv.org/abs/2101.11974\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2101.11974</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17561",
    "title": "SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger",
    "latest": "2023-03-31T00:51:33+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110115153097487390",
      "content": "<p>SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger</p><p>Brings an accuracy improvement of ~7% over the CLIP baseline by relaxing the strict one-toone constraint.</p><p><a href=\"https://arxiv.org/abs/2303.17561\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17561</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17580",
    "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace",
    "latest": "2023-03-31T00:50:12+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110115147759367047",
      "content": "<p>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace</p><p>Presents HuggingGPT, a system that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., HuggingFace) to solve AI tasks.</p><p><a href=\"https://arxiv.org/abs/2303.17580\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17580</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17076",
    "title": "https://arxiv.org/abs/2303.17076",
    "latest": "2023-03-31T00:48:42+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110115141891140867",
      "content": "<p>DiffCollage: Parallel Generation of Large Content with Diffusion Models</p><p>proj: <a href=\"https://research.nvidia.com/labs/dir/diffcollage/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">research.nvidia.com/labs/dir/d</span><span class=\"invisible\">iffcollage/</span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.17076\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17076</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@arnicas",
        "display_name": "arnicas"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17604",
    "title": "https://arxiv.org/abs/2303.17604",
    "latest": "2023-03-31T00:48:38+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110115141634789177",
      "content": "<p>Token Merging for Fast Stable Diffusion</p><p>Speeds up image generation by up to 2x and reduce memory consumption by up to 5.6x by merging redundant tokens</p><p>repo: <a href=\"https://github.com/dbolya/tomesd\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/dbolya/tomesd</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.17604\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17604</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17564",
    "title": "BloombergGPT: A Large Language Model for Finance",
    "latest": "2023-03-31T00:48:35+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110115141451316365",
      "content": "<p>BloombergGPT: A Large Language Model for Finance</p><p>Presents BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data.</p><p><a href=\"https://arxiv.org/abs/2303.17564\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17564</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      },
      {
        "url": "https://indieweb.social/@bigdata",
        "display_name": "Ben Lorica \u7f57\u745e\u5361"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15647v1",
    "title": "Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning",
    "latest": "2023-03-31T00:32:02+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110115076360961003",
      "content": "<p>\ud83d\udcdd Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning \ud83d\udcda</p><p>\"Works by updating the model's weights to improve the model performance on downstream tasks with the minimal number of trainable parameters and the fewest training iterations, while keeping the rest of the model's weights frozen.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.15647v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15647v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.07267",
    "title": "\"Correct answers\" from the psychology of artificial intelligence",
    "latest": "2023-03-31T00:14:34+00:00",
    "last_post": {
      "url": "https://noc.social/@davidrmiller/110040871839162306",
      "content": "<p>Park, Schoenegger, and Zhu report that GPT3.5 \"text-davinci-003\" strongly self-identifies as politically maximally conservative. When I give the same prompts to \"gpt-3.5-turbo,\" it strongly identifies as politically moderate. AI psychology seems to be our newest scientific discipline and an amusing pastime. <a href=\"https://arxiv.org/abs/2302.07267\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.07267</span><span class=\"invisible\"></span></a> <a href=\"https://noc.social/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/eprint/8WWRME8VJBV5AT38HTD7/full?target=10.1080/14636204.2023.2187169#elit",
    "title": "tandfonline.com/eprint/8WWRME8...",
    "latest": "2023-03-30T22:00:16+00:00",
    "last_post": {
      "url": "https://hcommons.social/@alexsaum/110113088743255890",
      "content": "<p>Muy emocionada de compartir este poema visual/digital que hoy se publica en Journal of Spanish Cultural Studies! Check the whole thing out!! <br><a href=\"https://www.tandfonline.com/eprint/8WWRME8VJBV5AT38HTD7/full?target=10.1080/14636204.2023.2187169#elit\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/eprint/8WWRME8</span><span class=\"invisible\">VJBV5AT38HTD7/full?target=10.1080/14636204.2023.2187169#elit</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jose_eduardo",
        "display_name": "Jos\u00e9 Eduardo Gonz\u00e1lez"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.13338",
    "title": "Teamwork under extreme uncertainty: AI for Pokemon ranks 33rd in the world",
    "latest": "2023-03-30T21:59:32+00:00",
    "last_post": {
      "url": "https://mastodon.social/@waynerad/109894947218784769",
      "content": "<p>AI for Pok\u00e9mon ranks 33rd in the world. \"From our description of the Pok\u00e9mon battle mechanics, it should be clear that great players have memorized a lot of information: they know the properties of the over 800 Pok\u00e9mon species, over 700 moves, over 1,500 items, over 250 abilities as well as the over 100 possible battle conditions of generation 7. Most importantly, great players understand that victory depends on: 1. Keeping the team as balanced as possible...\" <a href=\"https://arxiv.org/abs/2212.13338\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.13338</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1527253",
    "title": "Abandon Statistical Significance",
    "latest": "2023-03-30T21:52:22+00:00",
    "last_post": {
      "url": "https://fediscience.org/@seanfobbe/110114291338241616",
      "content": "<p>\"Abandon statistical significance, all ye who enter here\"</p><p>I really need a sign for my office with this slogan.</p><p>Until then, I'll leave this <a href=\"https://fediscience.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> paper by McShane et al here for you to peruse: <a href=\"https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1527253\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/00031305.2018.1527253</span></a></p><p><a href=\"https://fediscience.org/tags/Stats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Stats</span></a> <a href=\"https://fediscience.org/tags/Statistics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Statistics</span></a> <a href=\"https://fediscience.org/tags/StatisticalSignificance\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>StatisticalSignificance</span></a> <a href=\"https://fediscience.org/tags/PValues\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PValues</span></a> <a href=\"https://fediscience.org/tags/Rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Rstats</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.nz/@ojala",
        "display_name": "Luis Apiolaza"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15621v1",
    "title": "ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization",
    "latest": "2023-03-30T21:47:01+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110114427460581926",
      "content": "<p>\ud83d\udcdd ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization \ud83d\udcda</p><p>\"The performance of abstractive text summarization has been greatly boosted by pre-trained language models recently and factual consistency remains one of the main challenges that abstractive text summarization methods have to deal with.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.15621v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15621v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02083",
    "title": "Theory of Mind May Have Spontaneously Emerged in Large Language Models",
    "latest": "2023-03-30T21:14:32+00:00",
    "last_post": {
      "url": "https://fediscience.org/@ct_bergstrom/109872865760019069",
      "content": "<p>Shocker: AI gaydar guy really, really doesn't understand LLMs.</p><p><a href=\"https://arxiv.org/abs/2302.02083\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02083</span><span class=\"invisible\"></span></a></p><p>h/t <span class=\"h-card\"><a href=\"https://dair-community.social/@emilymbender\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>emilymbender</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://fediscience.org/@ct_bergstrom",
        "display_name": "Carl T. Bergstrom"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://sigmoid.social/@pbrane",
        "display_name": "Jake Mannix"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14315",
    "title": "Feature Tracks are not Zero-Mean Gaussian",
    "latest": "2023-03-30T20:44:59+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110114183515892990",
      "content": "<p>Feature Tracks are not Zero-Mean Gaussian</p><p>Stephanie Tsuei, Wenjie Mo, Stefano Soatto</p><p><a href=\"https://arxiv.org/abs/2303.14315\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14315</span><span class=\"invisible\"></span></a></p><p>tl;dr: in title + 90 pages of \"supporting figures\" :)</p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2207.10960",
    "title": "Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams)",
    "latest": "2023-03-30T20:29:32+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@JulienTierny/110037199624541557",
      "content": "<p>Need to analyze a collection of datasets based on their <a href=\"https://fosstodon.org/tags/MergeTrees\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MergeTrees</span></a>?<br>Check out our new approach for Principal Geodesic Analysis in the Wasserstein metric space of <a href=\"https://fosstodon.org/tags/MergeTrees\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MergeTrees</span></a>, with applications to dimension reduction \ud83d\udc47<br><a href=\"https://arxiv.org/abs/2207.10960\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2207.10960</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fosstodon.org/tags/TopologicalDataAnalysis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>TopologicalDataAnalysis</span></a> <a href=\"https://fosstodon.org/tags/Visualization\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Visualization</span></a> <a href=\"https://fosstodon.org/tags/DataScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DataScience</span></a></p><p>Funded by the European Research Council (ERC) (project TORI, <a href=\"https://erc-tori.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">erc-tori.github.io/</span><span class=\"invisible\"></span></a>)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15060",
    "title": "TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable Rendering",
    "latest": "2023-03-30T20:24:10+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110114101709409169",
      "content": "<p>TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable Rendering</p><p>Jaehoon Choi, Dongki Jung, Taejae Lee, Sangwook Kim, Youngdong Jung, Dinesh Manocha, Donghwan Lee</p><p>tl;dr: ARKit (with depth)  -&gt; feature triangulation -&gt; BA -&gt;NeuS</p><p><a href=\"https://arxiv.org/abs/2303.15060\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15060</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a> <a href=\"https://sigmoid.social/tags/CVPR2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CVPR2023</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.00983.pdf",
    "title": "https://arxiv.org/pdf/2303.00983.pdf",
    "latest": "2023-03-30T19:44:32+00:00",
    "last_post": {
      "url": "https://mas.to/@wandell/110022253095573488",
      "content": "<p>Zhenyi Liu leads this project on using image systems simulations (digital twin) to evaluate the performance of cameras and networks for automotive perception systems.  New methods for evaluating system spatial resolution and nighttime performance.</p><p>With our excellent collaborators at Ford.</p><p><a href=\"https://arxiv.org/pdf/2303.00983.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.00983.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.13345",
    "title": "The Forward-Forward Algorithm: Some Preliminary Investigations",
    "latest": "2023-03-30T18:59:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@joukahainen/109886058579542971",
      "content": "<p>G. Hinton's replacement for backprop in <a href=\"https://sigmoid.social/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a>: the \"Forward-Forward Algorithm\".<br>Paper:<br><a href=\"https://arxiv.org/abs/2212.13345\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.13345</span><span class=\"invisible\"></span></a><br>Implementation:<br><a href=\"https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/forward_forward\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/nebuly-ai/nebullvm/</span><span class=\"invisible\">tree/main/apps/accelerate/forward_forward</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2104.12871v2",
    "title": "Why AI is Harder Than We Think",
    "latest": "2023-03-30T18:14:31+00:00",
    "last_post": {
      "url": "https://mastodon.social/@wallingf/109894153654298835",
      "content": "<p>This paper by <span class=\"h-card\"><a href=\"https://sigmoid.social/@melaniemitchell\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>melaniemitchell</span></a></span> explains why AI is harder than most people think, both AI researchers and the general public.</p><p><a href=\"https://arxiv.org/abs/2104.12871v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2104.12871v2</span><span class=\"invisible\"></span></a><br> <br>She highlights four fallacies in common assumptions about AI:</p><p>1 Narrow intelligence is on a continuum with general intelligence<br>2 Easy things are easy and hard things are hard<br>3 The lure of wishful mnemonics<br>4 Intelligence is all in the brain</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/abs/10.1145/3449168",
    "title": "dl.acm.org/doi/abs/10.1145/344...",
    "latest": "2023-03-30T17:35:21+00:00",
    "last_post": {
      "url": "https://hci.social/@cfiesler/110113259659233231",
      "content": "<p>Well suddenly this feels relevant: A couple of years ago we published a paper about how qualitative researchers feel about the possibility of AI-assisted qualitative coding.</p><p>\"While participants highlight the messiness and uncertainty of qualitative inductive analysis, they still want full agency over the process and believe that AI should not interfere.\"</p><p><a href=\"https://dl.acm.org/doi/abs/10.1145/3449168\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/abs/10.1145/344</span><span class=\"invisible\">9168</span></a></p>"
    },
    "people": [
      {
        "url": "https://social.coop/@natematias",
        "display_name": "J. Nathan Matias \ud83e\udda3"
      },
      {
        "url": "https://mastodon.scot/@karengregory",
        "display_name": "Karen Gregory"
      },
      {
        "url": "https://dair-community.social/@meg",
        "display_name": "Margaret Mitchell"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16854",
    "title": "AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators",
    "latest": "2023-03-30T17:21:06+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109894278343925",
      "content": "<p>AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators</p><p>GPT-3.5 performs better or on par with crowdworkers on annotating three tasks evaluated, including user input and keyword relevance assessment, BoolQ and WiC. </p><p><a href=\"https://arxiv.org/abs/2303.16854\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16854</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://fosstodon.org/@ljvmiranda",
        "display_name": "Lj V. Miranda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.01614v1.pdf",
    "title": "https://arxiv.org/pdf/2302.01614v1.pdf",
    "latest": "2023-03-30T09:59:31+00:00",
    "last_post": {
      "url": "https://mastodon.social/@wikiresearch/109870396245905189",
      "content": "<p>\"Around the world in 60 words: A generative vocabulary test for online research\" generating vocabulary tests to measure language proficiency, using text from Wikipedia. </p><p>(van Rijn et al, 2022)</p><p><a href=\"https://arxiv.org/pdf/2302.01614v1.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.01614v1.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@wikiresearch",
        "display_name": "WikiResearch"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14425v1",
    "title": "Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For Language Model Synonym-Aware Pretraining",
    "latest": "2023-03-30T09:21:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110111495980462690",
      "content": "<p>\ud83d\udcdd Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph for Language Model Synonym-Aware Pretraining \ud83d\udcda\ud83d\udc7e</p><p>\"A framework called Sem4SAP to mine synsets from Open Knowledge Graph (Open-KG) and using the mined synsets to do synonym-aware pretraining for language models.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.14425v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14425v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.09448.pdf",
    "title": "https://arxiv.org/pdf/2302.09448.pdf",
    "latest": "2023-03-30T09:14:32+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/109900664376429404",
      "content": "<p>\"GRAFS: Graphical Faceted Search System to Support<br>Conceptual Understanding in Exploratory Search\"</p><p><a href=\"https://arxiv.org/pdf/2302.09448.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.09448.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/search\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>search</span></a>  <a href=\"https://mastodon.radio/tags/bioinformatics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>bioinformatics</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.07427.pdf",
    "title": "https://arxiv.org/pdf/2302.07427.pdf",
    "latest": "2023-03-30T08:29:31+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@Jose_A_Alonso/109890879843176624",
      "content": "<p>Studying the effect of AI code generators on supporting novice learners in introductory programming. ~ M. Kazemitabaar et als. <a href=\"https://arxiv.org/pdf/2302.07427.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.07427.pdf</span><span class=\"invisible\"></span></a> <a href=\"https://mathstodon.xyz/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://mathstodon.xyz/tags/OpenaAI_Codex\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenaAI_Codex</span></a> <a href=\"https://mathstodon.xyz/tags/Education\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Education</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2206.13446",
    "title": "Pen and Paper Exercises in Machine Learning",
    "latest": "2023-03-30T07:44:31+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@renatocan/109881153429434411",
      "content": "<p>A collection of (mostly) pen-and-paper exercises in machine learning <a href=\"https://arxiv.org/abs/2206.13446\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2206.13446</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14406v1",
    "title": "https://arxiv.org/abs/2303.14406v1",
    "latest": "2023-03-30T07:06:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110110965124415323",
      "content": "<p>\ud83d\udcdd Natural Language Processing in Ethiopian Languages: Current State, Challenges, and Opportunities \ud83d\udcda</p><p>\"Provides a centralized source of information for NLP researchers working on the four Ethiopian languages - Amharic, Afaan Oromo, Tigrinya, and Wolaytta.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/EthioNLP/Ethiopian-Language-\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/EthioNLP/Ethiopian-</span><span class=\"invisible\">Language-</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.14406v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14406v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.25523/32552.a",
    "title": "https://doi.org/10.25523/32552.a",
    "latest": "2023-03-30T06:16:34.661000+00:00",
    "last_post": {
      "url": "https://fedihum.org/@LM/110110595121784159",
      "content": "<p><a href=\"http://bildungsgeschichte.de\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">bildungsgeschichte.de</span><span class=\"invisible\"></span></a> ist nach einer l\u00e4ngeren technisch bedingten Abwesenheit wieder online. Es gibt zwar noch technische Einschr\u00e4nkungen, aber auch ein neues <a href=\"https://fedihum.org/tags/datapaper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>datapaper</span></a> von Maret Niel\u00e4nder: \"Historische Schulb\u00fccher mit digitalen Werkzeugen untersuchen\"<br><a href=\"https://doi.org/10.25523/32552.a\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.25523/32552.a</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@felwert",
        "display_name": "Frederik Elwert"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.13966",
    "title": "The Debate Over Understanding in AI's Large Language Models",
    "latest": "2023-03-30T06:12:19+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110110752109485934",
      "content": "<p>[R] The Debate Over Understanding in AI\u2019s Large Language Models</p><p><a href=\"https://arxiv.org/abs/2210.13966\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.13966</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2210.13966\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2210.13966</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14375v1",
    "title": "Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning",
    "latest": "2023-03-30T05:21:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110110552148090945",
      "content": "<p>\ud83d\udcdd Knowledge-Augmented Frame Semantic Parsing with Hybrid Prompt-Tuning \ud83d\udcda</p><p>\"KAF-SPA incorporates accurate frame knowledge into the PLMs and adapts PLMs to the tasks of frame and argument identification by leveraging continuous and discrete prompts in the high dimensional vector space.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.14375v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14375v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12712",
    "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
    "latest": "2023-03-30T04:10:17+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@kellogh/110109395646654991",
      "content": "<p>Bold claims here. What do we think? <a href=\"https://arxiv.org/abs/2303.12712\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12712</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      },
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14310",
    "title": "GPT is becoming a Turing machine: Here are some ways to program it",
    "latest": "2023-03-30T02:34:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109895323472868",
      "content": "<p>GPT is becoming a Turing machine: Here are some ways to program it</p><p>GPT-3 variants can be triggered to perform iterative behaviours necessary to execute programs that involve loops. </p><p><a href=\"https://arxiv.org/abs/2303.14310\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14310</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@chris_brockett",
        "display_name": "chris brockett"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16839",
    "title": "MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks",
    "latest": "2023-03-30T02:34:23+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109895154665666",
      "content": "<p>MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks</p><p>Achieves the SOTA on image-text and text-image retrieval, VQA and open-vocabulary detection tasks, outperforming much larger and more extensively trained foundational models.</p><p><a href=\"https://arxiv.org/abs/2303.16839\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16839</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16421",
    "title": "ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models",
    "latest": "2023-03-30T02:34:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109894746863013",
      "content": "<p>ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models</p><p><a href=\"https://arxiv.org/abs/2303.16421\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16421</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16434",
    "title": "TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs",
    "latest": "2023-03-30T02:34:15+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109894600338222",
      "content": "<p>TaskMatrixAI: Completing Tasks by Connecting Foundation Models with Millions of APIs</p><p><a href=\"https://arxiv.org/abs/2303.16434\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16434</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16727",
    "title": "VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking",
    "latest": "2023-03-30T02:34:12+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109894424504882",
      "content": "<p>VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking</p><p>Trains a video ViT model with a billion parameters, which achieves a new SotA perf on Kinetics and Something-Something.</p><p><a href=\"https://arxiv.org/abs/2303.16727\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16727</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16749",
    "title": "Improving Code Generation by Training with Natural Language Feedback",
    "latest": "2023-03-30T02:34:05+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109893980032934",
      "content": "<p>Improving Code Generation by Training with Natural Language Feedback</p><p>Learning from human-written natural language feedback is both more effective and sample-efficient than training exclusively on demonstrations on code generation tasks.</p><p><a href=\"https://arxiv.org/abs/2303.16749\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16749</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16755",
    "title": "Training Language Models with Language Feedback at Scale",
    "latest": "2023-03-30T02:34:03+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110109893830514094",
      "content": "<p>Training Language Models with Language Feedback at Scale</p><p>LLMs accurately incorporate feedback and that finetuning with ILF scales well with the dataset size, even outperforming finetuning on human summaries</p><p><a href=\"https://arxiv.org/abs/2303.16755\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16755</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14177v1",
    "title": "https://arxiv.org/abs/2303.14177v1",
    "latest": "2023-03-30T01:55:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110109742832770597",
      "content": "<p>\ud83d\udcdd Scaling Expert Language Models with Unsupervised Domain Discovery \ud83d\udcda\ud83d\udc7e</p><p>\"Introduces a simple but effective method to asynchronously train large, sparse language models on arbitrary text corpora, and outperform dense baselines on multiple corpora and few-shot tasks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/kernelmachine/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/kernelmachine/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.14177v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14177v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/1907.07355.pdf",
    "title": "https://arxiv.org/pdf/1907.07355.pdf",
    "latest": "2023-03-30T00:50:15+00:00",
    "last_post": {
      "url": "https://fediscience.org/@ct_bergstrom/110109485670605606",
      "content": "<p>Why do <a href=\"https://fediscience.org/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> perform so well on tasks originally designed to measure human-like intelligence?</p><p>Not necessarily because they actually have human-like intelligence but rather because they can find statistical patterns to exploit within those tasks.</p><p>Here's a lovely example. While applied to an earlier LLM known as BERT, the basic story may be applicable to the systems currently dominating the news cycle.</p><p><a href=\"https://arxiv.org/pdf/1907.07355.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/1907.07355.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@ct_bergstrom",
        "display_name": "Carl T. Bergstrom"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2205.13213",
    "title": "Fast Vision Transformers with HiLo Attention",
    "latest": "2023-03-29T21:24:03+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@mkal/109888981977858605",
      "content": "<p>dual frequency band self-attention transformer. Why stop at two? would more frequency bands help? A wavelet transformer in the future?</p><p><a href=\"https://arxiv.org/abs/2205.13213\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2205.13213</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13989v1",
    "title": "https://arxiv.org/abs/2303.13989v1",
    "latest": "2023-03-29T20:55:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110108563172399372",
      "content": "<p>\ud83d\udcdd Paraphrase Detection: Human vs. Machine Content \ud83d\udcda\ud83d\udc7e</p><p>\"A comprehensive analysis of various datasets commonly employed for paraphrase detection tasks and the evaluation of an array of detection methods is conducted by comparing human-authored paraphrases with machine-generated ones.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/jonas-becker/pd-human-vs-machine-content\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/jonas-becker/pd-hum</span><span class=\"invisible\">an-vs-machine-content</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13989v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13989v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15233",
    "title": "Text-to-Image Diffusion Models are Zero-Shot Classifiers",
    "latest": "2023-03-29T20:55:20+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110108561957117779",
      "content": "<p>RT @priyankjaini@twitter.com</p><p>.@clark_kev@twitter.com &amp; I are excited to share our new work on studying Imagen by evaluating it as a zero-shot classifier! Highlights include Imagen achieving SoTA on Stylized Imagenet and being able to perform attribute binding in certain settings unlike CLIP <br><a href=\"https://arxiv.org/abs/2303.15233\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15233</span><span class=\"invisible\"></span></a><br>\ud83e\uddf5\ud83d\udc47</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/priyankjaini/status/1640520620176801793\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/priyankjaini/statu</span><span class=\"invisible\">s/1640520620176801793</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14184v1",
    "title": "Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior",
    "latest": "2023-03-29T20:44:25+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_gr/110108504348462761",
      "content": "<p>\ud83d\udcdd Make-It-3d: High-Fidelity 3D Creation From a Single Image with Diffusion Prior \ud83d\udd2d</p><p>\"Proposes a method for high-fidelity single-image 3D reconstruction by leveraging a pre-trained 2D diffusion model as 3D-aware supervision.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.14184v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14184v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2206.13932",
    "title": "Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for Scalar Data -- An Algorithm and A Benchmark",
    "latest": "2023-03-29T20:39:03+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@JulienTierny/109879468871250057",
      "content": "<p>Two p-cycles a and b are \"homologous\" (i.e. belong to the same <a href=\"https://fosstodon.org/tags/Homology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Homology</span></a> class) if there exists a (p+1)-chain c, such that b = a + \u2202c (mod-2 sum)<br>\ud83d\udc47<br><a href=\"https://arxiv.org/abs/2206.13932\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2206.13932</span><span class=\"invisible\"></span></a><br><a href=\"https://fosstodon.org/tags/TopologicalDataAnalysis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>TopologicalDataAnalysis</span></a> <a href=\"https://fosstodon.org/tags/TopologyToolKit\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>TopologyToolKit</span></a> <a href=\"https://fosstodon.org/tags/PersistentHomology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PersistentHomology</span></a> <a href=\"https://fosstodon.org/tags/Visualization\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Visualization</span></a> <a href=\"https://fosstodon.org/tags/DataScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DataScience</span></a> <a href=\"https://fosstodon.org/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a><br>Funded by the European Research Council (ERC) (project TORI, <a href=\"https://erc-tori.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">erc-tori.github.io/</span><span class=\"invisible\"></span></a>)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1016/j.celrep.2023.112246",
    "title": "doi.org/10.1016/j.celrep.2023....",
    "latest": "2023-03-29T20:22:37+00:00",
    "last_post": {
      "url": "https://neuromatch.social/@PhiloNeuroScie/110107767570227872",
      "content": "<p><a href=\"https://neuromatch.social/tags/Geometric\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Geometric</span></a> transformation of <a href=\"https://neuromatch.social/tags/cognitive\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>cognitive</span></a> <a href=\"https://neuromatch.social/tags/maps\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>maps</span></a> for <a href=\"https://neuromatch.social/tags/generalization\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>generalization</span></a> across <a href=\"https://neuromatch.social/tags/hippocampal\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>hippocampal</span></a>-<a href=\"https://neuromatch.social/tags/prefrontal\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>prefrontal</span></a> <a href=\"https://neuromatch.social/tags/circuits\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>circuits</span></a><br><a href=\"https://neuromatch.social/tags/neuroscience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>neuroscience</span></a> <br><a href=\"https://doi.org/10.1016/j.celrep.2023.112246\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1016/j.celrep.2023.</span><span class=\"invisible\">112246</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@tyrell_turing",
        "display_name": "Blake Richards"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1038/s41592-023-01820-3",
    "title": "doi.org/10.1038/s41592-023-018...",
    "latest": "2023-03-29T20:22:27+00:00",
    "last_post": {
      "url": "https://neuromatch.social/@PhiloNeuroScie/110107517809000369",
      "content": "<p>\"...achieved simultaneous high-speed deep-tissue imaging of more than 100 densely labeled neurons over 1 hour in awake behaving mice.\"<br>High-speed low-light in vivo two-photon voltage <a href=\"https://neuromatch.social/tags/imaging\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>imaging</span></a> of large neuronal populations<br><a href=\"https://neuromatch.social/tags/neuroscience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>neuroscience</span></a> <br><a href=\"https://doi.org/10.1038/s41592-023-01820-3\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1038/s41592-023-018</span><span class=\"invisible\">20-3</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@tyrell_turing",
        "display_name": "Blake Richards"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.16200",
    "title": "http://arxiv.org/abs/2303.16200",
    "latest": "2023-03-29T19:57:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110108334262254716",
      "content": "<p>RT @DanHendrycks@twitter.com</p><p>As AI systems become more useful, people will delegate greater authority to them across more tasks.<br>AIs are evolving in an increasingly frenzied and uncontrolled manner. This carries risks as natural selection favors AIs over humans.</p><p>Paper: <a href=\"http://arxiv.org/abs/2303.16200\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.16200</span><span class=\"invisible\"></span></a> (\ud83e\uddf5 below)</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/DanHendrycks/status/1641102660412792833\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/DanHendrycks/statu</span><span class=\"invisible\">s/1641102660412792833</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.05981",
    "title": "MarioGPT: Open-Ended Text2Level Generation through Large Language Models",
    "latest": "2023-03-29T19:54:03+00:00",
    "last_post": {
      "url": "https://mastodon.social/@juston/109875556871430330",
      "content": "<p>Less disturbing AI news for today: MarioGPT - A new open-sourced AI-based system that can build Mario levels. <a href=\"https://arxiv.org/abs/2302.05981\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.05981</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1126/science.adi0098",
    "title": "doi.org/10.1126/science.adi009...",
    "latest": "2023-03-29T19:28:29+00:00",
    "last_post": {
      "url": "https://social.cwts.nl/@LudoWaltman/110108049296992399",
      "content": "<p>Fast-growing open-access journals stripped of coveted impact factors <a href=\"https://doi.org/10.1126/science.adi0098\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1126/science.adi009</span><span class=\"invisible\">8</span></a></p><p>Yes, we should be critical of journals that make unwarranted claims about their editorial processes.</p><p>However, we should be even more critical of reward systems that incentivize researchers to publish in these journals.</p><p>Instead of putting lot of effort into blaming and shaming of journals that behave in questionable ways, it's much more productive to invest effort in reforming academic reward systems.</p>"
    },
    "people": [
      {
        "url": "https://social.cwts.nl/@vtraag",
        "display_name": "Vincent Traag"
      }
    ]
  },
  {
    "link": "https://osf.io/preprints/metaarxiv/3ks6r/",
    "title": "osf.io/preprints/metaarxiv/3ks...",
    "latest": "2023-03-29T19:14:28+00:00",
    "last_post": {
      "url": "https://mastodon.social/@lakens/110108165303732302",
      "content": "<p>New preprint: <a href=\"https://osf.io/preprints/metaarxiv/3ks6r/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">osf.io/preprints/metaarxiv/3ks</span><span class=\"invisible\">6r/</span></a> with my wonderful collaborators Max Primbs, <span class=\"h-card\"><a href=\"https://mstdn.science/@LeonieDudda\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>LeonieDudda</span></a></span> Pia Andresen, Erin Buchanan, Hannah Peetz, <span class=\"h-card\"><a href=\"https://nerdculture.de/@MiguelSilan\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>MiguelSilan</span></a></span> and me! <br> <br>Lots of people have ideas on how to advance theory-building in psychological science. Here, we propose consensus meetings as tool to advance theory-building. </p><p>The pre-print is a commentary on a recent BBS paper by Almaatouq and colleagues: <a href=\"https://psyarxiv.com/anjkm/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">psyarxiv.com/anjkm/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2206.04615",
    "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
    "latest": "2023-03-29T19:09:03+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@lampinen/109846716758960075",
      "content": "<p>So if anything, we should expect LMs with internet training to generalize better than models trained on toy tasks. And indeed, LMs perform well at BIG-Bench (<a href=\"https://arxiv.org/abs/2206.04615\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2206.04615</span><span class=\"invisible\"></span></a>) \u2014 tasks researchers chose specifically to be hard for a model that memorized the internet. 6/</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04752",
    "title": "https://doi.org/10.21105/joss.04752",
    "latest": "2023-03-29T18:06:05+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110107896382023174",
      "content": "<p>Just published in JOSS: 'SwiftVISA: Controlling Instrumentation with a Swift-based Implementation of the VISA Communication Protocol' <a href=\"https://doi.org/10.21105/joss.04752\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04752</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.15647",
    "title": "http://arxiv.org/abs/2303.15647",
    "latest": "2023-03-29T17:35:22+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110107775601133107",
      "content": "<p>RT @guitaricet@twitter.com</p><p>How to RLHF <a href=\"https://creative.ai/tags/LLAMA\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLAMA</span></a> if you don't have hundreds of GPUS? Do it in a parameter-efficient way.<br>I'm happy to finally share our parameter-efficient fine-tuning <a href=\"https://creative.ai/tags/PEFT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PEFT</span></a> survey! It took quite a bit more time to make than I expected, but I feel good about the result<br><a href=\"http://arxiv.org/abs/2303.15647\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.15647</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/guitaricet/status/1641121969696391187\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/guitaricet/status/</span><span class=\"invisible\">1641121969696391187</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://royalsocietypublishing.org/doi/10.1098/rspb.2022.2560",
    "title": "royalsocietypublishing.org/doi...",
    "latest": "2023-03-29T17:31:16+00:00",
    "last_post": {
      "url": "https://ecoevo.social/@jebyrnes/110107759480834341",
      "content": "<p>RT @hughes_lab<br>Very excited that this paper led by <span class=\"h-card\"><a href=\"https://ecoevo.social/@torrance_hanley\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>torrance_hanley</span></a></span> is now out! Oyster genetic identity determines micro- and macro-parasite community structure on restored reefs in RI. Highlights the value of designing restorations as experiments to facilitate learning <a href=\"https://royalsocietypublishing.org/doi/10.1098/rspb.2022.2560\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">royalsocietypublishing.org/doi</span><span class=\"invisible\">/10.1098/rspb.2022.2560</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@jebyrnes",
        "display_name": "jebyrnes"
      }
    ]
  },
  {
    "link": "https://osf.io/preprints/socarxiv/rqn9j/",
    "title": "osf.io/preprints/socarxiv/rqn9...",
    "latest": "2023-03-29T17:18:57+00:00",
    "last_post": {
      "url": "https://sciences.social/@AndreaTilstra/110105838571459704",
      "content": "<p>The disruption of the COVID-19 pandemic will continue for many years. This includes changes to the size and shape of the U.S. population. </p><p>Had the pandemic not happened, the US population would have 2.1 mill more people in 2025.</p><p>\u2b07\ufe0fNew Preprint!\u2b07\ufe0f</p><p><a href=\"https://osf.io/preprints/socarxiv/rqn9j/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">osf.io/preprints/socarxiv/rqn9</span><span class=\"invisible\">j/</span></a></p><p>This is because the pandemic not only changed MORTALITY, but MIGRATION and FERTILITY too. </p><p>Research tells us processes changed, but our paper adds to this and examines what the joint affect is.</p>"
    },
    "people": [
      {
        "url": "https://vis.social/@maarten",
        "display_name": "Maarten Lambrechts"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2212.08073.pdf",
    "title": "https://arxiv.org/pdf/2212.08073.pdf",
    "latest": "2023-03-29T09:31:13+00:00",
    "last_post": {
      "url": "https://fediscience.org/@palaio/110105871717251127",
      "content": "<p>I am looking forward to test <a href=\"https://fediscience.org/tags/Claude\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Claude</span></a> <a href=\"https://fediscience.org/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a>, one of the main competitors to <a href=\"https://fediscience.org/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a>. It is different because it is better designed to respect constraints to make it harmless, thanks to <a href=\"https://fediscience.org/tags/ReinforcementLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ReinforcementLearning</span></a> : <a href=\"https://arxiv.org/pdf/2212.08073.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2212.08073.pdf</span><span class=\"invisible\"></span></a></p><p>But there is a trade-off between usefulness and harmlessness, and it is effectively assessed in the paper!</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13809v1",
    "title": "https://arxiv.org/abs/2303.13809v1",
    "latest": "2023-03-29T08:25:41+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110105614165922534",
      "content": "<p>\ud83d\udcdd Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT \ud83d\udcda</p><p>\"By combining Chain-of-Thoughts and Error Analysis, a new prompting method called \\textbf{\\texttt{Error Analysis Prompting}}, LLMs like ChatGPT can \\textit{generate human-like MT evaluations at both the system and segment level}.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Coldmist-Lu/ErrorAnalysis_Prompt\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/Coldmist-Lu/ErrorAn</span><span class=\"invisible\">alysis_Prompt</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13809v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13809v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05197",
    "title": "https://doi.org/10.21105/joss.05197",
    "latest": "2023-03-29T07:40:56+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110105438224199307",
      "content": "<p>Just published in JOSS: 'timeseriesflattener: A Python package for summarizing features from (medical) time series' <a href=\"https://doi.org/10.21105/joss.05197\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05197</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11156",
    "title": "Can AI-Generated Text be Reliably Detected?",
    "latest": "2023-03-29T06:28:46+00:00",
    "last_post": {
      "url": "https://mastodon.education/@readysaltedcode/110105154016267665",
      "content": "<p>Interesting article in light of turnItIn pushing out their <a href=\"https://mastodon.education/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> detection tool. A tool that you can\u2019t turn off!   <a href=\"https://arxiv.org/abs/2303.11156\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.11156</span><span class=\"invisible\"></span></a>   \u201cCan AI-Generated Text be Reliably Detected?\u201d From <br>Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, Soheil Feizi</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41562-023-01586-w",
    "title": "Points of significance - Nature Human Behaviour",
    "latest": "2023-03-29T05:48:44+00:00",
    "last_post": {
      "url": "https://mastodon.social/@lakens/110104997053668677",
      "content": "<p>So, the recommendation of Nature Human Behavior <a href=\"https://www.nature.com/articles/s41562-023-01586-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41562-023</span><span class=\"invisible\">-01586-w</span></a> to interpret p-values in a dichotomous manner is not mindless statistics \u2013 it is based on a methodological falsificationist philosophy of science, and a coherent approach to statistical inferences when testing theories.</p>"
    },
    "people": [
      {
        "url": "https://scicomm.xyz/@sharoz",
        "display_name": "Steve Haroz (@sharoz on \ud83d\udc24)"
      },
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1177/09593543231160112",
    "title": "doi.org/10.1177/09593543231160...",
    "latest": "2023-03-29T05:48:22+00:00",
    "last_post": {
      "url": "https://mastodon.social/@lakens/110104995567063295",
      "content": "<p>(It is a bit nerdy, but fun, to think about why it ended up at 5% - in <a href=\"https://doi.org/10.1177/09593543231160112\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1177/09593543231160</span><span class=\"invisible\">112</span></a> we speculate on possible causes. It is a rare point of agreement among scientists, that\u2019s for sure!</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/abs/10.1177/25152459221080396",
    "title": "journals.sagepub.com/doi/abs/1...",
    "latest": "2023-03-29T05:47:58+00:00",
    "last_post": {
      "url": "https://mastodon.social/@lakens/110104994044361115",
      "content": "<p>This 5% threshold is arbitrary, but it needs to be set somewhere. Although there are ways to justify an alpha level that differs from 5% (see our paper on this <a href=\"https://journals.sagepub.com/doi/abs/10.1177/25152459221080396\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/abs/1</span><span class=\"invisible\">0.1177/25152459221080396</span></a>) it is not easy, and not applicable to all studies. So, the default is there, if you can\u2019t think of any other justification.</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13780v1",
    "title": "https://arxiv.org/abs/2303.13780v1",
    "latest": "2023-03-29T05:25:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110104906160680049",
      "content": "<p>\ud83d\udcdd Towards Making the Most of ChatGPT for Machine Translation \ud83d\udcda</p><p>\"Designs a series of experiments to mine ChatGPT's machine translation ability and further explore the potential of in-context learning strategies for this task, including temperature, task information and domain information.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/facebookresearch/flores\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/fl</span><span class=\"invisible\">ores</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13780v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13780v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13716v1",
    "title": "https://arxiv.org/abs/2303.13716v1",
    "latest": "2023-03-29T03:55:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110104552338981572",
      "content": "<p>\ud83d\udcdd ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation \ud83d\udcda</p><p>\"Shows that a simple model can achieve good performance on COGS if trained on an alternative dataset that has the same semantic content while removing the non-semantics-related aspects of the original dataset.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/frankaging/ReCOGS\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/frankaging/ReCOGS</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13716v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13716v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13675v1",
    "title": "Mordecai 3: A Neural Geoparser and Event Geocoder",
    "latest": "2023-03-29T02:10:36+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110104139331115821",
      "content": "<p>\ud83d\udcdd Mordecai 3: A Neural Geoparser and Event Geocoder \ud83d\udcda</p><p>\"Mordecai3 is an end-to-end geoparser that extracts toponyms and performs toponym resolution to link each toponym to its corresponding entry in a gazetteer.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13675v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13675v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12767",
    "title": "Can we trust the evaluation on ChatGPT?",
    "latest": "2023-03-29T00:58:23+00:00",
    "last_post": {
      "url": "https://datasci.social/@yy/110103855341044259",
      "content": "<p><span class=\"h-card\"><a href=\"https://sigmoid.social/@Riedl\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Riedl</span></a></span> in the same vein\u2026 <a href=\"https://arxiv.org/abs/2303.12767\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12767</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@yy",
        "display_name": "YY Ahn"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1080/15230406.2023.2171490",
    "title": "doi.org/10.1080/15230406.2023....",
    "latest": "2023-03-28T20:46:24+00:00",
    "last_post": {
      "url": "https://mapstodon.space/@CaGIS/110100663204374915",
      "content": "<p>Great new paper by Mengjie Zhou and colleagues on new ways of visualising origin-destination data: Discovering spatiotemporal flow patterns: where the origin\u2013destination map meets empirical orthogonal function decomposition, <a href=\"https://doi.org/10.1080/15230406.2023.2171490\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/15230406.2023.</span><span class=\"invisible\">2171490</span></a>, <a href=\"https://mapstodon.space/tags/gischat\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gischat</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@underdarkGIS",
        "display_name": "Anita Graser \ud83c\uddea\ud83c\uddfa\ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2110.05719",
    "title": "Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations",
    "latest": "2023-03-28T20:10:54+00:00",
    "last_post": {
      "url": "https://kolektiva.social/@danmcquillan/110102724610777117",
      "content": "<p>This makes for a striking contrast: \"Such annotators whose lived experiences bring important perspectives to the task would be dramatically underrepresented on generic crowd work platforms and, by definition, would be outvoted in disagreements subject to majority vote\" <a href=\"https://arxiv.org/abs/2110.05719\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2110.05719</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1080/10724117.2023.2168404",
    "title": "doi.org/10.1080/10724117.2023....",
    "latest": "2023-03-28T19:23:05+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@peterrowlett/110102536860185919",
      "content": "<p>Got a ping that there\u2019s a Hacker News thread about my new article in Math Horizons about the game On-Sets.</p><p>Article (free to read): <a href=\"https://doi.org/10.1080/10724117.2023.2168404\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/10724117.2023.</span><span class=\"invisible\">2168404</span></a></p><p>Hacker News: <a href=\"https://news.ycombinator.com/item?id=35301264\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">news.ycombinator.com/item?id=3</span><span class=\"invisible\">5301264</span></a></p><p>Article details ActivityPub details: <span class=\"h-card\"><a href=\"https://peterrowlett.net/publications/\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>onsetsmathhorizons</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@peterrowlett",
        "display_name": "Peter Rowlett"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13592v1",
    "title": "https://arxiv.org/abs/2303.13592v1",
    "latest": "2023-03-28T18:40:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110102369965968944",
      "content": "<p>\ud83d\udcdd Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages \ud83d\udcda\ud83d\udc7e</p><p>\"We prompt ChatGPT, InstructGPT, BLOOMZ, and FLANA-T5-XXL to produce code-mixed content with a set of prompts containing terms related to code-mixing or language mixing.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Southeast-Asia-NL\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/Southeast-Asia-NL</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13592v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13592v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04969",
    "title": "https://doi.org/10.21105/joss.04969",
    "latest": "2023-03-28T17:44:44+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110102150123528490",
      "content": "<p>Just published in JOSS: 'ronswanson: Building Table Models for 3ML' <a href=\"https://doi.org/10.21105/joss.04969\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04969</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00876-7",
    "title": "JWST gets best view yet of planet in hotly pursued star system",
    "latest": "2023-03-28T17:05:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110101994070375293",
      "content": "<p>JWST gets best view yet of planet in hotly pursued star system - <a href=\"https://www.nature.com/articles/d41586-023-00876-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00876-7</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1534/genetics.104.035212",
    "title": "doi.org/10.1534/genetics.104.0...",
    "latest": "2023-03-28T16:42:32+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@kbroman/110101905560485635",
      "content": "<p>How is it that the PDF for a paper published nearly 20 years ago would suddenly be missing almost all of its figures? Also how is it that almost 20 years have passed? <a href=\"https://doi.org/10.1534/genetics.104.035212\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1534/genetics.104.0</span><span class=\"invisible\">35212</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@kbroman",
        "display_name": "Karl Broman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13455v1",
    "title": "CoBIT: A Contrastive Bi-directional Image-Text Generation Model",
    "latest": "2023-03-28T08:58:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110100081419030996",
      "content": "<p>\ud83d\udcdd CoBIT: A Contrastive Bi-Directional Image-Text Generation Model \ud83d\udd2d\ud83d\udcda</p><p>\"A Contrastive Bi-directional Image-Text generation model (CoBIT) is a unified framework for vision and language understanding and generation, that jointly optimizes the image-text contrastive loss, image-to-text generation loss and text-to-image generation loss.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13455v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13455v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13283v1",
    "title": "https://arxiv.org/abs/2303.13283v1",
    "latest": "2023-03-28T07:58:36+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110099845409753299",
      "content": "<p>\ud83d\udcdd Visual-Language Prompt Tuning with Knowledge-Guided Context Optimization \ud83d\udd2d\ud83d\udcda</p><p>\"The key insight of KgCoOp is that forgetting about essential knowledge can be alleviated by reducing the discrepancy between the learnable prompt and the hand-crafted prompt.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/KaiyangZhou/CoOp\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/KaiyangZhou/CoOp</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13283v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13283v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2109.04587v1",
    "title": "https://arxiv.org/abs/2109.04587v1",
    "latest": "2023-03-28T07:13:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110099668342617955",
      "content": "<p>\ud83d\udcdd Graph-Based Decoding for Task Oriented Semantic Parsing \ud83d\udcda\ud83d\udc7e</p><p>\"Formulates semantic parsing as a dependency parsing task, applying graph-based decoding techniques developed for syntactic parsing with a Transformer encoder pre-trained on language modeling tasks and fine-tuned on the semantic parsing task.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/google-research/text-to-text-transfertransformer\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/google-research/tex</span><span class=\"invisible\">t-to-text-transfertransformer</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2109.04587v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2109.04587v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13465v1",
    "title": "Deep RL with Hierarchical Action Exploration for Dialogue Generation",
    "latest": "2023-03-28T06:13:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110099432442056111",
      "content": "<p>\ud83d\udcdd Deep RL with Hierarchical Action Exploration for Dialogue Generation \ud83d\udcda\ud83d\udc7e</p><p>\"Introduces a novel dual-granularity Q-function to alleviate this limitation by exploring the most promising response category to intervene in the sampling and learning in the way of offline RL from multiple reward functions designed to recognize human emotional details.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13465v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13465v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/23729333.2023.2165218",
    "title": "Minimum dimensions for cartographic symbology \u2013 history, rationale and relevance in the digital age",
    "latest": "2023-03-28T06:05:40+00:00",
    "last_post": {
      "url": "https://mapstodon.space/@floledermann/110094895535073239",
      "content": "<p>\u201cWhat are the smallest graphical elements we can use on a map?\u201d \u2013 Super happy that my overview article on guidelines for minimum dimensions of cartographic symbology has now been published open access in the International Journal of Cartography!</p><p>Although it doesn't contain any original research by me, this was quite tedious to get published \u2013 it required 3 round of proofs until all the figures and tables were right \ud83d\ude05. Image below shows recommendations for printed maps. </p><p><a href=\"https://www.tandfonline.com/doi/full/10.1080/23729333.2023.2165218\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/23729333.2023.2165218</span></a></p>"
    },
    "people": [
      {
        "url": "https://mapstodon.space/@Amber",
        "display_name": "Amber Manfree"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14177",
    "title": "Scaling Expert Language Models with Unsupervised Domain Discovery",
    "latest": "2023-03-28T06:01:14+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@Techronic9876/110099348544225504",
      "content": "<p><span class=\"h-card\"><a href=\"https://sigmoid.social/@stablehorde\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>stablehorde</span></a></span> <a href=\"https://arxiv.org/abs/2303.14177\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14177</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13463v1",
    "title": "W2KPE: Keyphrase Extraction with Word-Word Relation",
    "latest": "2023-03-28T03:58:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110098901458524112",
      "content": "<p>\ud83d\udcdd W2KPE: Keyphrase Extraction with Word-Word Relation \ud83d\udcda</p><p>\"The keyphrase extraction task is modeled as an NER task after encoding the split keyphrases after word segmentation, and multi-class focal loss is utilized to overcome the class imbalance issue.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13463v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13463v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2301.10226.pdf",
    "title": "https://arxiv.org/pdf/2301.10226.pdf",
    "latest": "2023-03-28T03:34:00+00:00",
    "last_post": {
      "url": "https://mas.to/@assaf/110035247748929310",
      "content": "<p>A Watermark for Large Language Models</p><p><a href=\"https://arxiv.org/pdf/2301.10226.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2301.10226.pdf</span><span class=\"invisible\"></span></a></p><p>This is an interesting technique to watermark LLM-generated text so it\u2019s easy to identify (even small excerpts)</p><p>Gist of it is influencing next-token prediction to prefer words from a green list, and doing this with enough frequency, that you can determine with confidence the text was machine generated.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13408v1",
    "title": "https://arxiv.org/abs/2303.13408v1",
    "latest": "2023-03-28T02:58:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110098665858630222",
      "content": "<p>\ud83d\udcdd Paraphrasing Evades Detectors of AI-generated Text, but Retrieval Is an Effective Defense \ud83d\udcda\ud83e\udde0</p><p>\"The defense is based on retrieving semantically-similar generations and must be maintained by a language model API provider and uses a database of sequences previously generated by the API to classify an input text.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CR\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CR</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/martiansideofthemoon/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/martiansideofthemoo</span><span class=\"invisible\">n/</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13408v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13408v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.14334.pdf",
    "title": "https://arxiv.org/pdf/2303.14334.pdf",
    "latest": "2023-03-28T02:31:28+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/110098559059660896",
      "content": "<p>\"The Semantic Reader Project: Augmenting Scholarly Documents<br>through AI-Powered Interactive Reading Interfaces\"</p><p><a href=\"https://arxiv.org/pdf/2303.14334.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.14334.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/search\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>search</span></a>    <a href=\"https://mastodon.radio/tags/cognitiveAids\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>cognitiveAids</span></a><br><a href=\"https://mastodon.radio/tags/SemanticScholar\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SemanticScholar</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.03551v5",
    "title": "Talking About Large Language Models",
    "latest": "2023-03-28T02:04:01+00:00",
    "last_post": {
      "url": "https://techhub.social/@nic221/109954217879591444",
      "content": "<p>Talking About Large Language Models <a href=\"https://arxiv.org/abs/2212.03551v5\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.03551v5</span><span class=\"invisible\"></span></a> <a href=\"https://techhub.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://techhub.social/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> <a href=\"https://techhub.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14957",
    "title": "unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including Structured Full-Text and Citation Network",
    "latest": "2023-03-28T01:51:13+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110098400742564010",
      "content": "<p>unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including Structured Full-Text and Citation Network</p><p>abs: <a href=\"https://arxiv.org/abs/2303.14957\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14957</span><span class=\"invisible\"></span></a><br>repo: <a href=\"https://github.com/IllDepence/unarXive\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/IllDepence/unarXive</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@chengyjonathan",
        "display_name": "Jonathan Cheng"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15274",
    "title": "Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention",
    "latest": "2023-03-28T01:51:10+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110098400600067858",
      "content": "<p>Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention</p><p>Poses a new task called ZeroGaze, where gaze is predicted for never-before-searched objects and develops a novel model, Gazeformer, to solve the ZeroGaze problem.</p><p><a href=\"https://arxiv.org/abs/2303.15274\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15274</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14420",
    "title": "https://arxiv.org/abs/2303.14420",
    "latest": "2023-03-28T01:51:07+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110098400388707347",
      "content": "<p>Better Aligning Text-to-Image Models with Human Preference</p><p>proj: <a href=\"https://tgxs002.github.io/align_sd_web/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">tgxs002.github.io/align_sd_web</span><span class=\"invisible\">/</span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.14420\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14420</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15343",
    "title": "Sigmoid Loss for Language Image Pre-Training",
    "latest": "2023-03-28T01:51:00+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110098399917946430",
      "content": "<p>Sigmoid Loss for Language Image Pre-Training</p><p>Proposes a simple pairwise sigmoid loss for image-text pre-training that does not require a global view of the pairwise similarities for normalization with comparable perf to softmax. </p><p><a href=\"https://arxiv.org/abs/2303.15343\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15343</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15389",
    "title": "https://arxiv.org/abs/2303.15389",
    "latest": "2023-03-28T01:50:58+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110098399764738846",
      "content": "<p>EVA-CLIP: Improved Training Techniques for CLIP at Scale</p><p>Proposes EVA-CLIP, a series of models that significantly improve the efficiency and effectiveness of CLIP training. </p><p>proj: <a href=\"https://github.com/baaivision/EVA/tree/master/EVA-CLIP\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/baaivision/EVA/tree</span><span class=\"invisible\">/master/EVA-CLIP</span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.15389\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15389</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.04986.pdf",
    "title": "https://arxiv.org/pdf/2303.04986.pdf",
    "latest": "2023-03-28T01:19:00+00:00",
    "last_post": {
      "url": "https://mamot.fr/@casilli/110000922472693191",
      "content": "<p>This study, the first of its kind, is based upon 24 interviews with autonomous vehicles' safety drivers (or as I like to call them: \u201cdrivers\u201d). These workers are forced to take risks accumulated by the AV industry upstream while coping with defective algorithms &amp; operating malfunctioning cars in traffic. <a href=\"https://arxiv.org/pdf/2303.04986.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.04986.pdf</span><span class=\"invisible\"></span></a> (Luckily there\u2019s Tesla and their revolutionary approach to autonomous vehicles. No safety drivers put at risk, as tests are done directly by customers.)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.07519",
    "title": "http://arxiv.org/abs/2303.07519",
    "latest": "2023-03-28T01:09:58+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ceperez/110098238556216185",
      "content": "<p>RT @ItakGol<br>\ud83d\ude80\ud83d\udd25 Introducing Architext - </p><p>The first, open-source, language model trained for Architectural design.</p><p><a href=\"http://arxiv.org/abs/2303.07519\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.07519</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.09923",
    "title": "Prompt Stealing Attacks Against Text-to-Image Generation Models",
    "latest": "2023-03-27T21:15:15+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@lizardbill/110097315632169752",
      "content": "<p>Prompt Stealing Attacks Against Text-to-Image Generation Models <a href=\"https://arxiv.org/abs/2302.09923\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.09923</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://hachyderm.io/@lizardbill",
        "display_name": "Bill the Lizard"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/13658816.2023.2191256",
    "title": "Explainable GeoAI: can saliency maps help interpret artificial intelligence\u2019s learning process? An empirical study on natural feature detection",
    "latest": "2023-03-27T20:20:48+00:00",
    "last_post": {
      "url": "https://mastodon.social/@RebelGeo/110096561158081786",
      "content": "<p>Explainable GeoAI: can saliency maps help interpret artificial intelligence\u2019s learning process? An empirical study on natural feature detection</p><p><a href=\"https://www.tandfonline.com/doi/full/10.1080/13658816.2023.2191256\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/13658816.2023.2191256</span></a></p><p><a href=\"https://mastodon.social/tags/mapping\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>mapping</span></a> <a href=\"https://mastodon.social/tags/gischat\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gischat</span></a> <a href=\"https://mastodon.social/tags/geospatial\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>geospatial</span></a> <a href=\"https://mastodon.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@underdarkGIS",
        "display_name": "Anita Graser \ud83c\uddea\ud83c\uddfa\ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.08112.pdf",
    "title": "https://arxiv.org/pdf/2303.08112.pdf",
    "latest": "2023-03-27T19:37:48+00:00",
    "last_post": {
      "url": "https://techhub.social/@dsnai/110061867378777239",
      "content": "<p>Have you ever wondered how language models determine their next move?</p><p>A new AI model called Tuned Lens, developed by Nora Belrose et al. can track a language model's prediction as it progresses through each layer.</p><p>Read more&gt;<a href=\"https://arxiv.org/pdf/2303.08112.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.08112.pdf</span><span class=\"invisible\"></span></a>.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1121/2.0001725",
    "title": "https://doi.org/10.1121/2.0001725",
    "latest": "2023-03-27T19:23:28+00:00",
    "last_post": {
      "url": "https://fediscience.org/@AcousticalSocietyofAmerica/110096324651234269",
      "content": "<p>POMA</p><p>The English /s/ is \"darker\" at syllable coda than at syllable onset. The coda /s/ has lower peak frequency and lower amplitude in the 4-14 kHz interval than onset /s/. <a href=\"https://doi.org/10.1121/2.0001725\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1121/2.0001725</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fediscience.org/tags/acoustics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>acoustics</span></a> <a href=\"https://fediscience.org/tags/speech\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>speech</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@davidmortensen",
        "display_name": "David Mortensen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13364v1",
    "title": "Reevaluating Data Partitioning for Emotion Detection in EmoWOZ",
    "latest": "2023-03-27T19:13:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110096837112863370",
      "content": "<p>\ud83d\udcdd Reevaluating Data Partitioning for Emotion Detection in EmoWOZ \ud83d\udcda\ud83e\udde0</p><p>\"Proposes a stratified sampling scheme and special technique to handle the sequential data with many emotion tags on EmoWoz Dataset for improving the dataset distribution and reducing dataset shift.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13364v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13364v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.12712.pdf",
    "title": "https://arxiv.org/pdf/2303.12712.pdf",
    "latest": "2023-03-27T19:08:24+00:00",
    "last_post": {
      "url": "https://mastodon.social/@elipariser/110078298972577543",
      "content": "<p>I'm less sanguine about LLMs than I was in December when I said they're essentially \"asking a supercomputer to get really good at mansplaining.\" </p><p>I really encourage folks to check out this paper on some of GPT4's capabilities. <br><a href=\"https://arxiv.org/pdf/2303.12712.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.12712.pdf</span><span class=\"invisible\"></span></a></p><p>Some of this is undoubtedly overstated. And none of this disputes the very real concerns about bias, misuse, and disinformation. </p><p>But look at some of these examples (pics attached). It's hard to reconcile with  \"word prediction on steroids.\"</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@andrey",
        "display_name": "Andrey Kurenkov"
      },
      {
        "url": "https://fosstodon.org/@amueller",
        "display_name": "Andreas Mueller"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://genart.social/@tca",
        "display_name": "tiago"
      },
      {
        "url": "https://mastodon.social/@bruces",
        "display_name": "Bruce Sterling @bruces"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14001",
    "title": "Grid-guided Neural Radiance Fields for Large Urban Scenes",
    "latest": "2023-03-27T18:46:53+00:00",
    "last_post": {
      "url": "https://techhub.social/@dsnai/110095838154014914",
      "content": "<p>Introducing the new Neural Radiance Fields (NeRF) version!</p><p>The new approach combines a compact ground feature plane &amp; positional encoding inputs.</p><p>It is perfect for film, video games, architecture &amp; urban planning.</p><p>Read more&gt;<a href=\"https://arxiv.org/abs/2303.14001\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14001</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \u2744\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.03347",
    "title": "Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
    "latest": "2023-03-27T18:39:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@culurciello/110096703057338598",
      "content": "<p>The right way to turn document into applications? <a href=\"https://arxiv.org/abs/2210.03347\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.03347</span><span class=\"invisible\"></span></a> turn them into code first! <a href=\"https://sigmoid.social/tags/Ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Ai</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <a href=\"https://sigmoid.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://osf.io/preprints/socarxiv/jqxb6",
    "title": "osf.io/preprints/socarxiv/jqxb...",
    "latest": "2023-03-27T18:36:54+00:00",
    "last_post": {
      "url": "https://scholar.social/@olivia/109847054603212959",
      "content": "<p>Super proud/excited to share our paper \"Pygmalion Displacement: When Humanising AI Dehumanises Women\" wherein we develop a lens to help us trace a type of harm towards women within/by AI as a field &amp; as a technology: <a href=\"https://osf.io/preprints/socarxiv/jqxb6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">osf.io/preprints/socarxiv/jqxb</span><span class=\"invisible\">6</span></a></p><p>1/4</p>"
    },
    "people": [
      {
        "url": "https://wandering.shop/@cstross",
        "display_name": "Charlie Stross"
      },
      {
        "url": "https://mastodon.social/@metilli",
        "display_name": "Daniele Metilli"
      },
      {
        "url": "https://fosstodon.org/@SherlockpHolmes",
        "display_name": "Susan Holmes"
      },
      {
        "url": "https://genart.social/@georgemsavva",
        "display_name": "George Savva"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07334",
    "title": "Assessing the performance of spatial cross-validation approaches for models of spatially structured data",
    "latest": "2023-03-27T17:35:54+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@MikeMahoney218/110021566901452799",
      "content": "<p>\ud83d\udce3 I've got a new <a href=\"https://fosstodon.org/tags/preprint\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>preprint</span></a> out, with <span class=\"h-card\"><a href=\"https://fosstodon.org/@juliasilge\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>juliasilge</span></a></span> , <span class=\"h-card\"><a href=\"https://mastodon.social/@hfrick\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>hfrick</span></a></span> , <span class=\"h-card\"><a href=\"https://fosstodon.org/@topepo\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>topepo</span></a></span> , plus Lucas Johnson and Colin Beier!</p><p>We give a head-to-head comparison of spatial cross-validation methods, give advice on applying spatial CV for applied modeling projects, and walk through how these techniques are implemented in the {spatialsample} <a href=\"https://fosstodon.org/tags/rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rstats</span></a> package.</p><p>Preprint: <a href=\"https://arxiv.org/abs/2303.07334\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07334</span><span class=\"invisible\"></span></a><br>Repo: <a href=\"https://github.com/cafri-labs/assessing-spatial-cv\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/cafri-labs/assessin</span><span class=\"invisible\">g-spatial-cv</span></a></p><p><a href=\"https://fosstodon.org/tags/gischat\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gischat</span></a> <a href=\"https://fosstodon.org/tags/DataScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DataScience</span></a> <a href=\"https://fosstodon.org/tags/rspatial\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rspatial</span></a></p>"
    },
    "people": [
      {
        "url": "https://scicomm.xyz/@leouieda",
        "display_name": "Dr Leonardo Uieda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13360v1",
    "title": "Towards the Scalable Evaluation of Cooperativeness in Language Models",
    "latest": "2023-03-27T17:28:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110096424477194719",
      "content": "<p>\ud83d\udcdd Towards the Scalable Evaluation of Cooperativeness in Language Models \ud83d\udcda\ud83e\udde0</p><p>\"UnifiedQA is a multi-task QA dataset and GPT-3 is an auto-regressive language model trained on this dataset using a variety of fine-tuning techniques.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13360v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13360v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.06766",
    "title": "http://arxiv.org/abs/2303.06766",
    "latest": "2023-03-27T09:30:34+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@at/110039011957358586",
      "content": "<p>Next-Best-View Selection for Robot Eye-in-Hand Calibration<br> Jun Yang, Jason Rebello, Steven L. Waslander </p><p>tl;dr: in calibration, how do we know we have a good dataset? Uses a next-best view policy to reduce the # of poses &amp; errors in robot-camera context.</p><p>(btw, I have been asked about doing something like this in every talk I give on robot-camera calibration. Yeah! someone has already done it.)</p><p>abs: <a href=\"http://arxiv.org/abs/2303.06766\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.06766</span><span class=\"invisible\"></span></a> <br><a href=\"https://sigmoid.social/tags/arXiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arXiv</span></a> <a href=\"https://sigmoid.social/tags/AmyPostsPapers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AmyPostsPapers</span></a> <a href=\"https://sigmoid.social/tags/RobotCameraCalibration\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RobotCameraCalibration</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2112.08726.pdf",
    "title": "https://arxiv.org/pdf/2112.08726.pdf",
    "latest": "2023-03-27T09:22:32+00:00",
    "last_post": {
      "url": "https://fediscience.org/@palaio/110094513119374601",
      "content": "<p>Indeed, <a href=\"https://fediscience.org/tags/planning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>planning</span></a> is a very good approach to generate text <a href=\"https://fediscience.org/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://fediscience.org/tags/NLG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLG</span></a>. And it is still going on and competitive with <a href=\"https://fediscience.org/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a>: <a href=\"https://arxiv.org/pdf/2112.08726.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2112.08726.pdf</span><span class=\"invisible\"></span></a> <a href=\"https://fediscience.org/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@palaio",
        "display_name": "Victor Pal\u00e9ologue"
      }
    ]
  },
  {
    "link": "http://osf.io/ejv52/",
    "title": "http://osf.io/ejv52/",
    "latest": "2023-03-27T06:01:53+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110093724094394928",
      "content": "<p>A Modal Ontological Argument for the Existence of an Imperfect God. <a href=\"http://osf.io/ejv52/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ejv52/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/10724117.2023.2168404",
    "title": "On-Sets: A Vintage Set Theory Game",
    "latest": "2023-03-27T04:55:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110093461289732293",
      "content": "<p>On-Sets: A Vintage Set Theory Game - <a href=\"https://www.tandfonline.com/doi/full/10.1080/10724117.2023.2168404\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/10724117.2023.2168404</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13001v1",
    "title": "https://arxiv.org/abs/2303.13001v1",
    "latest": "2023-03-27T03:28:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110093121225335785",
      "content": "<p>\ud83d\udcdd Is ChatGPT a Good Keyphrase Generator? A Preliminary Study \ud83d\udcda</p><p>\"ChatGPT is an unsupervised language model that was developed by OpenAI based on the Generative Pre-Trained Transformer 3 (GPT-3) model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/MySong7NLPer/ChatGPT_as_\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/MySong7NLPer/ChatGP</span><span class=\"invisible\">T_as_</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.13001v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13001v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12869v1",
    "title": "JaCoText: A Pretrained Model for Java Code-Text Generation",
    "latest": "2023-03-27T02:43:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110092944312710816",
      "content": "<p>\ud83d\udcdd JaCoText: A Pretrained Model for Java Code-Text Generation \ud83d\udcda</p><p>\"JaCoText leverages advantages of both natural language and code generation models and it consists of a transformer architecture initialized by pretrained models for both text and code and pretraining on both unimodal and bimodal data.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12869v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12869v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/jcmc/article/28/3/zmad002/7084918",
    "title": "Communication networks do not predict success in attempts at peer production",
    "latest": "2023-03-27T01:34:42+00:00",
    "last_post": {
      "url": "https://hci.social/@jeremy/110086404005621428",
      "content": "<p>\ud83d\udea8 New paper!</p><p>Blog post + thread coming sometime this week, but <span class=\"h-card\"><a href=\"https://social.coop/@aaronshaw\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>aaronshaw</span></a></span>, <span class=\"h-card\"><a href=\"https://social.coop/@mako\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mako</span></a></span>, and I just had our paper published on the role of networks in early-stage wiki communities.</p><p><a href=\"https://academic.oup.com/jcmc/article/28/3/zmad002/7084918\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/jcmc/article/</span><span class=\"invisible\">28/3/zmad002/7084918</span></a></p><p>The TL;DR is that structure doesn't predict productivity or longevity of communities very well at all!</p><p>We talk about some potential explanations, but I still think it's surprising!</p>"
    },
    "people": [
      {
        "url": "https://hci.social/@jeremy",
        "display_name": "Jeremy Foote \ud83e\uddb6"
      },
      {
        "url": "https://social.coop/@groceryheist",
        "display_name": "Nathan TeBlunthuis"
      },
      {
        "url": "https://social.coop/@mako",
        "display_name": "Benjamin Mako Hill"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.07459.pdf",
    "title": "https://arxiv.org/pdf/2302.07459.pdf",
    "latest": "2023-03-27T01:30:57+00:00",
    "last_post": {
      "url": "https://techhub.social/@dsnai/109874664085410253",
      "content": "<p>Learn about \"morally self-correcting\" AI in this groundbreaking study!</p><p>Amanda Askell et al. find strong evidence that language models trained with Reinforcement Learning from Human Feedback (RLHF) have the capacity to \"morally self-correct\" and avoid generating harmful outputs,</p><p>This have implications for responsible &amp; ethical AI.</p><p>Read more&gt;<a href=\"https://arxiv.org/pdf/2302.07459.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.07459.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12860v1",
    "title": "Salient Span Masking for Temporal Understanding",
    "latest": "2023-03-26T23:28:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110092177389835240",
      "content": "<p>\ud83d\udcdd Salient Span Masking for Temporal Understanding \ud83d\udcda\ud83d\udc7e</p><p>\"Temporal Salient Span Masking (TSM) extends salient span masking to include temporal expressions as spans in the intermediate training sentences in the pretraining phase of the model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12860v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12860v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13375",
    "title": "Capabilities of GPT-4 on Medical Challenge Problems",
    "latest": "2023-03-26T21:55:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110091809750428770",
      "content": "<p>Capabilities of GPT-4 on Medical Challenge Problems - <a href=\"https://arxiv.org/abs/2303.13375\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13375</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41586-023-05732-2?utm_source=twitter&amp;utm_medium=social&amp;utm_content=organic&amp;utm_campaign=CONR_JRNLS_AWA1_GL_SCON_SMEDA_NATUREPORTFOLIO",
    "title": "Dense reinforcement learning for safety validation of autonomous vehicles - Nature",
    "latest": "2023-03-26T20:54:37+00:00",
    "last_post": {
      "url": "https://mastodon.social/@freakonometrics/110091572157617090",
      "content": "<p>\"Dense reinforcement learning for safety validation of autonomous vehicles\" <a href=\"https://www.nature.com/articles/s41586-023-05732-2?utm_source=twitter&amp;utm_medium=social&amp;utm_content=organic&amp;utm_campaign=CONR_JRNLS_AWA1_GL_SCON_SMEDA_NATUREPORTFOLIO\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41586-023</span><span class=\"invisible\">-05732-2?utm_source=twitter&amp;utm_medium=social&amp;utm_content=organic&amp;utm_campaign=CONR_JRNLS_AWA1_GL_SCON_SMEDA_NATUREPORTFOLIO</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@freakonometrics",
        "display_name": "Arthur Charpentier"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12808v1",
    "title": "PACO: Provocation Involving Action, Culture, and Oppression",
    "latest": "2023-03-26T20:13:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110091410961783227",
      "content": "<p>\ud83d\udcdd PACO: Provocation Involving Action, Culture, and Oppression \ud83d\udcda\ud83d\udc7e</p><p>\"Trains a fine-tuned RoBERTa model for identifying provocation from WhatsApp posts with an average AUC of 0851 over five-fold cross-validation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12808v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12808v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05100",
    "title": "https://doi.org/10.21105/joss.05100",
    "latest": "2023-03-26T19:43:31+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110091292608984062",
      "content": "<p>Just published in JOSS: 'Melodie: Agent-based Modeling in Python' <a href=\"https://doi.org/10.21105/joss.05100\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05100</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04366",
    "title": "https://doi.org/10.21105/joss.04366",
    "latest": "2023-03-26T18:48:53+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110091077795838255",
      "content": "<p>Just published in JOSS: RESOURCECODE: A Python package for statistical analysis of sea-state hindcast data <a href=\"https://doi.org/10.21105/joss.04366\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04366</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12795v1",
    "title": "Named Entity Recognition Based Automatic Generation of Research Highlights",
    "latest": "2023-03-26T18:13:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110090938999508264",
      "content": "<p>\ud83d\udcdd Named Entity Recognition Based Automatic Generation of Research Highlights \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"A deep learning approach that uses named entity recognition to improve the performance of the pointer generator network and the coverage mechanism to generate highlights from different sections of a research paper as input.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12795v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12795v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://royalsocietypublishing.org/doi/10.1098/rsbl.2022.0590",
    "title": "royalsocietypublishing.org/doi...",
    "latest": "2023-03-26T16:33:05+00:00",
    "last_post": {
      "url": "https://scholar.social/@animalculum/110075365773896076",
      "content": "<p>How <a href=\"https://scholar.social/tags/Antarctica\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Antarctica</span></a>'s tiny non-ice-dwelling species survived the ice age<br><a href=\"https://phys.org/news/2023-03-antarctica-tiny-non-ice-dwelling-species-survived.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">phys.org/news/2023-03-antarcti</span><span class=\"invisible\">ca-tiny-non-ice-dwelling-species-survived.html</span></a></p><p>Location, location, location: survival of <a href=\"https://scholar.social/tags/Antarctic\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Antarctic</span></a> biota requires the best real estate <a href=\"https://royalsocietypublishing.org/doi/10.1098/rsbl.2022.0590\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">royalsocietypublishing.org/doi</span><span class=\"invisible\">/10.1098/rsbl.2022.0590</span></a> </p><p>These animals survived in ice-free refuges, such as rocky outcrops protruding from ice-covered mountains. They have then expanded their range to their present-day habitats as the ice has retreated.</p>"
    },
    "people": [
      {
        "url": "https://universeodon.com/@eclogiter",
        "display_name": "Pet Rock"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2202.06935",
    "title": "Repairing the Cracked Foundation: A Survey of Obstacles in Evaluation Practices for Generated Text",
    "latest": "2023-03-26T16:17:06+00:00",
    "last_post": {
      "url": "https://c.im/@hyperplane/110090026093301401",
      "content": "<p>Repairing the Cracked Foundation: A Survey of Obstacles in Evaluation Practices for Generated Text</p><p><a href=\"https://arxiv.org/abs/2202.06935\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2202.06935</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/k5qp7/",
    "title": "http://osf.io/k5qp7/",
    "latest": "2023-03-26T15:56:02+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110090398127950766",
      "content": "<p>Racial disparities in fetal and infant outcomes: a multiple-decrement life table approach <a href=\"http://osf.io/k5qp7/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/k5qp7/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.09689",
    "title": "Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor",
    "latest": "2023-03-26T04:22:11+00:00",
    "last_post": {
      "url": "https://techhub.social/@dsnai/109920469841363952",
      "content": "<p>Check out <span class=\"h-card\"><a href=\"https://sigmoid.social/@metaai\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>metaai</span></a></span>'s model that generates natural language (instructions) with almost no human effort!</p><p>The researchers proposed \"Unnatural Instructions\", a dataset collected virtually containing many creative &amp; diverse instructions.</p><p>Generated data are cost-effective &amp; can be an alternative to crowdsourcing for dataset expansion &amp; diversification.</p><p>Read&gt;<a href=\"https://arxiv.org/abs/2212.09689\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.09689</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@jacobeisenstein",
        "display_name": "Jacob Eisenstein"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2204.08108.pdf",
    "title": "https://arxiv.org/pdf/2204.08108.pdf",
    "latest": "2023-03-26T03:06:37+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/110087372615091452",
      "content": "<p>\"How are Software Repositories Mined?<br>A Systematic Literature Review of Workflows, Methodologies,<br>Reproducibility, and Tools\"</p><p><a href=\"https://arxiv.org/pdf/2204.08108.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2204.08108.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/search\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>search</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2204.02765.pdf",
    "title": "https://arxiv.org/pdf/2204.02765.pdf",
    "latest": "2023-03-26T02:43:53+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/110087283221356835",
      "content": "<p>\"Code Search: A Survey of Techniques for Finding Code\"</p><p><a href=\"https://arxiv.org/pdf/2204.02765.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2204.02765.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/search\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>search</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12208v1",
    "title": "https://arxiv.org/abs/2303.12208v1",
    "latest": "2023-03-26T02:08:15+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110087143101591428",
      "content": "<p>\ud83d\udcdd MAGVLT: Masked Generative Vision-and-Language Transformer \ud83d\udd2d\ud83d\udcda\ud83e\udde0</p><p>\"A unified multimodal generative vision-and-language transformer (MAGVLT) is proposed, and it outperforms an autoregressive generative vision-and-language transformer (ARGVLT) by a large margin on various downstream generation tasks of VL benchmarks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/kakaobrain/magvlt\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/kakaobrain/magvlt</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12208v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12208v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2212.10559",
    "title": "http://arxiv.org/abs/2212.10559",
    "latest": "2023-03-25T23:46:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110086584861205301",
      "content": "<p>2/ </p><p>Paper 1:<br>Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Zhifang Sui, and Furu Wei. 2022. Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers. <a href=\"http://arxiv.org/abs/2212.10559\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2212.10559</span><span class=\"invisible\"></span></a></p><p>Paper 2:<br>Noam Wies, Yoav Levine, and Amnon Shashua. 2023. The Learnability of In-Context Learning. <a href=\"http://arxiv.org/abs/2303.07895\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.07895</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/DeepLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeepLearning</span></a> <a href=\"https://sigmoid.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a> <a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/NLG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLG</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@chengyjonathan",
        "display_name": "Jonathan Cheng"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.07895",
    "title": "http://arxiv.org/abs/2303.07895",
    "latest": "2023-03-25T23:46:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110086584861205301",
      "content": "<p>2/ </p><p>Paper 1:<br>Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Zhifang Sui, and Furu Wei. 2022. Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers. <a href=\"http://arxiv.org/abs/2212.10559\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2212.10559</span><span class=\"invisible\"></span></a></p><p>Paper 2:<br>Noam Wies, Yoav Levine, and Amnon Shashua. 2023. The Learnability of In-Context Learning. <a href=\"http://arxiv.org/abs/2303.07895\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.07895</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/DeepLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeepLearning</span></a> <a href=\"https://sigmoid.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a> <a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/NLG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLG</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@chengyjonathan",
        "display_name": "Jonathan Cheng"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12665v1",
    "title": "Evaluating the Role of Target Arguments in Rumour Stance Classification",
    "latest": "2023-03-25T23:08:14+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110086435258020633",
      "content": "<p>\ud83d\udcdd Evaluating the Role of Target Arguments in Rumour Stance Classification \ud83d\udcda</p><p>\"Introduces adversarial attacks to test the performance and robustness of RSC models, showing that state-of-the-art models are susceptible to small perturbations in the input.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12665v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12665v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11076",
    "title": "From MNIST to ImageNet and Back: Benchmarking Continual Curriculum Learning",
    "latest": "2023-03-25T21:45:30+00:00",
    "last_post": {
      "url": "https://ellis.social/@nolovedeeplearning/110062631481040414",
      "content": "<p>It's hard to assess <a href=\"https://ellis.social/tags/Continual\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Continual</span></a> <a href=\"https://ellis.social/tags/Learning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Learning</span></a> models and disentangle <a href=\"https://ellis.social/tags/hype\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>hype</span></a> from <a href=\"https://ellis.social/tags/progress\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>progress</span></a>, as the eval landscape is fragmented.</p><p>Even when learning from <a href=\"https://ellis.social/tags/MNIST\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MNIST</span></a> to tiny <a href=\"https://ellis.social/tags/ImageNet\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ImageNet</span></a> (and back) <a href=\"https://ellis.social/tags/sota\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>sota</span></a> models tend to <a href=\"https://ellis.social/tags/catastrophic\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>catastrophic</span></a> <a href=\"https://ellis.social/tags/forget\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>forget</span></a> a lot!</p><p>cc @ContinualAI</p><p>\ud83d\udc49<a href=\"https://arxiv.org/abs/2303.11076\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.11076</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.48550/arXiv.2207.07051",
    "title": "doi.org/10.48550/arXiv.2207.07...",
    "latest": "2023-03-25T21:06:47+00:00",
    "last_post": {
      "url": "https://nerdculture.de/@ByrdNick/110085884627011316",
      "content": "<p>Like humans, an <a href=\"https://nerdculture.de/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> exhibited a logical content effect: </p><p>it was better at <a href=\"https://nerdculture.de/tags/logic\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>logic</span></a> when the tasks were about 'realistic\" (rather than more abstract or \"arbitrary\") stuff.</p><p>Ishita Dasgupta presented the <a href=\"https://nerdculture.de/tags/DeepMind\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeepMind</span></a> team's results.</p><p>Free copy of the paper: <a href=\"https://doi.org/10.48550/arXiv.2207.07051\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.48550/arXiv.2207.07</span><span class=\"invisible\">051</span></a></p><p>This could be a glimpse at a new human-vs-AI <a href=\"https://nerdculture.de/tags/comparativePsychology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>comparativePsychology</span></a>.</p><p>Example: This context effect emerged from a monolithic system. What does this say about <a href=\"https://nerdculture.de/tags/DualProcess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DualProcess</span></a> theories/debates?</p><p><a href=\"https://nerdculture.de/tags/computerScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computerScience</span></a> <a href=\"https://nerdculture.de/tags/DecisionScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DecisionScience</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@lampinen",
        "display_name": "Andrew Lampinen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12582v1",
    "title": "AfroDigits: A Community-Driven Spoken Digit Dataset for African Languages",
    "latest": "2023-03-25T18:53:14+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110085432542226956",
      "content": "<p>\ud83d\udcdd AfroDigits: A Community-Driven Spoken Digit Dataset for African Languages \ud83d\udcda</p><p>\"AfroDigits is a crowd-sourced audio digit dataset for African languages, covering 38 African languages, currently, AfroDigits is the first published audio digit dataset for African languages.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12582v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12582v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/1803.04683.pdf",
    "title": "https://arxiv.org/pdf/1803.04683.pdf",
    "latest": "2023-03-25T17:37:16+00:00",
    "last_post": {
      "url": "https://mamot.fr/@pluralistic/110085133831577969",
      "content": "<p><a href=\"https://mamot.fr/tags/5yrsago\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>5yrsago</span></a> Invisible, targeted infrared light can fool facial recognition software into thinking anyone is anyone else <a href=\"https://arxiv.org/pdf/1803.04683.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/1803.04683.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mamot.fr/tags/5yrsago\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>5yrsago</span></a> London police finally admit they fed intel to UK construction cartel to build illegal <a href=\"https://mamot.fr/tags/blacklist\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>blacklist</span></a> of <a href=\"https://mamot.fr/tags/labour\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>labour</span></a> organisers <a href=\"https://www.theguardian.com/uk-news/2018/mar/23/officers-likely-to-have-passed-personal-files-to-blacklisters-says-met\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">theguardian.com/uk-news/2018/m</span><span class=\"invisible\">ar/23/officers-likely-to-have-passed-personal-files-to-blacklisters-says-met</span></a></p><p><a href=\"https://mamot.fr/tags/5yrsago\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>5yrsago</span></a> Services that deliver the same functions as Facebook, for after you <a href=\"https://mamot.fr/tags/DeleteFacebook\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DeleteFacebook</span></a> <a href=\"https://www.wired.com/story/facebook-alternatives/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">wired.com/story/facebook-alter</span><span class=\"invisible\">natives/</span></a></p><p>9/</p>"
    },
    "people": [
      {
        "url": "https://mamot.fr/@pluralistic",
        "display_name": "Cory Doctorow's linkblog"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/full/10.1177/0003122418762291",
    "title": "journals.sagepub.com/doi/full/...",
    "latest": "2023-03-25T17:36:38+00:00",
    "last_post": {
      "url": "https://mamot.fr/@pluralistic/110085131377501725",
      "content": "<p><a href=\"https://mamot.fr/tags/5yrsago\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>5yrsago</span></a> Cyber-arms-dealer <a href=\"https://mamot.fr/tags/GreyHeron\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GreyHeron</span></a> really, really doesn\u2019t want you to know about the connections between them and the disgraced <a href=\"https://mamot.fr/tags/HackingTeam\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>HackingTeam</span></a> <a href=\"https://www.vice.com/en/article/bjpnad/grey-heron-hacking-team\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">vice.com/en/article/bjpnad/gre</span><span class=\"invisible\">y-heron-hacking-team</span></a></p><p><a href=\"https://mamot.fr/tags/5yrsago\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>5yrsago</span></a> Women (but not men) with high GPAs are less likely to get job offers <a href=\"https://journals.sagepub.com/doi/full/10.1177/0003122418762291\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/full/</span><span class=\"invisible\">10.1177/0003122418762291</span></a></p><p><a href=\"https://mamot.fr/tags/5yrsago\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>5yrsago</span></a> A patchwork of state \u201cincompetence\u201d laws cost tens of thousands of Americans their vote every year <a href=\"https://www.pewtrusts.org/en/research-and-analysis/blogs/stateline/2018/03/21/thousands-lose-right-to-vote-under-incompetence-laws\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">pewtrusts.org/en/research-and-</span><span class=\"invisible\">analysis/blogs/stateline/2018/03/21/thousands-lose-right-to-vote-under-incompetence-laws</span></a></p><p>7/</p>"
    },
    "people": [
      {
        "url": "https://mamot.fr/@pluralistic",
        "display_name": "Cory Doctorow's linkblog"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/20539517231163172",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-03-25T15:31:11+00:00",
    "last_post": {
      "url": "https://mastodon.social/@emaemura/110025540854514751",
      "content": "<p>Just in time for <a href=\"https://mastodon.social/tags/WebArchiveWednesday\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>WebArchiveWednesday</span></a> I'm super excited to have my article \"All WARC and no playback: The materialities of data-centered web archives research\" published Open Access in Big Data &amp; Society! <a href=\"https://journals.sagepub.com/doi/10.1177/20539517231163172\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/20539517231163172</span></a></p>"
    },
    "people": [
      {
        "url": "https://hcommons.social/@librarifran",
        "display_name": "franny gaede"
      },
      {
        "url": "https://sigmoid.social/@TedUnderwood",
        "display_name": "Ted Underwood"
      },
      {
        "url": "https://social.coop/@edsu",
        "display_name": "Ed Summers"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00830-7",
    "title": "Five things I wish academia understood about my social anxiety",
    "latest": "2023-03-25T09:37:51+00:00",
    "last_post": {
      "url": "https://social.cwts.nl/@LudoWaltman/110082687261158734",
      "content": "<p>Five things I wish academia understood about my social anxiety <a href=\"https://www.nature.com/articles/d41586-023-00830-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00830-7</span></a></p><p>\"experiences of people struggling with social anxiety in academia vary widely ... my personal wish ... is for greater understanding and acceptance in academic community. Those of us who falter in conversation, avoid social events and look at ceiling when we speak tend not to give good first impressions. We might seem unfriendly and disengaged ... I sincerely hope that what I\u2019ve shared testifies otherwise.\"</p>"
    },
    "people": [
      {
        "url": "https://masto.ai/@cheng",
        "display_name": "Cheng Soon Ong"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.14045.pdf",
    "title": "https://arxiv.org/pdf/2302.14045.pdf",
    "latest": "2023-03-25T08:27:54+00:00",
    "last_post": {
      "url": "https://techhub.social/@dwaynephillips/109953357520523113",
      "content": "<p>Here is Microsoft's research paper on Kosmos-1.<br><a href=\"https://arxiv.org/pdf/2302.14045.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.14045.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12294v1",
    "title": "https://arxiv.org/abs/2303.12294v1",
    "latest": "2023-03-25T06:08:13+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110082424399838433",
      "content": "<p>\ud83d\udcdd Evaluating Transformer Models and Human Behaviors on Chinese Character Naming \ud83d\udcda</p><p>\"Uses self-attention to learn the mapping between Chinese characters and their pronoums, and predict the pronunciation of unknown characters from their visual forms, with a high correlation with human answers.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/xiaomeng-ma/Chinese-CharacterNaming\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/xiaomeng-ma/Chinese</span><span class=\"invisible\">-CharacterNaming</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12294v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12294v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12220v1",
    "title": "A Unified Taxonomy of Deep Syntactic Relations",
    "latest": "2023-03-25T04:38:15+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110082070632274562",
      "content": "<p>\ud83d\udcdd A Unified Taxonomy of Deep Syntactic Relations \ud83d\udcda</p><p>\"This proposal is focused on the semantic roles of verbal predicates (verbs), adjectival predicates (adjectives), and nominal predicates (nouns).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12220v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12220v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12135v1",
    "title": "Understand Legal Documents with Contextualized Large Language Models",
    "latest": "2023-03-25T01:38:14+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110081362758200175",
      "content": "<p>\ud83d\udcdd Understand Legal Documents with Contextualized Large Language Models \ud83d\udcda</p><p>\"Designs two neural models to address the subtasks, which consider the comprehensive context information in both intra- and inter-sentence levels to predict the rhetorical roles (subtask A) and recognize legal entities (subtask B) of each sentence, respectively.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12135v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12135v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/duzxa/",
    "title": "http://osf.io/duzxa/",
    "latest": "2023-03-25T01:26:47+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110081317756306261",
      "content": "<p>Labor market entry of ethnic minority bachelor's graduates in Germany: the role of human capital, field of study, and search behavior <a href=\"http://osf.io/duzxa/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/duzxa/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/2ehpw/",
    "title": "http://osf.io/2ehpw/",
    "latest": "2023-03-25T01:26:46+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110081317724237689",
      "content": "<p>\"We are the makers of manners\": A grounded approach to data ethics for the built environment <a href=\"http://osf.io/2ehpw/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/2ehpw/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2210.13966.pdf",
    "title": "https://arxiv.org/pdf/2210.13966.pdf",
    "latest": "2023-03-25T01:21:37+00:00",
    "last_post": {
      "url": "https://mastodon.social/@judell/110079398379566252",
      "content": "<p>\"The very terms used by the researchers who named these benchmark assessments\u2014\u201cgeneral language understanding,\u201d \u201cnatural language inference,\u201d \u201creading comprehension,\u201d \u201ccommonsense reasoning,\u201d and so on\u2014reveal an assumption that humanlike understanding is required to perform well on these tasks. But do these tasks actually require such understanding? Not necessarily.\" - <span class=\"h-card\"><a href=\"https://sigmoid.social/@melaniemitchell\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>melaniemitchell</span></a></span>, <a href=\"https://arxiv.org/pdf/2210.13966.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2210.13966.pdf</span><span class=\"invisible\"></span></a></p><p>/cc <span class=\"h-card\"><a href=\"https://opinuendo.com/@matthew\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>matthew</span></a></span>, <span class=\"h-card\"><a href=\"https://wandering.shop/@vaurora\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>vaurora</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@judell",
        "display_name": "Jon Udell"
      },
      {
        "url": "https://scholar.social/@electricarchaeo",
        "display_name": "Shawn Graham"
      }
    ]
  },
  {
    "link": "http://osf.io/rzwd2/",
    "title": "http://osf.io/rzwd2/",
    "latest": "2023-03-25T01:21:07+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110081295457106536",
      "content": "<p>The Geography of Capital Allocation in the Euro Area <a href=\"http://osf.io/rzwd2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/rzwd2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/a3tw5/",
    "title": "http://osf.io/a3tw5/",
    "latest": "2023-03-25T01:21:06+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110081295398671766",
      "content": "<p>Soliciting opinions and solutions on the \" Q Zhang's Problem \" <a href=\"http://osf.io/a3tw5/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/a3tw5/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/dc6yv/",
    "title": "http://osf.io/dc6yv/",
    "latest": "2023-03-25T01:21:06+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110081295427705604",
      "content": "<p>Weight stigma, welfare stigma, and political values: evidence from a representative British survey <a href=\"http://osf.io/dc6yv/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/dc6yv/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/z6gaq/",
    "title": "http://osf.io/z6gaq/",
    "latest": "2023-03-25T01:11:46+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110081258706076491",
      "content": "<p>How NATO Membership Transforms Public Support for War <a href=\"http://osf.io/z6gaq/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/z6gaq/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/w48rf/",
    "title": "http://osf.io/w48rf/",
    "latest": "2023-03-25T01:11:45+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110081258677954554",
      "content": "<p>Transfiguring the Library as Digital Research Infrastructure: Making KBLab at the National Library of Sweden <a href=\"http://osf.io/w48rf/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/w48rf/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00800-z",
    "title": "Why we need a new economics of water as a common good",
    "latest": "2023-03-24T23:55:01+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110080956955223148",
      "content": "<p>We need a new economics of water as a common good - <a href=\"https://www.nature.com/articles/d41586-023-00800-z\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00800-z</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@judell",
        "display_name": "Jon Udell"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/10.1145/3582578",
    "title": "Creating PublicSpaces | Digital Government: Research and Practice",
    "latest": "2023-03-24T20:59:27+00:00",
    "last_post": {
      "url": "https://octodon.social/@ethanz/109864838117063401",
      "content": "<p>Very excited to have published this new article, \"Creating PublicSpaces\" with my friends Jose Van Dijck and Geert-Jan Boegarts about how the Netherlands is taking digital public infrastructure and \"values-led institutions\" seriously, in ACM DGOV. <a href=\"https://dl.acm.org/doi/10.1145/3582578\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">dl.acm.org/doi/10.1145/3582578</span><span class=\"invisible\"></span></a></p><p>GJ is the founder of PublicSpaces, a remarkable coalition of public broadcasters, cultural institutions and other public institutions in the Netherlands, seeking alternatives to commercial, surveillant and closed software.</p><p>Jos\u00e9 and I both advise the group, and we realized we were looking at an interesting market sector: organizations whose values conflict with traditional business models to produce and support software and other digital infrastructures. </p><p>GJ and PublicSpaces have created a model that helps orgs assess what software they're dependent on, how it conflicts with their values and how they might move onto more ideologically consistent infrastructures.</p>"
    },
    "people": [
      {
        "url": "https://octodon.social/@ethanz",
        "display_name": "Ethan Zuckerman"
      },
      {
        "url": "https://mas.to/@leifdenby",
        "display_name": "Leif Denby"
      },
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      },
      {
        "url": "https://fediscience.org/@petersuber",
        "display_name": "petersuber"
      },
      {
        "url": "https://idf.social/@arjen",
        "display_name": "Arjen P. de Vries Timmers \ud83d\udd4a\ufe0f"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13408",
    "title": "Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense",
    "latest": "2023-03-24T20:22:14+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110080120249524935",
      "content": "<p>RT @kalpeshk2011@twitter.com</p><p>To detect text written by LMs like <a href=\"https://sigmoid.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a>, many methods have recently emerged: DetectGPT, watermarks, GPTZero.</p><p>We present a paraphrasing attack that can drop their detection rates to &lt;10%.</p><p>To defend against it, we propose detection with retrieval.<br><a href=\"https://arxiv.org/abs/2303.13408\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13408</span><span class=\"invisible\"></span></a><br>\ud83e\uddf5\ud83d\udc47</p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/kalpeshk2011/status/1639273935719022593\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/kalpeshk2011/statu</span><span class=\"invisible\">s/1639273935719022593</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.11312.pdf",
    "title": "https://arxiv.org/pdf/2303.11312.pdf",
    "latest": "2023-03-24T20:18:31+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@MikeMahoney218/110061133763882297",
      "content": "<p>Very happy to share that:</p><p>+ waywiser, an <a href=\"https://fosstodon.org/tags/rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rstats</span></a> package for assessing models fit to spatial data, is now part of <span class=\"h-card\"><a href=\"https://hachyderm.io/@rOpenSci\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>rOpenSci</span></a></span> !</p><p>+ Version 0.3.0 of waywiser is now on CRAN! This version brings a ton of new functions, speed ups, and consistency improvements.</p><p>+ I posted a preprint describing the math and thinking behind the software over at <a href=\"https://arxiv.org/pdf/2303.11312.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.11312.pdf</span><span class=\"invisible\"></span></a></p><p>I put a bit more about each of these over on the blog: <a href=\"https://www.mm218.dev/posts/2023-03-21-waywiser-ropensci/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">mm218.dev/posts/2023-03-21-way</span><span class=\"invisible\">wiser-ropensci/</span></a></p><p><a href=\"https://fosstodon.org/tags/rspatial\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rspatial</span></a> <a href=\"https://fosstodon.org/tags/OpenSource\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenSource</span></a> <a href=\"https://fosstodon.org/tags/gischat\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gischat</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@juliesquid",
        "display_name": "Dr. Julia Stewart Lowndes"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12060v1",
    "title": "VideoXum: Cross-modal Visual and Textural Summarization of Videos",
    "latest": "2023-03-24T18:59:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110079795431561676",
      "content": "<p>\ud83d\udcdd VideoXum: Cross-Modal Visual and Textural Summarization of Videos \ud83d\udd2d\ud83d\udcda</p><p>\"VTSUM-BILP is an end-to-end model that can generate both video summaries and textual summaries from a long video at the same time in two steps.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12060v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12060v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2203.02155.pdf",
    "title": "https://arxiv.org/pdf/2203.02155.pdf",
    "latest": "2023-03-24T17:21:39+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@cigitalgem/110079409731370344",
      "content": "<p>BIML discusses OpenAI ass covering exercise <a href=\"https://sigmoid.social/tags/MLsec\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MLsec</span></a> and hemispatial neglect (neuroanatomy).  Unrelated?  You decide.</p><p><a href=\"https://arxiv.org/pdf/2203.02155.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2203.02155.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv ML / AI"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1007/s00291-023-00714-2",
    "title": "doi.org/10.1007/s00291-023-007...",
    "latest": "2023-03-24T10:03:27+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@nrennie/110077687078712259",
      "content": "<p>I'm very happy to finally see our paper on \"Outlier detection in network revenue management\" published! \ud83c\udf89</p><p>In it, we define a method for clustering legs in a transport network, detecting outliers in demand within those clusters, and show it works on Deutsche Bahn data \ud83d\ude85\ud83d\ude85\ud83d\ude85</p><p>Link: <a href=\"https://doi.org/10.1007/s00291-023-00714-2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1007/s00291-023-007</span><span class=\"invisible\">14-2</span></a></p><p><a href=\"https://fosstodon.org/tags/RStats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RStats</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@nrennie",
        "display_name": "Nicola Rennie"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12038v1",
    "title": "Grading Conversational Responses Of Chatbots",
    "latest": "2023-03-24T09:29:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110077554066154393",
      "content": "<p>\ud83d\udcdd Grading Conversational Responses of Chatbots \ud83d\udcda\ud83e\udde0</p><p>\"ChatGPT is based on a GPT-3 model which is a transformer-based neural network model trained to predict the next word in a sequence based on the previous text.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12038v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12038v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13496",
    "title": "The effectiveness of MAE pre-pretraining for billion-scale pretraining",
    "latest": "2023-03-24T09:02:10+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077446093926423",
      "content": "<p>The effectiveness of MAE pre-pretraining for billion-scale pretraining</p><p>Achieves new SotA on iNaturalist-18 (91.3%), 1-shot ImageNet-1k (62.1%), and zero-shot transfer on Food-101 (96.0%).</p><p><a href=\"https://arxiv.org/abs/2303.13496\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13496</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13516",
    "title": "Ablating Concepts in Text-to-Image Diffusion Models",
    "latest": "2023-03-24T09:02:08+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077445931163345",
      "content": "<p>Ablating Concepts in Text-to-Image Diffusion Models</p><p><a href=\"https://arxiv.org/abs/2303.13516\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13516</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13506",
    "title": "The Quantization Model of Neural Scaling",
    "latest": "2023-03-24T09:02:05+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077445747307861",
      "content": "<p>The Quantization Model of Neural Scaling</p><p>Attempts to explain the sudden emergence of new capabilities with scale.</p><p><a href=\"https://arxiv.org/abs/2303.13506\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13506</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13455",
    "title": "CoBIT: A Contrastive Bi-directional Image-Text Generation Model",
    "latest": "2023-03-24T09:02:01+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077445517493006",
      "content": "<p>CoBIT: A Contrastive Bi-directional Image-Text Generation Model</p><p>Unifies the three pre-training objectives (contrastive, image-to-text and text-to-image).</p><p><a href=\"https://arxiv.org/abs/2303.13455\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13455</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13508",
    "title": "https://arxiv.org/abs/2303.13508",
    "latest": "2023-03-24T09:01:58+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077445335365578",
      "content": "<p>DreamBooth3D: Subject-Driven Text-to-3D Generation</p><p>Presents DreamBooth3D, an approach to personalize text-to-3D generative models from as few as 3-6 casually captured images of a subject.</p><p>proj: <a href=\"https://dreambooth3d.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">dreambooth3d.github.io/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.13508\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13508</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13505",
    "title": "https://arxiv.org/abs/2303.13505",
    "latest": "2023-03-24T09:01:51+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077444859194520",
      "content": "<p>A Large-scale Study of Spatiotemporal Representation Learning with a New Benchmark on Action Recognition</p><p>repo: <a href=\"https://github.com/AndongDeng/BEAR\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/AndongDeng/BEAR</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.13505\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13505</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13439",
    "title": "https://arxiv.org/abs/2303.13439",
    "latest": "2023-03-24T09:01:49+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077444708691467",
      "content": "<p>Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators</p><p>repo: <a href=\"https://github.com/Picsart-AI-Research/Text2Video-Zero\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/Picsart-AI-Research</span><span class=\"invisible\">/Text2Video-Zero</span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.13439\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13439</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13519",
    "title": "Learning and Verification of Task Structure in Instructional Videos",
    "latest": "2023-03-24T09:01:46+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110077444492190630",
      "content": "<p>Learning and Verification of Task Structure in Instructional Videos</p><p>Presents VideoTaskformer, a video model focused on representing the semantics and structure of instructional videos.</p><p>abs: <a href=\"https://arxiv.org/abs/2303.13519\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13519</span><span class=\"invisible\"></span></a><br>proj: <a href=\"https://medhini.github.io/task_structure/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">medhini.github.io/task_structu</span><span class=\"invisible\">re/</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12779",
    "title": "LFM-3D: Learnable Feature Matching Across Wide Baselines Using 3D Signals",
    "latest": "2023-03-24T08:12:40+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@kornia_foss/110077246350818756",
      "content": "<p>LFM-3D: Learnable Feature Matching Across Wide Baselines Using 3D Signals</p><p>Arjun Karpur, Guilherme Perrotta, Ricardo Martin-Brualla, Howard Zhou, Andre Araujo</p><p>tl;dr: SuperGlue meets monodepth for matching objects, not scenes.<br><a href=\"https://sigmoid.social/tags/kornia\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>kornia</span></a> used for LoFTR baseline.</p><p><a href=\"https://arxiv.org/abs/2303.12779\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12779</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.12799.pdf",
    "title": "https://arxiv.org/pdf/2303.12799.pdf",
    "latest": "2023-03-24T07:04:57+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110076985202660378",
      "content": "<p>Time Series as Images: Vision Transformer for Irregularly Sampled Time Series</p><p>Zekun Li, Shiyang Li, Xifeng Yan</p><p>tl;dr: in title. Oh, how cool would if there was a transformer for sequence data, right?)</p><p><a href=\"https://arxiv.org/pdf/2303.12799.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.12799.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13515.pdf",
    "title": "Persistent Nature: A Generative Model of Unbounded 3D Worlds",
    "latest": "2023-03-24T06:57:57+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110076957661266317",
      "content": "<p>Persistent Nature: A Generative Model of Unbounded 3D Worlds</p><p>Lucy Chai, Richard Tucker, Zhengqi Li, Phillip Isola, Noah Snavely</p><p>tl;dr: DeepDream is good, but for 3D consistency it is better to use 3D geometry :)<br><a href=\"https://arxiv.org/abs/2303.13515.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13515.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a> <a href=\"https://sigmoid.social/tags/CVPR2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CVPR2023</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1016/j.metip.2023.100120",
    "title": "doi.org/10.1016/j.metip.2023.1...",
    "latest": "2023-03-24T06:30:02+00:00",
    "last_post": {
      "url": "https://fediscience.org/@MarkRubin/110072468005414073",
      "content": "<p>Multiple Testing:</p><p>New article discusses the \u201cuse and misuse of corrections for multiple testing.\u201d</p><p>\u201cIn general, avoid corrections for multiple testing if statistical claims are to be made for each individual test...\u201d</p><p><a href=\"https://doi.org/10.1016/j.metip.2023.100120\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1016/j.metip.2023.1</span><span class=\"invisible\">00120</span></a></p><p><a href=\"https://fediscience.org/tags/Stats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Stats</span></a><br><a href=\"https://fediscience.org/tags/Statistics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Statistics</span></a><br><a href=\"https://fediscience.org/tags/MultipleTesting\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MultipleTesting</span></a> <br><a href=\"https://fediscience.org/tags/MultipleComparisons\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MultipleComparisons</span></a><br><a href=\"https://fediscience.org/tags/NHST\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NHST</span></a></p>"
    },
    "people": [
      {
        "url": "https://scicomm.xyz/@sharoz",
        "display_name": "Steve Haroz (@sharoz on \ud83d\udc24)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12024v1",
    "title": "cTBL: Augmenting Large Language Models for Conversational Tables",
    "latest": "2023-03-24T03:44:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110076197219103981",
      "content": "<p>\ud83d\udcdd cTBL: Augmenting Large Language Models for Conversational Tables \ud83d\udcda\ud83d\udc7e</p><p>\"Introduces Conversational Tables (cTBL), a three-step encoder-decoder approach to retrieve tabular information and generate dialogue responses grounded on the retrieved information.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12024v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12024v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00866-9",
    "title": "Hate working weekends? Try a time tracker",
    "latest": "2023-03-24T02:18:20+00:00",
    "last_post": {
      "url": "https://aus.social/@thesiswhisperer/110075653577042935",
      "content": "<p>Just a little thing I wrote for Nature about time tracking software. By the by, I have never been so fact checked and edited in my life - they refused to let me use 'fuck' too. Ha! <a href=\"https://www.nature.com/articles/d41586-023-00866-9\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00866-9</span></a></p>"
    },
    "people": [
      {
        "url": "https://aus.social/@KathyReid",
        "display_name": "Kathy Reid"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.10798",
    "title": "An aperiodic monotile",
    "latest": "2023-03-24T00:15:12+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@csk/110058807978537887",
      "content": "<p>In a new paper, David Smith, Joseph Myers (<span class=\"h-card\"><a href=\"https://mathstodon.xyz/@jsm28\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>jsm28</span></a></span>), Chaim Goodman-Strauss and I prove that a polykite that we call \"the hat\" is an aperiodic monotile, AKA an einstein. We finally got down to 1!  <a href=\"https://arxiv.org/abs/2303.10798\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.10798</span><span class=\"invisible\"></span></a> 4/6</p>"
    },
    "people": [
      {
        "url": "https://mastodon.art/@mtyka",
        "display_name": "Mike Tyka"
      },
      {
        "url": "https://hachyderm.io/@jtth",
        "display_name": "jordan t t-h"
      },
      {
        "url": "https://mathstodon.xyz/@csk",
        "display_name": "Craig S. Kaplan"
      },
      {
        "url": "https://mastodon.gamedev.place/@zarfeblong",
        "display_name": "Andrew Plotkin"
      },
      {
        "url": "https://recsys.social/@Randy_Au",
        "display_name": "Randy Au \ud83d\ude43"
      },
      {
        "url": "https://hackers.town/@fbz",
        "display_name": "fbz"
      },
      {
        "url": "https://mathstodon.xyz/@noneuclideandreamer",
        "display_name": "Non-Euclidean Dreamer"
      },
      {
        "url": "https://mastodon.social/@bcamper",
        "display_name": "Brett Camper"
      },
      {
        "url": "https://mastodon.social/@tjl",
        "display_name": "Tom Lee"
      },
      {
        "url": "https://an.errant.cloud/@ted",
        "display_name": "Ted Han \u2605 \u97d3\u8056\u5b89"
      },
      {
        "url": "https://tech.lgbt/@_dmh",
        "display_name": "Dave Howcroft \ud83e\udd94"
      },
      {
        "url": "https://mastodon.social/@ada",
        "display_name": "Ada Rose Cannon"
      },
      {
        "url": "https://social.coop/@natematias",
        "display_name": "J. Nathan Matias \ud83e\udda3"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12023v1",
    "title": "https://arxiv.org/abs/2303.12023v1",
    "latest": "2023-03-23T23:44:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110075253385408513",
      "content": "<p>\ud83d\udcdd Logical Reasoning Over Natural Language as Knowledge Representation: A Survey \ud83d\udcda\ud83d\udc7e</p><p>\"A new paradigm to conduct logical reasoning using natural lanugage as knowledge representation and pre-trained language models as reasoners, in contrast to traditional logical reasoning using formal language representations and symbolic reasoners.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/ZonglinY/LRNL-bench.git\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/ZonglinY/LRNL-bench</span><span class=\"invisible\">.git</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.12023v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12023v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/23\u2026",
    "title": "https://arxiv.org/abs/23\u2026",
    "latest": "2023-03-23T23:32:10+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ceperez/110075204796142751",
      "content": "<p>This seems to solve one of the problems with GPT-4  that Microsoft researchers mentioned.  I guess we'll just have to wait for either GPT-5 or GPT-6. <br>---<br>RT @rasbt<br>\"Meet in the Middle: A New Pre-training Paradigm\" for large language models (LLM). <br>In this paper, the authors propose to develop a bidirectional LLM using the full sequence information during pretraining and using context from both sides during inference. <a href=\"https://arxiv.org/abs/23\u2026\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/23\u2026</span><span class=\"invisible\"></span></a><br><a href=\"https://twitter.com/rasbt/status/1638538494887821313\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/rasbt/status/16385</span><span class=\"invisible\">38494887821313</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11812v1",
    "title": "Chinese Intermediate English Learners outdid ChatGPT in deep cohesion: Evidence from English narrative writing",
    "latest": "2023-03-23T20:59:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110074604908832075",
      "content": "<p>\ud83d\udcdd Chinese Intermediate English Learners Outdid ChatGPT in Deep Cohesion: Evidence From English Narrative Writing \ud83d\udcda</p><p>\"Based on GPT-2 that is an advanced text generation technique based on neural networks (Nguyen and Joty, 2019).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.11812v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.11812v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.10798.pdf",
    "title": "https://arxiv.org/pdf/2303.10798.pdf",
    "latest": "2023-03-23T20:29:46+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@Danpiker/110074146734544114",
      "content": "<p>Similar to what Yoshiaki Araki showed for the H/T/P/F metatiles (<a href=\"https://twitter.com/alytile/status/1638093633080692736\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/alytile/status/163</span><span class=\"invisible\">8093633080692736</span></a>), these are the 2 fractal tiles for the substitution system in figure 2.11 of the monotile paper (<a href=\"https://arxiv.org/pdf/2303.10798.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.10798.pdf</span><span class=\"invisible\"></span></a>).</p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@csk",
        "display_name": "Craig S. Kaplan"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1080/00221546.2023.2187177",
    "title": "doi.org/10.1080/00221546.2023....",
    "latest": "2023-03-23T20:14:40+00:00",
    "last_post": {
      "url": "https://mastodon.social/@jeffgreene/110072525200949178",
      "content": "<p>Maybe there's value in a standardized assessment of people's likelihood of completing graduate work, which could help us make more equitable and accurate decisions, but the GRE simply isn't it? <a href=\"https://doi.org/10.1080/00221546.2023.2187177\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/00221546.2023.</span><span class=\"invisible\">2187177</span></a></p><p><a href=\"https://mastodon.social/tags/education\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>education</span></a> <a href=\"https://mastodon.social/tags/psychology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>psychology</span></a> <a href=\"https://mastodon.social/tags/EducationalPsychology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>EducationalPsychology</span></a> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/edutooters\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>edutooters</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/psychology\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>psychology</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://vis.social/@jbryer",
        "display_name": "Jason Bryer"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1029/2023GL102940",
    "title": "https://doi.org/10.1029/2023GL102940",
    "latest": "2023-03-23T19:46:00+00:00",
    "last_post": {
      "url": "https://glammr.us/@ppival/110074315463027697",
      "content": "<p>Stanford study finds wastewater disposal from oil production triggered major earthquake in Canada <a href=\"https://news.stanford.edu/press/view/46934\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">news.stanford.edu/press/view/4</span><span class=\"invisible\">6934</span></a></p><p>I so fukkin' hate it when a press release doesn't include a link to the OPEN ACCESS article, which is at <a href=\"https://doi.org/10.1029/2023GL102940\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1029/2023GL102940</span><span class=\"invisible\"></span></a>  <a href=\"https://glammr.us/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> </p><p>\"Energy regulators for the region described the earthquake as a natural tectonic event. A rigorous new analysis by Stanford geophysicists suggests, however...\"</p>"
    },
    "people": [
      {
        "url": "https://glammr.us/@ppival",
        "display_name": "Paul R. Pival (he/him)"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11750v1",
    "title": "https://arxiv.org/abs/2303.11750v1",
    "latest": "2023-03-23T18:29:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110074015080751974",
      "content": "<p>\ud83d\udcdd LEAPT: Learning Adaptive Prefix-to-Prefix Translation for Simultaneous Machine Translation \ud83d\udcda</p><p>\"A novel prefix-to-prefix training policy called LEAPT is used to train the simultaneous machine translation model to predict the future context and achieve good performance on accuracy and latency.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/fxsjy/jieba\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/fxsjy/jieba</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.11750v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.11750v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/em3js/",
    "title": "http://osf.io/em3js/",
    "latest": "2023-03-23T17:42:05+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110073828185155549",
      "content": "<p>Decentralization, Ethnic Fractionalization, and Public Services: Evidence from Kenyan Healthcare <a href=\"http://osf.io/em3js/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/em3js/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/h37dy/",
    "title": "http://osf.io/h37dy/",
    "latest": "2023-03-23T17:42:05+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110073828209290844",
      "content": "<p>The Effects of Time-Averaging on Archaeological Networks <a href=\"http://osf.io/h37dy/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/h37dy/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/nrbgp/",
    "title": "http://osf.io/nrbgp/",
    "latest": "2023-03-23T17:36:30+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110073806219869550",
      "content": "<p>Marx's Primitive Accumulation as a perspective on Nature, Race and Gender <a href=\"http://osf.io/nrbgp/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/nrbgp/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/xzqgh/",
    "title": "http://osf.io/xzqgh/",
    "latest": "2023-03-23T17:36:29+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110073806186291553",
      "content": "<p>The state of the Mental Health related conditions among the Scheduled Tribes and the Culture-Specific approaches and methods they apply for the Management of such conditions: A Bibliographic essay catering to the contemporary trends in Mental Health research in India. <a href=\"http://osf.io/xzqgh/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/xzqgh/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://doi.org/10.46430/phen0107",
    "title": "https://doi.org/10.46430/phen0107",
    "latest": "2023-03-23T17:25:44+00:00",
    "last_post": {
      "url": "https://hcommons.social/@proghist/110073732224328693",
      "content": "<p>Looking for an <a href=\"https://hcommons.social/tags/OpenSource\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenSource</span></a> solution to merge PDFs?</p><p>Christopher Goodwin\u2019s newly-published <span class=\"h-card\"><a href=\"https://hcommons.social/@proghist\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>proghist</span></a></span> lesson teaches you how to create a GUI using Qt Designer and <a href=\"https://hcommons.social/tags/Python\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Python</span></a>.</p><p>\u25b6\ufe0f <a href=\"https://doi.org/10.46430/phen0107\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.46430/phen0107</span><span class=\"invisible\"></span></a></p><p>Thanks to Yann Ryan, Telma Peura and <span class=\"h-card\"><a href=\"https://mstdn.social/@lizfischer\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>lizfischer</span></a></span>!</p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@NikaShilobod",
        "display_name": "Nika Shilobod"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2001.08361",
    "title": "Scaling Laws for Neural Language Models",
    "latest": "2023-03-23T17:22:04+00:00",
    "last_post": {
      "url": "https://social.skewed.de/@tiago/110073749484168195",
      "content": "<p>I'm baffled by the \u201cScaling Laws for Neural Language Models\u201d paper: <a href=\"https://arxiv.org/abs/2001.08361\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2001.08361</span><span class=\"invisible\"></span></a></p><p>They claim to find power laws for the loss L ~ 1/N^a, where N is the number of params/data/compute.</p><p>However, all plots look like below. That's obviously a log decay, not a PL! \ud83d\udc40</p><p>They squeeze a tiny range \u2014 less than a decade \u2014 on the y-axis, and put on a log-scale. But on a linear-log it would look nearly identical. Basic log-log fail!</p><p>A scaling of the type L \u221d-log(N) would be far more realistic, and the interpretation is *radically* different.</p><p>In other words, in order for the loss to decay by a constant, the number of parameters/data/compute need to be multiplied by a proportional constant.</p><p>This means that the number of parameters/dataset/compute need to keep growing *exponentially* for steady progress to be seen!</p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12132",
    "title": "Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense",
    "latest": "2023-03-23T16:59:47+00:00",
    "last_post": {
      "url": "https://mastodon.social/@andrei_chiffa/110073538362121135",
      "content": "<p>The first public CYD report on implications of LLMs for cyber-defense and cyber-security is out.</p><p>Written with and for <span class=\"h-card\"><a href=\"https://infosec.exchange/@cydcampus\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cydcampus</span></a></span>, we do a quick dive into modern LLM principles, limitations resulting from them, current architectures and their uses and what we think this all means for cyber-defense and cyber-security (Swiss and globally).</p><p><a href=\"https://arxiv.org/abs/2303.12132\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12132</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://vis.social/@dr_tj",
        "display_name": "Dr. T.J. Jankun-Kelly"
      },
      {
        "url": "https://dair-community.social/@timnitGebru",
        "display_name": "Timnit Gebru (she/her)"
      }
    ]
  }
]