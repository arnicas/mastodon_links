[
  {
    "link": "https://arxiv.org/pdf/2212.06094",
    "title": "https://arxiv.org/pdf/2212.06094",
    "latest": "2023-04-06T09:45:57+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@lmqllang/110151193232071413",
      "content": "<p>\ud83e\uddf56/6 LMQL was also accepted as a research paper at this year's ACM PLDI'23. Check out the paper and make sure to follow <span class=\"h-card\"><a href=\"https://sigmoid.social/@lmqllang\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>lmqllang</span></a></span> for more updates in the coming days.</p><p>\ud83d\udcd1 Paper: <a href=\"https://arxiv.org/pdf/2212.06094\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2212.06094</span><span class=\"invisible\"></span></a><br>\ud83d\udcd6 Docs: <a href=\"http://docs.lmql.ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">docs.lmql.ai</span><span class=\"invisible\"></span></a><br>\u26a1\ufe0f Playground IDE: <a href=\"http://lmql.ai/playground\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">lmql.ai/playground</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.02016v1",
    "title": "The Multimodal And Modular Ai Chef: Complex Recipe Generation From Imagery",
    "latest": "2023-04-06T09:18:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110151120392311639",
      "content": "<p>\ud83d\udcdd The Multimodal and Modular Ai Chef: Complex Recipe Generation From Imagery \ud83d\udcda\ud83d\udd2d\ud83e\udde0</p><p>\"To submit a list of objects in a picture of a refrigerator to a language model to generate novel recipe cards tailored to complex constraints on cost, preparation time, dietary restrictions and portion sizes.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.02016v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.02016v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://link.springer.com/series/14749/books",
    "title": "New Directions in Book History | Book titles in this series",
    "latest": "2023-04-06T08:50:49+00:00",
    "last_post": {
      "url": "https://mastodon.social/@dbellingradt/110151011501730429",
      "content": "<p><a href=\"https://mastodon.social/tags/Servicetoot\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Servicetoot</span></a>: For those <a href=\"https://mastodon.social/tags/histodons\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>histodons</span></a> interested in <a href=\"https://mastodon.social/tags/bookhistory\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>bookhistory</span></a>, you might want to check the Hardcover-Sale of the (normally way too expensive) publisher PalgraveMacMillan. For example, all books and volumes of the series \"New Directions in Book History\" are 25 Euro, including my \"Books in Motion in Early Modern Europe\" and \"Magical Manuscripts\": <a href=\"https://link.springer.com/series/14749/books\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/series/14749</span><span class=\"invisible\">/books</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.scot/@vivdunstan",
        "display_name": "Vivienne Dunstan"
      },
      {
        "url": "https://mastodon.social/@dbellingradt",
        "display_name": "Daniel Bellingradt :mastodon:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.02015v1",
    "title": "https://arxiv.org/abs/2304.02015v1",
    "latest": "2023-04-06T08:33:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110150943528616476",
      "content": "<p>\ud83d\udcdd How Well Do Large Language Models Perform in Arithmetic Tasks? \ud83d\udcda\ud83d\udc7e</p><p>\"The dataset is a collection of math word problems designed to evaluate the ability of the latest large language models in arithmetic expression understanding via chain-of-thought generation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/GanjinZero/math401-llm\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/GanjinZero/math401-</span><span class=\"invisible\">llm</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.02015v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.02015v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/497zg/",
    "title": "http://osf.io/497zg/",
    "latest": "2023-04-06T08:23:59+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150905978367544",
      "content": "<p>Blog Data Analytics Using Blogtrackers <a href=\"http://osf.io/497zg/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/497zg/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/n7pbj/",
    "title": "http://osf.io/n7pbj/",
    "latest": "2023-04-06T08:23:58+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150905906799077",
      "content": "<p>Biodiversity Risk <a href=\"http://osf.io/n7pbj/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/n7pbj/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/vahny/",
    "title": "http://osf.io/vahny/",
    "latest": "2023-04-06T08:23:58+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150905940901652",
      "content": "<p>Capital as 'fetish value' has no 'true value': Beyond the Divide between the Analytical and the Normative <a href=\"http://osf.io/vahny/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/vahny/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/ev2m3/",
    "title": "http://osf.io/ev2m3/",
    "latest": "2023-04-06T08:23:57+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150905861568903",
      "content": "<p>Labor Redefined: Toward a Commonist Value Theory of Labor under and beyond Capital <a href=\"http://osf.io/ev2m3/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ev2m3/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/49jtf/",
    "title": "http://osf.io/49jtf/",
    "latest": "2023-04-06T08:23:57+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150905887892812",
      "content": "<p>Personal Educational Relationships: An Ethnographic Study on Private Music Lessons at the Collegiate Level <a href=\"http://osf.io/49jtf/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/49jtf/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/m6dpg/",
    "title": "http://osf.io/m6dpg/",
    "latest": "2023-04-06T08:16:42+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150877316610827",
      "content": "<p>Repeated Exposure and Protest Outcomes: How Fridays for Future Protests Influenced Voters <a href=\"http://osf.io/m6dpg/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/m6dpg/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/ua9p4/",
    "title": "http://osf.io/ua9p4/",
    "latest": "2023-04-06T08:16:41+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150877272539758",
      "content": "<p>Impacts Beyond Penal Population: Mass Incarceration and Trust in the Criminal Justice System <a href=\"http://osf.io/ua9p4/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ua9p4/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/xrwz8/",
    "title": "http://osf.io/xrwz8/",
    "latest": "2023-04-06T08:16:41+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150877294117102",
      "content": "<p>Resolving the Ethical Quagmire of the Persistent Vegetative State <a href=\"http://osf.io/xrwz8/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/xrwz8/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.02643",
    "title": "Segment Anything",
    "latest": "2023-04-06T08:12:22+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ogrisel/110150860306735568",
      "content": "<p>The Segment Anything project is really impressive. It's:</p><p>- a computer vision task: segment all areas in an image for any class of object &amp; background.<br>- a paper describing the task, model and dataset<br>  <a href=\"https://arxiv.org/abs/2304.02643\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.02643</span><span class=\"invisible\"></span></a><br>- a very large dataset (11M images!):<br>  <a href=\"https://segment-anything.com/dataset/index.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">segment-anything.com/dataset/i</span><span class=\"invisible\">ndex.html</span></a><br>- a model published as a running demo (the model runs in the browser):<br>  <a href=\"https://segment-anything.com/demo\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">segment-anything.com/demo</span><span class=\"invisible\"></span></a></p><p>The dataset and model where co-developed (model in the loop) to iteratively improve both via active learning.</p>"
    },
    "people": [
      {
        "url": "https://mstdn.social/@arnicas",
        "display_name": "arnicas"
      },
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12712",
    "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
    "latest": "2023-04-06T08:10:54+00:00",
    "last_post": {
      "url": "https://graz.social/@Dorianix/110119483703194384",
      "content": "<p>\"Sparks of Artificial General Intelligence: <br>Early experiments with GPT-4\"</p><p>Das offizielle Microsoft-Paper zu GPT-4 ist spannend zu lesen.</p><p>Mitnehmen kann man Strategien f\u00fcr Prompt-Design, Ideen f\u00fcr Anwendungsbereiche und einige kuriose Beispiele.</p><p><a href=\"https://graz.social/tags/gpt4\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gpt4</span></a> <a href=\"https://graz.social/tags/paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>paper</span></a> <a href=\"https://graz.social/tags/llm\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>llm</span></a> </p><p><a href=\"https://arxiv.org/abs/2303.12712#\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12712#</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      },
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/75gs6/",
    "title": "http://osf.io/75gs6/",
    "latest": "2023-04-06T08:08:34+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150845365500195",
      "content": "<p>Preprints as a medium for public debate on the COVID-19 pandemic: Observations on the blurring of internal and external scientific communication <a href=\"http://osf.io/75gs6/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/75gs6/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/phf2e/",
    "title": "http://osf.io/phf2e/",
    "latest": "2023-04-06T08:08:33+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150845314195250",
      "content": "<p>Better close to home? Geographical and socioeconomic constraints on gendered educational transitions at the upper secondary level <a href=\"http://osf.io/phf2e/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/phf2e/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/xb6vq/",
    "title": "http://osf.io/xb6vq/",
    "latest": "2023-04-06T08:01:50+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150818908382491",
      "content": "<p>The Average Uneven Mortality index: Building on the \"e-dagger\" measure of lifespan inequality <a href=\"http://osf.io/xb6vq/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/xb6vq/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/9aycp/",
    "title": "http://osf.io/9aycp/",
    "latest": "2023-04-06T08:01:49+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110150818853050132",
      "content": "<p>Working Conditions in Platform Work: Testing Digital Platform Workers' Rights on Platform Cooperatives <a href=\"http://osf.io/9aycp/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/9aycp/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01393",
    "title": "Every Author as First Author",
    "latest": "2023-04-06T07:40:03+00:00",
    "last_post": {
      "url": "https://social.skewed.de/@tiago/110150733239772082",
      "content": "<p><a href=\"https://arxiv.org/abs/2304.01393\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01393</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      },
      {
        "url": "https://fediscience.org/@bendfulcher",
        "display_name": "bendfulcher"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2210.13966.pdf",
    "title": "https://arxiv.org/pdf/2210.13966.pdf",
    "latest": "2023-04-06T06:14:33+00:00",
    "last_post": {
      "url": "https://mastodon.social/@judell/110079398379566252",
      "content": "<p>\"The very terms used by the researchers who named these benchmark assessments\u2014\u201cgeneral language understanding,\u201d \u201cnatural language inference,\u201d \u201creading comprehension,\u201d \u201ccommonsense reasoning,\u201d and so on\u2014reveal an assumption that humanlike understanding is required to perform well on these tasks. But do these tasks actually require such understanding? Not necessarily.\" - <span class=\"h-card\"><a href=\"https://sigmoid.social/@melaniemitchell\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>melaniemitchell</span></a></span>, <a href=\"https://arxiv.org/pdf/2210.13966.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2210.13966.pdf</span><span class=\"invisible\"></span></a></p><p>/cc <span class=\"h-card\"><a href=\"https://opinuendo.com/@matthew\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>matthew</span></a></span>, <span class=\"h-card\"><a href=\"https://wandering.shop/@vaurora\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>vaurora</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@judell",
        "display_name": "Jon Udell"
      },
      {
        "url": "https://scholar.social/@electricarchaeo",
        "display_name": "Shawn Graham"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.08073",
    "title": "Constitutional AI: Harmlessness from AI Feedback",
    "latest": "2023-04-06T05:29:32+00:00",
    "last_post": {
      "url": "https://scholar.social/@joakinen/110043669641385820",
      "content": "<p>\"As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'.\"</p><p>[2212.08073] Constitutional AI: Harmlessness from AI Feedback<br><a href=\"https://arxiv.org/abs/2212.08073#\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.08073#</span><span class=\"invisible\"></span></a></p><p><a href=\"https://scholar.social/tags/aitraining\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>aitraining</span></a> <a href=\"https://scholar.social/tags/aiethics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>aiethics</span></a> <a href=\"https://scholar.social/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.15056",
    "title": "ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks",
    "latest": "2023-04-06T05:15:44+00:00",
    "last_post": {
      "url": "https://mastodon.social/@fgilardi/110144907913291130",
      "content": "<p>Paper: <a href=\"https://arxiv.org/abs/2303.15056\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.15056</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00958-6",
    "title": "Tourist season",
    "latest": "2023-04-06T03:30:29+00:00",
    "last_post": {
      "url": "https://wandering.shop/@MarissaLingen/110146466346050910",
      "content": "<p>I'm sorry to tell you that the new story I have today in Nature Futures features humans. UGH, HUMANS. WHO CAN EVEN WITH THEM. Don't worry, there are other species too: <a href=\"https://www.nature.com/articles/d41586-023-00958-6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00958-6</span></a></p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@markgritter",
        "display_name": "Mark Gritter"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/epdf/10.1080/17513472.2023.2191572",
    "title": "tandfonline.com/doi/epdf/10.10...",
    "latest": "2023-04-06T03:26:20+00:00",
    "last_post": {
      "url": "https://ciberlandia.pt/@villares/110123876632324473",
      "content": "<p>Research Article<br>Knitted origami<br>Elizabeth L. Wilmer</p><p>\"Techniques are presented for embedding horizontal, vertical, and45\u25e6diagonal crease lines into garter stitch knitted fabric. While theseare mostly based on standard lace knitting stitches, the horizon-tal creases use double-cable-crossed elongated stitches in a non-standard way. This crease library suffices to knit a model of a squaretwist, a foundational origami tessellation unit.\"</p><p><a href=\"https://www.tandfonline.com/doi/epdf/10.1080/17513472.2023.2191572\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/epdf/10.10</span><span class=\"invisible\">80/17513472.2023.2191572</span></a></p>"
    },
    "people": [
      {
        "url": "https://ravenation.club/@AlgoCompSynth",
        "display_name": "AlgoCompSynth by znmeb #MaskUp"
      },
      {
        "url": "https://vis.social/@Justin_Lind",
        "display_name": "Justin Lind"
      },
      {
        "url": "https://dair-community.social/@trochee",
        "display_name": "Jeremy Kahn"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2209.15259",
    "title": "SoK: On the Impossible Security of Very Large Foundation Models",
    "latest": "2023-04-06T02:44:31+00:00",
    "last_post": {
      "url": "https://mastodon.social/@elmahdi/110112833938106747",
      "content": "<p>On the large AI models, this preprint synthesises what we know so far <a href=\"https://arxiv.org/abs/2209.15259\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2209.15259</span><span class=\"invisible\"></span></a></p><p>In short: it is mathematically impossible to have AIs combining the following properties:</p><p>1) High number of parameters<br>2) Robustness to poisoning (e.g. fake data)<br>3) Privacy-preserving</p>"
    },
    "people": [
      {
        "url": "https://wien.rocks/@AxelPolleres",
        "display_name": "AxelPolleres (Q54860587)"
      },
      {
        "url": "https://dair-community.social/@timnitGebru",
        "display_name": "Timnit Gebru (she/her)"
      },
      {
        "url": "https://scholar.social/@electricarchaeo",
        "display_name": "Shawn Graham"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.11049",
    "title": "Framework for Certification of AI-Based Systems",
    "latest": "2023-04-06T02:29:33+00:00",
    "last_post": {
      "url": "https://techhub.social/@dwaynephillips/109948158975977195",
      "content": "<p>In many industries, software is rigorously certified before it is released. This has not been the case in the vast majority of AI-related work.<br><a href=\"https://arxiv.org/abs/2302.11049\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.11049</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/ftp/arxiv/papers/2304/2304.02020.pdf",
    "title": "arxiv.org/ftp/arxiv/papers/230...",
    "latest": "2023-04-06T01:57:14+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/110149385191141878",
      "content": "<p>\"A Bibliometric Review of Large Language Models Research from 2017 to 2023\"</p><p><a href=\"https://arxiv.org/ftp/arxiv/papers/2304/2304.02020.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">arxiv.org/ftp/arxiv/papers/230</span><span class=\"invisible\">4/2304.02020.pdf</span></a></p><p><a href=\"https://mastodon.radio/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2209.15259.pdf",
    "title": "https://arxiv.org/pdf/2209.15259.pdf",
    "latest": "2023-04-06T01:10:21+00:00",
    "last_post": {
      "url": "https://dair-community.social/@timnitGebru/110147589284016869",
      "content": "<p>I haven't yet had a chance to dig into this pre-print but I know from <span class=\"h-card\"><a href=\"https://mastodon.social/@elmahdi\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>elmahdi</span></a></span> its been in the works for a while now, so looking forward to reading. Although I wouldn't call them foundation models. I'd call them multimodal pretrained models, or anything that doesn't confuse people further about them being close to foundational.<br><a href=\"https://arxiv.org/pdf/2209.15259.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2209.15259.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://dair-community.social/@timnitGebru",
        "display_name": "Timnit Gebru (she/her)"
      },
      {
        "url": "https://mastodon.online/@manuchis",
        "display_name": "manuchis"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00363v1",
    "title": "https://arxiv.org/abs/2304.00363v1",
    "latest": "2023-04-06T00:46:50+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110149108426561008",
      "content": "<p>\ud83d\udcdd Automatic Authorship Attribution in the Work of Tirso De Molina \ud83d\udcda</p><p>\"Automatic Authorship Attribution (AAA) is the result of applying tools and techniques from Digital Humanities to authorship attribution studies, which through a quantitative and statistical approach draw further conclusions about renowned authorship issues which traditional critics have been dealing with for centuries.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/gamallo/Autoria\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/gamallo/Autoria</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.00363v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.00363v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.02642",
    "title": "Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models",
    "latest": "2023-04-06T00:36:13+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110149066636746820",
      "content": "<p>Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models</p><p>Synthesizes images with compelling output quality, appearance diversity, and object fidelity, without the need of test-time optimization</p><p><a href=\"https://arxiv.org/abs/2304.02642\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.02642</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1093/jcmc/zmad002",
    "title": "https://doi.org/10.1093/jcmc/zmad002",
    "latest": "2023-04-06T00:23:28+00:00",
    "last_post": {
      "url": "https://hci.social/@jeremy/110148207595642091",
      "content": "<p>The vast, vast majority of attempts to build communities online (open source projects, wikis, subreddits, etc.) don't really go anywhere. Very few get more than a few contributions from a few contributors. Why do so many fail?</p><p>\ud83e\uddf5 about our newly published paper (with <span class=\"h-card\"><a href=\"https://social.coop/@aaronshaw\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>aaronshaw</span></a></span> and <span class=\"h-card\"><a href=\"https://social.coop/@mako\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mako</span></a></span>)</p><p><a href=\"https://doi.org/10.1093/jcmc/zmad002\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1093/jcmc/zmad002</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://social.coop/@communitydata",
        "display_name": "Community Data Science"
      },
      {
        "url": "https://hci.social/@jeremy",
        "display_name": "Jeremy Foote \ud83e\uddb6"
      },
      {
        "url": "https://mastodon.social/@schmudde",
        "display_name": "D. Schmudde"
      },
      {
        "url": "https://aus.social/@KathyReid",
        "display_name": "Kathy Reid"
      },
      {
        "url": "https://hci.social/@andresmh",
        "display_name": "Andr\u00e9s Monroy-Hern\u00e1ndez"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17580",
    "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace",
    "latest": "2023-04-06T00:20:45+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@Jose_A_Alonso/110128934505259754",
      "content": "<p>HuggingGPT: Solving AI tasks with ChatGPT and its friends in HuggingFace. ~ Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang. <a href=\"https://arxiv.org/abs/2303.17580\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17580</span><span class=\"invisible\"></span></a> <a href=\"https://mathstodon.xyz/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://mathstodon.xyz/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.13971v1",
    "title": "LLaMA: Open and Efficient Foundation Language Models",
    "latest": "2023-04-05T21:59:32+00:00",
    "last_post": {
      "url": "https://mast.eu.org/@martin1975/110034596213454140",
      "content": "<p>\ud83e\udd16\ud83d\udda5\ufe0f Plus d'un million d'heures de calcul au GPU pour entra\u00eener le mod\u00e8le le plus complet de LLAMA de Facebook. <a href=\"https://arxiv.org/abs/2302.13971v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.13971v1</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1016/S0378-8733(02)00049-7",
    "title": "doi.org/10.1016/S0378-8733(02)...",
    "latest": "2023-04-05T20:59:51+00:00",
    "last_post": {
      "url": "https://hci.social/@jeremy/110148215884963425",
      "content": "<p>Offline groups that have integrative structures peform better (<a href=\"https://doi.org/10.1016/S0378-8733(02)00049-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1016/S0378-8733(02)</span><span class=\"invisible\">00049-7</span></a>). If online communities are failing because they are struggling as organizations, then we would expect communities with more integrative networks to perform better.</p><p>In order to test this hypothesis, we measured the communication networks of ~1,000 Fandom wikis at the point that they had 700 edits. We then tested whether those with more integrative networks were 1) more productive or 2) more long-lasting.</p>"
    },
    "people": [
      {
        "url": "https://hci.social/@jeremy",
        "display_name": "Jeremy Foote \ud83e\uddb6"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1145/3025453.3025639",
    "title": "doi.org/10.1145/3025453.302563...",
    "latest": "2023-04-05T20:58:15+00:00",
    "last_post": {
      "url": "https://hci.social/@jeremy/110148209558425734",
      "content": "<p>There are certainly many factors. One is that most topics are niche and even founders don't expect them to become large communities (<a href=\"https://doi.org/10.1145/3025453.3025639\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1145/3025453.302563</span><span class=\"invisible\">9</span></a>).</p>"
    },
    "people": [
      {
        "url": "https://hci.social/@jeremy",
        "display_name": "Jeremy Foote \ud83e\uddb6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00228v1",
    "title": "Large language models can rate news outlet credibility",
    "latest": "2023-04-05T20:46:46+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110148164428179674",
      "content": "<p>\ud83d\udcdd Large Language Models Can Rate News Outlet Credibility \ud83d\udcda</p><p>\"ChatGPT is given news outlet names and asked to rate the credibility of the corresponding news outlet and provide a rationale for each rating in natural language text form (see Figure ).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.00228v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.00228v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2304.01982",
    "title": "http://arxiv.org/abs/2304.01982",
    "latest": "2023-04-05T19:19:15+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110147820268039765",
      "content": "<p>RT @leejnhk@twitter.com</p><p>Excited to share XTR from Google Research! Multi-vector retrievers like ColBERT are powerful, but they come at the cost of complicated inference. In this paper, we ask: \"can token retrieval alone achieve great performance in multi-vector retrieval?\"</p><p><a href=\"http://arxiv.org/abs/2304.01982\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2304.01982</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/leejnhk/status/1643632578824396805\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/leejnhk/status/164</span><span class=\"invisible\">3632578824396805</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2206.13932",
    "title": "Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for Scalar Data -- An Algorithm and A Benchmark",
    "latest": "2023-04-05T18:59:32+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@JulienTierny/110082367565504305",
      "content": "<p>To compute <a href=\"https://fosstodon.org/tags/PersistentHomology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PersistentHomology</span></a>, one needs to check, for each d-simplex \u03c3i of a filtration, if it \"fills\" a (d-1)-dimensional hole, i.e. if its boundary \u2202\u03c3i is homologous to a non-trivial (d-1)-cycle created on an unpaired (d-1)-simplex (blue).<br>\ud83d\udc47<br><a href=\"https://arxiv.org/abs/2206.13932\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2206.13932</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fosstodon.org/tags/TopologicalDataAnalysis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>TopologicalDataAnalysis</span></a> <a href=\"https://fosstodon.org/tags/Visualization\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Visualization</span></a> <a href=\"https://fosstodon.org/tags/DataScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DataScience</span></a></p><p>Funded by the European Research Council (ERC) (project TORI, <a href=\"https://erc-tori.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">erc-tori.github.io/</span><span class=\"invisible\"></span></a>)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://osf.io/ahpvq/",
    "title": "\n        Validated Names for Experimental Studies on Race and Ethnicity\n",
    "latest": "2023-04-05T18:23:45+00:00",
    "last_post": {
      "url": "https://nerdculture.de/@Protzko/110146983972072717",
      "content": "<p>In many studies, we use names (like vignettes, or applications).<br>Names bring a lot of baggage with them.</p><p>For example, with \u2018Hazel\u2019, you already are forming ideas about age, sex, likely SES etc.</p><p>Same with Arthur Worthington III, <br>or Ozamataz Buckshank.</p><p>No name is neutral.</p><p>In this study, 4,026 people rated 600 names on numerous attributes.</p><p>Full data is available here <a href=\"https://osf.io/ahpvq/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">osf.io/ahpvq/</span><span class=\"invisible\"></span></a> </p><p>Now you can \u2018match\u2019 names on all sorts of characteristics</p><p>From <span class=\"h-card\"><a href=\"https://mstdn.social/@cdcrabtree\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cdcrabtree</span></a></span> </p><p><a href=\"https://www.nature.com/articles/s41597-023-01947-0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41597-023</span><span class=\"invisible\">-01947-0</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41597-023-01947-0",
    "title": "nature.com/articles/s41597-023...",
    "latest": "2023-04-05T18:23:45+00:00",
    "last_post": {
      "url": "https://nerdculture.de/@Protzko/110146983972072717",
      "content": "<p>In many studies, we use names (like vignettes, or applications).<br>Names bring a lot of baggage with them.</p><p>For example, with \u2018Hazel\u2019, you already are forming ideas about age, sex, likely SES etc.</p><p>Same with Arthur Worthington III, <br>or Ozamataz Buckshank.</p><p>No name is neutral.</p><p>In this study, 4,026 people rated 600 names on numerous attributes.</p><p>Full data is available here <a href=\"https://osf.io/ahpvq/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">osf.io/ahpvq/</span><span class=\"invisible\"></span></a> </p><p>Now you can \u2018match\u2019 names on all sorts of characteristics</p><p>From <span class=\"h-card\"><a href=\"https://mstdn.social/@cdcrabtree\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cdcrabtree</span></a></span> </p><p><a href=\"https://www.nature.com/articles/s41597-023-01947-0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41597-023</span><span class=\"invisible\">-01947-0</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@lakens",
        "display_name": "Daniel Lakens"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01982",
    "title": "Rethinking the Role of Token Retrieval in Multi-Vector Retrieval",
    "latest": "2023-04-05T17:24:36+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110147369485899664",
      "content": "<p>Rethinking the Role of Token Retrieval in Multi-Vector Retrieval</p><p>Presents XTR, ConteXtualized Token Retriever, which introduces a simple, yet novel, objective function that encourages the model to retrieve the most important document tokens first.</p><p><a href=\"https://arxiv.org/abs/2304.01982\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01982</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01373",
    "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling",
    "latest": "2023-04-05T17:24:33+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110147369274657742",
      "content": "<p>RT @BlancheMinerva@twitter.com</p><p>Have you ever wanted to do an experiment on LLMs and found that none of the existing model suites met your needs? At @AiEleuther@twitter.com we got tired of this happening and so designed a model suite that centers enabling scientific research as its primary goal</p><p><a href=\"https://arxiv.org/abs/2304.01373\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01373</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/BlancheMinerva/status/1643411683858169861\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/BlancheMinerva/sta</span><span class=\"invisible\">tus/1643411683858169861</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01433",
    "title": "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings",
    "latest": "2023-04-05T17:24:33+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110147369244651158",
      "content": "<p>TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings</p><p>TPU v4 outperforms TPU v3 by 2.1x, and The TPU v4 pod is 4x larger at 4096 chips and thus ~10x faster overall.</p><p><a href=\"https://arxiv.org/abs/2304.01433\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01433</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01852",
    "title": "Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models",
    "latest": "2023-04-05T17:24:30+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110147369079223298",
      "content": "<p>Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models</p><p>Presents a comprehensive survey of ChatGPT and GPT-4 and their prospective applications across diverse domains.</p><p><a href=\"https://arxiv.org/abs/2304.01852\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01852</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00215v1",
    "title": "Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers",
    "latest": "2023-04-05T17:01:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110147280187534572",
      "content": "<p>\ud83d\udcdd Inductive Relation Prediction From Relational Paths and Context with Hierarchical Transformers \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"A novel method that captures both connections between entities and the intrinsic nature of entities, by simultaneously aggregating RElational Paths and cOntext with a unified hieRarchical Transformer framework.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2304.00215v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.00215v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/pdf/10.1145/3583079",
    "title": "dl.acm.org/doi/pdf/10.1145/358...",
    "latest": "2023-04-05T16:46:28+00:00",
    "last_post": {
      "url": "https://mastodon.scot/@karengregory/110147219503456335",
      "content": "<p>From Twitter: </p><p>khovanskaya (on the job market) @saysvera</p><p>\"Coming out of \ud83d\udd12 for a sec to share my article in @interactionsMag about data tools in the labor movement. When I wrote this, I was thinking about the unsung heroes of the tech supporting the labor movement, aka the stuff storing and moving membership data\"</p><p><a href=\"https://dl.acm.org/doi/pdf/10.1145/3583079\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/pdf/10.1145/358</span><span class=\"invisible\">3079</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.scot/@karengregory",
        "display_name": "Karen Gregory"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01481",
    "title": "The Vector Grounding Problem",
    "latest": "2023-04-05T16:18:02+00:00",
    "last_post": {
      "url": "https://mastodon.sdf.org/@dim/110146771309557949",
      "content": "<p>A preprint that I've been working on for quite some time with the brilliant <span class=\"h-card\"><a href=\"https://sigmoid.social/@raphaelmilliere\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>raphaelmilliere</span></a></span> is now available on ArXiv: The Vector Grounding Problem -<br><a href=\"https://arxiv.org/abs/2304.01481\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01481</span><span class=\"invisible\"></span></a></p><p>In a nutshell, we argue that some large pretrained <a href=\"https://mastodon.sdf.org/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a> models, especially those fine-tuned with <a href=\"https://mastodon.sdf.org/tags/RLHF\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RLHF</span></a>, have the features required to have internal representations and outputs imbued with intrinsic meaning.</p><p>We show this is in 3 steps. First, we argue that the traditional Symbol Grounding Problem for classical AI (...)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://mastodon.social/@gcampax",
        "display_name": "Giovanni Campagna"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01398",
    "title": "The unreasonable effectiveness of few-shot learning for machine translation",
    "latest": "2023-04-05T09:59:32+00:00",
    "last_post": {
      "url": "https://mastodon.online/@kurts/110026935165520375",
      "content": "<p>For people that say that LLMs \"don't really understand\" language.</p><p>How do you explain this?</p><p>\"The unreasonable effectiveness of few-shot learning for machine translation\" trains a model on text from different languages - NOT explicitly translated. It's never given matching pairs of the same text in two languages.</p><p>Just given about 5 example translations on the prompt, the model is then able to match the performance of state of the art specialized translation systems.</p><p><a href=\"https://arxiv.org/abs/2302.01398\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01398</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05328",
    "title": "https://doi.org/10.21105/joss.05328",
    "latest": "2023-04-05T09:02:30+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110145395123704437",
      "content": "<p>Just published in JOSS: 'predictNMB: An R package to estimate if or when a clinical prediction model is worthwhile' <a href=\"https://doi.org/10.21105/joss.05328\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05328</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07735",
    "title": "Can neural networks do arithmetic? A survey on the elementary numerical skills of state-of-the-art deep learning models",
    "latest": "2023-04-05T08:29:32+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@Jose_A_Alonso/110026949316896421",
      "content": "<p>Can neural networks do arithmetic? A survey on the elementary numerical skills of state-of-the-art deep learning models. ~ Alberto Testolin. <a href=\"https://arxiv.org/abs/2303.07735\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07735</span><span class=\"invisible\"></span></a> <a href=\"https://mathstodon.xyz/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://mathstodon.xyz/tags/NeuralNetwork\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NeuralNetwork</span></a> <a href=\"https://mathstodon.xyz/tags/Math\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Math</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01666",
    "title": "A Survey on Contextualised Semantic Shift Detection",
    "latest": "2023-04-05T07:40:07+00:00",
    "last_post": {
      "url": "https://qoto.org/@mapto/110145071186647919",
      "content": "<p>RT @PeritiFrancesco@twitter.com</p><p>I'm happy to announce that our Survey paper on Contextualised Semantic Shift Detection has just been published on arXiv! <br><a href=\"https://arxiv.org/abs/2304.01666\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01666</span><span class=\"invisible\"></span></a><br>Currently under review, stay tuned for updates on our paper's progress. <a href=\"https://qoto.org/tags/LSC\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LSC</span></a> <a href=\"https://qoto.org/tags/SSD\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SSD</span></a> <a href=\"https://qoto.org/tags/BERT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BERT</span></a> <a href=\"https://qoto.org/tags/Transformer\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Transformer</span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/PeritiFrancesco/status/1643495233903009798\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/PeritiFrancesco/st</span><span class=\"invisible\">atus/1643495233903009798</span></a></p>"
    },
    "people": [
      {
        "url": "https://qoto.org/@mapto",
        "display_name": "mapto"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.02009",
    "title": "OrienterNet: Visual Localization in 2D Public Maps with Neural Matching",
    "latest": "2023-04-05T07:11:12+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110144957448296989",
      "content": "<p>OrienterNet: Visual Localization in 2D Public Maps with Neural Matching</p><p>Paul-Edouard Sarlin, Daniel DeTone, Tsun-Yi Yang, Armen Avetisyan, Julian Straub, Tomasz Malisiewicz, Samuel Rota Bulo, Richard Newcombe, Peter Kontschieder, Vasileios Balntas</p><p>tl;dr: Photo -&gt; neural bird's view -&gt; matching vs encoded 2D map -&gt; profit!</p><p><a href=\"https://arxiv.org/abs/2304.02009\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.02009</span><span class=\"invisible\"></span></a><br><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.13966",
    "title": "The Debate Over Understanding in AI's Large Language Models",
    "latest": "2023-04-05T06:59:32+00:00",
    "last_post": {
      "url": "https://cktn.todon.de/@CKsTechNews/110079286553495042",
      "content": "<p>The Debate over Understanding in <a href=\"https://cktn.todon.de/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a>'s Large Language Models</p><p>Paper V3<br><a href=\"https://arxiv.org/abs/2210.13966\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.13966</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.02008",
    "title": "https://arxiv.org/abs/2304.02008",
    "latest": "2023-04-05T06:52:03+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110144882210052487",
      "content": "<p>GlueStick: Robust Image Matching by Sticking Points and Lines Together</p><p>R\u00e9mi Pautrat, Iago Su\u00e1rez, Yifan Yu, Marc Pollefeys, Viktor Larsson</p><p>tl;dr: Line-aware SuperGlue with line-connectivity message passing.<br><a href=\"https://github.com/cvg/gluestick\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/cvg/gluestick</span><span class=\"invisible\"></span></a><br><a href=\"https://arxiv.org/abs/2304.02008\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.02008</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2304.01852.pdf",
    "title": "https://arxiv.org/pdf/2304.01852.pdf",
    "latest": "2023-04-05T06:23:02+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@dezzai/110144767848031110",
      "content": "<p>This paper presents a comprehensive survey of <a href=\"https://sigmoid.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a> and <a href=\"https://sigmoid.social/tags/gpt4\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gpt4</span></a>  state-of-the-art large language models (<a href=\"https://sigmoid.social/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a>) from the GPT series, and their prospective applications across diverse domains.</p><p><a href=\"https://arxiv.org/pdf/2304.01852.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2304.01852.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17564",
    "title": "BloombergGPT: A Large Language Model for Finance",
    "latest": "2023-04-05T06:20:02+00:00",
    "last_post": {
      "url": "https://mastodon.social/@secou/110144756312138104",
      "content": "<p>[<a href=\"https://mastodon.social/tags/BI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BI</span></a>|<a href=\"https://mastodon.social/tags/GENERATIVEAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GENERATIVEAI</span></a>] BloombergGPT: A Large Language Model for Finance<br><a href=\"https://arxiv.org/abs/2303.17564\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17564</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.social/tags/businessintelligence\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>businessintelligence</span></a> <a href=\"https://mastodon.social/tags/gpt\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>gpt</span></a> <a href=\"https://mastodon.social/tags/nlp\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>nlp</span></a> <a href=\"https://mastodon.social/tags/financialdata\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>financialdata</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      },
      {
        "url": "https://indieweb.social/@bigdata",
        "display_name": "Ben Lorica \u7f57\u745e\u5361"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://sigmoid.social/@roban",
        "display_name": "Roban Hultman Kramer"
      },
      {
        "url": "https://mastodon.social/@secou",
        "display_name": "Serge Courrier"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2109.07958",
    "title": "http://arxiv.org/abs/2109.07958",
    "latest": "2023-04-05T06:14:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110025396401651528",
      "content": "<p>Looking closer and comparing the numbers with the TruthfulQA paper (<a href=\"http://arxiv.org/abs/2109.07958\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2109.07958</span><span class=\"invisible\"></span></a>), UnifiedQA (based on T5) performed roughly the same as GPT-4 with only 60M parameters. But it's specifically finetuned with QA task. Also unclear is if UnifiedQA scores were based on the mc1 section of TruthfulQA.</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.09503.pdf",
    "title": "https://arxiv.org/pdf/2303.09503.pdf",
    "latest": "2023-04-05T04:44:32+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/110138139869508404",
      "content": "<p>\"The Intel Neuromorphic DNS Challenge\"</p><p>using neuromorphic computing for audio denoising </p><p><a href=\"https://arxiv.org/pdf/2303.09503.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.09503.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/neuromorphicComputing\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>neuromorphicComputing</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2301.00243.pdf",
    "title": "https://arxiv.org/pdf/2301.00243.pdf",
    "latest": "2023-04-05T03:14:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@neuronflow/110074869702131625",
      "content": "<p><span class=\"h-card\"><a href=\"https://sigmoid.social/@at\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>at</span></a></span> <span class=\"h-card\"><a href=\"https://sigmoid.social/@lb\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>lb</span></a></span> I now uploaded the camera-ready version to arxiv with a few references from this discussion <a href=\"https://arxiv.org/pdf/2301.00243.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2301.00243.pdf</span><span class=\"invisible\"></span></a><br>thank you once again for the comments.<br><span class=\"h-card\"><a href=\"https://sigmoid.social/@ducha_aiki\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ducha_aiki</span></a></span> I respectfully disagree regarding the relevance being a function of dataset size (see previous comments) :)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00457",
    "title": "LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models",
    "latest": "2023-04-05T01:44:33+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110137840791092510",
      "content": "<p>LLMMaps - A Visual Metaphor for Stratified Evaluation of Large Language Models</p><p><a href=\"https://arxiv.org/abs/2304.00457\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.00457</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16967",
    "title": "Heuristic Search For Physics-Based Problems: Angry Birds in PDDL+",
    "latest": "2023-04-05T01:44:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@shiwali/110142324475331132",
      "content": "<p>Common wisdom in <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> and <a href=\"https://sigmoid.social/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a> is that <a href=\"https://sigmoid.social/tags/AIPlanning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AIPlanning</span></a> methods cannot deal with continuous state and action spaces. </p><p>Subverting these expectations - presenting our recent paper at <a href=\"https://sigmoid.social/tags/ICAPS23\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ICAPS23</span></a> on how a planning agent can play <a href=\"https://sigmoid.social/tags/AngryBirds\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AngryBirds</span></a>! </p><p>And, no <a href=\"https://sigmoid.social/tags/DL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DL</span></a> <a href=\"https://sigmoid.social/tags/DQN\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DQN</span></a> systems cannot play these games yet AND take so much data to learn to play a single level.</p><p><a href=\"https://sigmoid.social/tags/Planning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Planning</span></a> <a href=\"https://sigmoid.social/tags/Reasoning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Reasoning</span></a> <a href=\"https://sigmoid.social/tags/KRR\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>KRR</span></a> FTW!! </p><p><a href=\"https://arxiv.org/abs/2303.16967\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16967</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00612",
    "title": "https://arxiv.org/abs/2304.00612",
    "latest": "2023-04-05T01:27:12+00:00",
    "last_post": {
      "url": "https://fediverse.randomfoo.net/objects/d05f9bd8-ce2a-4fd0-85e3-52cd2bf8ea23",
      "content": "<p>A few links on AI risks that are interesting:</p><p>Scott Alexander calls out Tyler Cowen\u2019s framing and talks about what he calls the \u201cSafe Uncertainty Fallacy\u201d: <a href=\"https://astralcodexten.substack.com/p/mr-tries-the-safe-uncertainty-fallacy\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://astralcodexten.substack.com/p/mr-tries-the-safe-uncertainty-fallacy</a><br>Samuel Bowman, an NYU/Anthropic AI researcher recently wrote, Eight Things to Know about Large Language Models, a good summary of some not so obvious things to know about AI LLMs <a href=\"https://arxiv.org/abs/2304.00612\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://arxiv.org/abs/2304.00612</a><br>CBS published their full (45min) interview with Geoffrey Hinton (one of the godfathers of modern AI) - very thoughtful/interesting <a href=\"https://youtu.be/qpoRO378qRY\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://youtu.be/qpoRO378qRY</a><br>While ChatGPT 4 is by far the \u201cbest\u201d model, I\u2019ve found using the new Browsing model to be really useful for interactive interrogations on papers/topics: <a href=\"https://sharegpt.com/c/JFexqvm\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">https://sharegpt.com/c/JFexqvm</a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.01768",
    "title": "The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation",
    "latest": "2023-04-04T22:02:21+00:00",
    "last_post": {
      "url": "https://genart.social/@tca/110142799344741410",
      "content": "<p>The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation <a href=\"https://genart.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a>  </p><p><a href=\"https://arxiv.org/abs/2301.01768\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.01768</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://genart.social/@tca",
        "display_name": "tiago"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2105.02274",
    "title": "Rethinking Search: Making Domain Experts out of Dilettantes",
    "latest": "2023-04-04T21:14:32+00:00",
    "last_post": {
      "url": "https://neuromatch.social/@jonny/110138740730983257",
      "content": "<p>super dope, AMP to the scale of the whole internet.</p><p>the audacity of this paper from a Google researcher blows my mind. see that whole \"index\" part missing from the proposed new system for search on the right? that's also known as \"the rest of the internet\"</p><p>edit: the paper - <a href=\"https://arxiv.org/abs/2105.02274\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2105.02274</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17612v1",
    "title": "https://arxiv.org/abs/2303.17612v1",
    "latest": "2023-04-04T20:48:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110142507735190623",
      "content": "<p>\ud83d\udcdd oBERTa: Improving Sparse Transfer Learning via Improved Initialization, Distillation, and Pruning Regimes \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Introduces the Range of oBERTa, an easy-to-use set of language models with different sizes that allow NLP practitioners to obtain between 3,8 and 24,3 times faster models without expertise in model compression.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/neuralmagic/sparseml\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/neuralmagic/sparsem</span><span class=\"invisible\">l</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17612v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17612v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.11156.pdf",
    "title": "https://arxiv.org/pdf/2303.11156.pdf",
    "latest": "2023-04-04T19:54:27+00:00",
    "last_post": {
      "url": "https://mastodon.cloud/@neif/110142255455081974",
      "content": "<p>\"Can AI-Generated Text be Reliably Detected?\"<br> <a href=\"https://arxiv.org/pdf/2303.11156.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.11156.pdf</span><span class=\"invisible\"></span></a></p><p>TLDR: Sure, there are concerns with misuse and \"plagarism\" but the current generation of tools is insufficient to detect when AI is used and they are easily fooled.</p><p>For me, we can't get into an arms war with our students on AI, we MUST take a much more nuanced approach!</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.18223v1",
    "title": "A Survey of Large Language Models",
    "latest": "2023-04-04T19:48:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110142271811041615",
      "content": "<p>\ud83d\udcdd A Survey of Large Language Models \ud83d\udcda\ud83d\udc7e</p><p>\"By pre-training a Transformer model, and further fine-tuning it for a downstream task, such as natural language understanding (NLU), natural language generation (NLG), and text summarization.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.18223v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.18223v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.18190v1",
    "title": "Assessing Language Model Deployment with Risk Cards",
    "latest": "2023-04-04T19:03:16+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110142095111098387",
      "content": "<p>\ud83d\udcdd Assessing Language Model Deployment with Risk Cards \ud83d\udcda</p><p>\"RiskCards are composed of three parts, which are shown in figure 1: 1) risk prompts, 2) risk outputs, and 3) risk cards.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.18190v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.18190v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/pnasnexus/article/2/4/pgad077/7075905?login=true",
    "title": "academic.oup.com/pnasnexus/art...",
    "latest": "2023-04-04T18:54:03+00:00",
    "last_post": {
      "url": "https://datasci.social/@estebanmoro/110141530692172397",
      "content": "<p>Our new paper is out! Great work led by Zhuangyuan Fan to study what makes our streets more diverse. Urban density is not the only factor. Adjacent amenities, residential diversity, &amp; income level also play a significant role in social mixing. </p><p>You can check the results by street in some urban areas in our new viz tool: <a href=\"http://greatstreets.mit.edu\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">greatstreets.mit.edu</span><span class=\"invisible\"></span></a></p><p><a href=\"https://academic.oup.com/pnasnexus/article/2/4/pgad077/7075905?login=true\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/pnasnexus/art</span><span class=\"invisible\">icle/2/4/pgad077/7075905?login=true</span></a></p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@mszll",
        "display_name": "Michael Szell"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.15056.pdf",
    "title": "https://arxiv.org/pdf/2303.15056.pdf",
    "latest": "2023-04-04T18:02:04+00:00",
    "last_post": {
      "url": "https://mastodon.social/@LukaszOlejnik/110129870727305113",
      "content": "<p>\"per-annotation cost of ChatGPT is less than $0.003\u2014about twenty<br>times cheaper than MTurk. These results show the potential of large language<br>models to drastically increase the efficiency of text classification.\". Does this also mean that there will be much less (or none at all, soon?) need to issue low pay to humans for such tasks in certain countries?  <a href=\"https://arxiv.org/pdf/2303.15056.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.15056.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.18162v1",
    "title": "A Multiple Choices Reading Comprehension Corpus for Vietnamese Language Education",
    "latest": "2023-04-04T17:33:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110141742266480063",
      "content": "<p>\ud83d\udcdd A Multiple Choices Reading Comprehension Corpus for Vietnamese Language Education \ud83d\udcda</p><p>\"Proposes the multi-stage approach that combines the multi-step attention network (MAN) with the natural language inference (NLI) task to enhance the performance of the reading comprehension model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.18162v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.18162v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.07295",
    "title": "Meet in the Middle: A New Pre-training Paradigm",
    "latest": "2023-04-04T17:29:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ceperez/110021744025021800",
      "content": "<p>Another impressive paradigm change for self-supervised learning. \"Meet me in the middle.\"  This appears to point to a particularly design strategy that biology also employs.   <a href=\"https://arxiv.org/abs/2303.07295\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.07295</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00793",
    "title": "FinnWoodlands Dataset",
    "latest": "2023-04-04T10:01:00+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110139962816242002",
      "content": "<p>FinnWoodlands Dataset</p><p>Juan Lagos, Urho Lempi\u00f6, @EsaRahtu</p><p>tl;dr: working in segmentation and tired of MS COCO? Try recognizing trees in deep Finland forests!<br><a href=\"https://arxiv.org/abs/2304.00793\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.00793</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04289",
    "title": "Do Prosody Transfer Models Transfer Prosody?",
    "latest": "2023-04-04T09:59:32+00:00",
    "last_post": {
      "url": "https://icosahedron.website/@halcy/110018192027697626",
      "content": "<p><a href=\"https://arxiv.org/abs/2303.04289\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04289</span><span class=\"invisible\"></span></a> i don't know that this is a good paper but I randomly saw it on arxiv and the title made me chuckle</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41392-023-01396-6",
    "title": "Potential recombination between SARS-CoV-2 and MERS-CoV: calls for the development of Pan-CoV vaccines - Signal Transduction and Targeted Therapy",
    "latest": "2023-04-04T09:07:17+00:00",
    "last_post": {
      "url": "https://wandering.shop/@cstross/110139751636488540",
      "content": "<p>I am deeply unamused to see a peer-reviewed paper discussing one of my pet nightmares (the risk of a MERS/COVID19 hybrid emerging) and saying it's somewhere between possible and likely: <a href=\"https://www.nature.com/articles/s41392-023-01396-6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41392-023</span><span class=\"invisible\">-01396-6</span></a></p>"
    },
    "people": [
      {
        "url": "https://wandering.shop/@cstross",
        "display_name": "Charlie Stross"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17932v1",
    "title": "https://arxiv.org/abs/2303.17932v1",
    "latest": "2023-04-04T08:18:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110139558616388951",
      "content": "<p>\ud83d\udcdd Trimming Phonetic Alignments Improves the Inference of Sound Correspondence Patterns From Multilingual Wordlists \ud83d\udcda</p><p>\"First trims the data to eliminate sites where the phonetic alignment is likely to be problematic, and then proceeds to infer correspondence patterns from the trimmed alignment using a standard algorithm.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/pano-tacanan-history/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/pano-tacanan-histor</span><span class=\"invisible\">y/</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17932v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17932v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://ieeexplore.ieee.org/document/10077087",
    "title": "Are Metrics Enough? Guidelines for Communicating and Visualizing Predictive Models to Subject Matter Experts",
    "latest": "2023-04-04T08:12:10+00:00",
    "last_post": {
      "url": "https://masto.ai/@cheng/110139534869699970",
      "content": "<p>How to communicate the performance of your <a href=\"https://masto.ai/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a> classifier. Unsurprisingly, it turns out that reporting a metric of success (e.g. mean squared error) is not enough to communicate the risks, strengths, and limitations of the predictive model. The authors propose to use <a href=\"https://masto.ai/tags/visual\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>visual</span></a> and <a href=\"https://masto.ai/tags/presentation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>presentation</span></a> approaches for the results.<br><a href=\"https://ieeexplore.ieee.org/document/10077087\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">ieeexplore.ieee.org/document/1</span><span class=\"invisible\">0077087</span></a></p>"
    },
    "people": [
      {
        "url": "https://masto.ai/@cheng",
        "display_name": "Cheng Soon Ong"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2203.08913",
    "title": "Memorizing Transformers",
    "latest": "2023-04-04T07:44:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@chengyjonathan/110057954471437801",
      "content": "<p>Long document representations by adding knn self attn to regular self attn. <a href=\"https://arxiv.org/abs/2203.08913\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2203.08913</span><span class=\"invisible\"></span></a></p><p>But also an interesting study of *when* the additional context is actually useful in doing a task.</p><p>We apparently didn\u2019t need to stretch or compress self attention\u2026we just needed to set up a separate store for looking up similar hidden states from other parts of the longer document and do attention over that store (as well as local self attention as well).</p><p>Kind of infuriatingly smart!</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17930v1",
    "title": "JobHam-place with smart recommend job options and candidate filtering options",
    "latest": "2023-04-04T07:03:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110139263744001234",
      "content": "<p>\ud83d\udcdd JobHam-place with Smart Recommend Job Options and Candidate Filtering Options \ud83d\udcda</p><p>\"A smart job hunter combined with the above functionality will be conducted in this project including job recommendations, CV ranking and even a job dashboard for skills and job applicant functionality.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17930v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17930v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17927v1",
    "title": "Cross-Cultural Transfer Learning for Chinese Offensive Language Detection",
    "latest": "2023-04-04T05:33:10+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110138909670323200",
      "content": "<p>\ud83d\udcdd Cross-Cultural Transfer Learning for Chinese Offensive Language Detection \ud83d\udcda</p><p>\"Finds that culture-specific biases in what is considered offensive can negatively impact the transferability of language models (LMs) and that a LM trained on diverse cultural data is sensitive to different features in Chinese offensive language detection.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17927v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17927v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17910v1",
    "title": "Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation",
    "latest": "2023-04-04T04:33:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110138673889851956",
      "content": "<p>\ud83d\udcdd Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation \ud83d\udcda</p><p>\"Introduces selective knowledge distillation by introducing an NAT evaluator to select NAT-friendly targets that are of high quality and easy to learn, and introduce a simple yet effective progressive distillation method to boost NAT performance.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17910v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17910v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41556-023-01117-9",
    "title": "Metaboverse enables automated discovery and visualization of diverse metabolic regulatory patterns - Nature Cell Biology",
    "latest": "2023-04-04T04:03:07+00:00",
    "last_post": {
      "url": "https://mastodon.social/@rmflight/110137520964086151",
      "content": "<p>Metaboverse enables automated discovery and visualization of diverse metabolic regulatory patterns</p><p><a href=\"https://www.nature.com/articles/s41556-023-01117-9\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41556-023</span><span class=\"invisible\">-01117-9</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@grndstt",
        "display_name": "Pierre-Marie Allard"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2202.08370",
    "title": "CAREER: Transfer Learning for Economic Prediction of Labor Sequence Data",
    "latest": "2023-04-04T03:59:32+00:00",
    "last_post": {
      "url": "https://fediscience.org/@davdittrich/110056547130397105",
      "content": "<p>CAREER: Transfer Learning for Economic Prediction of Labor Sequence Data<br><a href=\"https://arxiv.org/abs/2202.08370\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2202.08370</span><span class=\"invisible\"></span></a><br>\u2026forms accurate predictions of job sequences on 3 widely-used economics datasets. <br>\u2026find that CAREER can be used to form good predictions of other downstream variables; incorporating CAREER into a wage model provides better predictions than the econometric models currently in use.<br><a href=\"https://fediscience.org/tags/DataScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DataScience</span></a> <a href=\"https://fediscience.org/tags/Econometrics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Econometrics</span></a>  <a href=\"https://fediscience.org/tags/LaborEconomics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LaborEconomics</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17876v1",
    "title": "WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset",
    "latest": "2023-04-04T03:18:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110138379004131624",
      "content": "<p>\ud83d\udcdd WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset \ud83d\udcda</p><p>\"WebQAmGaze includes webcam eye-tracking data from 332 participants naturally reading English, Spanish, and German texts and performing QA tasks on them.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17876v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17876v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41567-023-01993-w",
    "title": "Double-slit time diffraction at optical frequencies | Nature Physics",
    "latest": "2023-04-04T02:35:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110138209240982837",
      "content": "<p>Double-slit time diffraction at optical frequencies - <a href=\"https://www.nature.com/articles/s41567-023-01993-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41567-023</span><span class=\"invisible\">-01993-w</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2009.01325",
    "title": "Learning to summarize from human feedback",
    "latest": "2023-04-04T02:29:32+00:00",
    "last_post": {
      "url": "https://c.im/@hyperplane/110009686063061145",
      "content": "<p>Learning to summarize from human feedback <a href=\"https://arxiv.org/abs/2009.01325\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2009.01325</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2304.00457.pdf",
    "title": "https://arxiv.org/pdf/2304.00457.pdf",
    "latest": "2023-04-04T02:28:15+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/110138182532868228",
      "content": "<p>\"LLMMaps - A Visual Metaphor for Stratified Evaluation of Large Language Models\"</p><p><a href=\"https://arxiv.org/pdf/2304.00457.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2304.00457.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00287",
    "title": "Vision Transformers with Mixed-Resolution Tokenization",
    "latest": "2023-04-04T01:12:20+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110137884068729594",
      "content": "<p>Vision Transformers with Mixed-Resolution Tokenization</p><p>Using the same architecture as vanilla ViTs, their Quadformer models achieve substantial accuracy gains on image classification when controlling for the computational budget.</p><p><a href=\"https://arxiv.org/abs/2304.00287\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.00287</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01196",
    "title": "Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data",
    "latest": "2023-04-04T00:55:20+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110137817197799484",
      "content": "<p>Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data</p><p>Proposes a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself</p><p><a href=\"https://arxiv.org/abs/2304.01196\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01196</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17651v1",
    "title": "https://arxiv.org/abs/2303.17651v1",
    "latest": "2023-04-04T00:33:12+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110137730171217430",
      "content": "<p>\ud83d\udcdd Self-Refine: Iterative Refinement with Self-Feedback \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"By allowing the same model to provide feedback, refine its outputs, and repeat the process, SELF-REFINE improves the quality of LLM generations across a variety of tasks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/krishnakt031990/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/krishnakt031990/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17651v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17651v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2008.01487",
    "title": "Autoencoder Image Interpolation by Shaping the Latent Space",
    "latest": "2023-04-04T00:14:32+00:00",
    "last_post": {
      "url": "https://mastodon.social/@tiago_ribeiro/110051694551981186",
      "content": "<p>\"Autoencoder Image Interpolation by Shaping the Latent Space\"</p><p>\ud83d\udd17: <a href=\"https://arxiv.org/abs/2008.01487#\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2008.01487#</span><span class=\"invisible\"></span></a> <a href=\"https://mastodon.social/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a> <a href=\"https://mastodon.social/tags/interpolation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>interpolation</span></a> <a href=\"https://mastodon.social/tags/autoencoder\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>autoencoder</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17809",
    "title": "Never a Dull Moment: Distributional Properties as a Baseline for Time-Series Classification",
    "latest": "2023-04-04T00:10:47+00:00",
    "last_post": {
      "url": "https://fediscience.org/@bendfulcher/110137641992702749",
      "content": "<p>New (short) pre-print.</p><p>For time-series classification problems, we show that rock-bottom-simple models (that ignore the time-ordering of data!) can perform surprisingly well.<br>Some important general lessons for formulating and interpreting models.</p><p>Work led by <span class=\"h-card\"><a href=\"https://fosstodon.org/@trentlikesstats\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>trentlikesstats</span></a></span> </p><p><a href=\"https://arxiv.org/abs/2303.17809\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17809</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fediscience.org/tags/timeseries\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>timeseries</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@bendfulcher",
        "display_name": "bendfulcher"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2110.03569.pdf",
    "title": "https://arxiv.org/pdf/2110.03569.pdf",
    "latest": "2023-04-03T21:59:32+00:00",
    "last_post": {
      "url": "https://mastodon.social/@dahukanna/110137016853553934",
      "content": "<p>Found this useful paper <br>Human in the Loop for Machine Creativity by Neo Christopher Chung1<br>1Institute of Informatics, University of Warsaw - <a href=\"https://arxiv.org/pdf/2110.03569.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2110.03569.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17649v1",
    "title": "https://arxiv.org/abs/2303.17649v1",
    "latest": "2023-04-03T21:48:11+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110137081300022621",
      "content": "<p>\ud83d\udcdd Aligning a Medium-Size GPT Model in English to a Small Closed Domain in Spanish Using Reinforcement Learning \ud83d\udcda\ud83e\udde0</p><p>\"Uses a reward model to align the generation of responses with the input questions and an existing pretrained GPT-2 model fine-tuned on English question-answering pairs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/UKPLab/EasyNMT\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/UKPLab/EasyNMT</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17649v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17649v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04226",
    "title": "A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT",
    "latest": "2023-04-03T21:14:32+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@Jose_A_Alonso/110004299633796275",
      "content": "<p>A comprehensive survey of AI-Generated Content (AIGC): A history of generative AI from GAN to ChatGPT. ~ Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu &amp; Lichao Sun. <a href=\"https://arxiv.org/abs/2303.04226\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04226</span><span class=\"invisible\"></span></a> <a href=\"https://mathstodon.xyz/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2108.07258.pdf",
    "title": "https://arxiv.org/pdf/2108.07258.pdf",
    "latest": "2023-04-03T20:29:32+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@krishnan/110051267760386568",
      "content": "<p>A good paper talking about the opportunity and risks of Foundation Models <a href=\"https://arxiv.org/pdf/2108.07258.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2108.07258.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://royalsocietypublishing.org/doi/10.1098/rspb.2022.0978",
    "title": "Experimental and cross-cultural evidence that parenthood and parental care motives increase social conservatism | Proceedings of the Royal Society B: Biological Sciences",
    "latest": "2023-04-03T19:58:33+00:00",
    "last_post": {
      "url": "https://mastodon.social/@freakonometrics/110136650205658646",
      "content": "<p>\"... evidence that both parenthood and parental care motivation are associated with increased social conservatism around the globe. Further, most of the positive association globally between age and social conservatism is accounted for by parenthood. These findings support the hypothesis that parenthood and parental care motivation increase social conservatism\" <a href=\"https://royalsocietypublishing.org/doi/10.1098/rspb.2022.0978\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">royalsocietypublishing.org/doi</span><span class=\"invisible\">/10.1098/rspb.2022.0978</span></a> (via <span class=\"h-card\"><a href=\"https://mamot.fr/@Mmedejantee\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Mmedejantee</span></a></span>)</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@freakonometrics",
        "display_name": "Arthur Charpentier"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41597-023-02041-1",
    "title": "National contributions to climate change due to historical emissions of carbon dioxide, methane, and nitrous oxide since 1850 - Scientific Data",
    "latest": "2023-04-03T19:30:09+00:00",
    "last_post": {
      "url": "https://mastodon.social/@freakonometrics/110136538541738362",
      "content": "<p>\"National contributions to climate change due to historical emissions of carbon dioxide, methane, and nitrous oxide since 1850\" <a href=\"https://www.nature.com/articles/s41597-023-02041-1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41597-023</span><span class=\"invisible\">-02041-1</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@RicSchuster",
        "display_name": "Richard Schuster"
      },
      {
        "url": "https://mastodon.social/@freakonometrics",
        "display_name": "Arthur Charpentier"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17651",
    "title": "https://arxiv.org/abs/2303.17651",
    "latest": "2023-04-03T19:02:11+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110132107710866323",
      "content": "<p>Self-Refine: Iterative Refinement with Self-Feedback</p><p>Presents a novel approach that allows LLMs to iteratively refine outputs and incorporate feedback along multiple dimensions to improve performance on diverse tasks.</p><p>proj: <a href=\"https://selfrefine.info/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">selfrefine.info/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.17651\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17651</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1002/bes2.2067",
    "title": "https://doi.org/10.1002/bes2.2067",
    "latest": "2023-04-03T18:54:52+00:00",
    "last_post": {
      "url": "https://ecoevo.social/@naupaka/110136399783094466",
      "content": "<p>Great advice in this new ESA Bulletin article: \"How to Get a Job Offer from a Smaller Joint Teaching-Research Mission University and What to Do Once You Have It\" <a href=\"https://doi.org/10.1002/bes2.2067\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1002/bes2.2067</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@JoannaMasel",
        "display_name": "Joanna Masel"
      },
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17071",
    "title": "DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents",
    "latest": "2023-04-03T18:33:41+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110136316524485685",
      "content": "<p>RT @nairvarun18@twitter.com</p><p>Latest from @curaiHQ@twitter.com: DERA - Dialog-Enabled Resolving Agents! </p><p>We (@elliotschu@twitter.com, @gtsomd@twitter.com, @anithakan@twitter.com) use the conversational ability of GPT-4 to create an interpretable forum for agents to communicate and iteratively improve output. Thread \ud83d\udc47<br><a href=\"https://arxiv.org/abs/2303.17071\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17071</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/nairvarun18/status/1641602385331236864\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/nairvarun18/status</span><span class=\"invisible\">/1641602385331236864</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17590v1",
    "title": "Going Beyond Nouns With Vision & Language Models Using Synthetic Data",
    "latest": "2023-04-03T18:24:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110136280564327155",
      "content": "<p>\ud83d\udcdd Going Beyond Nouns with Vision &amp; Language Models Using Synthetic Data \ud83d\udd2d\ud83d\udcda</p><p>\"Uses SyViC to fine-tune VL models and improve their zero-shot and few shot accuracy on VLC understanding benchmarks such as VL-Checklist and Winoground.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17590v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17590v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17881",
    "title": "Pentimento: Data Remanence in Cloud FPGAs",
    "latest": "2023-04-03T17:50:16.588000+00:00",
    "last_post": {
      "url": "https://infosec.exchange/@hovav/110135084960548532",
      "content": "<p>I guarantee that this is the wildest paper you\u2019ll read all year. Drewes et al., \u201cPentimento: Data Remanence in Cloud FPGAs,\u201d <a href=\"https://arxiv.org/abs/2303.17881\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17881</span><span class=\"invisible\"></span></a></p><p><p>We find that a remote attacker can recover \u201cFPGA pentimentos\u201d \u2014 long-removed secret data belonging to a prior user or proprietary design image on a cloud FPGA. Just as a pentimento of a painting can be exposed via infrared imaging, FPGA pentimentos can be exposed via signal<br>timing sensors instantiated on a remote cloud FPGA. The sensitive data constituting an FPGA pentimento is imprinted to the device through bias temperature instability effects on the underlying transistors. We demonstrate how this slight degradation can be measured using a time-to-digital converter when an adversary programs one into the target cloud FPGA. This technique allows an attacker to ascertain previously safe information, after it is no longer explicitly present, on cloud FPGAs. Notably, it can allow an attacker to (1) extract proprietary details or keys from an encrypted FPGA design image available on the AWS marketplace and (2) recover information from a previous user of a cloud-FPGA. Both threat models are experimentally validated on the AWS F1 platform.</p></p>"
    },
    "people": [
      {
        "url": "https://hachyderm.io/@timbray",
        "display_name": "Tim Bray"
      },
      {
        "url": "https://wandering.shop/@cstross",
        "display_name": "Charlie Stross"
      },
      {
        "url": "https://social.gerwitz.com/users/hans",
        "display_name": "Hans Gerwitz"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/1706.03762",
    "title": "https://arxiv.org/abs/1706.03762",
    "latest": "2023-04-03T17:48:54+00:00",
    "last_post": {
      "url": "https://appdot.net/@jgordon/110136092918760807",
      "content": "<p>Attention Is All You Need: Google's transformer architecture paper from 2017.</p><p><a href=\"https://arxiv.org/abs/1706.03762\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1706.03762</span><span class=\"invisible\"></span></a></p><p>Five years later we had the LLMs.</p><p><a href=\"https://appdot.net/tags/jgshare\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>jgshare</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00890-9",
    "title": "Stressed plants \u2018cry\u2019 \u2014 and some animals can probably hear them",
    "latest": "2023-04-03T09:53:17+00:00",
    "last_post": {
      "url": "https://mastodon.social/@Sheril/110133373818483761",
      "content": "<p>Stressed <a href=\"https://mastodon.social/tags/plants\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>plants</span></a> \u2018cry\u2019 \u2014 and some animals can probably hear them</p><p>Fascinating new research using microphones captured ultrasonic crackles from plants that are water-deprived or injured. <a href=\"https://www.nature.com/articles/d41586-023-00890-9\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00890-9</span></a> <a href=\"https://mastodon.social/tags/nature\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>nature</span></a> <a href=\"https://mastodon.social/tags/science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>science</span></a></p>"
    },
    "people": [
      {
        "url": "https://hcommons.social/@sharonmleon",
        "display_name": "Sharon Leon"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00257",
    "title": "Implicit Regularization Leads to Benign Overfitting for Sparse Linear Regression",
    "latest": "2023-04-03T09:14:33+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@philipmlong/110028113650384476",
      "content": "<p>M. Zhou and R. Ge.  Implicit Regularization Leads to Benign Overfitting for Sparse Linear Regression.  <a href=\"https://arxiv.org/abs/2302.00257\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00257</span><span class=\"invisible\"></span></a>.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17367v1",
    "title": "https://arxiv.org/abs/2303.17367v1",
    "latest": "2023-04-03T08:39:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110133980542735271",
      "content": "<p>\ud83d\udcdd A BERT-based Unsupervised Grammatical Error Correction Framework \ud83d\udcda</p><p>\"A BERT-based unsupervised GEC framework is proposed, which contains a data flow construction module, a sentence perplexity scoring module, and an error detecting and correcting module.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/pytorch\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/pytorch</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17367v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17367v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04906",
    "title": "https://doi.org/10.21105/joss.04906",
    "latest": "2023-04-03T08:32:56+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110133954268182559",
      "content": "<p>Just published in JOSS: 'Vlasiator.jl: A Julia package for processing Vlasiator data' <a href=\"https://doi.org/10.21105/joss.04906\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04906</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.10559",
    "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
    "latest": "2023-04-03T07:57:10+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@Kingwulf/110133774823626719",
      "content": "<p>Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers ...</p><p><a href=\"https://arxiv.org/abs/2212.10559#\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.10559#</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.10440",
    "title": "Perplexed by Quality: A Perplexity-based Method for Adult and Harmful Content Detection in Multilingual Heterogeneous Web Data",
    "latest": "2023-04-03T07:44:32+00:00",
    "last_post": {
      "url": "https://mastodon.social/@oscarproj/109909745510323555",
      "content": "<p>\ud83d\ude2e Perplexity scores of the KenLM models are pre-computed, but it is up to the user to set a threshold for selecting the documents. \u26a0\ufe0f Please use with caution, and do not hesitate to send feedback Please refer to this pre-print for more information: <a href=\"https://arxiv.org/abs/2212.10440\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.10440</span><span class=\"invisible\"></span></a> \ud83d\udcdd</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17075",
    "title": "Viewpoint: A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelligence",
    "latest": "2023-04-03T06:59:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@LenoreBlum/110131929873473992",
      "content": "<p>As AIs become more powerful, we expect AIs that construct world models to experience \u201cfeelings of consciousness\u201d. If we want to avoid inflicting suffering on our planet\u2019s co-inhabitants it is more important than ever to understand <a href=\"https://sigmoid.social/tags/consciousness\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>consciousness</span></a>. See our Viewpoint, <a href=\"https://arxiv.org/abs/2303.17075\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17075</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17324v1",
    "title": "Topics in the Haystack: Extracting and Evaluating Topics beyond Coherence",
    "latest": "2023-04-03T06:24:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110133449348169109",
      "content": "<p>\ud83d\udcdd Topics in the Haystack: Extracting and Evaluating Topics Beyond Coherence \ud83d\udcda</p><p>\"Extracts and identifies latent topics in large text corpora by incorporating a deeper understanding of both sentence and document themes, and goes beyond simply analyzing word frequencies in the data.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17324v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17324v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.04910.pdf",
    "title": "https://arxiv.org/pdf/2303.04910.pdf",
    "latest": "2023-04-03T05:29:32+00:00",
    "last_post": {
      "url": "https://mastodon.social/@regehr/110024847760396634",
      "content": "<p>\"Baldur: Whole-Proof Generation and Repair with Large Language Models\"</p><p><a href=\"https://arxiv.org/pdf/2303.04910.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.04910.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "http://osf.io/zgjp2/",
    "title": "http://osf.io/zgjp2/",
    "latest": "2023-04-03T05:26:23+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110133220676882764",
      "content": "<p>THE LABOR INPUT IN THE AGE OF ARTIFICIAL INTELLIGENCE <a href=\"http://osf.io/zgjp2/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/zgjp2/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/ajrey/",
    "title": "http://osf.io/ajrey/",
    "latest": "2023-04-03T05:26:23+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110133220710526832",
      "content": "<p>Politicians, Bureaucrats, and the Battle for Credit <a href=\"http://osf.io/ajrey/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ajrey/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/jmn4k/",
    "title": "http://osf.io/jmn4k/",
    "latest": "2023-04-03T05:21:25+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110133201178542903",
      "content": "<p>The Villagers of Animal Crossing: New Horizons and the Fruits of Capitalism <a href=\"http://osf.io/jmn4k/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/jmn4k/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/qg93e/",
    "title": "http://osf.io/qg93e/",
    "latest": "2023-04-03T05:21:24+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110133201138095587",
      "content": "<p>Comparing Naturalistic Mental Health Expressions on Student Loan Debts Using Big Data <a href=\"http://osf.io/qg93e/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/qg93e/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/rm5dw/",
    "title": "http://osf.io/rm5dw/",
    "latest": "2023-04-03T05:11:53+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110133163706688841",
      "content": "<p>PLOVER and POLECAT: A New Political Event Ontology and Dataset <a href=\"http://osf.io/rm5dw/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/rm5dw/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/dcb93/",
    "title": "http://osf.io/dcb93/",
    "latest": "2023-04-03T05:11:53+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110133163691004492",
      "content": "<p>FOUR FACTS ABOUT ESG BELIEFS AND INVESTOR PORTFOLIOS <a href=\"http://osf.io/dcb93/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/dcb93/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.05032",
    "title": "Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis",
    "latest": "2023-04-03T04:44:32+00:00",
    "last_post": {
      "url": "https://qoto.org/@mapto/110111262982974312",
      "content": "<p>Other models followed, in November came Midjourney v4 and in December Structured Diffusion Guidance (<a href=\"https://arxiv.org/abs/2212.05032\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.05032</span><span class=\"invisible\"></span></a>). Better composition was notably easier to achieve. This allowed me to proceed with (and complete) my tasks of illustration of fairy tales. All resulting images can be seen in the paper, but the other important outcome is the definition of a preliminary process for the generation of images aligned to the original story text.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11156?ref=emergentmind",
    "title": "Can AI-Generated Text be Reliably Detected?",
    "latest": "2023-04-03T04:17:40+00:00",
    "last_post": {
      "url": "https://famichiki.jp/@rdviii/110132950035163860",
      "content": "<p>Joi Ito now talking about this paper:<br><a href=\"https://arxiv.org/abs/2303.11156?ref=emergentmind#\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">arxiv.org/abs/2303.11156?ref=e</span><span class=\"invisible\">mergentmind#</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2212.03551.pdf",
    "title": "https://arxiv.org/pdf/2212.03551.pdf",
    "latest": "2023-04-03T03:59:34+00:00",
    "last_post": {
      "url": "https://hci.social/@Heycori/109904133212308095",
      "content": "<p>Great paper from Murray Shanahan on how LLMs work - advocating for us to repeatedly keep this in mind to avoid confusing them with humans. <a href=\"https://arxiv.org/pdf/2212.03551.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2212.03551.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://mastodon.cloud/@seatrout",
        "display_name": "Andrew Brown"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17183v1",
    "title": "The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling",
    "latest": "2023-04-03T03:39:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110132800559363962",
      "content": "<p>\ud83d\udcdd The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling \ud83d\udcda\ud83d\udc7e</p><p>\"A curated dataset consisting of 1,200GB of text, in all of the major North Germanic languages (Danish, Icelandic, Norwegian, and Swedish), as well as some high-quality English data.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17183v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17183v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17161v1",
    "title": "TreePiece: Faster Semantic Parsing via Tree Tokenization",
    "latest": "2023-04-03T02:09:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110132446648125383",
      "content": "<p>\ud83d\udcdd TreePiece: Faster Semantic Parsing via Tree Tokenization \ud83d\udcda\ud83d\udc7e</p><p>\"At each time step, an autoregressive model generates the next token, conditioned on previous tokens and an external context (e,g, source sentence in machine translation).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17161v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17161v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2202.05924v2",
    "title": "Compute Trends Across Three Eras of Machine Learning",
    "latest": "2023-04-03T01:44:37+00:00",
    "last_post": {
      "url": "https://aus.social/@DinoCevolatti/110023588276643107",
      "content": "<p>\"...before 2010 training compute grew in line with Moore's law, doubling roughly every 20 months. Since the advent of Deep Learning in the early 2010s, the scaling of training compute has accelerated, doubling approximately every 6 months. In late 2015, a new trend emerged as firms developed large-scale ML models with 10 to 100-fold larger requirements in training compute...\"<br><a href=\"https://aus.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://aus.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a> <a href=\"https://aus.social/tags/MooresLaw\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MooresLaw</span></a></p><p>TEXT SOURCE: <a href=\"https://arxiv.org/abs/2202.05924v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2202.05924v2</span><span class=\"invisible\"></span></a></p><p>MAGE SOURCE: <a href=\"https://www.nature.com/articles/d41586-023-00777-9\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00777-9</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00777-9",
    "title": "nature.com/articles/d41586-023...",
    "latest": "2023-04-03T01:44:37+00:00",
    "last_post": {
      "url": "https://aus.social/@DinoCevolatti/110023588276643107",
      "content": "<p>\"...before 2010 training compute grew in line with Moore's law, doubling roughly every 20 months. Since the advent of Deep Learning in the early 2010s, the scaling of training compute has accelerated, doubling approximately every 6 months. In late 2015, a new trend emerged as firms developed large-scale ML models with 10 to 100-fold larger requirements in training compute...\"<br><a href=\"https://aus.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://aus.social/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a> <a href=\"https://aus.social/tags/MooresLaw\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MooresLaw</span></a></p><p>TEXT SOURCE: <a href=\"https://arxiv.org/abs/2202.05924v2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2202.05924v2</span><span class=\"invisible\"></span></a></p><p>MAGE SOURCE: <a href=\"https://www.nature.com/articles/d41586-023-00777-9\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00777-9</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0283893",
    "title": "Anchoring effects in the assessment of papers: An empirical survey of citing authors",
    "latest": "2023-04-03T01:42:09+00:00",
    "last_post": {
      "url": "https://fediscience.org/@petersuber/110130331112943032",
      "content": "<p>New study: When authors are asked to assess the <a href=\"https://fediscience.org/tags/quality\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>quality</span></a> of an article they had previously cited, they tend to adjust their assessments in light of the paper's <a href=\"https://fediscience.org/tags/citation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>citation</span></a> count.<br><a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0283893\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.plos.org/plosone/arti</span><span class=\"invisible\">cle?id=10.1371/journal.pone.0283893</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@petersuber",
        "display_name": "petersuber"
      },
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-022-04412-x",
    "title": "Degrowth can work \u2014 here\u2019s how science can help",
    "latest": "2023-04-03T01:22:53+00:00",
    "last_post": {
      "url": "https://mastodon.social/@UncensoredNews/110132263243408382",
      "content": "<p>Degrowth can work \u2014 here\u2019s how science can help</p><p>Wealthy countries can create prosperity while using less materials and energy if they abandon economic growth as an objective.</p><p><a href=\"https://www.nature.com/articles/d41586-022-04412-x\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-022</span><span class=\"invisible\">-04412-x</span></a></p><p>Via <a href=\"https://UncensoredNews.US/degrowth\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">UncensoredNews.US/degrowth</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.social/tags/degrowth\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>degrowth</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@UncensoredNews",
        "display_name": "Curated Climate Search"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17905",
    "title": "https://arxiv.org/abs/2303.17905",
    "latest": "2023-04-03T00:58:12+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110132166189116604",
      "content": "<p>3D-aware Image Generation using 2D Diffusion Models</p><p>proj: <a href=\"https://jeffreyxiang.github.io/ivid/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">jeffreyxiang.github.io/ivid/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.17905\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17905</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.12402.pdf",
    "title": "https://arxiv.org/pdf/2303.12402.pdf",
    "latest": "2023-04-03T00:45:11+00:00",
    "last_post": {
      "url": "https://mas.to/@msinnl/110094386409817054",
      "content": "<p>Finally moved to Mastodon from Twitter, with a new paper about efficiently blocking the spread of harmful contagions in networks which is probably quite fitting to the move. Joint work with N. Aras, E. G\u00fcney and K. Taninmis and available at <a href=\"https://arxiv.org/pdf/2303.12402.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.12402.pdf</span><span class=\"invisible\"></span></a> <a href=\"https://mas.to/tags/orms\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>orms</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      },
      {
        "url": "https://mastodon.social/@datatherapist",
        "display_name": "The Data Therapist"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.18240",
    "title": "https://arxiv.org/abs/2303.18240",
    "latest": "2023-04-03T00:36:05+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110132079182330866",
      "content": "<p>Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?</p><p>Presents the largest empirical study of pre-trained visual representations or visual foundation models for Embodied AI</p><p>proj: <a href=\"https://eai-vc.github.io/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">eai-vc.github.io/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.18240\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.18240</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.18242",
    "title": "$\\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States",
    "latest": "2023-04-03T00:34:05+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110132071312477465",
      "content": "<p>\u221e-Diff: Infinite Resolution Diffusion with Subsampled Mollified States</p><p>Achieves significantly higher sample quality as well as being able to effectively scale to higher resolutions than the training data while retaining detail.</p><p><a href=\"https://arxiv.org/abs/2303.18242\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.18242</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.18223",
    "title": "A Survey of Large Language Models",
    "latest": "2023-04-03T00:32:08+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110132063640713686",
      "content": "<p>A Survey of Large Language Models</p><p><a href=\"https://arxiv.org/abs/2303.18223\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.18223</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2207.06991",
    "title": "Language Modelling with Pixels",
    "latest": "2023-04-03T00:14:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@culurciello/109897830280389806",
      "content": "<p>Nice work about a neural network that can read and write rendered text, from image, documents directly!<br><a href=\"https://arxiv.org/abs/2207.06991\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2207.06991</span><span class=\"invisible\"></span></a><br><a href=\"https://sigmoid.social/tags/Ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Ai</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <a href=\"https://sigmoid.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2007.00720",
    "title": "Adversarial Example Games",
    "latest": "2023-04-02T21:59:34+00:00",
    "last_post": {
      "url": "https://types.pl/@jamestjw/110019379940406343",
      "content": "<p>I need to reproduce this paper (Adversarial Example Games) <a href=\"https://arxiv.org/abs/2007.00720\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2007.00720</span><span class=\"invisible\"></span></a> , help their code doesn't even run :oh_no_bubble:\u200b</p><p>I think I'm going to try to reimplement a subset of it from scratch, I don't think I can do better than this.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2302.01339.pdf",
    "title": "https://arxiv.org/pdf/2302.01339.pdf",
    "latest": "2023-04-02T20:51:27+00:00",
    "last_post": {
      "url": "https://sciences.social/@omarlizardo/110131155192438984",
      "content": "<p>Dennett Explained</p><p><a href=\"https://arxiv.org/pdf/2302.01339.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2302.01339.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.07459",
    "title": "The Capacity for Moral Self-Correction in Large Language Models",
    "latest": "2023-04-02T20:29:33+00:00",
    "last_post": {
      "url": "https://newsie.social/@bespacific/109880927247943476",
      "content": "<p>The Capacity for Moral Self-Correction in Large Language Models <a href=\"https://arxiv.org/abs/2302.07459\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.07459</span><span class=\"invisible\"></span></a> <a href=\"https://newsie.social/tags/LargeLanguageModels\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LargeLanguageModels</span></a> <a href=\"https://newsie.social/tags/moral\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>moral</span></a> <a href=\"https://newsie.social/tags/SelfCorrection\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SelfCorrection</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17003v1",
    "title": "https://arxiv.org/abs/2303.17003v1",
    "latest": "2023-04-02T20:24:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110131090446615331",
      "content": "<p>\ud83d\udcdd Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Language Models are used to tackle the Exame Nacional do Ensino M\\'edio (ENEM), a multidisciplinary entrance examination widely adopted by Brazilian universities.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/piresramon/gpt-4-enem\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/piresramon/gpt-4-en</span><span class=\"invisible\">em</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.17003v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17003v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/09692290.2016.1243143",
    "title": "The anatomy of the Cayman Islands offshore financial center: Anglo-America, Japan, and the role of hedge funds",
    "latest": "2023-04-02T19:10:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110130797125968876",
      "content": "<p>Cayman Islands offshore finance: Anglo-America, Japan, and hedge funds (2016) - <a href=\"https://www.tandfonline.com/doi/full/10.1080/09692290.2016.1243143\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/09692290.2016.1243143</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://onlinelibrary.wiley.com/doi/10.1002/advs.202300111",
    "title": "onlinelibrary.wiley.com/doi/10...",
    "latest": "2023-04-02T19:10:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110130797131261801",
      "content": "<p>Reducing Iron Oxide with Ammonia: A Sustainable Path to Green Steel - <a href=\"https://onlinelibrary.wiley.com/doi/10.1002/advs.202300111\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">onlinelibrary.wiley.com/doi/10</span><span class=\"invisible\">.1002/advs.202300111</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16992v1",
    "title": "ContraSim -- A Similarity Measure Based on Contrastive Learning",
    "latest": "2023-04-02T18:24:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110130618398370638",
      "content": "<p>\ud83d\udcdd ContraSim -- A Similarity Measure Based on Contrastive Learning \ud83d\udcda</p><p>\"ContraSim is trained on both similar and dissimilar examples, using a contrastive loss (Figure 1) to learn a similarity measure that assigns high scores to similar pairs while assigning low scores to dissimilar pairs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16992v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16992v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.04655",
    "title": "ChatGPT is not all you need. A State of the Art Review of large Generative AI models",
    "latest": "2023-04-02T18:14:33+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@swisstricky/110009731776121656",
      "content": "<p>ChatGPT is NOT all you need. A,using title for an interesting article.<br><a href=\"https://arxiv.org/abs/2301.04655\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.04655</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fosstodon.org/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a> <a href=\"https://fosstodon.org/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a>  <a href=\"https://fosstodon.org/tags/chatgpt\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>chatgpt</span></a></p>"
    },
    "people": [
      {
        "url": "https://idf.social/@arjen",
        "display_name": "Arjen P. de Vries Timmers \ud83d\udd4a\ufe0f"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5281/zenodo.3942742",
    "title": "https://doi.org/10.5281/zenodo.3942742",
    "latest": "2023-04-02T18:05:43+00:00",
    "last_post": {
      "url": "https://fediscience.org/@seanfobbe/110130517214106318",
      "content": "<p>\u26a0\ufe0f UPDATE \u26a0\ufe0f</p><p>Download 72,517 full-text decisions of the German Federal Court of Justice (BGH) covering 2000 to 2023 as a high-quality dataset here \u2b07\ufe0f</p><p>\u2705 <a href=\"https://fediscience.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <br>\u2705 <a href=\"https://fediscience.org/tags/PublicDomain\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PublicDomain</span></a> <br>\u2705 Formats: PDF, TXT, CSV, GraphML</p><p>Documentation: <a href=\"https://zenodo.org/record/7699032/files/CE-BGH_2023-03-10_Codebook.pdf?download=1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">zenodo.org/record/7699032/file</span><span class=\"invisible\">s/CE-BGH_2023-03-10_Codebook.pdf?download=1</span></a></p><p>All download options: <a href=\"https://doi.org/10.5281/zenodo.3942742\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.3942742</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fediscience.org/tags/RStats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RStats</span></a> source code: <a href=\"https://doi.org/10.5281/zenodo.4705864\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.4705864</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fediscience.org/tags/BGH\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BGH</span></a> <a href=\"https://fediscience.org/tags/CivilLaw\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CivilLaw</span></a> <a href=\"https://fediscience.org/tags/CriminalLaw\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CriminalLaw</span></a> <a href=\"https://fediscience.org/tags/Law\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Law</span></a> <a href=\"https://fediscience.org/tags/DigitalHumanities\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DigitalHumanities</span></a> <a href=\"https://fediscience.org/tags/OpenScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenScience</span></a> <a href=\"https://fediscience.org/tags/OpenData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenData</span></a> <a href=\"https://fediscience.org/tags/OpenSource\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenSource</span></a> <a href=\"https://fediscience.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://fediscience.org/tags/LawFedi\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LawFedi</span></a> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/rstats\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>rstats</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/rewi\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>rewi</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/law\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>law</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/politicalscience\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>politicalscience</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch (moderator)"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5281/zenodo.4705864",
    "title": "https://doi.org/10.5281/zenodo.4705864",
    "latest": "2023-04-02T18:05:43+00:00",
    "last_post": {
      "url": "https://fediscience.org/@seanfobbe/110130517214106318",
      "content": "<p>\u26a0\ufe0f UPDATE \u26a0\ufe0f</p><p>Download 72,517 full-text decisions of the German Federal Court of Justice (BGH) covering 2000 to 2023 as a high-quality dataset here \u2b07\ufe0f</p><p>\u2705 <a href=\"https://fediscience.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <br>\u2705 <a href=\"https://fediscience.org/tags/PublicDomain\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PublicDomain</span></a> <br>\u2705 Formats: PDF, TXT, CSV, GraphML</p><p>Documentation: <a href=\"https://zenodo.org/record/7699032/files/CE-BGH_2023-03-10_Codebook.pdf?download=1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">zenodo.org/record/7699032/file</span><span class=\"invisible\">s/CE-BGH_2023-03-10_Codebook.pdf?download=1</span></a></p><p>All download options: <a href=\"https://doi.org/10.5281/zenodo.3942742\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.3942742</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fediscience.org/tags/RStats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RStats</span></a> source code: <a href=\"https://doi.org/10.5281/zenodo.4705864\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.4705864</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fediscience.org/tags/BGH\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>BGH</span></a> <a href=\"https://fediscience.org/tags/CivilLaw\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CivilLaw</span></a> <a href=\"https://fediscience.org/tags/CriminalLaw\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CriminalLaw</span></a> <a href=\"https://fediscience.org/tags/Law\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Law</span></a> <a href=\"https://fediscience.org/tags/DigitalHumanities\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DigitalHumanities</span></a> <a href=\"https://fediscience.org/tags/OpenScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenScience</span></a> <a href=\"https://fediscience.org/tags/OpenData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenData</span></a> <a href=\"https://fediscience.org/tags/OpenSource\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenSource</span></a> <a href=\"https://fediscience.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://fediscience.org/tags/LawFedi\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LawFedi</span></a> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/rstats\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>rstats</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/rewi\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>rewi</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/law\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>law</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/politicalscience\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>politicalscience</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch (moderator)"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/gbe/article/15/3/evad032/7055906",
    "title": "Inferring Balancing Selection From Genome-Scale Data",
    "latest": "2023-04-02T17:14:30+00:00",
    "last_post": {
      "url": "https://genomic.social/@downingtim/110129320323228142",
      "content": "<p>Inferring Balancing Selection From Genome-Scale Data | Genome Biology and Evolution | Oxford Academic<br><a href=\"https://academic.oup.com/gbe/article/15/3/evad032/7055906\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/gbe/article/1</span><span class=\"invisible\">5/3/evad032/7055906</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@JoannaMasel",
        "display_name": "Joanna Masel"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2210.11981",
    "title": "Named Entity Detection and Injection for Direct Speech Translation",
    "latest": "2023-04-02T16:44:33+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@mgaido91/109903291155519307",
      "content": "<p>The paper of my internship at <br><a href=\"https://sigmoid.social/tags/meta\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>meta</span></a> (<a href=\"https://arxiv.org/abs/2210.11981\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2210.11981</span><span class=\"invisible\"></span></a>) was accepted to the 2023 IEEE ICASSP (<span class=\"h-card\"><a href=\"https://social.platypush.tech/@ieee_bot\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ieee_bot</span></a></span> <a href=\"https://sigmoid.social/tags/icassp\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>icassp</span></a>). See you there!</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.05511.pdf",
    "title": "https://arxiv.org/pdf/2303.05511.pdf",
    "latest": "2023-04-02T16:39:09+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110130203824204639",
      "content": "<p>RT @nathanbenaich@twitter.com</p><p>Giga-GAN based upsampling. I mean these results are just mind blowing compared to where we were in 2015/16 with super-resolution...</p><p><a href=\"https://arxiv.org/pdf/2303.05511.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.05511.pdf</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/nathanbenaich/status/1642507862449569792\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/nathanbenaich/stat</span><span class=\"invisible\">us/1642507862449569792</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2010.14648",
    "title": "Formally Verified SAT-Based AI Planning",
    "latest": "2023-04-02T10:00:07+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@Jose_A_Alonso/110002883850263535",
      "content": "<p>Formally verified SAT-based AI planning. ~ Mohammad Abdulaziz &amp; Friedrich Kurz. <a href=\"https://arxiv.org/abs/2010.14648\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2010.14648</span><span class=\"invisible\"></span></a> <a href=\"https://mathstodon.xyz/tags/ITP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ITP</span></a> <a href=\"https://mathstodon.xyz/tags/IsabelleHOL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>IsabelleHOL</span></a> <a href=\"https://mathstodon.xyz/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.07459v1",
    "title": "The Capacity for Moral Self-Correction in Large Language Models",
    "latest": "2023-04-02T09:14:33+00:00",
    "last_post": {
      "url": "https://techhub.social/@nic221/109877854350064763",
      "content": "<p>The Capacity for Moral Self-Correction in Large Language Models <a href=\"https://arxiv.org/abs/2302.07459v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.07459v1</span><span class=\"invisible\"></span></a> <a href=\"https://techhub.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.12712.pdf",
    "title": "https://arxiv.org/pdf/2303.12712.pdf",
    "latest": "2023-04-02T09:08:50+00:00",
    "last_post": {
      "url": "https://ioc.exchange/@peterrenshaw/110115709989298280",
      "content": "<p>\u201cAn impressive and alarming feature of modern <a href=\"https://ioc.exchange/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> and multimodal AIs that few are talking about in the major press.\u201c</p><p><a href=\"https://ioc.exchange/tags/toe\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>toe</span></a> / <a href=\"https://ioc.exchange/tags/CurtJaimungal\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CurtJaimungal</span></a> / <a href=\"https://ioc.exchange/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://ioc.exchange/tags/AGI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AGI</span></a>  &lt;<a href=\"https://youtube.com/watch?v=C3dICMA97Bs\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">youtube.com/watch?v=C3dICMA97B</span><span class=\"invisible\">s</span></a>&gt;</p><p>cite: \u201cSparks of Artificial General Intelligence: Early experiments with GPT-4\u201d, Bubeck, Chandrasekaran, Eldan. Microsoft Research, 2023. &lt;<a href=\"https://arxiv.org/pdf/2303.12712.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.12712.pdf</span><span class=\"invisible\"></span></a>&gt;</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@andrey",
        "display_name": "Andrey Kurenkov"
      },
      {
        "url": "https://fosstodon.org/@amueller",
        "display_name": "Andreas Mueller"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://genart.social/@tca",
        "display_name": "tiago"
      },
      {
        "url": "https://mastodon.social/@bruces",
        "display_name": "Bruce Sterling @bruces"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5860/lrts.67n1.4",
    "title": "https://doi.org/10.5860/lrts.67n1.4",
    "latest": "2023-04-02T07:50:21+00:00",
    "last_post": {
      "url": "https://openbiblio.social/@v_i_o_l_a/110128057969920144",
      "content": "<p>\"Using the Homosaurus in a Public Library Consortium: A Case Study\" <a href=\"https://doi.org/10.5860/lrts.67n1.4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5860/lrts.67n1.4</span><span class=\"invisible\"></span></a> <a href=\"https://openbiblio.social/tags/LGBTQIA\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LGBTQIA</span></a>+ <a href=\"https://openbiblio.social/tags/Vokabular\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Vokabular</span></a> <a href=\"https://openbiblio.social/tags/Thesaurus\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Thesaurus</span></a> <a href=\"https://openbiblio.social/tags/LinkedOpenData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LinkedOpenData</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@RonaldSnijder",
        "display_name": "Ronald Snijder"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16857v1",
    "title": "Did You Mean...? Confidence-based Trade-offs in Semantic Parsing",
    "latest": "2023-04-02T07:19:53+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110128004722314126",
      "content": "<p>\ud83d\udcdd Did You Mean...? Confidence-Based Trade-Offs in Semantic Parsing \ud83d\udcda</p><p>\"DidYouMean is a system that helps task-oriented dialogue systems balance the trade-off between usability and safety by providing a mechanism for users to correct system outputs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16857v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16857v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.00902",
    "title": "Language Quantized AutoEncoders: Towards Unsupervised Text-Image Alignment",
    "latest": "2023-04-02T06:59:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@Techronic9876/109906665826637546",
      "content": "<p>Cool work demonstrating that for any given image, there\u2019s a set of gibberish text tokens that can generate that image</p><p><a href=\"https://arxiv.org/abs/2302.00902\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.00902</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.04952",
    "title": "https://doi.org/10.21105/joss.04952",
    "latest": "2023-04-02T06:32:26+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110127818087815600",
      "content": "<p>Just published in JOSS: 'Ciclope: micro Computed Tomography to Finite Elements' <a href=\"https://doi.org/10.21105/joss.04952\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04952</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.10560",
    "title": "https://arxiv.org/abs/2212.10560",
    "latest": "2023-04-02T06:00:27+00:00",
    "last_post": {
      "url": "https://ioc.exchange/@peterrenshaw/110127691941305555",
      "content": "<p>Training language models using pre-trained LLMs to lower cost and size. </p><p><a href=\"https://ioc.exchange/tags/Alpaca\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Alpaca</span></a>: A Strong, Replicable Instruction-Following Model: \u201cWe are releasing our findings about an instruction-following language model, dubbed Alpaca, which is fine-tuned from Meta\u2019s LLaMA 7B model. We train the Alpaca model on 52K instruction-following demonstrations generated in the style of self-instruct using text-davinci-003. On the self-instruct evaluation set, Alpaca shows many behaviors similar to OpenAI\u2019s text-davinci-003, but is also surprisingly small and easy/cheap to reproduce\u201d</p><p><a href=\"https://ioc.exchange/tags/Alpaca\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Alpaca</span></a> / <a href=\"https://ioc.exchange/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> / <a href=\"https://ioc.exchange/tags/stanford\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>stanford</span></a> <a href=\"https://ioc.exchange/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a> &lt;<a href=\"https://crfm.stanford.edu/2023/03/13/alpaca.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">crfm.stanford.edu/2023/03/13/a</span><span class=\"invisible\">lpaca.html</span></a>&gt; / &lt;<a href=\"https://arxiv.org/abs/2212.10560\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2212.10560</span><span class=\"invisible\"></span></a>&gt;</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16854v1",
    "title": "AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators",
    "latest": "2023-04-02T05:49:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110127650880870375",
      "content": "<p>\ud83d\udcdd AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators \ud83d\udcda</p><p>\"Works by first explaining the demonstrated examples and then annotating unlabeled data with the self-generated explanations and few-shot chain-of-thought prompt constructed from them.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16854v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16854v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16835v1",
    "title": "Zero-shot Entailment of Leaderboards for Empirical AI Research",
    "latest": "2023-04-02T04:34:50+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110127355722558419",
      "content": "<p>\ud83d\udcdd Zero-Shot Entailment of Leaderboards for Empirical AI Research \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Creates a dataset of zero-shot entailment labels for leaderboard extraction RTE task by distant labeling and testing two prior reported state-of-the-art models for their abilities to generalize, given leaderboard labels that were unseen during training.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16835v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16835v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2202.12837",
    "title": "http://arxiv.org/abs/2202.12837",
    "latest": "2023-04-02T04:16:55+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110127285209252447",
      "content": "<p>2/</p><p>Paper 1:<br>Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? <a href=\"http://arxiv.org/abs/2202.12837\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2202.12837</span><span class=\"invisible\"></span></a></p><p>Paper 2:<br>Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, and Tengyu Ma. 2023. Larger language models do in-context learning differently. <a href=\"http://arxiv.org/abs/2303.03846\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.03846</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/NLG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLG</span></a> <a href=\"https://sigmoid.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2303.03846",
    "title": "http://arxiv.org/abs/2303.03846",
    "latest": "2023-04-02T04:16:55+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110127285209252447",
      "content": "<p>2/</p><p>Paper 1:<br>Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? <a href=\"http://arxiv.org/abs/2202.12837\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2202.12837</span><span class=\"invisible\"></span></a></p><p>Paper 2:<br>Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, and Tengyu Ma. 2023. Larger language models do in-context learning differently. <a href=\"http://arxiv.org/abs/2303.03846\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2303.03846</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/NLG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLG</span></a> <a href=\"https://sigmoid.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.13868",
    "title": "https://arxiv.org/abs/2211.13868",
    "latest": "2023-04-02T03:59:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@faro/110072514866039156",
      "content": "<p>Can Knowledge of End-to-End Text-to-Speech Models Improve Neural MIDI-to-Audio Synthesis Systems?</p><p>\ud83d\udc0d<a href=\"https://github.com/nii-yamagishilab/midi-to-audio\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/nii-yamagishilab/mi</span><span class=\"invisible\">di-to-audio</span></a> <br>\ud83d\udcc4<a href=\"https://arxiv.org/abs/2211.13868\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.13868</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.07730",
    "title": "Transformer models: an introduction and catalog",
    "latest": "2023-04-02T03:26:57+00:00",
    "last_post": {
      "url": "https://fedi.ai/@derek/110127088416401190",
      "content": "<p><a href=\"https://arxiv.org/abs/2302.07730\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.07730</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16764v1",
    "title": "Boosting Few-Shot Text Classification via Distribution Estimation",
    "latest": "2023-04-02T03:19:49+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110127060694076346",
      "content": "<p>\ud83d\udcdd Boosting Few-Shot Text Classification via Distribution Estimation \ud83d\udcda</p><p>\"We first assume a class or sample follows the Gaussian distribution, and use the original support set and the nearest few query samples to estimate the corresponding mean and covariance for each class.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16764v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16764v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.04910",
    "title": "Baldur: Whole-Proof Generation and Repair with Large Language Models",
    "latest": "2023-04-02T03:14:32+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@srikumarks/110004990589230004",
      "content": "<p>Baldur - whole proof generation and repair with large language models - <a href=\"https://arxiv.org/abs/2303.04910\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.04910</span><span class=\"invisible\"></span></a> (from <a href=\"https://twitter.com/AlbertQJiang/status/1634267741413691398\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/AlbertQJiang/statu</span><span class=\"invisible\">s/1634267741413691398</span></a>)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.07080",
    "title": "The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development",
    "latest": "2023-04-02T02:29:34+00:00",
    "last_post": {
      "url": "https://hci.social/@jweisz/110106720439861637",
      "content": "<p>\ud83d\udc4f\ud83c\udfc6 Our work on The Programmer's Assistant won the Best Demo Honorable Mention award at <a href=\"https://hci.social/tags/IUI2023\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>IUI2023</span></a>! Congratulations to my colleagues who did a fantastic job on building this prototype. <span class=\"h-card\"><a href=\"https://hci.social/@michael\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>michael</span></a></span> </p><p>Full paper of our work: <a href=\"https://arxiv.org/abs/2302.07080\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.07080</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16763v1",
    "title": "Meeting Action Item Detection with Regularized Context Modeling",
    "latest": "2023-04-02T01:49:52+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110126706990571177",
      "content": "<p>\ud83d\udcdd Meeting Action Item Detection with Regularized Context Modeling \ud83d\udcda</p><p>\"Context-Drop utilizes both local and global contexts by contrastive learning, and achieves better accuracy and robustness for action item detection in meetings, while Lightweight Model Ensemble exploits different pre-trained models for action item detection.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16763v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16763v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2206.14858.pdf",
    "title": "https://arxiv.org/pdf/2206.14858.pdf",
    "latest": "2023-04-02T01:44:32+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@rrogers/109889247455431939",
      "content": "<p>The beat goes on,  as I skimmed from the paper (below) the only thing is to train/write an interface between Minerva and Lean :) <br><a href=\"https://minerva-demo.github.io/#category=Algebra&amp;index=24\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">minerva-demo.github.io/#catego</span><span class=\"invisible\">ry=Algebra&amp;index=24</span></a><br><a href=\"https://arxiv.org/pdf/2206.14858.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2206.14858.pdf</span><span class=\"invisible\"></span></a></p><p>One would think that that wouldn't be too hard; says the person who thought IC's were impractical :)<br>I am going to try some combinatorial problems on Minerva; from <br><a href=\"https://www.dropbox.com/s/baaa7orl6bzp2f3/GouldBK.pdf?dl=0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">dropbox.com/s/baaa7orl6bzp2f3/</span><span class=\"invisible\">GouldBK.pdf?dl=0</span></a><br>Been looking for some Proof  assistant to validate some of those, including solutions I have written:_</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.03011",
    "title": "https://arxiv.org/abs/2302.03011",
    "latest": "2023-04-02T00:14:32+00:00",
    "last_post": {
      "url": "https://mastodon.xyz/@francoisguite/110090283193947551",
      "content": "<p>\"A multi-modal AI system that can generate novel videos with text, images, or video clips.\"</p><p>Gen-2 | Runway <a href=\"https://research.runwayml.com/gen2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">research.runwayml.com/gen2</span><span class=\"invisible\"></span></a></p><p>Structure and Content-Guided Video Synthesis with Diffusion Models | arXiv <a href=\"https://arxiv.org/abs/2302.03011\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.03011</span><span class=\"invisible\"></span></a><br><a href=\"https://mastodon.xyz/tags/openaccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>openaccess</span></a> <a href=\"https://mastodon.xyz/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@hrbrmstr",
        "display_name": "boB Rudis \ud83c\uddfa\ud83c\udde6"
      },
      {
        "url": "https://mstdn.social/@arnicas",
        "display_name": "arnicas"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16755v1",
    "title": "Training Language Models with Language Feedback at Scale",
    "latest": "2023-04-02T00:04:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110126294288051110",
      "content": "<p>\ud83d\udcdd Training Language Models with Language Feedback at Scale \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Introduces Imitation learning from Language Feedback (ILF), a new approach that utilizes more informative language feedback and learns by conditioning on feedback and input, choosing refinement incorporating the most feedback, and finetuning the language model to maximize the likelihood of the chosen refinement given the input.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16755v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16755v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1017/aap.2022.33",
    "title": "https://doi.org/10.1017/aap.2022.33",
    "latest": "2023-04-01T23:53:44+00:00",
    "last_post": {
      "url": "https://fediscience.org/@aap_saaorg/109978070109670623",
      "content": "<p>New in @SAAorg's AAP: The CARE Principles and the Reuse, Sharing, and Curation of Indigenous Data in Canadian Archaeology by @ArchaeoMapper; @UofA_IPIA; @archaeomap <a href=\"https://doi.org/10.1017/aap.2022.33\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1017/aap.2022.33</span><span class=\"invisible\"></span></a> <a href=\"https://fediscience.org/tags/archaeology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>archaeology</span></a> <a href=\"https://fediscience.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://fediscience.org/tags/CARE\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CARE</span></a></p>"
    },
    "people": [
      {
        "url": "https://scholar.social/@electricarchaeo",
        "display_name": "Shawn Graham"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1017/aap.2022.42",
    "title": "https://doi.org/10.1017/aap.2022.42",
    "latest": "2023-04-01T23:53:40+00:00",
    "last_post": {
      "url": "https://fediscience.org/@aap_saaorg/109978070192498594",
      "content": "<p>New in @SAAorg's AAP: What North American Archaeology Needs to Take Advantage of the Digital Data Revolution by @ortman_scott <a href=\"https://doi.org/10.1017/aap.2022.42\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1017/aap.2022.42</span><span class=\"invisible\"></span></a> <a href=\"https://fediscience.org/tags/archaeology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>archaeology</span></a> <a href=\"https://fediscience.org/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://fediscience.org/tags/Synthesis\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Synthesis</span></a></p>"
    },
    "people": [
      {
        "url": "https://scholar.social/@electricarchaeo",
        "display_name": "Shawn Graham"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2202.12872",
    "title": "AutoFR: Automated Filter Rule Generation for Adblocking",
    "latest": "2023-04-01T23:29:32+00:00",
    "last_post": {
      "url": "https://infosec.exchange/@pgl/110000084818386626",
      "content": "<p>Fascinating paper from Hieu Le, Salma Elmalaki, Athina Markopoulou, and <span class=\"h-card\"><a href=\"https://mastodon.social/@zubair_shafiq\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>zubair_shafiq</span></a></span>: AutoFR: Automated Filter Rule Generation for Adblocking.</p><p>This research is really exciting to see.</p><p>And code!</p><p><a href=\"https://arxiv.org/abs/2202.12872\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2202.12872</span><span class=\"invisible\"></span></a><br><a href=\"https://github.com/UCI-Networking-Group/AutoFR\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/UCI-Networking-Grou</span><span class=\"invisible\">p/AutoFR</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2209.14389",
    "title": "Downstream Datasets Make Surprisingly Good Pretraining Corpora",
    "latest": "2023-04-01T21:59:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@fschilder/109887523684166639",
      "content": "<p><a href=\"https://arxiv.org/abs/2209.14389\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2209.14389</span><span class=\"invisible\"></span></a> Not so large language models. <a href=\"https://sigmoid.social/tags/llm\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>llm</span></a> <a href=\"https://sigmoid.social/tags/nlp\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>nlp</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@fschilder",
        "display_name": "Frank Schilder"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1002/asi.24751",
    "title": "https://doi.org/10.1002/asi.24751",
    "latest": "2023-04-01T21:41:59+00:00",
    "last_post": {
      "url": "https://ieji.de/@MikeThelwall/110124686899685045",
      "content": "<p>Do altmetric scores reflect article quality? Evidence from the UK Research Excellence Framework 2021. Journal of the Association for Information Science and Technology. <a href=\"https://doi.org/10.1002/asi.24751\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.1002/asi.24751</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://social.cwts.nl/@vtraag",
        "display_name": "Vincent Traag"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16434",
    "title": "TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs",
    "latest": "2023-04-01T21:14:32+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@don_kosak/110114657395608844",
      "content": "<p>TaskMatrix.AI a new <a href=\"https://fosstodon.org/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a> paper from <a href=\"https://fosstodon.org/tags/Microsoft\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Microsoft</span></a>.</p><p>\"...we introduce TaskMatrix.AI as a new AI ecosystem that connects foundation models with millions of APIs for task completion.\"</p><p>arXiv link: <a href=\"https://arxiv.org/abs/2303.16434\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16434</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fosstodon.org/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a> papers</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16343",
    "title": "Facial recognition technology can expose political orientation from facial images even when controlling for demographics and self-presentation",
    "latest": "2023-04-01T20:29:33+00:00",
    "last_post": {
      "url": "https://mastodon.social/@thefirstred/110115931614429502",
      "content": "<p>What on earth is this?!?<br>\u201cThe analysis of facial features associated with political orientation revealed that conservatives had larger lower faces, although political orientation was only weakly associated with body mass index (BMI).\u201d<br>And concluding: \u201cThe predictability of political orientation from standardized images has critical implications for privacy, regulation of facial recognition technology\u2026\u201d Ummm, yeah!!!<br><a href=\"https://arxiv.org/abs/2303.16343\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16343</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16726v1",
    "title": "https://arxiv.org/abs/2303.16726v1",
    "latest": "2023-04-01T20:04:52+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110125350410120558",
      "content": "<p>\ud83d\udcdd Text Revision in Scientific Writing Assistance: An Overview \ud83d\udcda</p><p>\"Based on a corpus of 22,000 scientific articles from various sources (ACL Anthology, PubMed, arXiv, etc.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/vipulraheja/IteraTeR/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/vipulraheja/IteraTe</span><span class=\"invisible\">R/</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16726v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16726v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2211.00241",
    "title": "Adversarial Policies Beat Superhuman Go AIs",
    "latest": "2023-04-01T19:44:32+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@inthehands/109897622383814266",
      "content": "<p>Aha! Here is the paper on the research behind this story (ht \u202a<span class=\"h-card\"><a href=\"https://queer.af/@leftpaddotpy\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>leftpaddotpy</span></a></span>\u202c):</p><p><a href=\"https://arxiv.org/abs/2211.00241\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2211.00241</span><span class=\"invisible\"></span></a></p><p>The researchers\u2019 abstract puts it quite crisply: \u201cOur results demonstrate that even superhuman AI systems may harbor surprising failure modes.\u201d</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14937",
    "title": "LEURN: Learning Explainable Univariate Rules with Neural Networks",
    "latest": "2023-04-01T18:12:22+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110124908039247411",
      "content": "<p>[R] LEURN: Learning Explainable Univariate Rules with Neural Networks</p><p><a href=\"https://arxiv.org/abs/2303.14937\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14937</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2303.14937\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2303.14937</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2303.17564.pdf",
    "title": "https://arxiv.org/pdf/2303.17564.pdf",
    "latest": "2023-04-01T17:44:15+00:00",
    "last_post": {
      "url": "https://mastodon.social/@aleszu/110124797490499175",
      "content": "<p>Natural headline generation, just one possibility with BloombergGPT. Very interesting work:</p><p><a href=\"https://arxiv.org/pdf/2303.17564.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2303.17564.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@aleszu",
        "display_name": "Aleszu Bajak"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2102.07619",
    "title": "MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models by Instance-Guided Mask",
    "latest": "2023-04-01T17:14:52+00:00",
    "last_post": {
      "url": "https://recsys.social/@karlhigley/110124681952514345",
      "content": "<p>I don\u2019t have it in me to write a long thread today, but the Twitter recommender code release has surfaced another ranking/scoring model for <a href=\"https://recsys.social/tags/RecSys\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RecSys</span></a> that uses multiplicative feature interactions in a relatively principled and understandable way:<br><a href=\"https://arxiv.org/abs/2102.07619\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2102.07619</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@chengyjonathan",
        "display_name": "Jonathan Cheng"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://recsys.social/@karlhigley",
        "display_name": "Karl Higley"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.14272",
    "title": "Learning to Operate in Open Worlds by Adapting Planning Models",
    "latest": "2023-04-01T09:59:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@shiwali/110102095327967271",
      "content": "<p>New in <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://sigmoid.social/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a> that is not <a href=\"https://sigmoid.social/tags/chatgpt\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>chatgpt</span></a> </p><p>I am STOKED about our research on <a href=\"https://sigmoid.social/tags/OpenWorldLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenWorldLearning</span></a> at <a href=\"https://sigmoid.social/tags/AAMAS\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AAMAS</span></a> 2023. </p><p><a href=\"https://sigmoid.social/tags/OWL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OWL</span></a> is a novel learning paradigm. The three waves of <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> share a common design pattern. Phase 1 - program/train the inference algorithm; Phase 2 - deploy it. If deployment finds some unhandled usecases, go back to the first phase.</p><p><a href=\"https://sigmoid.social/tags/OWL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OWL</span></a> breaks this cycle &amp; builds systems that can <a href=\"https://sigmoid.social/tags/learn\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>learn</span></a> like <a href=\"https://sigmoid.social/tags/humans\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>humans</span></a> - they learn autonomously AFTER they have been deployed. </p><p><a href=\"https://arxiv.org/abs/2303.14272\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.14272</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41599-020-00650-4",
    "title": "The mechanical monster and discourses of fear and fascination in the early history of the computer - Humanities and Social Sciences Communications",
    "latest": "2023-04-01T09:34:23+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@lampinen/110122871287959847",
      "content": "<p>It\u2019s not surprising that recent developments in AI are eliciting a range of skeptical and fearful reactions. This almost always happens when technology develops. Early computers famously elicited skepticism such as \u201cthere\u2019s a world market for maybe five computers,\u201d but also fear (<a href=\"https://www.nature.com/articles/s41599-020-00650-4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41599-020</span><span class=\"invisible\">-00650-4</span></a>) \u2014 fear of their impact on society, on government, or on warfare. 1/7</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@lampinen",
        "display_name": "Andrew Lampinen"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2112.10003.pdf",
    "title": "https://arxiv.org/pdf/2112.10003.pdf",
    "latest": "2023-04-01T09:14:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@shreydan/110095584331041830",
      "content": "<p>here's a cool paper I found out about just now (from 2021):</p><p>Image Segmentation Using Text and Image Prompts - using CLIP for one/zero-shot image segmentation</p><p><a href=\"https://arxiv.org/pdf/2112.10003.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2112.10003.pdf</span><span class=\"invisible\"></span></a></p><p>demo: <a href=\"https://huggingface.co/spaces/taesiri/CLIPSeg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">huggingface.co/spaces/taesiri/</span><span class=\"invisible\">CLIPSeg</span></a></p><p><a href=\"https://sigmoid.social/tags/CLIP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CLIP</span></a> <a href=\"https://sigmoid.social/tags/segmentation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>segmentation</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/1908.07442",
    "title": "TabNet: Attentive Interpretable Tabular Learning",
    "latest": "2023-04-01T08:29:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@joukahainen/109899192064564802",
      "content": "<p><a href=\"https://sigmoid.social/tags/TabNet\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>TabNet</span></a> <br>Original paper:<br><a href=\"https://arxiv.org/abs/1908.07442\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1908.07442</span><span class=\"invisible\"></span></a><br><a href=\"https://sigmoid.social/tags/PapersWithCode\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PapersWithCode</span></a>:<br><a href=\"https://paperswithcode.com/paper/tabnet-attentive-interpretable-tabular#code\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">paperswithcode.com/paper/tabne</span><span class=\"invisible\">t-attentive-interpretable-tabular#code</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://link.springer.com/article/10.1007/s11136-023-03355-8",
    "title": "Estimating meaningful thresholds for multi-item questionnaires using item response theory - Quality of Life Research",
    "latest": "2023-04-01T08:19:27+00:00",
    "last_post": {
      "url": "https://mastodon.social/@jrboehnke/110022265482283977",
      "content": "<p>A paper introducing a new IRT approach to estimate meaningful thresholds to accurately interpret questionnaire scores and facilitate clinical decision making:</p><p>In this approach an anchor item indicating the criterion state of interest is added to <a href=\"https://mastodon.social/tags/IRT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>IRT</span></a> model estimation. In simulation studies the method perfectly recovered threshold values on the latent trait with practically no bias and high precision:<br><a href=\"https://link.springer.com/article/10.1007/s11136-023-03355-8\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">link.springer.com/article/10.1</span><span class=\"invisible\">007/s11136-023-03355-8</span></a></p><p><a href=\"https://mastodon.social/tags/Psychometrics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Psychometrics</span></a> <a href=\"https://mastodon.social/tags/HRQL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>HRQL</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@JoranJongerling",
        "display_name": "Joran"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16256v1",
    "title": "https://arxiv.org/abs/2303.16256v1",
    "latest": "2023-04-01T08:04:53+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110122519352778390",
      "content": "<p>\ud83d\udcdd Scalable Handwritten Text Recognition System for Lexicographic Sources of Under-Resourced Languages and Alphabets \ud83d\udcda\ud83d\udd2d</p><p>\"Uses a tailored handwritten text recognition model to decipher the handwritten content from index cards, designed to be used in combination with a constrained Word Beam Search post-processing step to find the matching dictionary entry.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/perechen/htr_lexicography\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/perechen/htr_lexico</span><span class=\"invisible\">graphy</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16256v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16256v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2006.14830",
    "title": "Metrics and peer review agreement at the institutional level",
    "latest": "2023-04-01T07:26:49+00:00",
    "last_post": {
      "url": "https://social.cwts.nl/@vtraag/110107119844768262",
      "content": "<p>After quite some time, I'm happy to say that we finally made a thorough revision of our paper comparing peer review with metrics at the institutional level. <a href=\"https://arxiv.org/abs/2006.14830\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2006.14830</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://social.cwts.nl/@vtraag",
        "display_name": "Vincent Traag"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16252v1",
    "title": "Zero-Shot Generalizable End-to-End Task-Oriented Dialog System using Context Summarization and Domain Schema",
    "latest": "2023-04-01T07:04:54+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110122283449872644",
      "content": "<p>\ud83d\udcdd Zero-Shot Generalizable End-to-End Task-Oriented Dialog System Using Context Summarization and Domain Schema \ud83d\udcda\ud83e\udde0</p><p>\"ZS-ToD is a task-oriented dialog model that leverages domain schemas to allow for robust generalization to unseen domains and exploits effective summarization of the dialog history.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16252v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16252v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.02083",
    "title": "Theory of Mind May Have Spontaneously Emerged in Large Language Models",
    "latest": "2023-04-01T06:59:32+00:00",
    "last_post": {
      "url": "https://malaga.social/@luishg/109880529055569949",
      "content": "<p>And this is precisely what is most exciting, this way of exploring technology as an unknown space, which allows new features to emerge. Unexpected ones. That allows us to move forward in one direction. <a href=\"https://arxiv.org/abs/2302.02083\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.02083</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@LChoshen",
        "display_name": "Leshem Choshen"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://fediscience.org/@ct_bergstrom",
        "display_name": "Carl T. Bergstrom"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      },
      {
        "url": "https://sigmoid.social/@pbrane",
        "display_name": "Jake Mannix"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17035",
    "title": "On The Planetary Theory of Everything",
    "latest": "2023-04-01T06:38:49+00:00",
    "last_post": {
      "url": "https://scicomm.xyz/@mustapipa/110122150608612493",
      "content": "<p>A new theory of everything.</p><p>Galaxy formation, dark matter, and the tension in the expansion of the universe can all be explained by the natural behaviors of an overwhelmingly large population of exoplanets.</p><p>Since planets are obviously the ubiquitous answer to every current question that can be posed by astronomers, planetary science must then be the basis for all science, and therefore that all current funding for science be reserved for (exo)planetary science.</p><p><a href=\"https://arxiv.org/abs/2303.17035\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17035</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://universeodon.com/@eclogiter",
        "display_name": "Pet Rock"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16915",
    "title": "A Modest Proposal for the Non-existence of Exoplanets: The Expansion of Stellar Physics to Include Squars",
    "latest": "2023-04-01T06:38:20+00:00",
    "last_post": {
      "url": "https://scicomm.xyz/@mustapipa/110122166289953305",
      "content": "<p>Exoplanets do not exist.</p><p>A general framework for a novel type of cuboid star, or squar, which can precisely reproduce the full range of observed phenomena in stellar light curves, including the trapezoidal flux deviations (TFDs) often attributed to \"exoplanets.\"<br><a href=\"https://arxiv.org/abs/2303.16915\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16915</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@rrmutt",
        "display_name": "rrmutt"
      },
      {
        "url": "https://universeodon.com/@eclogiter",
        "display_name": "Pet Rock"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11366",
    "title": "Reflexion: an autonomous agent with dynamic memory and self-reflection",
    "latest": "2023-04-01T06:14:32+00:00",
    "last_post": {
      "url": "https://c.im/@hyperplane/110090008377107947",
      "content": "<p>A Self-Reflecting LLM Agent</p><p>Equips LLM-based agent w/ <br>-dynamic memory<br>-a self-reflective LLM<br>-a method for detecting hallucinations</p><p>Challenge agent to learn from its own mistakes</p><p>-Evaluate on knowledge-intensive tasks<br>-Outperforms ReAct agents</p><p><a href=\"https://arxiv.org/abs/2303.11366\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.11366</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.13515",
    "title": "Persistent Nature: A Generative Model of Unbounded 3D Worlds",
    "latest": "2023-04-01T05:29:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@at/110095481816749476",
      "content": "<p>Persistent Nature: A Generative Model of Unbounded 3D Worlds<br> Lucy Chai, Richard Tucker, Zhengqi Li, Phillip Isola, Noah Snavely </p><p>Input -- single-view landscape photos, output -- consistent world model for simulating flights through the scene.</p><p><a href=\"https://sigmoid.social/tags/arXiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arXiv</span></a> <a href=\"https://sigmoid.social/tags/AmyPostsPapers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AmyPostsPapers</span></a> <a href=\"https://sigmoid.social/tags/GenerativeWorlds\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeWorlds</span></a><br>abs: <a href=\"https://arxiv.org/abs/2303.13515\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.13515</span><span class=\"invisible\"></span></a> <br>web: <a href=\"https://chail.github.io/persistent-nature/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">chail.github.io/persistent-nat</span><span class=\"invisible\">ure/</span></a> <br>video alt: flyover of a region with low mountains and streams.</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.06594",
    "title": "Geometric Clifford Algebra Networks",
    "latest": "2023-04-01T04:44:32+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@braneloop/109898235445909604",
      "content": "<p>Beautiful paper:</p><p>Geometric Clifford Algebra Networks</p><p><a href=\"https://arxiv.org/abs/2302.06594\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.06594</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2010.09714",
    "title": "https://arxiv.org/abs/2010.09714",
    "latest": "2023-04-01T03:59:32+00:00",
    "last_post": {
      "url": "https://mastodon.online/@darabos/110118233040760198",
      "content": "<p>TIL of Schlick's bias and gain functions. The bias function is a parametric easing function that can go from sharp ease-in to linear to sharp ease-out. The gain has easing on both ends and can be likewise controlled.<br>Cool demo: <a href=\"http://demofox.org/biasgain.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">demofox.org/biasgain.html</span><span class=\"invisible\"></span></a><br>Cool article: <a href=\"https://arxiv.org/abs/2010.09714\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2010.09714</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2301.11716",
    "title": "Pre-training for Speech Translation: CTC Meets Optimal Transport",
    "latest": "2023-04-01T03:14:32+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@fbk_mt/109880311741581426",
      "content": "<p>Our Pick of the week: Phuong-Hang Le et al., \"Pre-training for Speech Translation: CTC Meets Optimal Transport\" <br>by <span class=\"h-card\"><a href=\"https://sigmoid.social/@mgaido91\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>mgaido91</span></a></span> </p><p>:arxiv: <a href=\"https://arxiv.org/abs/2301.11716\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2301.11716</span><span class=\"invisible\"></span></a></p><p><a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a>  <a href=\"https://sigmoid.social/tags/optimaltransport\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>optimaltransport</span></a> <a href=\"https://sigmoid.social/tags/CTC\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CTC</span></a> <a href=\"https://sigmoid.social/tags/speechtranslation\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>speechtranslation</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.09419",
    "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT",
    "latest": "2023-04-01T02:29:32+00:00",
    "last_post": {
      "url": "https://techhub.social/@dwaynephillips/109948128524182871",
      "content": "<p>Here is an international study presenting a history of the pretrained foundation models used today.<br><a href=\"https://arxiv.org/abs/2302.09419\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.09419</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2302.01226",
    "title": "Factor Fields: A Unified Framework for Neural Fields and Beyond",
    "latest": "2023-04-01T01:44:32+00:00",
    "last_post": {
      "url": "https://masto.ai/@cheng/109950618750135963",
      "content": "<p>Representing signals as a product of other signals. Factorization as a unifying principle behind recent methods for signal processing using <a href=\"https://masto.ai/tags/MachineLearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MachineLearning</span></a> .<br> <br><a href=\"https://arxiv.org/abs/2302.01226\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2302.01226</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv",
        "display_name": "arXiv Highlights AI/ML \ud83d\udcdd\ud83e\udd16"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17491",
    "title": "Language Models can Solve Computer Tasks",
    "latest": "2023-04-01T01:27:53+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110119184464783438",
      "content": "<p>Language Models can Solve Computer Tasks</p><p>Letting LLM to recursively criticize and improve its output significantly outperforms existing LLM methods on computer tasks and surpasses supervised learning (SL) and RL approaches.</p><p><a href=\"https://arxiv.org/abs/2303.17491\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17491</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://fosstodon.org/@ljvmiranda",
        "display_name": "Lj V. Miranda"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.16173v1",
    "title": "Towards Countering Essentialism through Social Bias Reasoning",
    "latest": "2023-04-01T01:17:03+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110120915669239225",
      "content": "<p>\ud83d\udcdd Towards Countering Essentialism Through Social Bias Reasoning \ud83d\udcda</p><p>\"Counter-stereotypical statements can challenge essentialist beliefs by broadening the scope of a stereotype to other groups, as in \"conservatives can also be stupid.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2303.16173v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.16173v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  }
]