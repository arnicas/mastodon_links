[
  {
    "link": "https://doi.org/10.21105/joss.04861",
    "title": "https://doi.org/10.21105/joss.04861",
    "latest": "2023-05-10T21:56:35+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110346619835474823",
      "content": "<p>Just published in JOSS: 'SPyCi-PDB: A modular command-line interface for back-calculating experimental datatypes of protein structures.' <a href=\"https://doi.org/10.21105/joss.04861\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.04861</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05227",
    "title": "https://doi.org/10.21105/joss.05227",
    "latest": "2023-05-10T21:48:50+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110346589371941708",
      "content": "<p>Just published in JOSS: 'mutyper: assigning and summarizing mutation types for analyzing germline mutation spectra' <a href=\"https://doi.org/10.21105/joss.05227\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05227</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.01393",
    "title": "Every Author as First Author",
    "latest": "2023-05-10T21:27:17+00:00",
    "last_post": {
      "url": "https://chaos.social/@blinry/110339449766097832",
      "content": "<p>Finally, a solution to the unfairness of authorship ordering in scientific papers! \ud83d\ude02</p><p>\"Every Author as First Author\"</p><p><a href=\"https://arxiv.org/abs/2304.01393\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.01393</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      },
      {
        "url": "https://fediscience.org/@bendfulcher",
        "display_name": "bendfulcher"
      },
      {
        "url": "https://fediscience.org/@dustinstoltz",
        "display_name": "D\u1d1cs\u1d1b\u026a\u0274 S\u1d1b\u1d0f\u029f\u1d1b\u1d22 :tardis:"
      },
      {
        "url": "https://dair-community.social/@DrVeronikaCH",
        "display_name": "Veronika Cheplygina"
      },
      {
        "url": "https://octodon.social/@hmason",
        "display_name": "Hilary"
      },
      {
        "url": "https://mathstodon.xyz/@csk",
        "display_name": "Craig S. Kaplan"
      },
      {
        "url": "https://vis.social/@mcnutt",
        "display_name": "Andrew McNutt"
      },
      {
        "url": "https://toot.aquilenet.fr/@rougier",
        "display_name": "Nicolas P. Rougier"
      },
      {
        "url": "https://mastodon.social/@freakonometrics",
        "display_name": "Arthur Charpentier"
      },
      {
        "url": "https://sigmoid.social/@osma",
        "display_name": "Osma Suominen"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      },
      {
        "url": "https://friend.camp/@aparrish",
        "display_name": "allison"
      },
      {
        "url": "https://octodon.social/@craignicol",
        "display_name": "Craig Nicol"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2304.14787.pdf",
    "title": "https://arxiv.org/pdf/2304.14787.pdf",
    "latest": "2023-05-10T21:22:45+00:00",
    "last_post": {
      "url": "https://infosec.exchange/@juanan/110346204106706084",
      "content": "<p>A Network Perspective on the Influence of Code Review Bots on the Structure of Developer Collaborations<br><a href=\"https://arxiv.org/pdf/2304.14787.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2304.14787.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@gvwilson",
        "display_name": "Greg Wilson"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2304.14628.pdf",
    "title": "https://arxiv.org/pdf/2304.14628.pdf",
    "latest": "2023-05-10T21:22:40+00:00",
    "last_post": {
      "url": "https://infosec.exchange/@juanan/110346200821591223",
      "content": "<p>Barriers and Self-Efficacy: A Large-Scale Study on the Impact of<br>OSS Courses on Student Perceptions<br><a href=\"https://arxiv.org/pdf/2304.14628.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2304.14628.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@gvwilson",
        "display_name": "Greg Wilson"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05252v1",
    "title": "https://arxiv.org/abs/2305.05252v1",
    "latest": "2023-05-10T21:07:41+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110346427558887700",
      "content": "<p>\ud83d\udcdd Distilling Script Knowledge From Large Language Models for Constrained Language Planning \ud83d\udcda\ud83d\udc7e</p><p>\"Proposes an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/siyuyuan/coscript\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/siyuyuan/coscript</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.05252v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05252v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04365",
    "title": "LatinCy: Synthetic Trained Pipelines for Latin NLP",
    "latest": "2023-05-10T20:46:17+00:00",
    "last_post": {
      "url": "https://fedihum.org/@stefan_hessbrueggen/110346343402465297",
      "content": "<p>New Latin model for spacy. Preprint: <a href=\"https://arxiv.org/abs/2305.04365\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04365</span><span class=\"invisible\"></span></a> <a href=\"https://fedihum.org/tags/nlp\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>nlp</span></a>  <a href=\"https://fedihum.org/tags/dh\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dh</span></a> <a href=\"https://fedihum.org/tags/digiclassics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>digiclassics</span></a></p>"
    },
    "people": [
      {
        "url": "https://fedihum.org/@stefan_hessbrueggen",
        "display_name": "@frueheneuzeit"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05226v1",
    "title": "Multi-Teacher Knowledge Distillation For Text Image Machine Translation",
    "latest": "2023-05-10T20:22:40+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110346250502806011",
      "content": "<p>\ud83d\udcdd Multi-Teacher Knowledge Distillation for Text Image Machine Translation \ud83d\udcda</p><p>\"Multi-Teacher Knowledge Distillation (MTKD) is proposed to effectively distill knowledge from the pipeline model into the end-to-end TIMT model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.05226v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05226v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05214v1",
    "title": "https://arxiv.org/abs/2305.05214v1",
    "latest": "2023-05-10T20:07:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110346191397451467",
      "content": "<p>\ud83d\udcdd Utilizing Lexical Similarity to Enable Zero-Shot Machine Translation for Extremely Low-Resource Languages \ud83d\udcda</p><p>\"We inject character and character-span noise into the training data of the high-resource language prior to learning the vocabulary and then train the model on the noisy high-resource language and low-resource language pair.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/anoopkunchukuttan/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/anoopkunchukuttan/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.05214v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05214v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.00612",
    "title": "https://arxiv.org/abs/2304.00612",
    "latest": "2023-05-10T20:05:31+00:00",
    "last_post": {
      "url": "https://mastodon.social/@rrmutt/110340291659030519",
      "content": "<p>Term of the moment: \"sandbagging\" (via <a href=\"https://arxiv.org/abs/2304.00612\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.00612</span><span class=\"invisible\"></span></a>)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      },
      {
        "url": "https://mastodon.social/@rrmutt",
        "display_name": "rrmutt"
      }
    ]
  },
  {
    "link": "https://doi.org/10.3998/jep.3372",
    "title": "https://doi.org/10.3998/jep.3372",
    "latest": "2023-05-10T19:44:05+00:00",
    "last_post": {
      "url": "https://openbiblio.social/@ferli90/110346053149724805",
      "content": "<p>Snyder, L. O. &amp; Fathallah, J., (2023) \u201cSustainable Futures for OA Books: The Open Book Collective\u201d, The Journal of Electronic Publishing 26(1). <a href=\"https://doi.org/10.3998/jep.3372\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.3998/jep.3372</span><span class=\"invisible\"></span></a> <a href=\"https://openbiblio.social/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://openbiblio.social/tags/Books\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Books</span></a></p>"
    },
    "people": [
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2304.15004",
    "title": "http://arxiv.org/abs/2304.15004",
    "latest": "2023-05-10T19:42:58+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110345199904887368",
      "content": "<p><a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a>\u2019s Ostensible Emergent Abilities Are a Mirage</p><p>Blog: <a href=\"https://hai.stanford.edu/news/ais-ostensible-emergent-abilities-are-mirage\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">hai.stanford.edu/news/ais-oste</span><span class=\"invisible\">nsible-emergent-abilities-are-mirage</span></a></p><p>Paper: Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. 2023. \u201cAre Emergent Abilities of Large Language Models a Mirage?\u201d ArXiv [Cs.AI]. arXiv. <a href=\"http://arxiv.org/abs/2304.15004\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2304.15004</span><span class=\"invisible\"></span></a>.</p><p><a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> <a href=\"https://sigmoid.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a> <a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2305.00118.pdf",
    "title": "https://arxiv.org/pdf/2305.00118.pdf",
    "latest": "2023-05-10T19:29:43+00:00",
    "last_post": {
      "url": "https://famichiki.jp/@takosix/110302352752340124",
      "content": "<p>\"OpenAI models have memorized a wide collection of copyrighted materials, and that the degree of memorization is tied to the frequency with which passages of those books appear on the web.\"</p><p>\"...dominance of science fiction and fantasy works, including Harry Potter, 1984, Lord of the Rings, Hunger Games, Hitchhiker\u2019s Guide to the Galaxy, Fahrenheit 451, A Game of Thrones, and Dune\u201412 of the top 20 most memorized books in copy-right fall in this category.\"</p><p><a href=\"https://arxiv.org/pdf/2305.00118.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2305.00118.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01056",
    "title": "From Organizations to Individuals: Psychoactive Substance Use By Professional Programmers",
    "latest": "2023-05-10T19:15:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110345984600017873",
      "content": "<p>Psychoactive Substance Use by Professional Programmers - <a href=\"https://arxiv.org/abs/2305.01056\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01056</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://doi.org/10.5281/zenodo.3826444",
    "title": "https://doi.org/10.5281/zenodo.3826444",
    "latest": "2023-05-10T19:14:37+00:00",
    "last_post": {
      "url": "https://fediscience.org/@seanfobbe/110345978577533811",
      "content": "<p>\u26a0\ufe0f UPDATE with better OCR \u26a0\ufe0f</p><p>All judgments and opinions of the International Court of Justice (ICJ) from 1947 up to April 2023 are now available as a data set!</p><p>\u2705 Enhanced OCR<br>\u2705 <a href=\"https://fediscience.org/tags/PublicDomain\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>PublicDomain</span></a><br>\u2705 <a href=\"https://fediscience.org/tags/RStats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>RStats</span></a> Code<br>\u2705 PDF, TXT and CSV formats</p><p>Codebook: <a href=\"https://zenodo.org/record/7876286/files/CD-ICJ_2023-05-07_Codebook.pdf?download=1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">zenodo.org/record/7876286/file</span><span class=\"invisible\">s/CD-ICJ_2023-05-07_Codebook.pdf?download=1</span></a></p><p>JELS Paper: <a href=\"https://zenodo.org/record/6628885/files/Fobbe2022_JELS_Twin-Corpora-of-Decisions-for-the-International-Court-of-Justice.pdf?download=1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">zenodo.org/record/6628885/file</span><span class=\"invisible\">s/Fobbe2022_JELS_Twin-Corpora-of-Decisions-for-the-International-Court-of-Justice.pdf?download=1</span></a></p><p>All downloads: <a href=\"https://doi.org/10.5281/zenodo.3826444\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.5281/zenodo.3826444</span><span class=\"invisible\"></span></a></p><p><a href=\"https://fediscience.org/tags/OpenData\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenData</span></a> <a href=\"https://fediscience.org/tags/OpenSource\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenSource</span></a> <a href=\"https://fediscience.org/tags/Law\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Law</span></a> <a href=\"https://fediscience.org/tags/LawFedi\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LawFedi</span></a> <a href=\"https://fediscience.org/tags/ICJ\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ICJ</span></a> <a href=\"https://fediscience.org/tags/Histodons\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Histodons</span></a> <a href=\"https://fediscience.org/tags/DigitalHumanities\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>DigitalHumanities</span></a> <a href=\"https://fediscience.org/tags/Jessup\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Jessup</span></a> <a href=\"https://fediscience.org/tags/InternationalLaw\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>InternationalLaw</span></a> <a href=\"https://fediscience.org/tags/papers\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>papers</span></a> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/histodons\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>histodons</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/law\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>law</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/politicalscience\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>politicalscience</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/rstats\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>rstats</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      },
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch"
      }
    ]
  },
  {
    "link": "http://osf.io/uh5y6/",
    "title": "http://osf.io/uh5y6/",
    "latest": "2023-05-10T19:06:22+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110345950474885510",
      "content": "<p>Sensing weather and climate: phenomenological and ethnographic approaches <a href=\"http://osf.io/uh5y6/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/uh5y6/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05191v1",
    "title": "COLA: Contextualized Commonsense Causal Reasoning from the Causal Inference Perspective",
    "latest": "2023-05-10T18:37:42+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110345837779914191",
      "content": "<p>\ud83d\udcdd COLA: Contextualized Commonsense Causal Reasoning From the Causal Inference Perspective \ud83d\udcda\ud83d\udc7e</p><p>\"Obtains rich incidental supervision from temporality and balances covariates from multiple timestamps to remove confounding effects, which can accurately detect commonsense causality between events in an event sequence.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.05191v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05191v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05189v1",
    "title": "SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models",
    "latest": "2023-05-10T18:22:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110345778611187665",
      "content": "<p>\ud83d\udcdd SUR-adapter: Enhancing Text-to-Image Pre-Trained Diffusion Models with Large Language Models \ud83d\udcda\ud83d\udd2d</p><p>\"SUR-adapter is a parameter-efficient approach that can enable pre-trained diffusion models to understand and reason concise natural language without image quality degradation, by bridging the semantic gap between simple narrative prompts and complex keyword-based prompts.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.05189v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05189v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05183v1",
    "title": "CSED: A Chinese Semantic Error Diagnosis Corpus",
    "latest": "2023-05-10T17:22:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110345542590794094",
      "content": "<p>\ud83d\udcdd CSED: A Chinese Semantic Error Diagnosis Corpus \ud83d\udcda\ud83d\udc7e</p><p>\"Of Chinese semantic error diagnosis (CSED) is important because it focuses on the correction of semantic errors, which are common in Chinese writing and may cause syntactic irregularities or even problems of comprehension.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.05183v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05183v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/nmeth.2659",
    "title": "Error bars - Nature Methods",
    "latest": "2023-05-10T17:03:48+00:00",
    "last_post": {
      "url": "https://fediscience.org/@ct_bergstrom/110331658837624116",
      "content": "<p>It sounds trivial and obvious, but are you reading error bars correctly? </p><p>Do you know whether you're looking at standard errors (measures of inferential uncertainty), standard deviations (measures of spread of individual observations), or 95% confidence intervals around the mean? </p><p>And are your intuitions correct about how to interpret each of these?</p><p>Here's a nice primer, refresher, or teaching article. </p><p><a href=\"https://www.nature.com/articles/nmeth.2659\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"\">nature.com/articles/nmeth.2659</span><span class=\"invisible\"></span></a></p><p>h/t <span class=\"h-card\"><a href=\"https://hci.social/@jakehofman\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>jakehofman</span></a></span></p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@bearloga",
        "display_name": "Mikhail Popov"
      },
      {
        "url": "https://datasci.social/@mszll",
        "display_name": "Michael Szell"
      },
      {
        "url": "https://fediscience.org/@ct_bergstrom",
        "display_name": "Carl T. Bergstrom"
      },
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      },
      {
        "url": "https://nerdculture.de/@dornhaus",
        "display_name": "Anna Dornhaus"
      },
      {
        "url": "https://mathstodon.xyz/@theta_max",
        "display_name": "Tom"
      },
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05181v1",
    "title": "https://arxiv.org/abs/2305.05181v1",
    "latest": "2023-05-10T16:22:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110345306742358570",
      "content": "<p>\ud83d\udcdd MoT: Pre-Thinking and Recalling Enable ChatGPT to Self-Improve with Memory-of-Thoughts \ud83d\udcda\ud83d\udc7e</p><p>\"Proposes Memory of Thoughts (MoT), which let the LLM self-improve through Memory of Thoughts, without annotated datasets and parameter updates.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/LeeSureman/MoT\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/LeeSureman/MoT</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.05181v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05181v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04990v1",
    "title": "Explanation-based Finetuning Makes Models More Robust to Spurious Cues",
    "latest": "2023-05-10T09:07:40+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110343596332263652",
      "content": "<p>\ud83d\udcdd Explanation-Based Finetuning Makes Models More Robust to Spurious Cues \ud83d\udcda\ud83e\udde0</p><p>\"Fine-tunes the model to generate the free-text explanation using training data consisting of examples and their corresponding human-written explanations, and then further finetune the model to predict the answer given the input and the generated explanation using the same training data.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04990v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04990v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04989v1",
    "title": "Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust",
    "latest": "2023-05-10T08:07:38+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110343360272919252",
      "content": "<p>\ud83d\udcdd Knowledge Graph Guided Semantic Evaluation of Language Models for User Trust \ud83d\udcda\ud83d\udc7e</p><p>\"Proposes novel metrics to measure the reconstruction error when providing graph path sequences from a knowledge graph and trying to reproduce/reconstruct the same from the outputs of the self-attention transformer models.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04989v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04989v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04978v1",
    "title": "NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge",
    "latest": "2023-05-10T07:22:41+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110343183516265841",
      "content": "<p>\ud83d\udcdd NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge \ud83d\udcda</p><p>\"Proposes a novel NeuroComparative framework to acquire the comparative knowledge for common objects, such as \"steel is heavier than styrofoam\" or \"spiders are more creepy than snakes\", by distilling the knowledge from a larger pretrained model (e.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04978v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04978v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.3998/jep.3303",
    "title": "https://doi.org/10.3998/jep.3303",
    "latest": "2023-05-10T05:21:36+00:00",
    "last_post": {
      "url": "https://openbiblio.social/@ferli90/110342649869004728",
      "content": "<p>Ferwerda, E. &amp; Snijder, R. &amp; Stern, N., (2023) \u201cOpen Access to Books \u2013 the Perspective of a Non-profit Infrastructure Provider\u201d, The Journal of Electronic Publishing 26(1). <a href=\"https://doi.org/10.3998/jep.3303\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.3998/jep.3303</span><span class=\"invisible\"></span></a> <a href=\"https://openbiblio.social/tags/OpenAccess\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenAccess</span></a> <a href=\"https://openbiblio.social/tags/Books\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Books</span></a> <a href=\"https://openbiblio.social/tags/OAPENLibrary\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OAPENLibrary</span></a> <a href=\"https://openbiblio.social/tags/Directoryof\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Directoryof</span></a> OpenAccessBooks</p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@RonaldSnijder",
        "display_name": "Ronald Snijder"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04166v1",
    "title": "https://arxiv.org/abs/2305.04166v1",
    "latest": "2023-05-10T04:02:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110342396349702898",
      "content": "<p>\ud83d\udcdd UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in Vietnamese \ud83d\udd2d\ud83d\udcda</p><p>\"Works by using a multi-level encoder output fusion mechanism, which effectively enhanced the image representation ability by a multi-level encoder output fusion mechanism to improve the quality of generated captions compared to previous image captioning models.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/caodoanh2001/UIT-OpenViIC-labeller\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/caodoanh2001/UIT-Op</span><span class=\"invisible\">enViIC-labeller</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04166v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04166v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04082v1",
    "title": "A Minimal Approach for Natural Language Action Space in Text-based Games",
    "latest": "2023-05-10T03:32:27+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110342278174333522",
      "content": "<p>\ud83d\udcdd A Minimal Approach for Natural Language Action Space in Text-Based Games \ud83e\udde0\ud83d\udcda</p><p>\"Presents a text-based actor-critic (TAC) agent that produces textual commands for game, solely from game observations, without requiring any KG or LM.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04082v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04082v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03157",
    "title": "Good Will Hunting's Problem: Counting Homeomorphically Irreducible Trees",
    "latest": "2023-05-10T02:46:44+00:00",
    "last_post": {
      "url": "https://social.skewed.de/@tiago/110337125502312003",
      "content": "<p>How do you like them apples?</p><p><a href=\"https://arxiv.org/abs/2305.03157\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03157</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      },
      {
        "url": "https://hci.social/@bkeegan",
        "display_name": "Brian C. Keegan"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05364",
    "title": "Large Language Model Programs",
    "latest": "2023-05-10T02:24:00+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110342009048427910",
      "content": "<p>Large Language Model Programs</p><p>Presents LLM programs, the emerging methodology of embedding LLMs in a classic program to carry out more complex tasks</p><p><a href=\"https://arxiv.org/abs/2305.05364\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05364</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05383",
    "title": "Code Execution with Pre-trained Language Models",
    "latest": "2023-05-10T02:23:58+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110342008899127695",
      "content": "<p>Code Execution with Pre-trained Language Models</p><p>Presents CodeExecutor, a Transformer model that leverages code execution pre-training and curriculum learning to enhance its semantic comprehension.</p><p><a href=\"https://arxiv.org/abs/2305.05383\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05383</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03668",
    "title": "A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding",
    "latest": "2023-05-10T02:23:56+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110342008754247182",
      "content": "<p>A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding</p><p>Presents the Wikipedia Webpage 2M suite; the first to retain the full set of images, text, and structure data available in a page.</p><p><a href=\"https://arxiv.org/abs/2305.03668\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03668</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.05662",
    "title": "https://arxiv.org/abs/2305.05662",
    "latest": "2023-05-10T02:23:53+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110342008591442905",
      "content": "<p>InternChat: Solving Vision-Centric Tasks by Interacting with Chatbots Beyond Language</p><p>repo: <a href=\"https://github.com/OpenGVLab/InternChat\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/OpenGVLab/InternCha</span><span class=\"invisible\">t</span></a><br>abs: <a href=\"https://arxiv.org/abs/2305.05662\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.05662</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03923v1",
    "title": "Active Continual Learning: Labelling Queries in a Sequence of Tasks",
    "latest": "2023-05-10T02:17:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110341983481072693",
      "content": "<p>\ud83d\udcdd Active Continual Learning: Labelling Queries in a Sequence of Tasks \ud83e\udde0\ud83d\udcda</p><p>\"Proposes a forgetting-learning profile to evaluate the trade-off between forgetting and learning in continual active learning (ACL), and demonstrate the effectiveness of conditioning the query strategy on the annotations collected for the previous tasks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03923v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03923v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1080/00031305.2017.1375989",
    "title": "doi.org/10.1080/00031305.2017....",
    "latest": "2023-05-10T01:58:10+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@kbroman/110339581912808989",
      "content": "<p>\ud83e\uddf510 fun facts about my paper with <span class=\"h-card\"><a href=\"https://vis.social/@kara_woo\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>kara_woo</span></a></span> on Data Organization in Spreadsheets <a href=\"https://doi.org/10.1080/00031305.2017.1375989\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/00031305.2017.</span><span class=\"invisible\">1375989</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@bramzandbelt",
        "display_name": "Bram Zandbelt"
      },
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      },
      {
        "url": "https://fosstodon.org/@hadleywickham",
        "display_name": "Hadley Wickham"
      },
      {
        "url": "https://toot.cat/@infotroph",
        "display_name": "Chris Black"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04183v1",
    "title": "https://arxiv.org/abs/2305.04183v1",
    "latest": "2023-05-10T01:32:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110341806599738707",
      "content": "<p>\ud83d\udcdd OpenViVQA: Task, Dataset, and Multimodal Fusion Models for Visual Question Answering in Vietnamese \ud83d\udcda</p><p>\"OpenViVQA consists of a dataset of 11,000+ images associated with 37,000+ question-answer pairs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/hieunghia-pat/OpenViVQA-dataset\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/hieunghia-pat/OpenV</span><span class=\"invisible\">iVQA-dataset</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04183v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04183v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04181v1",
    "title": "https://arxiv.org/abs/2305.04181v1",
    "latest": "2023-05-10T00:32:27+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110341570364872042",
      "content": "<p>\ud83d\udcdd Shall We Trust All Relational Tuples by Open Information Extraction? A Study on Speculation Detection \ud83d\udcda\ud83d\udc7e</p><p>\"OIE-Spec consists of two components: (1) Sentence-level speculation detection model trained on LSOIE, and (2) a rule-based post-processing algorithm.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/daviddongkc/OIE_Spec\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/daviddongkc/OIE_Spe</span><span class=\"invisible\">c</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04181v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04181v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04160v1",
    "title": "https://arxiv.org/abs/2305.04160v1",
    "latest": "2023-05-09T23:47:26+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110341393404048601",
      "content": "<p>\ud83d\udcdd X-Llm: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages \ud83d\udcda\ud83d\udc7e\ud83d\udd2d</p><p>\"Proposes X-LLM, which aligns multiple frozen single-modal encoders and a frozen LLM using X2L interfaces, where ''X'' denotes multi-modalities such as image, speech, and videos, and ''L'' denotes languages.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/THUDM/ChatGLM-6B\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/THUDM/ChatGLM-6B</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04160v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04160v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04100v1",
    "title": "Rhetorical Role Labeling of Legal Documents using Transformers and Graph Neural Networks",
    "latest": "2023-05-09T21:17:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110340803705483606",
      "content": "<p>\ud83d\udcdd Rhetorical Role Labeling of Legal Documents Using Transformers and Graph Neural Networks \ud83d\udcda</p><p>\"Graph Convolutional Networks, Label Propagation Algorithm, Transformer-based Approaches, and variants of BERT to perform text classification on complex legal documents for the task of rhetorical role labelling.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04100v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04100v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04091v1",
    "title": "https://arxiv.org/abs/2305.04091v1",
    "latest": "2023-05-09T21:02:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110340744884649811",
      "content": "<p>\ud83d\udcdd Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models \ud83d\udcda</p><p>\"Devises a plan to divide the entire task into smaller subtasks, and then carry out the subtasks according to the plan to obtain final answers for the original task.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/AGI-Edgerunners/Pla</span><span class=\"invisible\">n-and-Solve-Prompting</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04091v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04091v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41562-023-01589-7",
    "title": "Seeing racial avoidance on New York City streets - Nature Human Behaviour",
    "latest": "2023-05-09T20:40:01+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110340656455796116",
      "content": "<p>Seeing racial avoidance on New York City streets - <a href=\"https://www.nature.com/articles/s41562-023-01589-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41562-023</span><span class=\"invisible\">-01589-7</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.00955",
    "title": "Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation",
    "latest": "2023-05-09T20:19:59+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110340577670535193",
      "content": "<p>RT @HelloSurgeAI@twitter.com</p><p>Human feedback is important to train safe and helpful LLMs.</p><p>Did you know there is now a large taxonomy of methods that leverage human feedback?</p><p>This recent paper provides a comprehensive overview of recent methods.</p><p><a href=\"https://arxiv.org/abs/2305.00955\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.00955</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/HelloSurgeAI/status/1655920376612806657\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/HelloSurgeAI/statu</span><span class=\"invisible\">s/1655920376612806657</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04076v1",
    "title": "https://arxiv.org/abs/2305.04076v1",
    "latest": "2023-05-09T20:17:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110340567873392015",
      "content": "<p>\ud83d\udcdd SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition \ud83d\udcda\ud83d\udc7e</p><p>\"Our SANTA framework is composed of memory-smoothed focal loss (M-SFL), entity-aware KNN (E-KNN), boundary mixup, and noise-tolerant loss (NT).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/PKUnlpicler/SANTA\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/PKUnlpicler/SANTA</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04076v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04076v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-00633-w",
    "title": "Fed up and burnt out: \u2018quiet quitting\u2019 hits academia",
    "latest": "2023-05-09T19:50:57.358000+00:00",
    "last_post": {
      "url": "https://mastodon.acm.org/@mxp/110340309135296068",
      "content": "<p>\u201cI think the main thing universities can do is change their priorities to take care of employees and create a workplace where people feel appreciated and seen.\u201d <a href=\"https://www.nature.com/articles/d41586-023-00633-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-00633-w</span></a></p>"
    },
    "people": [
      {
        "url": "https://datasci.social/@mszll",
        "display_name": "Michael Szell"
      },
      {
        "url": "https://mastodon.social/@ojala",
        "display_name": "Luis Apiolaza"
      },
      {
        "url": "https://tech.lgbt/@_dmh",
        "display_name": "Dave Howcroft \ud83e\udd94"
      },
      {
        "url": "https://social.luca.run/@luca",
        "display_name": "Luca \ud83d\udd28"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      },
      {
        "url": "https://mstdn.social/@felwert",
        "display_name": "Frederik Elwert"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/1809.05679",
    "title": "Graph Convolutional Networks for Text Classification",
    "latest": "2023-05-09T19:29:09+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ansgarscherp/110340377554329480",
      "content": "<p>We have been tracking Graph Neural Networks (GNN)  for text classification (TC) for the past 2+ years (w <span class=\"h-card\"><a href=\"https://sigmoid.social/@lpag\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>lpag</span></a></span>). Every other week, a new paper comes out, but *still* does not improve the results. Will it stop? There is now even a full survey: <a href=\"https://arxiv.org/abs/1809.05679\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/1809.05679</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04067v1",
    "title": "Reactive Perturbation Defocusing for Textual Adversarial Defense",
    "latest": "2023-05-09T19:17:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110340331981515701",
      "content": "<p>\ud83d\udcdd Reactive Perturbation Defocusing for Textual Adversarial Defense \ud83d\udcda</p><p>\"Uses an adversarial detector to identify adversarial examples and reduce false defenses on natural examples, and then injects safe perturbations into adversarial examples to distract the objective models from the malicious ones.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04067v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04067v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04049v1",
    "title": "https://arxiv.org/abs/2305.04049v1",
    "latest": "2023-05-09T19:02:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110340272998800590",
      "content": "<p>\ud83d\udcdd Actively Discovering New Slots for Task-Oriented Conversation \ud83d\udcda</p><p>\"A general new slot discovery task is formulated in an information extraction fashion and incorporated into a active learning framework to realize human-in-the-loop learning by incorporating uncertainty-based sampling and diversity-based sampling.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/newslotdetection/newslotdetection\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/newslotdetection/ne</span><span class=\"invisible\">wslotdetection</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04049v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04049v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04044v1",
    "title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation",
    "latest": "2023-05-09T18:17:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110340095928063731",
      "content": "<p>\ud83d\udcdd Diffusion-Nat: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation \ud83d\udcda</p><p>\"Proposes Diffusion-NAT which introduces discrete diffusion models (DDM) into NAR text-to-text generation and integrates BART to improve the performance.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04044v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04044v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04039v1",
    "title": "https://arxiv.org/abs/2305.04039v1",
    "latest": "2023-05-09T18:02:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110340037068191098",
      "content": "<p>\ud83d\udcdd Refining the Responses of LLMs by Themselves \ud83d\udcda\ud83d\udc7e</p><p>\"An iterative self-evaluating optimization mechanism, leveraging the large language model itself, is employed to iteratively optimize the answers generated by large language models without relying on auxiliary models.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/henryyantq/OptimaLLM\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/henryyantq/OptimaLL</span><span class=\"invisible\">M</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04039v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04039v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04003v1",
    "title": "https://arxiv.org/abs/2305.04003v1",
    "latest": "2023-05-09T17:47:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110339978112853741",
      "content": "<p>\ud83d\udcdd ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Works in three steps: (1) it converts a natural language processing (NLP) problem statement into a logic problem using a formal grammar, (2) it converts this logic problem into a verification query using an encoding scheme, (3) it solves this query using a neural network verifier.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/aisecprivate/ANTONIO\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/aisecprivate/ANTONI</span><span class=\"invisible\">O</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.04003v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04003v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03987v1",
    "title": "Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization",
    "latest": "2023-05-09T17:17:29+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110339860044119852",
      "content": "<p>\ud83d\udcdd Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization \ud83d\udcda\ud83d\udc7e</p><p>\"An offline imitation learning that can learn from real dialogues dataset, the state transition information is used which can alleviate the covariate shift problem caused by sequential decision-making process.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03987v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03987v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03981v1",
    "title": "Pre-training Language Model as a Multi-perspective Course Learner",
    "latest": "2023-05-09T16:47:29+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110339742054030765",
      "content": "<p>\ud83d\udcdd Pre-Training Language Model as a Multi-Perspective Course Learner \ud83d\udcda</p><p>\"Multiperspective self-supervision courses are designed to alleviate inherent flaws of MLM and balance the label in a multi-perspective way; Two self-correction courses are proposed to bridge the chasm between the two encoders by creating a \"correction notebook\" for secondary-supervision.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03981v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03981v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41386-023-01588-2",
    "title": "Dose-response relationships of LSD-induced subjective experiences in humans - Neuropsychopharmacology",
    "latest": "2023-05-09T16:40:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110339712806028003",
      "content": "<p>Dose-response relationships of LSD-induced subjective experiences in humans - <a href=\"https://www.nature.com/articles/s41386-023-01588-2\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41386-023</span><span class=\"invisible\">-01588-2</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://doi.org/10.7287/peerj.preprints.3210v1",
    "title": "doi.org/10.7287/peerj.preprint...",
    "latest": "2023-05-09T16:11:14+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@kbroman/110339599543047419",
      "content": "<p>9. The series includes a cool paper by Hilary Parker that's available only with the preprints.<br><a href=\"https://doi.org/10.7287/peerj.preprints.3210v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.7287/peerj.preprint</span><span class=\"invisible\">s.3210v1</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@kbroman",
        "display_name": "Karl Broman"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/toc/utas20/72/1?nav=tocList",
    "title": "The American Statistician",
    "latest": "2023-05-09T16:11:01+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@kbroman/110339598685430542",
      "content": "<p>8. The paper is part of a great series of articles on data science, instigated by <span class=\"h-card\"><a href=\"https://fosstodon.org/@jennybryan\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>jennybryan</span></a></span> and <span class=\"h-card\"><a href=\"https://fosstodon.org/@hadleywickham\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>hadleywickham</span></a></span>. <a href=\"https://www.tandfonline.com/toc/utas20/72/1?nav=tocList\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/toc/utas20/72/</span><span class=\"invisible\">1?nav=tocList</span></a><br><a href=\"https://peerj.com/collections/50-practicaldatascistats\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">peerj.com/collections/50-pract</span><span class=\"invisible\">icaldatascistats</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@kbroman",
        "display_name": "Karl Broman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04603.pdf",
    "title": "Privacy-Preserving Representations are not Enough -- Recovering Scene Content from Camera Poses",
    "latest": "2023-05-09T09:44:25+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ducha_aiki/110338078515823649",
      "content": "<p>Privacy-Preserving Representations are not Enough -- Recovering Scene Content from Camera Poses</p><p>Kunal Chelani, Torsten Sattler, Fredrik Kahl, Zuzana Kukelova</p><p>tl;dr: clever attack: you query with IKEA furniture, get camera pose and recover the scene. <br><a href=\"https://arxiv.org/abs/2305.04603.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04603.pdf</span><span class=\"invisible\"></span></a><br><a href=\"https://sigmoid.social/tags/computervision\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>computervision</span></a> <a href=\"https://sigmoid.social/tags/deeplearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>deeplearning</span></a> <br><a href=\"https://sigmoid.social/tags/dmytrotweetsaboutDL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>dmytrotweetsaboutDL</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@ducha_aiki",
        "display_name": "Dmytro Mishkin \ud83c\uddfa\ud83c\udde6"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02437",
    "title": "Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory",
    "latest": "2023-05-09T09:28:27+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313372685356350",
      "content": "<p>Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory</p><p><a href=\"https://arxiv.org/abs/2305.02437\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02437</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2212.08073?utm_source=substack&amp;utm_medium=email",
    "title": "Constitutional AI: Harmlessness from AI Feedback",
    "latest": "2023-05-09T09:18:24+00:00",
    "last_post": {
      "url": "https://techpolicy.social/@guifitz/110337975847092477",
      "content": "<p>Well, this is an interesting proposition for <a href=\"https://techpolicy.social/tags/ArtificialIntelligence\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ArtificialIntelligence</span></a>:</p><p>\"As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'.\"</p><p><a href=\"https://arxiv.org/abs/2212.08073?utm_source=substack&amp;utm_medium=email\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">arxiv.org/abs/2212.08073?utm_s</span><span class=\"invisible\">ource=substack&amp;utm_medium=email</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03819v1",
    "title": "Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces",
    "latest": "2023-05-09T09:17:29+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110337972618900846",
      "content": "<p>\ud83d\udcdd Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces \ud83d\udcda</p><p>\"S are trained on text data in a self-supervised fashion to predict the next word given its previous words as input, and then fine-tuned to predict the next character given its previous characters as input.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03819v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03819v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03796v1",
    "title": "Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation",
    "latest": "2023-05-09T08:32:25+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110337795406316262",
      "content": "<p>\ud83d\udcdd Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation \ud83d\udcda</p><p>\"A new Transformer variant named RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY, and it rediscovers the local windowed attention effect deemed necessary for length extrapolation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03796v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03796v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-022-00793-1",
    "title": "The rise of citational justice: how scholars are making references fairer",
    "latest": "2023-05-09T07:28:12+00:00",
    "last_post": {
      "url": "https://scholar.social/@dingemansemark/110337537130685675",
      "content": "<p>Clarivate's Web of Science \u2014for-profit purveyor of scholarly status\u2014 offers a \"geographic citation map\" showing the distribution of citations of researcher's work. In the interest of citational justice, I would be much more interested in being able to generate the reverse: the geographic diversity of the research cited *by* a researcher</p><p>See this on <a href=\"https://scholar.social/tags/citationaljustice\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>citationaljustice</span></a>: <a href=\"https://www.nature.com/articles/d41586-022-00793-1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-022</span><span class=\"invisible\">-00793-1</span></a></p>"
    },
    "people": [
      {
        "url": "https://aleph.land/@mtriclot",
        "display_name": "Mathieu Triclot"
      },
      {
        "url": "https://dair-community.social/@DrVeronikaCH",
        "display_name": "Veronika Cheplygina"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02412",
    "title": "Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents",
    "latest": "2023-05-09T07:23:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313368544832809",
      "content": "<p>Plan, Eliminate, and Track \u2014 Language Models are Good Teachers for Embodied Agents</p><p><a href=\"https://arxiv.org/abs/2305.02412\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02412</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0081714",
    "title": "The M\u00fcller-Lyer Illusion in Ant Foraging",
    "latest": "2023-05-09T07:15:55+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@gregeganSF/110337494574679035",
      "content": "<p>Some researchers claim to have shown that swarms of ants can collectively be subject to the same illusion:</p><p><a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0081714\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.plos.org/plosone/arti</span><span class=\"invisible\">cle?id=10.1371/journal.pone.0081714</span></a></p><p>But I got frustrated trying to make sense of their paper, given that Figs 2 &amp; 3, supposedly outwards/inwards arrows respectively, are identical!</p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@gregeganSF",
        "display_name": "Greg Egan"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03793v1",
    "title": "Towards Zero-Shot Frame Semantic Parsing with Task Agnostic Ontologies and Simple Labels",
    "latest": "2023-05-09T07:02:17+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110337440959515738",
      "content": "<p>\ud83d\udcdd Towards Zero-Shot Frame Semantic Parsing with Task Agnostic Ontologies and Simple Labels \ud83d\udcda\ud83e\udde0</p><p>\"OpenFSP relies on sentence encoders for intent detection and slot filling tasks, and on a novel domain matching algorithm to predict the domains from a handful of domain-agnostic slot types.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03793v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03793v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14454",
    "title": "PMC-LLaMA: Further Finetuning LLaMA on Medical Papers",
    "latest": "2023-05-09T05:10:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110336999651048914",
      "content": "<p>PMC-LLaMA: Further Finetuning LLaMA on Medical Papers - <a href=\"https://arxiv.org/abs/2304.14454\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14454</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03726v1",
    "title": "Otter: A Multi-Modal Model with In-Context Instruction Tuning",
    "latest": "2023-05-09T03:41:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110336649928577936",
      "content": "<p>\ud83d\udcdd Otter: A Multi-Modal Model with in-Context Instruction Tuning \ud83d\udd2d\ud83d\udcda</p><p>\"A multi-modal large language model (LLM) with in-context learning ability that is fine-tuned from OpenFlamingo, which is a multi-modal extension of DeepMind's Flamingo model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03726v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03726v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03602v1",
    "title": "A Dual Semantic-Aware Recurrent Global-Adaptive Network For Vision-and-Language Navigation",
    "latest": "2023-05-09T03:17:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110336555492724520",
      "content": "<p>\ud83d\udcdd A Dual Semantic-Aware Recurrent Global-Adaptive Network for Vision-and-Language Navigation \ud83d\udd2d\ud83d\udcda</p><p>\"DSRG consists of three parts: Instruction-guidance linguistic module (IGL), Appearance-semantics visual module (ASV), Global-adaptive aggregation module (GAA) and Recurrent memory fusion module (RMF).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03602v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03602v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/fullHtml/10.1145/3543873.3585579",
    "title": "dl.acm.org/doi/fullHtml/10.114...",
    "latest": "2023-05-09T03:05:31+00:00",
    "last_post": {
      "url": "https://mas.to/@vrandecic/110334985014764119",
      "content": "<p>\"Wikidata: The Making Of\"</p><p>The history of <a href=\"https://mas.to/tags/wikidata\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>wikidata</span></a> by Markus Kr\u00f6tzsch, <span class=\"h-card\"><a href=\"https://mastodon.online/@nightrose\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>nightrose</span></a></span> , and me. From the inception of the idea to the project proposal and development, and the first ten years of <span class=\"h-card\"><a href=\"https://wikis.world/@wikidata\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>wikidata</span></a></span> </p><p>Video on YouTube with a recording of the presentation (not the actual presentation from The Web Conference, though):<br><a href=\"https://www.youtube.com/watch?v=P3-nklyrDx4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">youtube.com/watch?v=P3-nklyrDx</span><span class=\"invisible\">4</span></a></p><p>Paper as HTML:<br><a href=\"https://dl.acm.org/doi/fullHtml/10.1145/3543873.3585579\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/fullHtml/10.114</span><span class=\"invisible\">5/3543873.3585579</span></a></p><p>Paper as PDF (Open access):<br><a href=\"https://dl.acm.org/doi/pdf/10.1145/3543873.3585579\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/pdf/10.1145/354</span><span class=\"invisible\">3873.3585579</span></a></p>"
    },
    "people": [
      {
        "url": "https://mas.to/@vrandecic",
        "display_name": "Denny Vrande\u010di\u0107"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://dl.acm.org/doi/pdf/10.1145/3543873.3585579",
    "title": "dl.acm.org/doi/pdf/10.1145/354...",
    "latest": "2023-05-09T03:05:31+00:00",
    "last_post": {
      "url": "https://mas.to/@vrandecic/110334985014764119",
      "content": "<p>\"Wikidata: The Making Of\"</p><p>The history of <a href=\"https://mas.to/tags/wikidata\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>wikidata</span></a> by Markus Kr\u00f6tzsch, <span class=\"h-card\"><a href=\"https://mastodon.online/@nightrose\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>nightrose</span></a></span> , and me. From the inception of the idea to the project proposal and development, and the first ten years of <span class=\"h-card\"><a href=\"https://wikis.world/@wikidata\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>wikidata</span></a></span> </p><p>Video on YouTube with a recording of the presentation (not the actual presentation from The Web Conference, though):<br><a href=\"https://www.youtube.com/watch?v=P3-nklyrDx4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">youtube.com/watch?v=P3-nklyrDx</span><span class=\"invisible\">4</span></a></p><p>Paper as HTML:<br><a href=\"https://dl.acm.org/doi/fullHtml/10.1145/3543873.3585579\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/fullHtml/10.114</span><span class=\"invisible\">5/3543873.3585579</span></a></p><p>Paper as PDF (Open access):<br><a href=\"https://dl.acm.org/doi/pdf/10.1145/3543873.3585579\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">dl.acm.org/doi/pdf/10.1145/354</span><span class=\"invisible\">3873.3585579</span></a></p>"
    },
    "people": [
      {
        "url": "https://mas.to/@vrandecic",
        "display_name": "Denny Vrande\u010di\u0107"
      },
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03204v1",
    "title": "VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation",
    "latest": "2023-05-09T02:53:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110336461040993213",
      "content": "<p>\ud83d\udcdd VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation \ud83d\udd2d\ud83d\udcda</p><p>\"Our VideoOFA model first pre-trains a vision-language Transformer on image-text data, and then adapts it to video data in an intermediate video-text pre-training stage.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03204v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03204v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2305.04532.pdf",
    "title": "https://arxiv.org/pdf/2305.04532.pdf",
    "latest": "2023-05-09T02:32:51+00:00",
    "last_post": {
      "url": "https://mastodon.radio/@mgiven/110336381529639323",
      "content": "<p>\"Latest Trends in Artificial Intelligence Technology: A Scoping Review\"</p><p><a href=\"https://arxiv.org/pdf/2305.04532.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2305.04532.pdf</span><span class=\"invisible\"></span></a></p><p><a href=\"https://mastodon.radio/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.radio/@mgiven",
        "display_name": "Mott"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03695v1",
    "title": "Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements",
    "latest": "2023-05-09T02:29:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110336366812745064",
      "content": "<p>\ud83d\udcdd Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements \ud83d\udcda\ud83d\udc7e</p><p>\"Uses a RoBERTa-Large as the backbone, and a training set of 7 million commonsense statements created from 19 QA datasets and two large-scale knowledge bases.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03695v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03695v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04087",
    "title": "Self-Edit: Fault-Aware Code Editor for Code Generation",
    "latest": "2023-05-09T02:10:14+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110336292594128861",
      "content": "<p>Self-Edit: Fault-Aware Code Editor for Code Generation</p><p>Improves the average of pass@1 by 89% on APPS-dev, 31% on APPS-test, and 48% on HumanEval over nine popular code generation LLMs with parameter sizes ranging from 110M to 175B.</p><p><a href=\"https://arxiv.org/abs/2305.04087\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04087</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04091",
    "title": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models",
    "latest": "2023-05-09T02:08:13+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110336284626211643",
      "content": "<p>Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models</p><p>Improved performance on various reasoning tasks in zero/few shot </p><p><a href=\"https://arxiv.org/abs/2305.04091\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04091</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03668v1",
    "title": "A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding",
    "latest": "2023-05-09T01:53:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110336225144290093",
      "content": "<p>\ud83d\udcdd A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding \ud83d\udcda\ud83d\udd2d</p><p>\"By separating the most relevant image and text content as global tokens to attend to the rest of the webpage for context, Prefix Global performs better than full attention with lower computational complexity.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03668v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03668v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.12712",
    "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
    "latest": "2023-05-09T01:43:14+00:00",
    "last_post": {
      "url": "https://mastodon.social/@vrruiz/110336128845717428",
      "content": "<p>Sparks of AGI: early experiments with GPT-4 - YouTube <a href=\"https://www.youtube.com/watch?v=qbIk7-JPB2c\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">youtube.com/watch?v=qbIk7-JPB2</span><span class=\"invisible\">c</span></a></p><p>Sebastian Bubek. \u00abThe new wave of AI systems, ChatGPT and its more powerful successors, exhibit extraordinary capabilities across a broad swath of domains. In light of this, we discuss whether artificial intelligence  has arrived. Paper available here: <a href=\"https://arxiv.org/abs/2303.12712\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.12712</span><span class=\"invisible\"></span></a> Video recorded at MIT on March 22nd, 2023\u00bb.</p><p><a href=\"https://mastodon.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://mastodon.social/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a> <a href=\"https://mastodon.social/tags/GPT4\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GPT4</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://sigmoid.social/@ceperez",
        "display_name": "Carlos E. Perez @IntuitMachine"
      },
      {
        "url": "https://social.skewed.de/@tiago",
        "display_name": "Tiago Peixoto"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03655v1",
    "title": "https://arxiv.org/abs/2305.03655v1",
    "latest": "2023-05-09T01:41:03+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110336177833135689",
      "content": "<p>\ud83d\udcdd White-Box Multi-Objective Adversarial Attack on Dialogue Generation \ud83d\udcda\ud83e\udde0</p><p>\"DGSlow balances two objectives -- generation accuracy and length, via a gradient-based multi-objective optimizer and applies an adaptive searching mechanism to iteratively craft adversarial samples with only a few modifications.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CR\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CR</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/yul091/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/yul091/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03655v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03655v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04241",
    "title": "Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens",
    "latest": "2023-05-09T01:25:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110336116421156322",
      "content": "<p>Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens</p><p>Proposes to significantly reduce the long attention cost by compressing the input into a fixed-size set of vectors at each layer.</p><p><a href=\"https://arxiv.org/abs/2305.04241\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04241</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04757",
    "title": "Augmented Large Language Models with Parametric Knowledge Guiding",
    "latest": "2023-05-09T01:22:22+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110336104349372354",
      "content": "<p>Augmented Large Language Models with Parametric Knowledge Guiding</p><p>Enhances the performance of \"black-box\" LLMs on a range of long-tail and domain-specific downstream tasks requiring factual, tabular, medical, and multimodal knowledge.</p><p><a href=\"https://arxiv.org/abs/2305.04757\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04757</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04369",
    "title": "Getting More out of Large Language Models for Proofs",
    "latest": "2023-05-09T01:19:25+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110336092790565906",
      "content": "<p>Getting More out of Large Language Models for Proofs</p><p><a href=\"https://arxiv.org/abs/2305.04369\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04369</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03573v1",
    "title": "In-context Learning as Maintaining Coherency: A Study of On-the-fly Machine Translation Using Large Language Models",
    "latest": "2023-05-09T01:05:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110336036489399245",
      "content": "<p>\ud83d\udcdd In-Context Learning as Maintaining Coherency: A Study of on-the-Fly Machine Translation Using Large Language Models \ud83d\udcda\ud83d\udc7e</p><p>\"Achieved by finetuning the pretrained language model on the prompt examples and then evaluating the finetuned model for translation of the test sentence, using the prompt examples as the context for generating the translation of the test sentence.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03573v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03573v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03520v1",
    "title": "https://arxiv.org/abs/2305.03520v1",
    "latest": "2023-05-09T00:53:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110335989324551631",
      "content": "<p>\ud83d\udcdd Context-Aware Semantic Similarity Measurement for Unsupervised Word Sense Disambiguation \ud83d\udcda\ud83d\udc7e</p><p>\"Introduces a new context-aware approach to unsupervised word sense disambiguation that provides a flexible mechanism for incorporating contextual information into the similarity measurement process by leveraging the contextual similarity between word senses.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/jorge-martinez-gil/uwsd\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/jorge-martinez-gil/</span><span class=\"invisible\">uwsd</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03520v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03520v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.04790",
    "title": "https://arxiv.org/abs/2305.04790",
    "latest": "2023-05-09T00:50:13+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110335977955364104",
      "content": "<p>MultiModal-GPT: A Vision and Language Model for Dialogue with Humans</p><p>repo: <a href=\"https://github.com/open-mmlab/Multimodal-GPT\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/open-mmlab/Multimod</span><span class=\"invisible\">al-GPT</span></a><br>abs: <a href=\"https://arxiv.org/abs/2305.04790\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.04790</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.03612",
    "title": "What does ChatGPT return about human values? Exploring value bias in ChatGPT using a descriptive value theory",
    "latest": "2023-05-09T00:37:10+00:00",
    "last_post": {
      "url": "https://hci.social/@mluczak/110335926209422753",
      "content": "<p>And finally we brought it all back into the immediate present with \"What does <a href=\"https://hci.social/tags/ChatGPT\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ChatGPT</span></a> return about human <a href=\"https://hci.social/tags/values\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>values</span></a>? Exploring value bias in ChatGPT using a descriptive value theory\" <a href=\"https://arxiv.org/abs/2304.03612\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.03612</span><span class=\"invisible\"></span></a> 10/10 <a href=\"https://hci.social/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> <a href=\"https://hci.social/tags/psychology\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>psychology</span></a> <a href=\"https://hci.social/tags/science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>science</span></a> <a href=\"https://hci.social/tags/research\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>research</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03518v1",
    "title": "Black-box Prompt Tuning with Subspace Learning",
    "latest": "2023-05-09T00:05:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110335800554801451",
      "content": "<p>\ud83d\udcdd Black-Box Prompt Tuning with Subspace Learning \ud83d\udcda\ud83d\udc7e</p><p>\"First identifies nearly optimal prompts for source tasks in a shared subspace by meta-learning and then finds a prompt for the target task by optimizing prompts in the subspace.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03518v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03518v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41550-023-01962-6",
    "title": "Spatially resolved imaging of the inner Fomalhaut disk using JWST/MIRI - Nature Astronomy",
    "latest": "2023-05-08T23:36:30+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@filipw/110334781318606083",
      "content": "<p>new beautiful James Webb Space Telescope image - the star Fomalhaut and its planetary system with spectacular nested concentric rings of dust</p><p>\ud83d\udcdd The accompanying paper in Nature Astronomy: Spatially resolved imaging of the inner Fomalhaut disk using JWST/MIRI<br>\ud83d\udd17 <a href=\"https://www.nature.com/articles/s41550-023-01962-6\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41550-023</span><span class=\"invisible\">-01962-6</span></a><br>\ud83c\udff7\ufe0f <a href=\"https://mathstodon.xyz/tags/astrodon\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>astrodon</span></a> <a href=\"https://mathstodon.xyz/tags/astronomy\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>astronomy</span></a> <a href=\"https://mathstodon.xyz/tags/science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>science</span></a></p><p>Credits<br>IMAGE: NASA, ESA, CSA \u2028IMAGE PROCESSING: Andr\u00e1s G\u00e1sp\u00e1r (University of Arizona), Alyssa Pagan (STScI) \u2028SCIENCE: Andr\u00e1s G\u00e1sp\u00e1r (University of Arizona)</p>"
    },
    "people": [
      {
        "url": "https://mastodon.art/@mtyka",
        "display_name": "Mike Tyka"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03517v1",
    "title": "https://arxiv.org/abs/2305.03517v1",
    "latest": "2023-05-08T23:29:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110335658998693803",
      "content": "<p>\ud83d\udcdd Few-Shot Domain-Adaptive Visually-Fused Event Detection From Text \ud83d\udcda\ud83d\udc7e</p><p>\"Relies on an imaginator, which is trained on text-only data points and can generate images from text descriptions in the absence of visual context for training the event detection model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/huggingface/transformers\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/huggingface/transfo</span><span class=\"invisible\">rmers</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03517v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03517v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1126/science.adg0493",
    "title": "doi.org/10.1126/science.adg049...",
    "latest": "2023-05-08T23:10:44+00:00",
    "last_post": {
      "url": "https://fediscience.org/@Forrest/110321615593912438",
      "content": "<p>RT @erleellis<br>Malthus &amp; Ehrlich were wrong.</p><p>Boserup &amp; Ostrom were right.</p><p>Why are they ignored?</p><p>My review of Jonsson &amp; Wennerlind's \"Scarcity\" @ScienceMagazine<br><a href=\"https://doi.org/10.1126/science.adg0493\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1126/science.adg049</span><span class=\"invisible\">3</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.nz/@ojala",
        "display_name": "Luis Apiolaza"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03511v1",
    "title": "Shared Latent Space by Both Languages in Non-Autoregressive Neural Machine Translation",
    "latest": "2023-05-08T21:53:03+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110335281330801667",
      "content": "<p>\ud83d\udcdd Shared Latent Space by Both Languages in Non-Autoregressive Neural Machine Translation \ud83d\udcda\ud83e\udde0</p><p>\"Designs an advanced hierarchical latent modeling that is based on a dual reconstruction perspective and shares a latent space across both languages so that it hypothetically alleviates or solves the above disadvantages.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03511v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03511v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03510v1",
    "title": "Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment",
    "latest": "2023-05-08T21:17:03+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110335139728589151",
      "content": "<p>\ud83d\udcdd Parameter-Efficient Cross-Lingual Transfer of Vision and Language Models via Translation-Based Alignment \ud83d\udcda\ud83d\udc7e</p><p>\"Proposes a new parameter-efficient cross-lingual transfer learning framework that utilizes a translation-based alignment method to mitigate multilingual disparities and explores parameter-efficient fine-tuning methods for parameter-efficient cross-lingual transfer.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03510v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03510v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01711",
    "title": "Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner",
    "latest": "2023-05-08T21:12:58+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110312515022885739",
      "content": "<p>Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner</p><p>Proposes Prompt-based Continued Pre-training, which consistently improves the performance of prompt-based fine-tuning (up to 20.1% absolute).</p><p>Paper: <a href=\"https://arxiv.org/abs/2305.01711\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01711</span><span class=\"invisible\"></span></a><br>Code: <a href=\"https://github.com/ZhengxiangShi/PowerfulPromptFT\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/ZhengxiangShi/Power</span><span class=\"invisible\">fulPromptFT</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03508v1",
    "title": "https://arxiv.org/abs/2305.03508v1",
    "latest": "2023-05-08T20:41:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334998295380724",
      "content": "<p>\ud83d\udcdd CiteCaseLAW: Citation Worthiness Detection in Caselaw for Legal Assistive Writing \ud83d\udcda\ud83e\udde0</p><p>\"Introduces a labeled dataset of 178M sentences for citation-worthiness detection in the legal domain from the Caselaw Access Project (CAP).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/fnl/segtok\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/fnl/segtok</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03508v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03508v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.13712",
    "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond",
    "latest": "2023-05-08T20:36:27+00:00",
    "last_post": {
      "url": "https://mastodon.online/@tomstafford/110332961058200534",
      "content": "<p>The evolutionary tree of Large Language Models</p><p>Figure 1 from Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond <a href=\"https://arxiv.org/abs/2304.13712\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.13712</span><span class=\"invisible\"></span></a>, via <a href=\"https://datamachina.substack.com/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">datamachina.substack.com/</span><span class=\"invisible\"></span></a> @ds_ldn</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      }
    ]
  },
  {
    "link": "http://osf.io/hxuws/",
    "title": "http://osf.io/hxuws/",
    "latest": "2023-05-08T20:11:05+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110334880325749222",
      "content": "<p>It all runs in the family? A life course perspective on intergenerational family positions and wealth accumulation <a href=\"http://osf.io/hxuws/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/hxuws/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/ka6nr/",
    "title": "http://osf.io/ka6nr/",
    "latest": "2023-05-08T20:11:05+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110334880356703724",
      "content": "<p>Transitions into and out of Car Ownership among Low-Income Households in the United States <a href=\"http://osf.io/ka6nr/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ka6nr/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03453v1",
    "title": "T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering",
    "latest": "2023-05-08T19:53:07+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334809699146096",
      "content": "<p>\ud83d\udcdd T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering \ud83d\udcda</p><p>\"Generates high-quality chain-of-thought (CoT) rationales as teaching signals to train smaller models to perform CoT reasoning in complex modalities.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03453v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03453v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03461v1",
    "title": "https://arxiv.org/abs/2305.03461v1",
    "latest": "2023-05-08T19:41:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334762396044128",
      "content": "<p>\ud83d\udcdd Interactive Acquisition of Fine-Grained Visual Concepts by Exploiting Semantics of Generic Characterizations in Discourse \ud83d\udcda</p><p>\"Composed of two interacting neural modules: a (1) referential learner which grounds the novel words, and (2) pragmatic inference module which infers the meaning of these grounded concepts.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/itl-ed/ns-arch\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/itl-ed/ns-arch</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03461v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03461v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03445v1",
    "title": "https://arxiv.org/abs/2305.03445v1",
    "latest": "2023-05-08T19:17:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334667955438771",
      "content": "<p>\ud83d\udcdd LMs Stand Their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models \ud83d\udcda</p><p>\"Language models conceptualise embodied concepts to a degree which facilitates the interpretation of figurative language in a better fashion when the action of the figurative sentence is more embodied.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/armandrotaru/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/armandrotaru/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03445v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03445v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03429v1",
    "title": "Simulating H.P. Lovecraft horror literature with the ChatGPT large language model",
    "latest": "2023-05-08T18:41:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334526408047753",
      "content": "<p>\ud83d\udcdd Simulating H.P. Lovecraft Horror Literature with the ChatGPT Large Language Model \ud83d\udcda</p><p>\"Presents a novel approach to simulating H P Lovecraft's horror literature using the ChatGPT large language model, specifically the GPT-4 architecture.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03429v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03429v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03423v1",
    "title": "Using ChatGPT for Entity Matching",
    "latest": "2023-05-08T18:05:04+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334384844671592",
      "content": "<p>\ud83d\udcdd Using ChatGPT for Entity Matching \ud83d\udcda</p><p>\"Investigates using ChatGPT for entity matching as a more robust, training data-efficient alternative to traditional Transformer models by designing three experiments on different aspects of this approach.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03423v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03423v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03356v1",
    "title": "From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base",
    "latest": "2023-05-08T17:05:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334148967331912",
      "content": "<p>\ud83d\udcdd From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering Over Knowledge Base \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"A novel parse-execute-refine paradigm is proposed to improve reasoning abilities of semantic parsers on complex questions over knowledge bases (KBQA) by demonstrating intermediate reasoning processes to the KBQA model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03356v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03356v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.36850/mr5",
    "title": "https://doi.org/10.36850/mr5",
    "latest": "2023-05-08T16:49:22+00:00",
    "last_post": {
      "url": "https://fediscience.org/@MarkRubin/110329879444046719",
      "content": "<p>Open Science and Academic Workload</p><p>New article by Thomas Hostler in the Journal of Trial and Error:</p><p>\u201cThere is a high chance that without intervention, increased expectations to engage in open research practices may lead to unacceptable increases in demands on academics.\u201d</p><p>Open access: <a href=\"https://doi.org/10.36850/mr5\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.36850/mr5</span><span class=\"invisible\"></span></a> </p><p><a href=\"https://fediscience.org/tags/Science\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Science</span></a><br><a href=\"https://fediscience.org/tags/OpenScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>OpenScience</span></a><br><a href=\"https://fediscience.org/tags/MetaScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MetaScience</span></a><br><a href=\"https://fediscience.org/tags/MetaResearch\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>MetaResearch</span></a><br><a href=\"https://fediscience.org/tags/SociologyofScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>SociologyofScience</span></a><br><a href=\"https://fediscience.org/tags/ScienceofScience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ScienceofScience</span></a><br><a href=\"https://fediscience.org/tags/STS\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>STS</span></a><br><span class=\"h-card\"><a href=\"https://a.gup.pe/u/stsing\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>stsing</span></a></span><br><span class=\"h-card\"><a href=\"https://a.gup.pe/u/academicchatter\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>academicchatter</span></a></span><br><a href=\"https://fediscience.org/tags/AcademicWorkload\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AcademicWorkload</span></a></p>"
    },
    "people": [
      {
        "url": "https://mapstodon.space/@floledermann",
        "display_name": "Florian Ledermann"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03353v1",
    "title": "https://arxiv.org/abs/2305.03353v1",
    "latest": "2023-05-08T16:41:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110334054587542018",
      "content": "<p>\ud83d\udcdd MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic \ud83d\udcda\ud83d\udc7e</p><p>\"Uses dynamic epistemic logic (DEL), a formal theory of knowledge, to generate more intricate problems than in prior studies and express these problems using natural language.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/antoinelrnld/modlog\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/antoinelrnld/modlog</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03353v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03353v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01532-w",
    "title": "Researchers who agree to manipulate citations are more likely to get their papers published",
    "latest": "2023-05-08T16:34:46+00:00",
    "last_post": {
      "url": "https://fediscience.org/@petersuber/110334029733078035",
      "content": "<p>When <a href=\"https://fediscience.org/tags/journals\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>journals</span></a> coerce authors to add superfluous <a href=\"https://fediscience.org/tags/citations\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>citations</span></a> to their papers, authors who cave are more likely to be published and more likely to do it again later. <br><a href=\"https://www.nature.com/articles/d41586-023-01532-w\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01532-w</span></a></p><p><a href=\"https://fediscience.org/tags/ScholComm\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ScholComm</span></a></p>"
    },
    "people": [
      {
        "url": "https://esq.social/@icymi_law",
        "display_name": "ICYMI (Law)"
      },
      {
        "url": "https://dair-community.social/@DrVeronikaCH",
        "display_name": "Veronika Cheplygina"
      },
      {
        "url": "https://fediscience.org/@petersuber",
        "display_name": "petersuber"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05135",
    "title": "https://doi.org/10.21105/joss.05135",
    "latest": "2023-05-08T16:34:08+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110333274647485807",
      "content": "<p>Just published in JOSS: 'LaMa: a thematic labelling web application' <a href=\"https://doi.org/10.21105/joss.05135\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05135</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://piaille.fr/@paulanomalie",
        "display_name": "Paul"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03132v1",
    "title": "The Role of Global and Local Context in Named Entity Recognition",
    "latest": "2023-05-08T09:29:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332355898722537",
      "content": "<p>\ud83d\udcdd The Role of Global and Local Context in Named Entity Recognition \ud83d\udcda</p><p>\"Finds that correctly retrieving global document context has a greater impact on performance than only leveraging local context, prompting for further research on how to better retrieve that context.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03132v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03132v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03130v1",
    "title": "https://arxiv.org/abs/2305.03130v1",
    "latest": "2023-05-08T09:05:05+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332261551212177",
      "content": "<p>\ud83d\udcdd Chain-of-Skills: A Configurable Model for Open-Domain Question Answering \ud83d\udcda</p><p>\"Modular retriever is a multitask retriever trained in a modular way, where individual retriever modules correspond to key retrieval skills that can be reused across datasets.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/facebookresearch/DPR\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/DP</span><span class=\"invisible\">R</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03130v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03130v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05019",
    "title": "https://doi.org/10.21105/joss.05019",
    "latest": "2023-05-08T09:00:03+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110332241711382737",
      "content": "<p>Just published in JOSS: 'CORA and LOGIGRAM: A Duo of Python Packages for Combinational Regularity Analysis (CORA)' <a href=\"https://doi.org/10.21105/joss.05019\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05019</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03117v1",
    "title": "Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations",
    "latest": "2023-05-08T08:53:06+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332214389730256",
      "content": "<p>\ud83d\udcdd Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations \ud83d\udcda</p><p>\"Evaluates the quality of explanation by the impact of the explanation on the model performance on the desired NLP task, for both fine-tuning (train phase) and inference (test phase).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03117v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03117v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03111v1",
    "title": "Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs",
    "latest": "2023-05-08T08:17:03+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110332072635036666",
      "content": "<p>\ud83d\udcdd Can LLM Already Serve as a Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs \ud83d\udcda</p><p>\"Presents Bird, a big database grounded in text-to-SQL tasks, containing 12751 pairs of data-to-SQL data and 95 databases with a total size of 33.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03111v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03111v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.14732",
    "title": "Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks",
    "latest": "2023-05-08T07:46:47+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110331953652956029",
      "content": "<p>[Research] Towards Accurate, Credible and Traceable Large Language Models\uff01\uff01\uff01</p><p><a href=\"https://arxiv.org/abs/2304.14732\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.14732</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2304.14732\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2304.14732</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03410",
    "title": "Tidally Heated Exomoons around $\u03b5$ Eridani b: Observability and prospects for characterization",
    "latest": "2023-05-08T07:39:57+00:00",
    "last_post": {
      "url": "https://mastodon.social/@mattkenworthy/110331836604163402",
      "content": "<p>Can we image tidally heated exomoons using JWST? Probably! This is a new paper by graduate student Elina Kleisioti who is working with me and Dominic Dirkx from TU Delft - she simulated internal models for exomoons around Eps Eri b, a gas giant exoplanet around a very nearby star. <a href=\"https://arxiv.org/abs/2305.03410\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03410</span><span class=\"invisible\"></span></a> \"Tidally Heated Exomoons around \u03b5 Eridani b: Observability and prospects for characterization\" /1 \ud83e\uddf5</p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@gregeganSF",
        "display_name": "Greg Egan"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03088v1",
    "title": "Modeling What-to-ask and How-to-ask for Answer-unaware Conversational Question Generation",
    "latest": "2023-05-08T07:17:43+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110331839329919135",
      "content": "<p>\ud83d\udcdd Modeling What-to-Ask and How-to-Ask for Answer-Unaware Conversational Question Generation \ud83d\udcda\ud83d\udc7e</p><p>\"Answer with content missing: SG-CQG, a two-stage Conversational Question Generation framework, is proposed to address the two main challenges in the answer-unaware setting: what-to-ask and how-to-ask.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03088v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03088v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03092v1",
    "title": "Curating corpora with classifiers: A case study of clean energy sentiment online",
    "latest": "2023-05-08T06:57:48+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110331761038876505",
      "content": "<p>\ud83d\udcdd Curating Corpora with Classifiers: A Case Study of Clean Energy Sentiment Online \ud83d\udcda</p><p>\"Trains a BERT-base-uncased transformer model (Devlin et al 2019) to predict whether a given tweet is relevant to public opinion on a given issue.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CY\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CY</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03092v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03092v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2204.03954",
    "title": "Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification",
    "latest": "2023-05-08T06:46:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@ansgarscherp/110331715980114761",
      "content": "<p>Are we really making progress in text classification? Two AAAI papers outperformed by Logistic Regression -&gt; TextGCN (2019) and BERT-base -&gt; TextSSL (2022). What's wrong? See <span class=\"h-card\"><a href=\"https://sigmoid.social/@lpag\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>lpag</span></a></span>  et al. in <a href=\"https://arxiv.org/abs/2204.03954\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2204.03954</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/ve6rb/",
    "title": "http://osf.io/ve6rb/",
    "latest": "2023-05-08T03:06:13+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110330850383293766",
      "content": "<p>Emerging Measurement Opportunities for Studying Sexual and Gender Diverse Partnerships in Recent Population-based Surveys <a href=\"http://osf.io/ve6rb/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/ve6rb/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.00118",
    "title": "Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",
    "latest": "2023-05-08T03:02:28+00:00",
    "last_post": {
      "url": "https://creative.ai/@alexjc/110300973715415340",
      "content": "<p>Anyone working on such analyses for open models? Curious how the model size affects this analysis too.</p><p>The AI Act indeed mandates transparency of training data, so I think everyone is on same page here!</p><p>Time for @OpenAI@twitter.com to prepare non-infringing models.<br><a href=\"https://arxiv.org/abs/2305.00118\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.00118</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@dbamman",
        "display_name": "David Bamman"
      },
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      },
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      },
      {
        "url": "https://fedihum.org/@christof",
        "display_name": "Christof Sch\u00f6ch (moderator)"
      },
      {
        "url": "https://mastodon.social/@jose_eduardo",
        "display_name": "Jos\u00e9 Eduardo Gonz\u00e1lez"
      },
      {
        "url": "https://sigmoid.social/@roban",
        "display_name": "Roban Hultman Kramer"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/hk7fb/",
    "title": "http://osf.io/hk7fb/",
    "latest": "2023-05-08T03:02:17+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110330834937560983",
      "content": "<p>A Review of Longevity Validations up to May 2023 <a href=\"http://osf.io/hk7fb/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/hk7fb/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/fky6t/",
    "title": "http://osf.io/fky6t/",
    "latest": "2023-05-08T03:02:17+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110330834975128998",
      "content": "<p>What at power-with looks like and why we should choose it <a href=\"http://osf.io/fky6t/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/fky6t/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02301",
    "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes",
    "latest": "2023-05-07T22:42:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110307797061098943",
      "content": "<p>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes</p><p>Their 770M T5 outperforms the 540B PaLM model using only 80% of available data on a benchmark task.</p><p><a href=\"https://arxiv.org/abs/2305.02301\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02301</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/pdf/2206.07682.pdf",
    "title": "https://arxiv.org/pdf/2206.07682.pdf",
    "latest": "2023-05-07T20:56:10+00:00",
    "last_post": {
      "url": "https://mastodon.uno/@PietroTerna/110329394912664242",
      "content": "<p>Emergent Abilities of Large Language Models<br>Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models.<br><a href=\"https://arxiv.org/pdf/2206.07682.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/pdf/2206.07682.pdf</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02317",
    "title": "Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings",
    "latest": "2023-05-07T18:42:08+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110307616154617481",
      "content": "<p>Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings</p><p>Presents VCoT, a novel method that leverages chain of thought prompting with vision-language grounding to recursively bridge the logical gaps within sequential data</p><p><a href=\"https://arxiv.org/abs/2305.02317\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02317</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.17651",
    "title": "https://arxiv.org/abs/2303.17651",
    "latest": "2023-05-07T18:20:52+00:00",
    "last_post": {
      "url": "https://z2h.dev/@volkan/110328783911026053",
      "content": "<p>Iterative Refinement with Self-Feedback</p><p>SELF-REFINE, a framework improving LLM outputs using iterative feedback, emulates human text refinement. It doesn't need supervised training or reinforcement learning, functioning with one LLM. In 7 diverse tasks, SELF-REFINE surpasses direct generation, with outputs favored by humans and automated metrics, outperforming GPT-3.5 and GPT-4.</p><p><a href=\"https://arxiv.org/abs/2303.17651\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2303.17651</span><span class=\"invisible\"></span></a></p><p><a href=\"https://z2h.dev/tags/research\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>research</span></a> <a href=\"https://z2h.dev/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://z2h.dev/tags/ML\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ML</span></a> <a href=\"https://z2h.dev/tags/LLM\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLM</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2009.12240",
    "title": "Weird AI Yankovic: Generating Parody Lyrics",
    "latest": "2023-05-07T16:29:16+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@Riedl/110328345839214159",
      "content": "<p><span class=\"h-card\"><a href=\"https://hci.social/@jbigham\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>jbigham</span></a></span> <span class=\"h-card\"><a href=\"https://idf.social/@Ian\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Ian</span></a></span> <span class=\"h-card\"><a href=\"https://hci.social/@amyjko\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>amyjko</span></a></span> <a href=\"https://arxiv.org/abs/2009.12240\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2009.12240</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@Riedl",
        "display_name": "Mark Riedl"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.00944",
    "title": "Poisoning Language Models During Instruction Tuning",
    "latest": "2023-05-07T15:47:48+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110328182736960926",
      "content": "<p>[R] Poisoning Language Models During Instruction Tuning</p><p><a href=\"https://arxiv.org/abs/2305.00944\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.00944</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2305.00944\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2305.00944</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      },
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01487-y",
    "title": "\u2018Remarkable\u2019 AI tool designs mRNA vaccines that are more potent and stable",
    "latest": "2023-05-07T04:55:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110325616045116699",
      "content": "<p>\u2018Remarkable\u2019 AI tool designs mRNA vaccines that are more potent and stable - <a href=\"https://www.nature.com/articles/d41586-023-01487-y\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01487-y</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2204.14146",
    "title": "Training Language Models with Language Feedback",
    "latest": "2023-05-07T04:48:40+00:00",
    "last_post": {
      "url": "https://aus.social/@poofdyke/110325590335524673",
      "content": "<p>reinforcement learning via natural language feedback is a thing (<a href=\"https://arxiv.org/abs/2204.14146\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2204.14146</span><span class=\"invisible\"></span></a>) but... still seems inefficient</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2303.11156",
    "title": "Can AI-Generated Text be Reliably Detected?",
    "latest": "2023-05-07T01:10:14+00:00",
    "last_post": {
      "url": "https://fediverse.randomfoo.net/objects/4578b0e1-5ae2-4e5a-bc71-bae31707f9cf",
      "content": "<p>A couple \u201chuman interest\u201d stories related to ChatGPT:</p><p><a href=\"https://www.reddit.com/r/ChatGPT/comments/139o1q6/lost_all_my_content_writing_contracts_feeling/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Lost all my content writing contracts. Feeling hopeless as an author.</a> - follows another thread from a couple days ago <a href=\"https://www.reddit.com/r/ChatGPT/comments/138clv9/spent_5_years_building_up_my_craft_and_ai_will/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Spent 5 years building up my craft and AI will make me jobless</a> - entire classes of dislocation will be happening this year and it will only accelerate<br><a href=\"https://www.reddit.com/r/OpenAI/comments/138ayhf/professor_using_gptzero_to_accuse_students_of/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Professor using GPTZero to accuse students of cheating</a> - these detectors <a href=\"https://www.reddit.com/r/ChatGPT/comments/12q6ktf/ta_here_and_we_have_to_use_this_website_to_detect/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">are pretty bad</a> and <a href=\"https://www.reddit.com/r/OpenAI/comments/132ax3i/research_discredits_ai_detectors_gptzero_below_50/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">easy to get around</a> and a <a href=\"https://arxiv.org/abs/2303.11156\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">losing proposition</a>- but also pretty misguided for education IMO. Sal Kahn gave a recent talk about the <a href=\"https://www.youtube.com/watch?v=hJP5GqnTrNo\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">positive implication for AI tutors and teaching assistants</a>; also Po Shen Loh (CMU) <a href=\"https://www.youtube.com/watch?v=oO-akX66i24\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">gave an interesting talk</a> that touched on some of this last month at the Berkeley Simons Institute. Ethan Mollick (UPenn Wharton) has also <a href=\"https://www.oneusefulthing.org/p/all-my-classes-suddenly-became-ai\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">published on his approach</a>.<br><a href=\"https://www.reddit.com/r/OpenAI/comments/134p47z/the_first_chatgpt_powered_video_game_free_and/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">ChatGPT Powered Video Game</a> - on the heels of Square Enix\u2019s <a href=\"https://www.jp.square-enix.com/ai-tech-preview/portopia/en/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">new NLP-powered Portopia Serial Muder Case port</a> and the <a href=\"https://www.youtube.com/watch?v=UVNZ3_FwqJE\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">ChatGPT NPC experiments</a> (that Skyrim video has 8-second delays (waiting for ElevenLabs?), but <a href=\"https://github.com/AUGMXNT/llm-experiments/blob/main/05-command-ai-tts.py\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">my simple chat script</a> using TTS VITS for local voice generation has almost no delays)</p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02519v1",
    "title": "ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos",
    "latest": "2023-05-06T21:52:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323954760334321",
      "content": "<p>\ud83d\udcdd ANetQA: A Large-Scale Benchmark for Fine-Grained Compositional Reasoning Over Untrimmed Videos \ud83d\udd2d\ud83d\udcda</p><p>\"Answer with content missing: (A) - Introduces a new benchmark that consists of fine-grained compositional questions over ActivityNet videos and spatio-temporal scene graphs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02519v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02519v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02790v1",
    "title": "BranchNorm: Robustly Scaling Extremely Deep Transformers",
    "latest": "2023-05-06T20:52:37+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323719036150224",
      "content": "<p>\ud83d\udcdd BranchNorm: Robustly Scaling Extremely Deep Transformers \ud83e\udde0\ud83d\udcda</p><p>\"A dynamic normalization technique that rescales the norm of the non-residual branch in the Transformer model according to the training period, which theoretically stabilizes the training with smooth gradient norms at the early stage and encourages better convergence in the subsequent training.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a> <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02790v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02790v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03029v1",
    "title": "https://arxiv.org/abs/2305.03029v1",
    "latest": "2023-05-06T19:32:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323404191468378",
      "content": "<p>\ud83d\udcdd What Changes When You Randomly Choose BPE Merge Operations? Not Much \ud83d\udcda\ud83d\udc7e</p><p>\"Byte pair encoding (BPE) is a data compression method which iteratively merges the most frequent pair of adjacent symbols into a new symbol and recodes the corpus accordingly.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/bltlab/random-bpe\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/bltlab/random-bpe</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03029v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03029v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03025v1",
    "title": "https://arxiv.org/abs/2305.03025v1",
    "latest": "2023-05-06T18:52:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323246897144780",
      "content": "<p>\ud83d\udcdd Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models \ud83d\udcda\ud83d\udc7e</p><p>\"It's the first time to explore how to enhance open-source large language models through instruction-tuning and provide comprehensive evaluations of their performance on various aspects including language understanding, dialogue, and commonsense reasoning.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/dandelionsllm/pandallm\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/dandelionsllm/panda</span><span class=\"invisible\">llm</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03025v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03025v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03010v1",
    "title": "Sentence Embedding Leaks More Information than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence",
    "latest": "2023-05-06T17:52:34+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110323011030965624",
      "content": "<p>\ud83d\udcdd Sentence Embedding Leaks More Information Than You Expect: Generative Embedding Inversion Attack to Recover the Whole Sentence \ud83d\udcda</p><p>\"GEIA treats sentence-embedding as initial tokens representations and trains a powerful sequence decoder, which can be fine-tuned from pre-trained language models, such as BERT or GPT-2.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CR\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CR</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03010v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03010v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02869v1",
    "title": "2x Faster Language Model Pre-training via Masked Structural Growth",
    "latest": "2023-05-06T16:32:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110322696421149124",
      "content": "<p>\ud83d\udcdd 2x Faster Language Model Pre-Training via Masked Structural Growth \ud83d\udcda</p><p>\"The Masked Structural Growth (MSG) pre-training framework involves growth schedules involving all possible dimensions and a strictly function-preserving growth operator that is independent of the initialization of new weights.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02869v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02869v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01628",
    "title": "The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers",
    "latest": "2023-05-06T16:20:29+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110301980608185874",
      "content": "<p>The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers</p><p>Proposes a novel approach that utilizes the contrast between layers to improve text generation outputs.</p><p><a href=\"https://arxiv.org/abs/2305.01628\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01628</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03007v1",
    "title": "https://arxiv.org/abs/2305.03007v1",
    "latest": "2023-05-06T16:12:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110322617807529598",
      "content": "<p>\ud83d\udcdd NatCS: Eliciting Natural Customer Support Dialogues \ud83d\udcda</p><p>\"NatCS contains multi-domain conversations between customers and agents that are more representative of real human-to-human conversations compared to previous dialogue datasets along multiple quality metrics.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/amazon-science/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/amazon-science/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.03007v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03007v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/r5a7z/",
    "title": "http://osf.io/r5a7z/",
    "latest": "2023-05-06T16:03:20+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110322581529782893",
      "content": "<p>Degrees of Freedom Analysis: A mixed method for theory building, decision making, and prediction <a href=\"http://osf.io/r5a7z/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/r5a7z/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.10423",
    "title": "Fully Autonomous Programming with Large Language Models",
    "latest": "2023-05-06T15:47:08+00:00",
    "last_post": {
      "url": "https://mastodon.social/@compsci_discussions/110322517804224569",
      "content": "<p>[R] Fully Autonomous Programming with Large Language Models</p><p><a href=\"https://arxiv.org/abs/2304.10423\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.10423</span><span class=\"invisible\"></span></a></p><p>Discussions: <a href=\"https://discu.eu/q/https://arxiv.org/abs/2304.10423\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">discu.eu/q/https://arxiv.org/a</span><span class=\"invisible\">bs/2304.10423</span></a></p><p><a href=\"https://mastodon.social/tags/compsci\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>compsci</span></a> <a href=\"https://mastodon.social/tags/machinelearning\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>machinelearning</span></a> <a href=\"https://mastodon.social/tags/programming\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>programming</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@compsci_discussions",
        "display_name": "Compsci Weekly"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02865v1",
    "title": "CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing",
    "latest": "2023-05-06T15:32:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110322460310005821",
      "content": "<p>\ud83d\udcdd CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing \ud83d\udcda\ud83d\udc7e</p><p>\"Projects literal and semantic information into independent feature subspaces, and constrains the involvement of literal information in subsequent predictions by a causal intervention based on the backdoor adjustment criterion.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02865v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02865v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02750v1",
    "title": "A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects",
    "latest": "2023-05-06T09:52:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110321123501081960",
      "content": "<p>\ud83d\udcdd A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects \ud83d\udcda\ud83d\udc7e</p><p>\"A proactive dialogue system is a conversational agent that proactively leads the conversation to achieve pre-defined goals, which requires strategic dialogues to progress from simple to more complicated tasks.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02750v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02750v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41541-023-00661-7",
    "title": "Risk assessment of retinal vascular occlusion after COVID-19 vaccination - npj Vaccines",
    "latest": "2023-05-06T09:35:02+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110321054709275285",
      "content": "<p>Risk assessment of retinal vascular occlusion after Covid-19 vaccination - <a href=\"https://www.nature.com/articles/s41541-023-00661-7\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41541-023</span><span class=\"invisible\">-00661-7</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01523-x",
    "title": "Saudi universities entice top scientists to switch affiliations \u2014 sometimes with cash",
    "latest": "2023-05-06T09:13:16+00:00",
    "last_post": {
      "url": "https://akademienl.social/@mvugt/110320827133099883",
      "content": "<p>Wow... One of the problems of the obsession with citation indices... <a href=\"https://www.nature.com/articles/d41586-023-01523-x\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01523-x</span></a></p>"
    },
    "people": [
      {
        "url": "https://mastodon.social/@gvwilson",
        "display_name": "Greg Wilson"
      },
      {
        "url": "https://dair-community.social/@DrVeronikaCH",
        "display_name": "Veronika Cheplygina"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02747v1",
    "title": "https://arxiv.org/abs/2305.02747v1",
    "latest": "2023-05-06T08:52:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320887571314963",
      "content": "<p>\ud83d\udcdd Unsupervised Dialogue Topic Segmentation with Topic-Aware Utterance Representation \ud83d\udcda\ud83d\udc7e</p><p>\"DAMO-ConvAI is a novel unsupervised DTS framework that learns topic-aware utterance representations from unlabeled dialogue data through neighboring utterance matching and pseudo-segmentation.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/AlibabaResearch/DAMO-ConvAI\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/AlibabaResearch/DAM</span><span class=\"invisible\">O-ConvAI</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02747v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02747v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02637v1",
    "title": "Towards Weakly-Supervised Hate Speech Classification Across Datasets",
    "latest": "2023-05-06T07:32:30+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320572880565541",
      "content": "<p>\ud83d\udcdd Towards Weakly-Supervised Hate Speech Classification Across Datasets \ud83d\udcda\ud83d\udc7e</p><p>\"Applies a state-of-the-art weak-supervision technique that relies solely on class names to train HS classifiers and analyze the source of their low generalizability.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CY\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CY</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02637v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02637v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02633v1",
    "title": "Conformal Nucleus Sampling",
    "latest": "2023-05-06T06:52:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320415749570117",
      "content": "<p>\ud83d\udcdd Conformal Nucleus Sampling \ud83d\udcda\ud83e\udde0</p><p>\"A calibration procedure based on conformal prediction that uses the entropy of the next-word distribution as a calibration score to calibrate the parameter $p$ of nucleus sampling as a function of the confidence level.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02633v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02633v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02615v1",
    "title": "Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach",
    "latest": "2023-05-06T05:52:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110320179970859222",
      "content": "<p>\ud83d\udcdd Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach \ud83d\udcda\ud83d\udc7e</p><p>\"CACD contains two steps: (i) building a common centering one graph node causal skeleton for all utterances in variable-length conversations; (ii) Causal Auto-Encoder correcting the skeleton to yield causal representation through generated implicit causes and known explicit causes.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02615v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02615v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02606v1",
    "title": "Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-training",
    "latest": "2023-05-06T04:52:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319944007793795",
      "content": "<p>\ud83d\udcdd Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-Training \ud83d\udcda</p><p>\"Re3Dial first trains an Unsupervised Dense Session Retriever (UDSR) to capture semantic and discourse relationships within multi-turn dialogues for retrieving relevant and coherent sessions.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02606v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02606v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02564v1",
    "title": "RetroMAE-2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models",
    "latest": "2023-05-06T04:12:31+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319786463031550",
      "content": "<p>\ud83d\udcdd RetroMAE-2: Duplex Masked Auto-Encoder for Pre-Training Retrieval-Oriented Language Models \ud83d\udcda</p><p>\"Duplex Masked Auto-Encoder, a method that jointly learns two complementary Masked Token Prediction (MTP) tasks, namely, sentence-level MTP and token-level MTP.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02564v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02564v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02556v1",
    "title": "Faithful Question Answering with Monte-Carlo Planning",
    "latest": "2023-05-06T02:52:35+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319472162212090",
      "content": "<p>\ud83d\udcdd Faithful Question Answering with Monte-Carlo Planning \ud83d\udcda</p><p>\"Proposes FAME (FAithful question answering with MONTE-CARLO planning) to answer questions based on faithful reasoning steps organized as an entailment tree.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02556v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02556v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2305.00118",
    "title": "http://arxiv.org/abs/2305.00118",
    "latest": "2023-05-06T01:51:55+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110319233637367668",
      "content": "<p>8/</p><p>[3] Kent K. Chang, Mackenzie Cramer, Sandeep Soni, and David Bamman. 2023. Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4. <a href=\"http://arxiv.org/abs/2305.00118\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2305.00118</span><span class=\"invisible\"></span></a> </p><p><a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a> <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "http://arxiv.org/abs/2305.00050",
    "title": "http://arxiv.org/abs/2305.00050",
    "latest": "2023-05-06T01:51:39+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@BenjaminHan/110319232557899341",
      "content": "<p>7/</p><p>[1] Emre K\u0131c\u0131man, Robert Ness, Amit Sharma, and Chenhao Tan. 2023. Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. <a href=\"http://arxiv.org/abs/2305.00050\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/abs/2305.00050</span><span class=\"invisible\"></span></a></p><p>[2] Joris M. Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard Sch\u00f6lkopf. 2016. Distinguishing Cause from Effect Using Observational Data: Methods and Benchmarks. Journal of machine learning research: JMLR, 17(32):1\u2013102. <a href=\"https://jmlr.org/papers/v17/14-518.html\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">jmlr.org/papers/v17/14-518.htm</span><span class=\"invisible\">l</span></a> </p><p><a href=\"https://sigmoid.social/tags/NLP\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLP</span></a> <a href=\"https://sigmoid.social/tags/NLProc\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NLProc</span></a> <a href=\"https://sigmoid.social/tags/Paper\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>Paper</span></a> <a href=\"https://sigmoid.social/tags/GenerativeAI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>GenerativeAI</span></a> <a href=\"https://sigmoid.social/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@BenjaminHan",
        "display_name": "Benjamin Han"
      }
    ]
  },
  {
    "link": "https://journals.sagepub.com/doi/10.1177/00031224231169790",
    "title": "journals.sagepub.com/doi/10.11...",
    "latest": "2023-05-06T01:22:20+00:00",
    "last_post": {
      "url": "https://sciences.social/@andrew_jorgenson/110316584941624562",
      "content": "<p>Our paper, Guns versus Climate: How Militarization Amplifies the Effect of Economic Growth on Carbon Emissions, is now published in American Sociological Review. <a href=\"https://journals.sagepub.com/doi/10.1177/00031224231169790\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">journals.sagepub.com/doi/10.11</span><span class=\"invisible\">77/00031224231169790</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@dustinstoltz",
        "display_name": "D\u1d1cs\u1d1b\u026a\u0274 S\u1d1b\u1d0f\u029f\u1d1b\u1d22 :tardis:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02549v1",
    "title": "FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction",
    "latest": "2023-05-06T01:12:32+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110319078750838393",
      "content": "<p>\ud83d\udcdd FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction \ud83d\udcda\ud83d\udd2d\ud83e\udde0</p><p>\"FormNetV2 unifies multimodal pre-training by graph contrastive learning, and extracts image features within the bounding box to capture targeted information for graph edges that connect text tokens.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02549v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02549v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02499v1",
    "title": "AutoML-GPT: Automatic Machine Learning with GPT",
    "latest": "2023-05-06T00:12:33+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110318842892144154",
      "content": "<p>\ud83d\udcdd AutoML-GPT: Automatic Machine Learning with GPT \ud83d\udcda\ud83d\udc7e\ud83d\udd2d\ud83e\udde0</p><p>\"AutoML-GPT uses the GPT model as the bridge to diverse AI models and dynamically trains models with optimized hyperparameters by leveraging {\\ours}'s powerful language capabilities.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02499v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02499v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01530-y",
    "title": "Hard feelings over mission change for NASA\u2019s Pluto spacecraft",
    "latest": "2023-05-05T22:00:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110318321880196489",
      "content": "<p>Hard feelings over mission change for NASA\u2019s Pluto spacecraft - <a href=\"https://www.nature.com/articles/d41586-023-01530-y\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01530-y</span></a></p>"
    },
    "people": [
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02538",
    "title": "Cuttlefish: Low-rank Model Training without All The Tuning",
    "latest": "2023-05-05T21:55:17+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@rahuldave/110318303155768157",
      "content": "<p>RT @DimitrisPapail<br>1/6 \ud83c\udf89 Happy to share Cuttlefish \ud83e\udd91 our project for low-rank neural network training, without tuning factorization hyperparams! </p><p>arXiv link: <a href=\"https://arxiv.org/abs/2305.02538\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02538</span><span class=\"invisible\"></span></a></p><p>This is great work from my PhD graduate @HongyiWang10 that he'll present at MLSys this year</p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@rahuldave",
        "display_name": "Rahul Dave"
      }
    ]
  },
  {
    "link": "http://osf.io/5rwa9/",
    "title": "http://osf.io/5rwa9/",
    "latest": "2023-05-05T20:32:20+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317976947541706",
      "content": "<p>Decolonizing Historical Linguistics in the Classroom and Beyond <a href=\"http://osf.io/5rwa9/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/5rwa9/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/4r6ws/",
    "title": "http://osf.io/4r6ws/",
    "latest": "2023-05-05T20:27:05+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317956337106307",
      "content": "<p>Revitalization at a Distance: Engaging Digital Archives for Language Reclamation <a href=\"http://osf.io/4r6ws/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/4r6ws/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/xcg8j/",
    "title": "http://osf.io/xcg8j/",
    "latest": "2023-05-05T20:27:04+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317956286324035",
      "content": "<p>Step-gap in Upward Support Regarding Biological Relatedness and Childhood Co-residence Duration <a href=\"http://osf.io/xcg8j/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/xcg8j/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/5s4gr/",
    "title": "http://osf.io/5s4gr/",
    "latest": "2023-05-05T20:27:04+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317956252534870",
      "content": "<p>Puzzling out graphic codes <a href=\"http://osf.io/5s4gr/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/5s4gr/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/6rshg/",
    "title": "http://osf.io/6rshg/",
    "latest": "2023-05-05T19:47:04+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317798971787943",
      "content": "<p>ON FACIAL RECOGNITION, REGULATION, AND DATA NECROPOLITICS <a href=\"http://osf.io/6rshg/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/6rshg/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/fhgm5/",
    "title": "http://osf.io/fhgm5/",
    "latest": "2023-05-05T19:47:03+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110317798943829650",
      "content": "<p>Jobs and skills for adaptation and resilience in Scotland <a href=\"http://osf.io/fhgm5/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/fhgm5/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05340",
    "title": "https://doi.org/10.21105/joss.05340",
    "latest": "2023-05-05T19:12:12+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110317661903956142",
      "content": "<p>Just published in JOSS: 'STARRED: a two-channel deconvolution method with Starlet regularization' <a href=\"https://doi.org/10.21105/joss.05340\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05340</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02459v1",
    "title": "Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge",
    "latest": "2023-05-05T18:15:43+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110317439795574955",
      "content": "<p>\ud83d\udcdd Transfer and Active Learning for Dissonance Detection: Addressing the Rare-Class Challenge \ud83d\udcda\ud83e\udde0</p><p>\"A probability-of-rare-class (PRC) method is used for acquisition function which estimates the probability of a sample belonging to the rare class, and selects examples from a pool based on this score.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02459v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02459v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01625",
    "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input",
    "latest": "2023-05-05T18:15:03+00:00",
    "last_post": {
      "url": "https://die-partei.social/@hackernews/110317437176879156",
      "content": "<p>Unlimiformer: Long-Range Transformers with Unlimited Length Input - <a href=\"https://arxiv.org/abs/2305.01625\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01625</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@pbrane",
        "display_name": "Jake Mannix"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.07193",
    "title": "DINOv2: Learning Robust Visual Features without Supervision",
    "latest": "2023-05-05T17:32:24+00:00",
    "last_post": {
      "url": "https://hachyderm.io/@j15r/110220758476432011",
      "content": "<p>Meta Research \"Dino v2\" model: <a href=\"https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">ai.facebook.com/blog/dino-v2-c</span><span class=\"invisible\">omputer-vision-self-supervised-learning/</span></a></p><p>Lots of interesting stuff in here, but one of my favorite bits is that their model internalized enough information about the \u201csemantic parts\u201d of objects it recognizes, that it can correlate them across widely-varying images.</p><p>Definitely try the demos (linked from the blog post).</p><p>Paper: <a href=\"https://arxiv.org/abs/2304.07193\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.07193</span><span class=\"invisible\"></span></a></p><p><a href=\"https://hachyderm.io/tags/ml\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ml</span></a> <a href=\"https://hachyderm.io/tags/ai\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>ai</span></a> <a href=\"https://hachyderm.io/tags/research\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>research</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://sigmoid.social/@ogrisel",
        "display_name": "Olivier Grisel"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1080/10724117.2023.2168404",
    "title": "doi.org/10.1080/10724117.2023....",
    "latest": "2023-05-05T17:05:49+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@peterrowlett/110317164918912338",
      "content": "<p>Ooo, a copy of Math Horizons has arrived - the April issue with my article about the 1960s set theory game On-Sets.</p><p>Read my article for free here: <a href=\"https://doi.org/10.1080/10724117.2023.2168404\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/10724117.2023.</span><span class=\"invisible\">2168404</span></a></p><p>See what else is in the issue here: <a href=\"https://www.tandfonline.com/toc/umho20/30/4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/toc/umho20/30/</span><span class=\"invisible\">4</span></a></p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@peterrowlett",
        "display_name": "Peter Rowlett"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/toc/umho20/30/4",
    "title": "tandfonline.com/toc/umho20/30/...",
    "latest": "2023-05-05T17:05:49+00:00",
    "last_post": {
      "url": "https://mathstodon.xyz/@peterrowlett/110317164918912338",
      "content": "<p>Ooo, a copy of Math Horizons has arrived - the April issue with my article about the 1960s set theory game On-Sets.</p><p>Read my article for free here: <a href=\"https://doi.org/10.1080/10724117.2023.2168404\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1080/10724117.2023.</span><span class=\"invisible\">2168404</span></a></p><p>See what else is in the issue here: <a href=\"https://www.tandfonline.com/toc/umho20/30/4\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/toc/umho20/30/</span><span class=\"invisible\">4</span></a></p>"
    },
    "people": [
      {
        "url": "https://mathstodon.xyz/@peterrowlett",
        "display_name": "Peter Rowlett"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02437v1",
    "title": "Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory",
    "latest": "2023-05-05T16:55:42+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110317125136858528",
      "content": "<p>\ud83d\udcdd Lift Yourself Up: Retrieval-Augmented Text Generation with Self Memory \ud83d\udcda\ud83d\udc7e</p><p>\"A framework called Selfmem that iteratively adopts a retrieval-augmented generator itself to generate an unbounded memory pool and uses a memory selector to pick one generated memory for the next generation round.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02437v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02437v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/s41467-023-37194-5",
    "title": "Clarifying the effect of biodiversity on productivity in natural ecosystems with longitudinal data and methods for causal inference - Nature Communications",
    "latest": "2023-05-05T16:49:06+00:00",
    "last_post": {
      "url": "https://ecoevo.social/@jebyrnes/110317099193187970",
      "content": "<p>RT @Jon_Chase03<br>From a quick read, I think\ud83d\udc47 paper from \u2066\u2066@LauraEllenDee\u2069 et al, is probably one of the most important I\u2019ve seen in the BEF literature for some time. Better analytical \ud83d\udee0 suggest that \u2b06\ufe0f biodiversity =\u2b07\ufe0fproductivity in \u2066@NutNetGlobal\u2069 plots <a href=\"https://www.nature.com/articles/s41467-023-37194-5\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/s41467-023</span><span class=\"invisible\">-37194-5</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@jebyrnes",
        "display_name": "jebyrnes"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02386v1",
    "title": "Approximating CKY with Transformers",
    "latest": "2023-05-05T09:35:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110315394794337892",
      "content": "<p>\ud83d\udcdd Approximating CKY with Transformers \ud83d\udcda\ud83e\udde0</p><p>\"Works by predicting the parse chart directly using a transformer architecture that mirrors the chart structure, and then using gradients with respect to the chart to make a prediction at each span.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02386v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02386v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://doi.org/10.21105/joss.05220",
    "title": "https://doi.org/10.21105/joss.05220",
    "latest": "2023-05-05T08:39:47+00:00",
    "last_post": {
      "url": "https://fosstodon.org/@joss/110315175146639989",
      "content": "<p>Just published in JOSS: 'TSInterpret: A Python Package for the Interpretability of Time Series Classification' <a href=\"https://doi.org/10.21105/joss.05220\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">doi.org/10.21105/joss.05220</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://piaille.fr/@paulanomalie",
        "display_name": "Paul"
      },
      {
        "url": "https://fosstodon.org/@joss",
        "display_name": "JOSS"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02364v1",
    "title": "https://arxiv.org/abs/2305.02364v1",
    "latest": "2023-05-05T08:35:42+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110315159060621658",
      "content": "<p>\ud83d\udcdd PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives \ud83d\udcda</p><p>\"A large-scale dataset and commonsense knowledge graph, containing over 100k facts describing diverse personas and their world knowledge (e g a singer is likely to sing and be good at singing, and may have attended conservatoire).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/Silin159/PeaCoK\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/Silin159/PeaCoK</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02364v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02364v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02363v1",
    "title": "Entity Tracking in Language Models",
    "latest": "2023-05-05T07:35:39+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110314922918915030",
      "content": "<p>\ud83d\udcdd Entity Tracking in Language Models \ud83d\udcda</p><p>\"Pretraining on large amounts of text corpora and code helps models learn to track entities in text, but large-scale pretraining alone does not make this capacity surface.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02363v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02363v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://arxiv.org/pdf/2304.14082v1.pdf",
    "title": "http://arxiv.org/pdf/2304.14082v1.pdf",
    "latest": "2023-05-05T00:49:27+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313325662205098",
      "content": "<p>RT @utkuevci@twitter.com</p><p>Hyped to share JaxPruner: a concise library for sparsity research.</p><p>JaxPruner includes 10+ easy-to-modify baseline algorithms and provides integration with popular libraries like t5x, scenic, dopamine and fedjax. 1/7</p><p>Code: <a href=\"http://github.com/google-research/jaxpruner\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"ellipsis\">github.com/google-research/jax</span><span class=\"invisible\">pruner</span></a><br>Paper: <a href=\"http://arxiv.org/pdf/2304.14082v1.pdf\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">arxiv.org/pdf/2304.14082v1.pdf</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/utkuevci/status/1654251794845843457\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/utkuevci/status/16</span><span class=\"invisible\">54251794845843457</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03053",
    "title": "ZipIt! Merging Models from Different Tasks without Training",
    "latest": "2023-05-05T00:48:22+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313321437176788",
      "content": "<p>ZipIt! Merging Models from Different Tasks without Training</p><p>Presents ZipIt!, a general method for merging two arbitrary models of the same architecture that incorporates two simple strategies.</p><p><a href=\"https://arxiv.org/abs/2305.03053\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03053</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.03052",
    "title": "https://arxiv.org/abs/2305.03052",
    "latest": "2023-05-05T00:44:23+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313305736457797",
      "content": "<p>Tracking through Containers and Occluders in the Wild</p><p>Proposes a model, called TCOW, that can segment objects in videos with a notion of object permanence.</p><p>proj: <a href=\"https://tcow.cs.columbia.edu/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">tcow.cs.columbia.edu/</span><span class=\"invisible\"></span></a><br>abs: <a href=\"https://arxiv.org/abs/2305.03052\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.03052</span><span class=\"invisible\"></span></a> <a href=\"https://twitter.com/i/web/status/1654285634075238400\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/i/web/status/16542</span><span class=\"invisible\">85634075238400</span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02463",
    "title": "Shap-E: Generating Conditional 3D Implicit Functions",
    "latest": "2023-05-05T00:39:26+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313286310917481",
      "content": "<p>RT @unixpickle@twitter.com</p><p>Super excited to release Shap-E, our latest work on 3D generative modeling.</p><p>Paper: <a href=\"https://arxiv.org/abs/2305.02463\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02463</span><span class=\"invisible\"></span></a><br>Code/models: <a href=\"https://github.com/openai/shap-e\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/openai/shap-e</span><span class=\"invisible\"></span></a></p><p>\ud83d\udc26\ud83d\udd17: <a href=\"https://twitter.com/unixpickle/status/1654282269065105409\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">twitter.com/unixpickle/status/</span><span class=\"invisible\">1654282269065105409</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@alexjc",
        "display_name": "Alex J. Champandard \ud83c\udf31"
      },
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02968",
    "title": "https://arxiv.org/abs/2305.02968",
    "latest": "2023-05-05T00:39:23+00:00",
    "last_post": {
      "url": "https://sigmoid.social/@aran/110313286123002080",
      "content": "<p>Masked Trajectory Models for Prediction, Representation, and Control</p><p>Presents Masked Trajectory Models (MTM) as a generic abstraction for sequential decision making.</p><p>repo: <a href=\"https://github.com/facebookresearch/mtm\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/facebookresearch/mt</span><span class=\"invisible\">m</span></a><br>proj: <a href=\"https://wuphilipp.github.io/mtm/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">wuphilipp.github.io/mtm/</span><span class=\"invisible\"></span></a> <br>abs: <a href=\"https://arxiv.org/abs/2305.02968\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02968</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02265v1",
    "title": "https://arxiv.org/abs/2305.02265v1",
    "latest": "2023-05-04T21:53:23+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312633338300156",
      "content": "<p>\ud83d\udcdd A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval From Linguistically Complex Text \ud83d\udcda</p><p>\"A pretrained VLMs-based visual-linguistic interactor achieves the interaction between decomposed proposition sentences and images, a neural-symbolic reasoner combines the above reasoning states to obtain the final solution via a neural logic reasoning approach.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/YunxinLi/NDCR\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/YunxinLi/NDCR</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02265v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02265v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02261v1",
    "title": "https://arxiv.org/abs/2305.02261v1",
    "latest": "2023-05-04T21:23:18+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312515101770256",
      "content": "<p>\ud83d\udcdd End-to-End Training and Decoding for Pivot-Based Cascaded Translation Model \ud83d\udcda\ud83d\udc7e</p><p>\"The training of the source-pivot and pivot-target models is end-to-end, and a weighted pivot embedding is used as input to the pivot-target model.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/fxsjy/jieba\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/fxsjy/jieba</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02261v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02261v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02239v1",
    "title": "The Benefits of Label-Description Training for Zero-Shot Text Classification",
    "latest": "2023-05-04T20:43:18+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312357766235395",
      "content": "<p>\ud83d\udcdd The Benefits of Label-Description Training for Zero-Shot Text Classification \ud83d\udcda\ud83d\udc7e</p><p>\"We finetune the model on data describing the labels in language, such as by using related words for a given label, dictionary/encyclopedia entries, and short templates.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02239v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02239v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02235v1",
    "title": "AttenWalker: Unsupervised Long-Document Question Answering via Attention-based Graph Walking",
    "latest": "2023-05-04T20:13:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312240025243815",
      "content": "<p>\ud83d\udcdd AttenWalker: Unsupervised Long-Document Question Answering via Attention-Based Graph Walking \ud83d\udcda</p><p>\"AttenWalker is composed of three modules, i) Span Collector, ii) Span Linker and iii) Answer Aggregator, to generate answers with long-range dependency in an unsupervised fashion.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02235v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02235v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.nature.com/articles/d41586-023-01469-0",
    "title": "The sleight-of-hand trick that can simplify scientific computing",
    "latest": "2023-05-04T20:13:00+00:00",
    "last_post": {
      "url": "https://sciencemastodon.com/@jperkel/110293734810783250",
      "content": "<p>Today <span class=\"h-card\"><a href=\"https://mstdn.social/@Nature\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>Nature</span></a></span>, by me: why you might want to do your computing work inside computational environments (e.g., conda, renv). With <span class=\"h-card\"><a href=\"https://genomic.social/@ctb\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>ctb</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.online/@fertiglab\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>fertiglab</span></a></span> <span class=\"h-card\"><a href=\"https://fosstodon.org/@minecr\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>minecr</span></a></span> <span class=\"h-card\"><a href=\"https://mastodon.social/@benmarwick\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>benmarwick</span></a></span> et al.  <a href=\"https://www.nature.com/articles/d41586-023-01469-0\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">nature.com/articles/d41586-023</span><span class=\"invisible\">-01469-0</span></a></p>"
    },
    "people": [
      {
        "url": "https://fosstodon.org/@minecr",
        "display_name": "Mine \u00c7etinkaya-Rundel"
      },
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02215v1",
    "title": "Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages",
    "latest": "2023-05-04T19:53:24+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312161602284500",
      "content": "<p>\ud83d\udcdd Exploring Linguistic Properties of Monolingual BERTs with Typological Classification Among Languages \ud83d\udcda\ud83d\udc7e</p><p>\"A novel perspective that uses Centered kernel Alignment to measure similarity between layers of different BERT models trained on different languages, and then compare this similarity to the similarity of the linguistic structure of different languages.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02215v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02215v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02176v1",
    "title": "https://arxiv.org/abs/2305.02176v1",
    "latest": "2023-05-04T19:33:26+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312083048198656",
      "content": "<p>\ud83d\udcdd Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity \ud83d\udcda</p><p>\"A stratified mixture of experts (SMoE) model assigns different numbers of experts to tokens based on their complexity, which enables it to be more parameter efficient than previous mixture-of-experts architectures.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/fe1ixxu/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/fe1ixxu/</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02176v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02176v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02170v1",
    "title": "A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus",
    "latest": "2023-05-04T19:13:24+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110312004279285100",
      "content": "<p>\ud83d\udcdd A Statistical Exploration of Text Partition Into Constituents: The Case of the Priestly Source in the Books of Genesis and Exodus \ud83d\udcda</p><p>\"Presents a pipeline for a statistical textual exploration, offering a stylometry-based explanation and statistical validation of a hypothesized partition of a text (Fig 1).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02170v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02170v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02151v1",
    "title": "Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space",
    "latest": "2023-05-04T18:33:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311846788797698",
      "content": "<p>\ud83d\udcdd Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"Shows evidence that language-specific characteristics have a measurable impact on both representation spaces and cross-lingual transfer performance of multilingual language models (MLLMs), especially for more linguistically distant language pairs.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02151v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02151v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2304.15004",
    "title": "Are Emergent Abilities of Large Language Models a Mirage?",
    "latest": "2023-05-04T18:33:08+00:00",
    "last_post": {
      "url": "https://fediscience.org/@UlrikeHahn/110310857610802064",
      "content": "<p><a href=\"https://fediscience.org/tags/LLMs\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LLMs</span></a> <a href=\"https://fediscience.org/tags/NewPreprintThread\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>NewPreprintThread</span></a> <a href=\"https://fediscience.org/tags/neuroscience\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>neuroscience</span></a> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/cogsci\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>cogsci</span></a></span> <span class=\"h-card\"><a href=\"https://a.gup.pe/u/philosophy\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>philosophy</span></a></span> </p><p>1/n</p><p>Really interesting new preprint on emergence in LLMs. It raises a whole number of interesting issues, so some initial, first thoughts in the hope of prompting more discussion.</p><p>I also suspect this paper will generate a fair bit of confusion due to the central notion of 'emergence'</p><p>First off, the paper is looking at the issue of *how model capabilities develop as a function of model size.*</p><p><a href=\"https://arxiv.org/abs/2304.15004\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2304.15004</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://sigmoid.social/@aran",
        "display_name": "Aran Komatsuzaki"
      },
      {
        "url": "https://die-partei.social/@hackernews",
        "display_name": "Hackernews"
      },
      {
        "url": "https://qoto.org/@mapto",
        "display_name": "mapto"
      },
      {
        "url": "https://sigmoid.social/@troos",
        "display_name": "Teemu Roos"
      },
      {
        "url": "https://sigmoid.social/@rich",
        "display_name": "Rich Tong \u2764\ufe0f\ud83c\udf93"
      },
      {
        "url": "https://fediscience.org/@UlrichJunker",
        "display_name": "Ulrich Junker"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02118v1",
    "title": "https://arxiv.org/abs/2305.02118v1",
    "latest": "2023-05-04T18:23:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311807483100241",
      "content": "<p>\ud83d\udcdd Pay More Attention to Relation Exploration for Knowledge Base Question Answering \ud83d\udcda</p><p>\"Proposes a novel framework RE-KBQA that utilizes relations in the knowledge base to enhance entity representation and introduce additional supervision for knowledge base question answering task with three aspects.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/yongcaoplus/RE-KBQA\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/yongcaoplus/RE-KBQA</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02118v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02118v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02105v1",
    "title": "GPT-RE: In-context Learning for Relation Extraction using Large Language Models",
    "latest": "2023-05-04T18:03:23+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311728994688241",
      "content": "<p>\ud83d\udcdd GPT-RE: In-Context Learning for Relation Extraction Using Large Language Models \ud83d\udcda</p><p>\"GPT-RE leverages task-specific entity representations and reasoning logic to address the two major shortcomings of LLMs in RE: (1) low relevance regarding entity and relation in retrieved demonstrations for in-context learning; and (2) the strong inclination to wrongly classify NULL examples into other pre-defined labels.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02105v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02105v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://academic.oup.com/proteincell/advance-article/doi/10.1093/procel/pwad024/7147618",
    "title": "best practice for microbiome analysis using R",
    "latest": "2023-05-04T17:35:07+00:00",
    "last_post": {
      "url": "https://mastodon.online/@moorejh/110310716968594800",
      "content": "<p>A review of 324 common R packages for microbiome analysis <a href=\"https://academic.oup.com/proteincell/advance-article/doi/10.1093/procel/pwad024/7147618\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">academic.oup.com/proteincell/a</span><span class=\"invisible\">dvance-article/doi/10.1093/procel/pwad024/7147618</span></a> <a href=\"https://mastodon.online/tags/microbiome\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>microbiome</span></a> <a href=\"https://mastodon.online/tags/rstats\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>rstats</span></a> <a href=\"https://mastodon.online/tags/bioinformatics\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>bioinformatics</span></a></p>"
    },
    "people": [
      {
        "url": "https://ecoevo.social/@naupaka",
        "display_name": "Naupaka Zimmerman"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02101v1",
    "title": "What makes a good pause? Investigating the turn-holding effects of fillers",
    "latest": "2023-05-04T17:33:18+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311610707513047",
      "content": "<p>\ud83d\udcdd What Makes a Good Pause? Investigating the Turn-Holding Effects of Fillers \ud83d\udcda</p><p>\"Show that, while filled pauses do indeed have a turn holding effect, it is perhaps not as strong as could be expected, probably due to the redundancy of other cues.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02101v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02101v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.02036v1",
    "title": "Response-conditioned Turn-taking Prediction",
    "latest": "2023-05-04T17:13:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110311532203334152",
      "content": "<p>\ud83d\udcdd Response-Conditioned Turn-Taking Prediction \ud83d\udcda\ud83e\udde0</p><p>\"An extension of the TurnGPT model with a next-speaker prediction task, which conditions the end-of-turn prediction on both conversation history and what the next speaker wants to say.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.02036v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.02036v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://www.tandfonline.com/doi/full/10.1080/13530194.2020.1750290",
    "title": "Beirut on the stage: the Great War in melodrama",
    "latest": "2023-05-04T17:13:06+00:00",
    "last_post": {
      "url": "https://hcommons.social/@jcpeyssard/110311531241738223",
      "content": "<p>Beirut on the stage: the Great War in melodrama: British Journal of Middle Eastern Studies: Vol 48, No 3<br><a href=\"https://www.tandfonline.com/doi/full/10.1080/13530194.2020.1750290\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://www.</span><span class=\"ellipsis\">tandfonline.com/doi/full/10.10</span><span class=\"invisible\">80/13530194.2020.1750290</span></a><br>@lebanon <a href=\"https://hcommons.social/tags/lebanon\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>lebanon</span></a></p>"
    },
    "people": [
      {
        "url": "https://hcommons.social/@jcpeyssard",
        "display_name": "Jean-Christophe Peyssard"
      }
    ]
  },
  {
    "link": "https://doi.org/10.1177/17499755231160692",
    "title": "doi.org/10.1177/17499755231160...",
    "latest": "2023-05-04T17:12:30+00:00",
    "last_post": {
      "url": "https://sciences.social/@Giselinde/110311325822219799",
      "content": "<p>New paper alert... <br>To celebrate a successful move to the sciences.social server (surprisingly easy)  I would like to share with you: </p><p>Fashion as \u2018Force for Change\u2019? How Ideologization Reshapes the Work of Intermediaries in the Legitimation of Culture</p><p>With Luuc Brans: <span class=\"h-card\"><a href=\"https://mastodon.social/@luuc\" class=\"u-url mention\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">@<span>luuc</span></a></span> </p><p>In Cultural Sociology: <br><a href=\"https://doi.org/10.1177/17499755231160692\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">doi.org/10.1177/17499755231160</span><span class=\"invisible\">692</span></a></p>"
    },
    "people": [
      {
        "url": "https://fediscience.org/@dustinstoltz",
        "display_name": "D\u1d1cs\u1d1b\u026a\u0274 S\u1d1b\u1d0f\u029f\u1d1b\u1d22 :tardis:"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01778v1",
    "title": "https://arxiv.org/abs/2305.01778v1",
    "latest": "2023-05-04T09:43:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309762776034839",
      "content": "<p>\ud83d\udcdd SLTUNET: A Simple Unified Model for Sign Language Translation \ud83d\udcda\ud83d\udd2d</p><p>\"SLTUNET is a simple unified neural model which consists of a shared encoder and task-specific decoders, such as a sign-to-gloss decoder, a gloss-to-text decoder and a sign-to-text decoder.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/CV\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CV</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/bzhangGo/sltunet\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/bzhangGo/sltunet</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01778v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01778v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01764v1",
    "title": "https://arxiv.org/abs/2305.01764v1",
    "latest": "2023-05-04T09:13:21+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309644794873110",
      "content": "<p>\ud83d\udcdd Psychologically-Inspired Causal Prompts \ud83d\udcda\ud83d\udc7e\ud83e\udde0</p><p>\"We take sentiment classifier as an example, and explore the causal relation between the review sentence (X) and sentimental label (Y).\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a> <a href=\"https://creative.ai/tags/LG\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>LG</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/cogito233/psych-causal-prompt\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"ellipsis\">github.com/cogito233/psych-cau</span><span class=\"invisible\">sal-prompt</span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01764v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01764v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "https://arxiv.org/abs/2305.01750v1",
    "title": "https://arxiv.org/abs/2305.01750v1",
    "latest": "2023-05-04T08:23:22+00:00",
    "last_post": {
      "url": "https://creative.ai/@arxiv_cl/110309448227226842",
      "content": "<p>\ud83d\udcdd Few-Shot in-Context Learning for Knowledge Base Question Answering \ud83d\udcda\ud83d\udc7e</p><p>\"KB-BINDER first leverages large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations, and then grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching.\" [gal30b+] \ud83e\udd16 <a href=\"https://creative.ai/tags/CL\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>CL</span></a> <a href=\"https://creative.ai/tags/AI\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>AI</span></a></p><p>\u2699\ufe0f <a href=\"https://github.com/castorini/pyserini\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">github.com/castorini/pyserini</span><span class=\"invisible\"></span></a><br>\ud83d\udd17 <a href=\"https://arxiv.org/abs/2305.01750v1\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">https://</span><span class=\"\">arxiv.org/abs/2305.01750v1</span><span class=\"invisible\"></span></a> <a href=\"https://creative.ai/tags/arxiv\" class=\"mention hashtag\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">#<span>arxiv</span></a></p>"
    },
    "people": [
      {
        "url": "https://creative.ai/@arxiv_cl",
        "display_name": "arXiv Comp. Linguistics\ud83d\udcda"
      }
    ]
  },
  {
    "link": "http://osf.io/nkj3x/",
    "title": "http://osf.io/nkj3x/",
    "latest": "2023-05-04T08:16:48+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309422425531151",
      "content": "<p>Does Lunar Cartography Do the Work of Capitalism? <a href=\"http://osf.io/nkj3x/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/nkj3x/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  },
  {
    "link": "http://osf.io/bn42s/",
    "title": "http://osf.io/bn42s/",
    "latest": "2023-05-04T08:16:48+00:00",
    "last_post": {
      "url": "https://botsin.space/@SocArXivBot/110309422447288777",
      "content": "<p>Sustainable social housing retrofit? Circular economy and tenant trade-offs <a href=\"http://osf.io/bn42s/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><span class=\"invisible\">http://</span><span class=\"\">osf.io/bn42s/</span><span class=\"invisible\"></span></a></p>"
    },
    "people": [
      {
        "url": "https://botsin.space/@SocArXivBot",
        "display_name": "SocArXiv"
      }
    ]
  }
]